head	1.33;
access;
symbols
	Browse-2_16:1.33
	Browse-2_15:1.33
	Browse-2_14:1.33
	Browse-2_13:1.33
	Browse-2_12:1.33
	Browse-2_11:1.33
	Browse-2_10:1.33
	Browse-2_09:1.33
	ahodgkin_208_i4_2:1.32
	ahodgkin_208_i4:1.30
	ahodgkin_208_i3:1.30
	ahodgkin_208_i2:1.30
	ahodgkin_208_i1:1.30
	ahodgkin_207release:1.28
	ahodgkin_206release:1.25
	ahodgkin_205release:1.24
	ahodgkin_204release:1.24
	ahodgkin_202release:1.23
	ahodgkin_201release:1.22
	ahodgkin_200release:1.22
	ahodgkin_133beta:1.22
	ahodgkin_132beta:1.22
	ahodgkin_131beta:1.21
	ahodgkin_130beta:1.20
	ahodgkin_129:1.19
	ahodgkin_128beta:1.16
	ahodgkin_128alpha:1.16
	ahodgkin_127beta2:1.14
	ahodgkin_127beta:1.14
	ahodgkin_126beta:1.13
	ahodgkin_AW97patch:1.13
	ahodgkin_AW97:1.13;
locks; strict;
comment	@# @;


1.33
date	2005.04.26.09.42.35;	author ahodgkin;	state Exp;
branches;
next	1.32;

1.32
date	2000.11.14.08.45.08;	author ahodgkin;	state Exp;
branches;
next	1.31;

1.31
date	2000.05.31.15.58.50;	author ahodgkin;	state Exp;
branches;
next	1.30;

1.30
date	99.09.02.13.10.36;	author ahodgkin;	state Exp;
branches;
next	1.29;

1.29
date	99.03.30.15.52.06;	author ahodgkin;	state Exp;
branches;
next	1.28;

1.28
date	98.10.06.09.28.57;	author ahodgkin;	state Exp;
branches;
next	1.27;

1.27
date	98.09.23.13.18.16;	author ahodgkin;	state Exp;
branches;
next	1.26;

1.26
date	98.09.07.11.47.04;	author ahodgkin;	state Exp;
branches;
next	1.25;

1.25
date	98.07.09.10.27.29;	author ahodgkin;	state Exp;
branches;
next	1.24;

1.24
date	98.04.16.08.14.25;	author ahodgkin;	state Exp;
branches;
next	1.23;

1.23
date	98.03.20.12.13.01;	author ahodgkin;	state Exp;
branches;
next	1.22;

1.22
date	98.02.06.13.55.31;	author ahodgkin;	state Exp;
branches;
next	1.21;

1.21
date	98.01.31.10.55.41;	author ahodgkin;	state Exp;
branches;
next	1.20;

1.20
date	97.12.18.10.07.11;	author ahodgkin;	state Exp;
branches;
next	1.19;

1.19
date	97.12.12.17.12.30;	author ahodgkin;	state Exp;
branches;
next	1.18;

1.18
date	97.12.12.14.35.08;	author ahodgkin;	state Exp;
branches;
next	1.17;

1.17
date	97.12.12.11.18.08;	author ahodgkin;	state Exp;
branches;
next	1.16;

1.16
date	97.12.02.16.14.07;	author ahodgkin;	state Exp;
branches;
next	1.15;

1.15
date	97.11.26.17.11.16;	author ahodgkin;	state Exp;
branches;
next	1.14;

1.14
date	97.11.19.10.29.16;	author ahodgkin;	state Exp;
branches;
next	1.13;

1.13
date	97.10.13.07.07.04;	author ahodgkin;	state Exp;
branches;
next	1.12;

1.12
date	97.10.05.17.16.26;	author ahodgkin;	state Exp;
branches;
next	1.11;

1.11
date	97.10.03.09.19.06;	author ahodgkin;	state Exp;
branches;
next	1.10;

1.10
date	97.09.29.11.24.17;	author dbrown;	state Exp;
branches;
next	1.9;

1.9
date	97.09.22.07.43.27;	author ahodgkin;	state Exp;
branches;
next	1.8;

1.8
date	97.09.09.14.13.23;	author ahodgkin;	state Exp;
branches;
next	1.7;

1.7
date	97.09.03.12.36.12;	author ahodgkin;	state Exp;
branches;
next	1.6;

1.6
date	97.09.02.15.46.07;	author ahodgkin;	state Exp;
branches;
next	1.5;

1.5
date	97.08.31.18.38.24;	author ahodgkin;	state Exp;
branches;
next	1.4;

1.4
date	97.08.28.16.08.09;	author ahodgkin;	state Exp;
branches;
next	1.3;

1.3
date	97.08.18.09.24.08;	author ahodgkin;	state Exp;
branches;
next	1.2;

1.2
date	97.08.08.16.38.57;	author ahodgkin;	state Exp;
branches;
next	1.1;

1.1
date	97.07.18.15.29.11;	author blaughto;	state Exp;
branches;
next	;


desc
@@


1.33
log
@  Huge pile of changes bringing relatively ancient sources up to date.
Detail:
  This check-in includes Phoenix version 2.11 (26-Apr-2005); only the
  debug and JavaScript builds of Phoenix have been tested and resources
  will definitely be out of date for other versions. The various "!..."
  scripts have been updated to require a minimum of 2MB with no maximum
  limit for building, as CC 5.60 is quite RAM hungry.
Admin:
  Phoenix 2.11 JS builds OK, works reasonably well. Many outstanding
  issues of course, as this is a very outdated browser now.

Version 2.09. Tagged as 'Browse-2_09'
@
text
@/* Copyright 1997 Acorn Computers Ltd
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**************************************************************/
/* File:    URLutils.c                                        */
/*          (C) 2000 Pace Micro Technology PLC                */
/*          All rights reserved                               */
/*                                                            */
/* Purpose: URL manipulation for the browser.browser.         */
/*                                                            */
/* Author:  A.D.Hodgkinson.                                   */
/*                                                            */
/* History: 06-Feb-1997 (ADH): Created.                       */
/*          23-May-2000 (ADH): 64-wide comments adopted.      */
/**************************************************************/

#include <stdlib.h>
#include <stdio.h>
#include <string.h>

#include <kernel.h>
#include <swis.h>

#include <URI.h>

#include <tboxlibs/wimp.h>
#include <tboxlibs/event.h>

#include "Global.h"
#include "Utils.h"

#include "Fetch.h" /* (Which itself includes URLstat.h) */
#include "Filetypes.h"
#include "Javascript.h"
#include "List.h"
#include "MimeMap.h"
#include "URIfile.h"
#include "URLveneer.h"

#include "URLutils.h"

/* Local definitions */

#define ExtensionMatches(url, len, ext) (len) > strlen(ext) && !strncmp((url) + (len) - strlen(ext), (ext), strlen(ext))

/* Local variables */

/* Pointer to first item in queue of URLs dispatched through */
/* the URI handler (structure defined in URLutils.h)         */

static uri_queue * uri_queue_base = NULL;

/**************************************************************/
/* urlutils_urlsscmp()                                        */
/*                                                            */
/* Compares two URLs, returning 1 if they differ or 0 if they */
/* are the same. Both URLs are converted internally to        */
/* url_descriptions.                                          */
/*                                                            */
/* Parameters: Pointer to a null terminated URL string;       */
/*                                                            */
/*             Pointer to a second null termina- ted URL      */
/*             string.                                        */
/*                                                            */
/* Returns:    0 if the URLs match, else 1.                   */
/**************************************************************/

int urlutils_urlsscmp(const char * url_s1, const char * url_s2)
{
  url_description * url_d1;
  url_description * url_d2;
  int               result;

  /* Sanity check */

  if (!url_s1 && !url_s2) return 0;
  if (!url_s1 || !url_s2) return 1;

  // Awaiting URL module stuff

  url_d1 = urlutils_return_description(url_s1);
  url_d2 = urlutils_return_description(url_s2);

  if (url_d1 && url_d2)
  {
    result = !!strcmp(url_d1->full, url_d2->full);
  }

  /* No memory, no brain. Hey ho. */

  else result = !!strcmp(url_s1, url_s2);

  urlutils_free_description(url_d1);
  urlutils_free_description(url_d2);

  return result;
}

/**************************************************************/
/* urlutils_urldscmp()                                        */
/*                                                            */
/* Compares two URLs, returning 1 if they differ or 0 if they */
/* are the same. The first URL is specified as a              */
/* url_description, the second URL is converted internally.   */
/*                                                            */
/* Parameters: Pointer to a url_description filled in with    */
/*             the URL details;                               */
/*                                                            */
/*             Pointer to a second null termina- ted URL      */
/*             string.                                        */
/*                                                            */
/* Returns:    0 if the URLs match, else 1.                   */
/**************************************************************/

int urlutils_urldscmp(const url_description * url_d, const char * url_s)
{
  url_description * url_d2;
  int               result;

  /* Sanity check */

  if (!url_d)                 return 1;
  if (!url_s && !url_d->full) return 0;
  if (!url_s || !url_d->full) return 1;

  // Awaiting URL module stuff

  url_d2 = urlutils_return_description(url_s);

  if (url_d && url_d2)
  {
    result = !!strcmp(url_d->full, url_d2->full);
  }
  else result = !!strcmp(url_d->full, url_s);

  urlutils_free_description(url_d2);

  return result;
}

/**************************************************************/
/* urlutils_urlddcmp()                                        */
/*                                                            */
/* Compares two URLs, returning 1 if they differ or 0 if they */
/* are the same. Both URLs are specified as url_description   */
/* structures.                                                */
/*                                                            */
/* Parameters: Pointer to a url_description filled in with    */
/*             the URL details;                               */
/*                                                            */
/*             Another url_description pointer, filled in     */
/*             with the details of a second URL.              */
/*                                                            */
/* Returns:    0 if the URLs match, else 1.                   */
/**************************************************************/

int urlutils_urlddcmp(const url_description * url_d1, const url_description * url_d2)
{
  /* Sanity check */

  if (!url_d1 && url_d2)  return 1;
  if (!url_d2 && url_d1)  return 1;
  if (!url_d1 && !url_d2) return 0;

  if (!url_d1->full && !url_d2->full) return 0;
  if (!url_d1->full || !url_d2->full) return 1;

  // Awaiting URL module stuff

  return !!strcmp(url_d1->full, url_d2->full);
}

/**************************************************************/
/* urlutils_return_description()                              */
/*                                                            */
/* Given a URL string, returns a url_description structure    */
/* which contains more accessible details on the URL          */
/* contents.                                                  */
/*                                                            */
/* The block itself and all filled in fields are allocated    */
/* with malloc(), and any additions to the structure should   */
/* be allocated in the same way.                              */
/*                                                            */
/* Parameters: Pointer to a null terminated URL string.       */
/*                                                            */
/* Returns:    Pointer to a url_description structure filled  */
/*             in with details of the string, or NULL if      */
/*             allocation failed.                             */
/**************************************************************/

url_description * urlutils_return_description(const char * url_s)
{
  url_description * new;

  size_t            rlen;
  char *            tlen;
  int               plen;

  if (!url_s || !*url_s) return NULL;

  /* Allocate the structure */

  new = calloc(1, sizeof(url_description));

  if (!new) return NULL;

  /* Find the item lengths */

  if (_swix(URL_ParseURL,
            _INR(0,5),

            URL_ParseURL_LengthInR5,
            URL_ParseURL_Reason_FindLengths,
            url_s,
            NULL,
            new,
            sizeof(url_description) / sizeof(int))) goto urlutils_return_description_free_and_exit;

  /* Expect the canonicalised form at the very least; new->full on */
  /* return from the SWI holds the buffer length required for this */

  if (!new->full) goto urlutils_return_description_free_and_exit;

  /* Allocate a block to hold all of the fields */

  rlen = (int) new->full     +
         (int) new->protocol +
         (int) new->host     +
         (int) new->port     +
         (int) new->user     +
         (int) new->password +
         (int) new->account  +
         (int) new->path     +
         (int) new->query    +
         (int) new->fragment;

  if (!rlen) goto urlutils_return_description_free_and_exit;

  tlen      = (char *) new->full;
  new->full = malloc(rlen);
  if (!new->full) goto urlutils_return_description_free_and_exit;

  tlen     += (int) new->full;

  if (new->protocol) plen = (int) new->protocol, new->protocol = tlen, tlen += plen;
  if (new->host)     plen = (int) new->host,     new->host     = tlen, tlen += plen;
  if (new->port)     plen = (int) new->port,     new->port     = tlen, tlen += plen;

  if (new->user)     plen = (int) new->user,     new->user     = tlen, tlen += plen;
  if (new->password) plen = (int) new->password, new->password = tlen, tlen += plen;
  if (new->account)  plen = (int) new->account,  new->account  = tlen, tlen += plen;

  if (new->path)     plen = (int) new->path,     new->path     = tlen, tlen += plen;

  if (new->query)    plen = (int) new->query,    new->query    = tlen, tlen += plen;
  if (new->fragment) new->fragment = tlen;

  /* Fill in the block */

  if (_swix(URL_ParseURL,
            _INR(0,5),

            URL_ParseURL_LengthInR5,
            URL_ParseURL_Reason_FillBuffers,
            url_s,
            NULL,
            new,
            sizeof(url_description) / sizeof(int))) goto urlutils_return_description_free_and_exit;

  /* Finished */

  return new;

  /* Error condition exit routine */

urlutils_return_description_free_and_exit:

  urlutils_free_description(new);

  return NULL;
}

/**************************************************************/
/* urlutils_free_description()                                */
/*                                                            */
/* Frees a url_description and all memory associated with it. */
/*                                                            */
/* The function expects all filled in fields in the structure */
/* to point to malloced blocks, as this is the way that       */
/* urlutils_return_description allocates it.                  */
/*                                                            */
/* Parameters: Pointer to a url_description structure.        */
/**************************************************************/

void urlutils_free_description(url_description * url_d)
{
  /* Not the most demanding code in the world, really */

  free(url_d->full);
  free(url_d);

  return;
}

/**************************************************************/
/* urlutils_matches_special()                                 */
/*                                                            */
/* Given a URL description and a string with a comma          */
/* separated list of entries describing match parameters,     */
/* return 1 if the URL meets any of the match criteria. The   */
/* match string should be in a writeable buffer and will be   */
/* corrupted on exit. The string consists of:                 */
/*                                                            */
/* 1. An optional hostname; either fully qualified (e.g.      */
/*    'www.acorn.com') or partially if starting with a dot    */
/*    (e.g. .acorn.com' to match any host with a name ending  */
/*    in '.acorn.com').                                       */
/*                                                            */
/* 2. An optional port following the host name, separated by  */
/*    a colon (e.g. 'www:3172'). Note that specifying the     */
/*    default port for whatever fetch protocol is in use will */
/*    never match (e.g. 'www:80' would never match for an     */
/*    HTTP fetch of server 'www') so this is only useful for  */
/*    matching unusual port values.                           */
/*                                                            */
/* 3. An optional path fragment, which is matched against the */
/*    left hand side of the URL (e.g. 'www/this/that' would   */
/*    match any path 'this/that', 'this/that/more',           */
/*    'this/thatandmore.gif', etc.).                          */
/*                                                            */
/* Parameters: Pointer to a url_description filled in with    */
/*             details of the URL to examine;                 */
/*                                                            */
/*             Pointer to a string with the match parameters  */
/*             in it, comma separated if many are needed,     */
/*             which must be in a writeable buffer.           */
/*                                                            */
/* Returns:    1 if there's a match, else 0. The given match  */
/*             string is corrupted.                           */
/**************************************************************/

int urlutils_matches_special(const url_description * d, char * writeable)
{
  if (d && writeable)
  {
    char * at;

    char * host = d->host ? d->host : "";
    char * path = d->path ? d->path : "";
    char * port = d->port ? d->port : "";

    do
    {
      /* Get each comma separated section individually */

      at = strtok(writeable, ","), writeable = NULL;

      if (at)
      {
        char * slash = strchr(at, '/');
        char * colon = strchr(at, ':');

        int    match = 0;

        /* Overwrite key seperator characters with terminators to make */
        /* subsequent comparisons easier                               */

        if (colon) *colon = '\0', colon++;
        if (slash) *slash = '\0', slash++;

        /* Match port and left hand side of path if required */

        if (!colon) match++;
        else if (!utils_strcasecmp(port, colon)) match++;

        if (!slash) match++;
        else if (!utils_strncasecmp(path, slash, strlen(slash))) match++;

        /* Allow no host (so just match by port or path) */

        if (!*at && (colon || slash)) match++;

        /* Otherwise, do host matching */

        else if (*at)
        {
          /* Compare only the right hand side */

          if (*at == '.')
          {
            int hlen   = strlen(host);
            int offset = hlen - strlen(at);

            if (offset >= 0 && !utils_strcasecmp(host + offset, at)) match++;
          }

          /* Compare the whole thing */

          else
          {
            if (!utils_strcasecmp(host, at)) match++;
          }
        }

        /* Did we match it? */

        if (match == 3) return 1;

        /* No, so restore the string so strtok will continue to work */

        if (slash) *(--slash) = '/';
        if (colon) *(--colon) = ':';
      }
    }
    while (at);
  }

  return 0;
}

/**************************************************************/
/* urlutils_match_by_token()                                  */
/*                                                            */
/* Similar to urlutils_matches_special, but has a more        */
/* accessible API. Given a URL and a Choices file token name, */
/* see if the list of specifiers expected to be in the value  */
/* of the Choices file token matches the given URL. Has to    */
/* expand the URL to a url_description and go through the     */
/* List dialogue box lookup routines so this isn't all that   */
/* fast; if there is a series of matches to do on the same    */
/* URL, it would be better to make the url_description        */
/* externally and call urlutils_matches_special directly.     */
/*                                                            */
/* Parameters: Pointer to the URL to check;                   */
/*                                                            */
/*             Pointer to the Choices file token to check     */
/*             against.                                       */
/*                                                            */
/* Returns:    1 if the value of the token from the Choices   */
/*             file leads to a match with the URL. For        */
/*             details on the format, see the Choices file    */
/*             for comments on things like the                */
/*             LOProxyExclusions entry, or see                */
/*             urlutils_matches_special.                      */
/**************************************************************/

int urlutils_match_by_token(const char * url, const char * token)
{
  url_description * d    = NULL;
  char            * list = NULL;
  int               ret  = 0;

  if (!url || !token || !*url || !*token) return 0;

  d = urlutils_return_description(url);

  if (d)
  {
    char * list = list_get_malloc_list_string(token);
    if (list) ret = urlutils_matches_special(d, list);
  }

  if (d) urlutils_free_description(d);
  free(list);

  return ret;
}

/**************************************************************/
/* urlutils_pathname_to_url()                                 */
/*                                                            */
/* Takes a pathname, and turns it into a File URL, if it      */
/* isn't one already. The pathname that you give is altered   */
/* directly, so if you want to remember the path as well as   */
/* the URL, ensure there is a second copy of it in another    */
/* buffer somewhere.                                          */
/*                                                            */
/* Parameters: Pointer to the pathname;                       */
/*                                                            */
/*             Size of the buffer the pathname is stored in.  */
/**************************************************************/

void urlutils_pathname_to_url(char * path, int buffersize)
{
  int    len;
  char * pathdup;

  /* Try to expand the path - if this fails, carry on */
  /* without the expansion.                           */

  pathdup = malloc(strlen(path) + 1);

  if (pathdup)
  {
    unsigned int flags;

    strcpy(pathdup, path);

    /* Expand the path */

    if (
         _swix(OS_GSTrans,
               _INR(0,2) | _OUT(_FLAGS),

               pathdup,
               path,
               buffersize,

               &flags)

         || (flags & _C)
       )
    {
      strcpy(path, pathdup);
    }
    else
    {
      /* Terminate the string at any control code */

      for (len = 0; len < buffersize; len++)
      {
        if (path[len] < 32)
        {
          path[len] = 0;
          break;
        }
      }
    }

    free(pathdup);
  }

  /* Find the length of the File module protocol specifier */

  len = strlen(FileMethod ProtocolSepShort); /* (urlutils.h) */

  /* If the first part of the string doesn't match the FileMethod */
  /* specifier (see URLutils.h) then insert this text and convert */
  /* the rest of the path to a URL.                               */

  if (strncmp(path, FileMethod ProtocolSepShort, len))
  {
    memmove(path + len, path, buffersize - len);
    strncpy(path, FileMethod ProtocolSepShort, len);

    /* Ensure the string is terminated */

    path[buffersize - 1] = 0;

    /* Now translate the pathname part of the URL to a Unix-style */
    /* path scheme.                                               */

    urlutils_translate_pathname(path + len);
  }

  return;
}

/**************************************************************/
/* urlutils_url_to_pathname()                                 */
/*                                                            */
/* Takes a file:// URL, and turns it into a RISC OS pathname, */
/* if it isn't one already. The URL that you give is altered  */
/* directly, so if you want to remember the URL as well as    */
/* the new path, ensure there is a second copy of it in       */
/* another buffer somewhere.                                  */
/*                                                            */
/* Parameters: Pointer to the URL;                            */
/*                                                            */
/*             Size of the buffer the URL is stored in.       */
/**************************************************************/

void urlutils_url_to_pathname(char * url, int buffersize)
{
  url_description * url_d;

  url_d = urlutils_return_description(url);

  /* If this fails, try a more basic approach... */

  if (!url_d)
  {
    int    len;
    char * hash;

    /* Find the length of the File module protocol specifier */

    len = strlen(FileMethod); /* (urlutils.h) */

    /* If the first part of the string doesn't match the FileMethod */
    /* specifier (see URLutils.h) then we can't do anything.        */

    if (!url || strncmp(url, FileMethod, len)) return;

    /* Copy over the file: specifier and any '/'s */

    while (url[len] == '/') len++;

    memmove(url, url + len, buffersize - len);

    /* Strip off any fragment (this bit could fail badly for file */
    /* system specifiers, but in the absence of URL_ParseURL      */
    /* working - 'url_d' is NULL if we reach here - there's not a */
    /* lot of point working very hard to pull out.                */

    hash = strrchr(url, '#');
    if (hash) *hash = 0;
  }

  else
  {
    /* We managed to get a full URL description, so take the */
    /* path component of this.                               */

    strncpy(url, url_d->path, buffersize - 1);
    url[buffersize - 1] = 0;

    urlutils_free_description(url_d);
  }

  /* Convert the path component of the URL back to RISC OS style */

  urlutils_translate_pathname(url);

  return;
}

/**************************************************************/
/* urlutils_translate_pathname()                              */
/*                                                            */
/* Takes a RISC OS-style pathname and turns it into a         */
/* Unix-style pathname, or vice versa.                        */
/*                                                            */
/* The pathname you give is altered directly, so if you want  */
/* to remember the path before translation, ensure there is a */
/* second copy of in another buffer somewhere.                */
/*                                                            */
/* Parameters: Pointer to the pathname.                       */
/**************************************************************/

void urlutils_translate_pathname(char * path)
{
  char * p;

  p = path;

  /* Skip past any filing system separators (e.g. as in the */
  /* colons in 'ADFS::<disc>.<path>').                      */

  while (*p && *p != ':') p++;

  /* Swap '/' for '.' */

  while (*p)
  {
    if      (*p == '/') *p = '.';
    else if (*p == '.') *p = '/';

    p++;
  }

  return;
}

/**************************************************************/
/* urlutils_leafname_from_url()                               */
/*                                                            */
/* Returns a pointer to a string containing a possible        */
/* leafname, based upon the URL passed into the function.     */
/*                                                            */
/* Parameters: Pointer to a URL string;                       */
/*                                                            */
/*             Pointer to a buffer into which to place the    */
/*             leafname (not the same as the URL string);     */
/*                                                            */
/*             Size of the buffer.                            */
/*                                                            */
/* Returns:    Will fill the buffer in with some leafname,    */
/*             even if one could not be worked out from the   */
/*             URL. Returns the buffer pointer for            */
/*             convenience (even though the caller will       */
/*             almost certainly know this).                   */
/*                                                            */
/* Assumes:    Neither pointer may be NULL. The buffer must   */
/*             be at least 2 bytes in size. If either         */
/*             condition is not met, NULL is returned and the */
/*             buffer is left untouched.                      */
/**************************************************************/

char * urlutils_leafname_from_url(char * url, char * leaf, int size)
{
  int l = 0;

  if (!url || !leaf || size < 2) return NULL;

  memset(leaf, 0, size);

  /* l holds the string length if b->urlfdata exists */

  l = (int) strlen(url);

  /* If the string exists and is not null, try to extract */
  /* a leafname from it.                                  */

  if (l)
  {
    /* Set 'e' to point at the last character in the string, */
    /* and we will use 's' to point to the first character   */
    /* after the host name.                                  */

    int e     = l - 1;
    int s     = 0;
    int found = 0;

    /* We want to do the following, bearing in mind that whilst */
    /* a protocol at the start of the URL is assumed, it may be */
    /* separated by nothing more than a colon (not even ':/' or */
    /* '://'). The use of square brackets implies one or more   */
    /* analogous optional terms.                                */
    /*                                                          */
    /* a.b.c/[dir/]name.html  ->  name                          */
    /* a.b.c/dir[/]           ->  dir                           */
    /* a.b.c[/]               ->  Generic                       */
    /* a.b.c/name.txt         ->  name                          */
    /* a.b.c/name.tar.gz      ->  name/tar (as a consequence)   */
    /* a.b.c/name_1.2.1.gz    ->  name/1/2/1 (as a consequence) */
    /* a.b.c/name.html#anc    ->  anc                           */
    /*                                                          */
    /* A slight change to the above behaviour is to only strip  */
    /* filename extensions if there is a defined filetype for   */
    /* that extension. Then, for example, we get the following. */
    /*                                                          */
    /* a.b.c/dir/name.txt     ->  name                          */
    /* a.b.c/dir/name.zip     ->  name                          */
    /* a.b.c/dir/name.01      ->  name/01                       */
    /* a.b.c/dir/name.02      ->  name/02                       */
    /*                                                          */
    /* The tricky part is determining what bit is host name and */
    /* what bit is path; it gets easier after that. First, look */
    /* for a ':'. This will either be a protocol separator, or  */
    /* a port number separator. Trouble is, you need to skip    */
    /* any '/'s after the ':' if it's the first case, so check  */
    /* if any '.'s are passed when looking for the ':'. If so,  */
    /* we're on a port number. The only possible failure case   */
    /* is a URL with no protocol specified and a single word    */
    /* host name with a port number; but then, just about every */
    /* other system will fail as the host name will be taken to */
    /* be the protocol (e.g. 'dylan:8080'). So this isn't a     */
    /* problem, really - we'd return a generic response.        */

    while (s < l && url[s] != ':')
    {
      if (url[s] == '.') found = 1;
      s++;
    }

    /* Did we run out of string? If so, go back to the start; */
    /* we may just have no protocol or port specified.        */

    if (s == l) s = 0;

    /* If we've not found any dots, may need to skip a few slashes;  */
    /* but not more than two, as three slashes (for example) implies */
    /* that no host name is present.                                 */

    if (!found)
    {
      s++; /* Skip past the ':' */

      if (url[s] == '/') s++;
      if (url[s] == '/') s++;

      /* If we ran out of string, must use a generic response */

      if (s == l) goto return_generic;
    }

    /* We're either now on the ':' separating the host name */
    /* and port number, or on the first character after any */
    /* '/'s or the ':' separating the protocol from the     */
    /* host name. In either case, we now search forward for */
    /* a single slash - the separator between host name and */
    /* path.                                                */

    while (s < l && url[s] != '/')
    {
      s++;
    }

    /* Skip past the '/' */

    if (url[s] == '/') s++;

    /* If we're run out string, go for a generic response - */
    /* e.g. 'http://www/' or just 'http://www'.             */

    if (s >= l) goto return_generic;

    /* Otherwise, we can now start searching backwards for a */
    /* usable leafname, knowing that reaching 's' is the     */
    /* exit condition. First, look for anchor names.         */

    if (strrchr(url, '#') > strrchr(url, '/')) /* Want 'a/b#c' -> 'c', but not 'a#b/c' -> 'b/c' */
    {
      while (e > s && url[e] != '#')
      {
        e--;
      }

      /* Step forward past the '#' */

      e++;

      /* If it turns out that the '#' is all that there is after */
      /* the host name, it may be possible to step back and get  */
      /* whatever comes before it; or if we hit 's' in trying,   */
      /* we'll have to return a generic response.                */

      if (e == l)
      {
        e --;

        if (e <= s) goto return_generic;
        else        goto get_directory_name;
      }

      /* Right, copy the string from this point forwards */

      strncpy(leaf, url + e, size - 1);

      /* Finished, so jump to the final stripping routine */

      goto strip_illegal_chars;
    }

    /* Right, if we have a trailing '/' or '#' (from the above code), */
    /* following a directory name, then get that directory name.      */

get_directory_name:

    if (url[e] == '/' || url[e] == '#')
    {
      int chars;

      found = e--;

      /* Find the start point of the name */

      while (e > s && url[e] != '/') e--;

      /* If e is greater than s, we're sitting on the '/' */
      /* found above, so advance past it.                 */

      if (e > s) e++;

      /* Copy the name in */

      chars = found - e;
      if (chars > size - 1) chars = size - 1;
      strncpy(leaf, url + e, chars);

      /* Finished - just need to take care of any illegal characters */

      goto strip_illegal_chars;
    }

    /* Otherwise, continue, looking for a '/'. If a '.' is found on the */
    /* way, remember the offset for the first time it is encountered.   */

    found = 0;

    while (e > s && url[e] != '/')
    {
      if (url[e] == '.' && !found) found = e;
      e--;
    }

    if (url[e] == '/')
    {
      e++;
      if (e >= l) goto return_generic;
    }

    /* We now have 'e' pointing to the start of a leafname */
    /* and possibly 'found' pointing to the start of a     */
    /* filename extension. If the latter is true, check    */
    /* that there is something between the two...          */

    if (found && found <= e) goto return_generic;

    /* Take a copy of as much of the current leafname will fit;  */
    /* we may have to write zero terminators in at this point if */
    /* there is any CGI information to strip.                    */

    strncpy(leaf, url + e, size - 1);

    /* OK, we have a string. If found is NULL, then we don't have a  */
    /* filename extension to strip - there's no more work to do.     */
    /* Otherwise, strip the extension if a filetype is found for it. */

    if (found && (found - e) <= size - 1)
    {
      int chars = found - e;
      int filetype;

      /* Is there a filetype for this extension? And should we actually */
      /* strip it anyway?                                               */

      if (
           choices.strip_extensions &&
           (
             !utils_strcasecmp(leaf + chars, ".cgi") /* Special case '.cgi' - always strip it */
             ||
             (
               !mimemap_extension_to_riscos(leaf + chars, &filetype) &&
               filetype != FileType_DATA
             )
           )
         )
      {
        /* Strip the extension */

        *(leaf + chars) = '\0';
      }
    }

    /* Right, that's the worst of it over...! The strip routine will */
    /* take care of converting '.'s to '/'s, etc., if there are any. */

    goto strip_illegal_chars;

return_generic:

    lookup_token("NoURLleaf:Index",0,0);
    strncpy(leaf, tokens, size - 1);
  }

  /* There was apparently no URL in the buffer, so offer a */
  /* neutral filename of HTMLfile.                         */

  else
  {
    lookup_token("NoURLdata:HTMLfile",0,0); /* Will put the string in the 'tokens' global buffer */
    strncpy(leaf, tokens, size - 1);
  }

strip_illegal_chars:

  /* Scan the leaf for illegal characters */

  l = 0;

  while (leaf[l])
  {
    /* A few we can replace with meaningful alternatives */

    if (leaf[l] == '.')  leaf[l] = '/';
    if (leaf[l] == '\\') leaf[l] = '/';
    if (leaf[l] == '&')  leaf[l] = '+';
    if (leaf[l] == '"')  leaf[l] = '\'';

    /* And the rest, replace with underscores */

    if (
         leaf[l] == '$' ||
         leaf[l] == '%' ||
         leaf[l] == '@@' ||
         leaf[l] == '^' ||
         leaf[l] == ':' ||
         leaf[l] == '#' ||
         leaf[l] == '*' ||
         leaf[l] == '"' ||
         leaf[l] == '|'
       )
       leaf[l] = '_';

    l++;
  }

  /* Finished. */

  return leaf;
}

/**************************************************************/
/* urlutils_host_name_from_url()                              */
/*                                                            */
/* Extracts the host name from a given URL.                   */
/*                                                            */
/* Parameters: Pointer to the URL string;                     */
/*                                                            */
/*             Pointer to a buffer to write the host name     */
/*             into;                                          */
/*                                                            */
/*             Size of the buffer.                            */
/**************************************************************/

void urlutils_host_name_from_url(char * url, char * host, int size)
{
  char * p;

  host[0] = 0;

  /* First look for '//', as in 'http://' */

  p = strstr(url, ProtocolSeparator);

  if (p)
  {
    /* If found, copy everything after that into 'host' */

    p += 2;
    strncpy(host, p, size - 1);
    host[size - 1] = 0;

    /* Now search for a '/', as in 'http://www.acorn/', */
    /* and if found force a terminator there.           */

    p = strchr(host, '/');
    if (p) *p = 0;
  }
}

/**************************************************************/
/* urlutils_filetype_from_url()                               */
/*                                                            */
/* Examines a URL and returns a RISC OS filetype based on the */
/* filename extension in the URL.                             */
/*                                                            */
/* FileType_TEXT is returned if no absolute determination can */
/* be made (e.g. no filename extension!).                     */
/*                                                            */
/* Parameters: Pointer to a null-terminated URL string.       */
/*                                                            */
/* Returns:    A RISC OS filetype.                            */
/**************************************************************/

int urlutils_filetype_from_url(const char * url)
{
  const char * dot;
  int          filetype;

  if (!url || !*url) return NULL;

  dot = strrchr(url, '.');

  if (!dot) return FileType_TEXT;

  if (mimemap_extension_to_riscos(dot, &filetype)) return FileType_TEXT;

  return filetype;

//  /* For now, hard code it. In future, use a mime mapper module. */
//
//  int len;
//
//  if (!url || !*url) return NULL;
//  else len = strlen(url);
//
//  /* Document types */
//
//  if (ExtensionMatches(url, len, ".html"))  return FileType_HTML;
//  if (ExtensionMatches(url, len, ".htm"))   return FileType_HTML;
//  if (ExtensionMatches(url, len, ".txt"))   return FileType_TEXT;
//  if (ExtensionMatches(url, len, ".shtml")) return FileType_HTML;
//  if (ExtensionMatches(url, len, ".shtm"))  return FileType_HTML;
//  if (ExtensionMatches(url, len, ".pdf"))   return FileType_PDF;
//  if (ExtensionMatches(url, len, ".doc"))   return FileType_WORD;
//  if (ExtensionMatches(url, len, ".ps"))    return FileType_PS;
//  if (ExtensionMatches(url, len, ".eps"))   return FileType_PS;
//  if (ExtensionMatches(url, len, ".wri"))   return FileType_DOS;
//  if (ExtensionMatches(url, len, ".xls"))   return FileType_XLS;
//
//  /* Images */
//
//  if (ExtensionMatches(url, len, ".gif"))   return FileType_GIF;
//  if (ExtensionMatches(url, len, ".jpg"))   return FileType_JPEG;
//  if (ExtensionMatches(url, len, ".jpeg"))  return FileType_JPEG;
//  if (ExtensionMatches(url, len, ".tiff"))  return FileType_TIFF;
//  if (ExtensionMatches(url, len, ".tif"))   return FileType_TIFF;
//  if (ExtensionMatches(url, len, ".png"))   return FileType_PNG;
//
//  /* Archives */
//
//  if (ExtensionMatches(url, len, ".zip"))   return FileType_ARC;
//  if (ExtensionMatches(url, len, ".arc"))   return FileType_ARC;
//  if (ExtensionMatches(url, len, ".spk"))   return FileType_ARC;
//  if (ExtensionMatches(url, len, ".arj"))   return FileType_ARC;
//  if (ExtensionMatches(url, len, ".gz"))    return FileType_GZ;
//  if (ExtensionMatches(url, len, ".tar"))   return FileType_ARC;
//  if (ExtensionMatches(url, len, ".zoo"))   return FileType_ARC;
//
//  /* Sounds */
//
//  if (ExtensionMatches(url, len, ".wav"))   return FileType_WAVE;
//  if (ExtensionMatches(url, len, ".arm"))   return FileType_ARMA;
//  if (ExtensionMatches(url, len, ".mod"))   return FileType_MOD;
//
//  /* Movies */
//
//  if (ExtensionMatches(url, len, ".mov"))   return FileType_AVI;
//  if (ExtensionMatches(url, len, ".avi"))   return FileType_AVI;
//  if (ExtensionMatches(url, len, ".qt"))    return FileType_AVI;
//  if (ExtensionMatches(url, len, ".qtvr"))  return FileType_AVI;
//  if (ExtensionMatches(url, len, ".rpl"))   return FileType_ARMO;
//  if (ExtensionMatches(url, len, ".rep"))   return FileType_ARMO;
//
//  /* Miscellaneous */
//
//  if (ExtensionMatches(url, len, ".bin"))   return FileType_DATA;
//  if (ExtensionMatches(url, len, ".dat"))   return FileType_DATA;
//  if (ExtensionMatches(url, len, ".data"))  return FileType_DATA;
//  if (ExtensionMatches(url, len, ".exe"))   return FileType_DOS;
//  if (ExtensionMatches(url, len, ".com"))   return FileType_DOS;
//
//  /* Otherwise, return text */
//
//  return FileType_TEXT;
}

/**************************************************************/
/* urlutils_create_hotlist_url()                              */
/*                                                            */
/* Creates a URL though which a hotlist file may be fetched.  */
/* This is done by looking at a system variable               */
/* '<App>$HotlistURL'. If that isn't set it looks at          */
/* '<App>$HotlistURIFile' which can hold the path of a URI    */
/* file to load. Lastly, it looks at the Choices file token   */
/* 'HotlistPath', where a RISC OS pathname pointing to the    */
/* file should be placed. This will be turned into a URL for  */
/* fetching, so care must be taken over the path used.        */
/*                                                            */
/* Parameters: Pointer to a buffer to place the URL in (not   */
/*             in a flex block!);                             */
/*                                                            */
/*             Size of the buffer.                            */
/**************************************************************/

void urlutils_create_hotlist_url(char * buffer, int size)
{
  _kernel_oserror * e;
  char            * varname;

  /* See if the variable exists. */

  memset(buffer, 0, size);

  /* Equivalent to getenv, but the RISC OS implementation evaluates  */
  /* the system variable as an expression which we don't want; hence */
  /* the direct use of the SWI.                                      */

  varname = lookup_token("_TaskName",1,0);
  strcat(varname, "$HotlistURL");

  e = _swix(OS_ReadVarVal,
            _INR(0,4),

            varname, /* Variable name                      */
            buffer,  /* Buffer                             */
            size,    /* Buffer size, -1 to check it exists */
            0,       /* Name pointer (0 for 1st call)      */
            4);      /* Variable type (4 = literal string) */

  /* First lookup failed, so try the URI file. */

  if (e)
  {
    varname = lookup_token("_TaskName",1,0);
    strcat(varname, "$HotlistURIFile");

    e = _swix(OS_ReadVarVal,
              _INR(0,4),

              varname,
              buffer,
              size,
              0,
              4);

    if (e)
    {
      /* If the above gives an error, the variable doesn't exist; get */
      /* the HotlistPath string from the Messages file instead.       */

      strncpy(buffer, lookup_choice("HotlistPath",1,0), size - 1);
      urlutils_pathname_to_url(buffer, size);
    }
    else
    {
      char path[Limits_OS_Pathname];

      StrNCpy0(path, buffer);
      urlutils_load_uri_file(buffer, size, NULL, 0, path);
    }
  }
}

/**************************************************************/
/* urlutils_create_home_url()                                 */
/*                                                            */
/* Creates a URL though which a home page may be fetched.     */
/* This is done by looking at a system variable               */
/* '<App>$HomeURL'. If that isn't set, it looks at            */
/* '<App>$HomeURIFile', which can  hold the path of a URI     */
/* file to load. Lastly, it looks at the Choices file token   */
/* 'HomePage'.                                                */
/*                                                            */
/* Parameters: Pointer to a buffer to place the URL in (not   */
/*             in a flex block!);                             */
/*                                                            */
/*             Size of the buffer.                            */
/**************************************************************/

void urlutils_create_home_url(char * buffer, int size)
{
  _kernel_oserror * e;
  char            * varname;

  /* See if the variable exists */

  memset(buffer, 0, size);

  /* Equivalent to getenv, but the RISC OS implementation evaluates  */
  /* the system variable as an expression which we don't want; hence */
  /* the direct use of the SWI.                                      */

  varname = lookup_token("_TaskName",1,0);
  strcat(varname, "$HomeURL");

  e = _swix(OS_ReadVarVal,
            _INR(0,4),

            varname, /* Variable name                      */
            buffer,  /* Buffer                             */
            size,    /* Buffer size, -1 to check it exists */
            0,       /* Name pointer (0 for 1st call)      */
            4);      /* Variable type (4 = literal string) */

  /* First lookup failed, so try the URI file. */

  if (e)
  {
    varname = lookup_token("_TaskName",1,0);
    strcat(varname, "$HomeURIFile");

    e = _swix(OS_ReadVarVal,
              _INR(0,4),

              varname,
              buffer,
              size,
              0,
              4);

    if (e)
    {
      /* If the above gives an error, the variable doesn't exist; get */
      /* the HotlistPath string from the global choices structure     */
      /* instead.                                                     */

      strncpy(buffer, choices.home_page, size - 1);
    }
    else
    {
      char path[Limits_OS_Pathname];

      StrNCpy0(path, buffer);
      urlutils_load_uri_file(buffer, size, NULL, 0, path);
    }
  }
}

/**************************************************************/
/* urlutils_fix_url()                                         */
/*                                                            */
/* Takes a URL and 'fixes' it, e.g. appends a '/' character   */
/* to a URL which is missing one. The contents of the buffer  */
/* you give with the URL inside are altered directly, so if   */
/* you want to remember the old URL, ensure there is a second */
/* copy of it in another buffer somewhere.                    */
/*                                                            */
/* Parameters: Pointer to the URL;                            */
/*                                                            */
/*             Size of the buffer the URL is stored in.       */
/*                                                            */
/* Returns:    Pointer to the fixed URL (which at the moment  */
/*             is the buffer that you passed in).             */
/**************************************************************/

char * urlutils_fix_url(char * buffer, int buffersize)
{
  int len,  shl;
  int flen, fshl;
  int glen, gshl;
  int blen, plen;

  plen = strlen(ProtocolSeparator);

  shl  = strlen(HTTPmethod);
  len  = shl + plen;

  fshl = strlen(FTPmethod);
  flen = fshl + plen;

  gshl = strlen(GopherMethod);
  glen = gshl + plen;

  blen = strlen(buffer);

  /* If there's no ':' in the string, insert a protocol type */

  if (
       !strchr(buffer, ':')     &&
       blen + len  < buffersize &&
       blen + flen < buffersize
     )
  {
    /* If the site appears to be an FTP site, insert the FTP protocol */
    /* at the start. Similarly for Gopher; else insert HTTP.          */

    if (!strncmp(buffer, FTPmethod, fshl - 1)) /* -1 as we don't want to compare the ':' */
    {
      memmove(buffer + flen, buffer, buffersize - flen);
      strncpy(buffer, FTPmethod ProtocolSeparator, flen);
    }
    else if (!strncmp(buffer, GopherMethod, gshl - 1))
    {
      memmove(buffer + glen, buffer, buffersize - glen);
      strncpy(buffer, GopherMethod ProtocolSeparator, glen);
    }
    else
    {
      memmove(buffer + len, buffer, buffersize - len);
      strncpy(buffer, HTTPmethod ProtocolSeparator, len);
    }

    buffer[buffersize - 1] = 0;
  }

  /* If there are at least 2 unused bytes in the buffer, and the */
  /* front of the string matches the HTTPMethod specifier (again */
  /* this is defined at the top of this file) then search for a  */
  /* '/' character which isn't part of a '//' sequence. If none  */
  /* is found, append a '/'. This is why 2 bytes free are needed */
  /* - one for the '/', one for the string terminator.           */

  if (strlen(buffer) < buffersize - 2 && !strncmp(buffer, HTTPmethod, shl))
  {
    int i, s = 0;

    for (i = 0;
         !s && buffer[i] && (i < (buffersize - 1));
         i ++)
    {
      /* If we have a '/' but not a '//' sequence, mark this with s = 1 */

      if (buffer[i] == '/' && buffer[i + 1] != '/') s = 1;

      /* If at start of a '//' sequence, skip past it */

      else if (buffer[i] == '/') i++;
    }

    if (!s) strcat(buffer,"/");
  }

  return buffer;
}

/**************************************************************/
/* urlutils_relativise_url()                                  */
/*                                                            */
/* HTMLLib has a call to take a base URL and a relative URL   */
/* and produce a canonical result based on the combination of */
/* the two. This does the same (it is based on the HTMLLib    */
/* code) but doesn't need an HTMLLib memory context to        */
/* operate in - the HTMLLib call is useful when context based */
/* memory allocation is handy.                                */
/*                                                            */
/* Parameters: Pointer to a base URL;                         */
/*                                                            */
/*             Pointer to a relative URL.                     */
/*                                                            */
/* Returns:    Pointer to a malloc'd URL (so it must be       */
/*             eventually free'd by the caller) which is the  */
/*             canonical result of combining the base and     */
/*             relative URLs.                                 */
/**************************************************************/

char * urlutils_relativise_url(const char * base, const char * link)
{
  _kernel_oserror * e;
  char            * ptr;
  int               blen;
  char            * ret = NULL;

  if (link == NULL) return NULL;

  if (base == NULL)
  {
    ret = utils_strdup(link);
    return ret;
  }

  /* Strip preceeding spaces */

  while (*link == ' ') link++;

  /* Cope with empty link URLs */

  if (*link == '\0') return utils_strdup(base);

  /* Otherwise, just go for it... */

  if (!base) base = "";

  blen = strlen(base) + 4 + (link ? strlen(link) : 0);
  ptr  = malloc(blen);

  if (ptr == NULL) return NULL;

  e = _swix(URL_ParseURL,
            _INR(0,5),

            0,
            URL_ParseURL_Reason_QuickResolve,
            base,
            link,
            ptr,
            blen);

  /* Did the above succeed? */

  if (e != NULL)
  {
    free(ptr);
    return NULL;
  }

  return ptr;
}

/**************************************************************/
/* urlutils_load_uri_file()                                   */
/*                                                            */
/* Version 1.00 files:                                        */
/*                                                            */
/* Loads a URI file. Will take ANT URL files too. The given   */
/* buffer will be filled with a null-terminated URI from the  */
/* file.                                                      */
/*                                                            */
/* The load terminates when the buffer is full except for the */
/* last byte (to allow for a forced terminator), or a control */
/* code is met in the URI file. Note that the buffer is       */
/* initialised to hold null bytes before the URI file is      */
/* opened.                                                    */
/*                                                            */
/* For URI files, you may also try to read a title string.    */
/*                                                            */
/* If there is an error opening the file or the file is       */
/* empty, the contents of the buffer are undefined.           */
/*                                                            */
/* Version 1.01 files:                                        */
/*                                                            */
/* As above, but will also automatically scan past the URL    */
/* looking for command lines and act upon them with no        */
/* external notification. For example, 'open <url>' will lead */
/* to a new window being created.                             */
/*                                                            */
/* Parameters: Pointer to the buffer for the URL;             */
/*                                                            */
/*             Size of the buffer;                            */
/*                                                            */
/*             Pointer to the buffer for the title (if any),  */
/*             or NULL;                                       */
/*                                                            */
/*             Size of the buffer (or zero);                  */
/*                                                            */
/*             Pointer to the pathname of the URI file.       */
/*                                                            */
/* Assumes:    The buffers and path must NOT be the same area */
/*             in memory.                                     */
/**************************************************************/

void urlutils_load_uri_file(char * buffer, size_t size, char * tbuffer, size_t tsize, char * path)
{
  urifile_command * commands;

  if (!size) return;
  memset(buffer, 0, size);

  if (tbuffer && tsize) memset(tbuffer, 0, tsize);

  /* Deal with any actual commands first */

  show_error_ret(urifile_parse_uri_file(path, &commands));

  urifile_execute_command_list(commands, 0);

  /* If the first item is command urifile_none, this holds the data */
  /* we should write into the given buffers.                        */

  if (commands->hdr.type == urifile_none)
  {
    if (commands->data.none.url)              strncpy(buffer,  commands->data.none.url,   size  - 1);
    if (commands->data.none.title && tbuffer) strncpy(tbuffer, commands->data.none.title, tsize - 1);
  }

  /* Finished */

  urifile_free_command_list(commands);
}

/**************************************************************/
/* urlutils_extract_uri()                                     */
/*                                                            */
/* Looks at a URI file loaded into a buffer, and overwrites   */
/* it with the URL contents extracted from the body. Will     */
/* also look for command lines in version 1.01 lines, and act */
/* upon them.                                                 */
/*                                                            */
/* Parameters: Pointer to the buffer holding the URI file;    */
/*                                                            */
/*             Size of the file (the buffer is assumed to be  */
/*             at least this size but not assumed to be       */
/*             larger).                                       */
/*                                                            */
/* Returns:    Contents of the buffer are updated to hold a   */
/*             null terminated URI followed by a null         */
/*             terminated title string, if there is one.      */
/**************************************************************/

void urlutils_extract_uri(char * buffer, size_t file_size)
{
  int copy    = 0;
  int counter = 0;
  int is_uri  = 1;

  if (!buffer || !file_size) return;

  /* Ensure it starts with 'URI' - if not, jump straight to */
  /* URI extraction (assume it's a URL file).               */

  if (strncmp(buffer, "URI", 3))
  {
    is_uri = 0;

    goto urlutils_extract_uri_read_uri;
  }

  /* Point to the first byte after the 'URI' indentifier */

  counter = 3;

  /* Skip white space to find the version number */

urlutils_extract_uri_skip_white_space_1:

  while (
          counter < file_size   &&
          buffer[counter]       &&
          buffer[counter] < ' '
        )
        counter++;

  /* If we find a comment, skip the comment body */

  if (buffer[counter] == '#')
  {
    while (
            counter < file_size    &&
            buffer[counter]        &&
            buffer[counter] >= ' '
          )
          counter++;

    /* Now go back to skip the white space after the comment, and */
    /* thus any other comments that follow.                       */

    if (buffer[counter]) goto urlutils_extract_uri_skip_white_space_1;
  }

  /* Skip the file version */

  while (
          counter < file_size    &&
          buffer[counter]        &&
          buffer[counter] >= ' '
        )
        counter++;

  /* Again, skip white space and comments */

urlutils_extract_uri_skip_white_space_2:

  while (
          counter < file_size   &&
          buffer[counter]       &&
          buffer[counter] < ' '
        )
        counter++;

  if (buffer[counter] == '#')
  {
    while (
            counter < file_size    &&
            buffer[counter]        &&
            buffer[counter] >= ' '
          )
          counter++;

    if (buffer[counter]) goto urlutils_extract_uri_skip_white_space_2;
  }

urlutils_extract_uri_read_uri:

  /* Now we're at the URI. Copy it to the start of the buffer. */

  while (
          counter < file_size    &&
          buffer[counter]        &&
          buffer[counter] >= ' '
        )
        buffer[copy++] = buffer[counter++];

  /* Need to make sure that the string is terminated - if we're */
  /* likely to overflow the buffer, we must overwrite the last  */
  /* char with a terminator. You never know, it could be a non- */
  /* essential last character (e.g. trailing '/').              */

  if (copy && copy < file_size) buffer[copy] = 0, copy++;
  else buffer[copy - 1] = 0;

  /* May have a title to read, too. */

  if (is_uri)
  {
    /* Skip white space and comments once more */

urlutils_extract_uri_skip_white_space_3:

    while (
            counter < file_size   &&
            buffer[counter]       &&
            buffer[counter] < ' '
          )
          counter++;

    if (buffer[counter] == '#')
    {
      while (
              counter < file_size    &&
              buffer[counter]        &&
              buffer[counter] >= ' '
            )
            counter++;

      if (buffer[counter]) goto urlutils_extract_uri_skip_white_space_3;
    }

    /* Now read the title */

    while (
            counter < file_size    &&
            buffer[counter]        &&
            buffer[counter] >= ' '
          )
          buffer[copy++] = buffer[counter++];

    /* Again, ensure things are correctly terminated */

    if (copy && copy < file_size) buffer[copy] = 0;
    else buffer[copy - 1] = 0;
  }

  /* If we've ended up with just a single star, the field is blank */

  if (!strcmp(buffer, "*")) *buffer = 0;

  return;
}

/**************************************************************/
/* urlutils_internal_extra()                                  */
/*                                                            */
/* Returns an offset into a given string at which extra data  */
/* in an internal URL may be found.                           */
/*                                                            */
/* Parameters: Pointer to the URL string.                     */
/*                                                            */
/* Returns:    Offset for the extra data, or 0 if none is     */
/*             found.                                         */
/**************************************************************/

int urlutils_internal_extra(char * iurl)
{
  char * extra;

  if (strncmp(iurl, Internal_URL, Int_URL_Len)) return 0;

  extra = strchr(iurl, ':');

  if (!extra) return 0;
  else extra ++;

  return (int) (extra - iurl);
}

/**************************************************************/
/* urlutils_internal_tail()                                   */
/*                                                            */
/* Returns an offset into a given string at which tail data   */
/* (typically a URL leafname) may be found.                   */
/*                                                            */
/* Parameters: Pointer to the URL string.                     */
/*                                                            */
/* Returns:    Offset for the tail data, or 0 if none is      */
/*             found.                                         */
/**************************************************************/

int urlutils_internal_tail(char * iurl)
{
  char * tail, * extra;
  int    exoff, found = 0;

  exoff = urlutils_internal_extra(iurl);

  if (!exoff) return 0;

  extra = iurl + exoff;
  tail  = iurl + strlen(iurl); /* No '-1' here as tail is decremented early in the while loop below */

  while (tail > extra && !found)
  {
    tail--;
    if (*tail == '/') found = 1;
  }

  if (!found) return 0;
  else tail ++;

  return (int) (tail - iurl);
}

/**************************************************************/
/* urlutils_set_displayed()                                   */
/*                                                            */
/* On the basis of a given internal URL, sets the 'displayed' */
/* field of a given browser_data structure.                   */
/*                                                            */
/* Knows also about JavaScript URLs and sets the 'displayed'  */
/* field for those too.                                       */
/*                                                            */
/* Parameters: Pointer to a browser_data struct that is to be */
/*             altered;                                       */
/*                                                            */
/*             Pointer to the internal URL.                   */
/**************************************************************/

void urlutils_set_displayed(browser_data * b, char * iurl)
{
  if (!strncmp(iurl, Internal_URL, Int_URL_Len))
  {
    if      (!strncmp(iurl + Int_URL_Len, ForExternalHImage, strlen(ForExternalHImage))) b->displayed = Display_External_Image;
    else if (!strncmp(iurl + Int_URL_Len, ForExternalNImage, strlen(ForExternalNImage))) b->displayed = Display_External_Image;
    else if (!strncmp(iurl + Int_URL_Len, ForScrapFile,      strlen(ForScrapFile)))      b->displayed = Display_Scrap_File;
    else if (!strncmp(iurl + Int_URL_Len, ForGoBack,         strlen(ForGoBack)))         b->displayed = Display_Previous_Page;
    else if (!strncmp(iurl + Int_URL_Len, ForGoForward,      strlen(ForGoForward)))      b->displayed = Display_Next_Page;
    else if (!strncmp(iurl + Int_URL_Len, ForGoRecover,      strlen(ForGoRecover)))      b->displayed = Display_Recovered_Page;
    else if (!strncmp(iurl + Int_URL_Len, ForGoReload,       strlen(ForGoReload)))       b->displayed = Display_Reloaded_Page;
    else if (!strncmp(iurl + Int_URL_Len, ForGoHome,         strlen(ForGoHome)))         b->displayed = Display_Home_Page;
    else if (!strncmp(iurl + Int_URL_Len, ForAbout,          strlen(ForAbout)))          b->displayed = Display_About_Page;
    else if (!strncmp(iurl + Int_URL_Len, ForGoToURL,        strlen(ForGoToURL)))        b->displayed = Display_Embedded_URL;
    else if (!strncmp(iurl + Int_URL_Len, ForAnError,        strlen(ForAnError)))        b->displayed = Display_Embedded_Error;

    else b->displayed = Display_Fetched_Page;
  }
  else
  {
    #ifdef JAVASCRIPT

      if (javascript_url(iurl)) b->displayed = Display_JavaScript_Info;
      else                      b->displayed = Display_Fetched_Page;

    #else

      b->displayed = Display_Fetched_Page;

    #endif
  }
}

/**************************************************************/
/* urlutils_check_protocols()                                 */
/*                                                            */
/* Checks a given URL to see if the fetch protocol it         */
/* specifies can be handled.                                  */
/*                                                            */
/* Parameters: Pointer to the URL string.                     */
/*                                                            */
/* Returns:    1 if the URL can be handled (i.e. the protocol */
/*             at the start of the URL matches one that the   */
/*             Messages file says a module which is currently */
/*             running copes with), else 0.                   */
/**************************************************************/

int urlutils_check_protocols(char * url)
{
  int          context = 0;
  const char * scheme;

  if (!url || (url && !*url)) return 0;

  /* Don't forget about JavaScript... */

  #ifdef JAVASCRIPT

    if (javascript_url(url)) return 1;

  #endif

  /* Look for a matching protocol */

  while (context != -1)
  {
    if (
         !url_enumerate_schemes(0, &context, &scheme)    &&
         context != -1                                   &&
         !utils_strncasecmp(scheme, url, strlen(scheme))
       )
       return 1;
  }

  /* If we reach here, no protocol was found. */

  return 0;
}

/**************************************************************/
/* urlutils_cycle_protocol()                                  */
/*                                                            */
/* Given a URL, add in the HTTP protocol specifier if none is */
/* already present, or cycle through those in order of        */
/* appearance in the protocols list in Controls.              */
/*                                                            */
/* Parameters: Pointer to the URL string;                     */
/*                                                            */
/*             Size of the buffer the URL string lies in (the */
/*             string will be updated).                       */
/*                                                            */
/* Returns:    1 if the URL was changed, else 0.              */
/**************************************************************/

int urlutils_cycle_protocol(char * url, int size)
{
  int          context  = 0;
  int          have_any = 0;
  int          have_one = 0;
  int          ulen;
  int          plen;
  const char * scheme;

  if (!url || !size) return 0;

  /* Loop round all protocols */

  do
  {
    if (url_enumerate_schemes(0, &context, &scheme)) return 0;

    if (context != -1)
    {
      have_any = 1;

      if (!utils_strncasecmp(scheme, url, strlen(scheme))) have_one = 1;
    }
  }
  while (context != -1 && !have_one);

  if (!have_any)
  {
    /* If we haven't got any available protocols (!) exit */

    return 0;
  }

  /* Assume a protocol ends with "://", and get rid of any */
  /* existing protocol specifier                           */

  {
    char * separator = strstr(url, "://");

    if (separator)
    {
      separator = separator + 3;
      memmove(url, separator, strlen(url) - (((int) separator) - ((int) url)) + 1);
    }
  }

  /* If we didn't recognise the current protocol, start from */
  /* either the first, or if we have it, HTTP.               */

  if (!have_one)
  {
    context = 0;

    do
    {
      if (url_enumerate_schemes(0, &context, &scheme)) return 0;

      if (
           context != -1 &&
           !utils_strncasecmp(scheme, HTTPmethod, strlen(scheme))
         )
         have_one = 1;
    }
    while (context != -1 && !have_one);

    /* No HTTP? Use the first protocol */

    if (!have_one)
    {
      context = 0;

      if (url_enumerate_schemes(0, &context, &scheme)) return 0;
    }
  }
  else
  {
    /* Find the first/next protocol */

    if (url_enumerate_schemes(0, &context, &scheme)) return 0;

    if (context == -1)
    {
      context = 0;
      if (url_enumerate_schemes(0, &context, &scheme)) return 0;
    }
  }

  /* Insert the new protocol */

  ulen = strlen(url);
  plen = strlen(scheme);

  /* (+3 to account for terminator and "//") */

  if (ulen + plen + 3 > size) return have_one; /* Yikes, if it won't fit we may have thrown out an existing protocol... */

  memmove(url + plen + 2, url, ulen + 1);

  strncpy(url, scheme, plen);
  strncpy(url + plen, "//", 2);

  /* Finished */

  return 1;
}

/**************************************************************/
/* urlutils_dispatch()                                        */
/*                                                            */
/* Puts a given URI into the URI queue and sends it out to    */
/* the URI handler.                                           */
/*                                                            */
/* Parameters: Pointer to a browser_data struct for which the */
/*             URI relates;                                   */
/*                                                            */
/*             Pointer to null-terminated URI string (not in  */
/*             a movable block, so not, e.g., in a flex       */
/*             block);                                        */
/*                                                            */
/*             URI queue flags (see URIutils.h).              */
/*                                                            */
/* Assumes:    That the caller has already made sure the URI  */
/*             handler is present.                            */
/**************************************************************/

_kernel_oserror * urlutils_dispatch(browser_data * b, char * uri, unsigned int flags)
{
  _kernel_oserror * e;
  unsigned int      return_code;
  uri_queue       * entry;

  dprintf(("URIH", "urlutils_dispatch: Called for %p with '%s'\n",b,uri));

  /* Claim memory for the new entry */

  entry = malloc(sizeof(uri_queue));

  /* Moan if the claim failed */

  if (!entry)
  {
    dprintf(("URIH", "urlutils_dispatch: Memory claim for queue entry failed\n"));

    return make_no_fetch_memory_error(15);
  }

  #ifdef TRACE
    malloccount += sizeof(uri_queue);
    dprintf(("CMal", "** malloccount (urlutils_dispatch): \0211%d\0217\n",malloccount));
  #endif

  dprintf(("URIH", "urlutils_dispatch: Claimed queue entry %p\n",entry));

  /* Fill in part of the entry */

  entry->flags = flags;
  entry->b     = b;

  /* If there are no entries, set uri_queue_base to the */
  /* address of this one. Otherwise, point this entry's */
  /* 'next' to the current base item, and point that    */
  /* item's 'prev' back to this entry. Then replace the */
  /* current base entry with this new one.              */

  entry->prev = NULL;

  if (!uri_queue_base) entry->next = NULL;
  else
  {
    entry->next          = uri_queue_base;
    uri_queue_base->prev = entry;
  }

  uri_queue_base = entry;

  /* Now call the URI handler and get a handle to fill in */
  /* the last uri_queue field.                            */

  e = uri_dispatch(URI_Dispatch_Action_Inform,
                   uri,
                   task_handle,

                   &return_code,
                   NULL,
                   &entry->uri_handle);

  if (e)
  {
    dprintf(("URIH", "urlutils_dispatch: Exitting with error\n"));

    return e;
  }

  /* If the request was refused complain */

  if (return_code != URI_Dispatch_Request_Accepted)
  {
    erb.errnum = Utils_Error_Custom_Message;
    StrNCpy0(erb.errmess,
             lookup_token("Refused:Cannot fetch this address as the fetch request was refused by the internal handler.",
                          0,0));

    dprintf(("URIH", "urlutils_dispatch: Exitting with error\n"));

    return &erb;
  }

  /* Otherwise exit successfully */

  dprintf(("URIH", "urlutils_dispatch: Successful\n"));

  return NULL;
}

/**************************************************************/
/* urlutils_remove_from_queue()                               */
/*                                                            */
/* Removes a specified entry from the list of uri_queue       */
/* structures, freeing the memory allocated for it.           */
/*                                                            */
/* Parameters: The URI handle of the entry.                   */
/**************************************************************/

_kernel_oserror * urlutils_remove_from_queue(URI_handle_t uri_handle)
{
  uri_queue * entry = uri_queue_base;

  dprintf(("URIH", "urlutils_remove_from_queue: Called with handle %p\n", uri_handle));

  /* Try to find the entry */

  while (entry && entry->uri_handle != uri_handle) entry = entry->next;

  #ifdef TRACE

    /* Complain if not found */

    if (!entry)
    {
      erb.errnum = Utils_Error_Custom_Normal;
      sprintf(erb.errmess, "Can't find URI handle %p in URI queue", uri_handle);

      dprintf(("URI", "urlutils_remove_from_queue: Exitting with error\n"));

      return &erb;
    }

  #else

    /* Fail silently */

    if (!entry) return NULL;

  #endif

  if (entry->prev) entry->prev->next = entry->next;
  if (entry->next) entry->next->prev = entry->prev;

  if (entry == uri_queue_base) uri_queue_base = entry->next;

  #ifdef TRACE
    malloccount -= sizeof(uri_queue);
    dprintf(("CMal", "** malloccount (uriutils_remove_from_queue): \0212%d\0217\n",malloccount));
  #endif

  dprintf(("URIH", "urlutils_remove_from_queue: Freeing entry %p\n",entry));

  free (entry);

  dprintf(("URIH", "urlutils_remove_from_queue: Successful\n"));

  return NULL;
}

/**************************************************************/
/* urlutils_find_queue_entry()                                */
/*                                                            */
/* Finds an entry in the list of uri_queue structures.        */
/*                                                            */
/* Parameters: The URI handle of the entry.                   */
/*                                                            */
/* Returns:    Pointer to the entry, or NULL if no entry with */
/*             that handle could be found.                    */
/**************************************************************/

uri_queue * urlutils_find_queue_entry(URI_handle_t uri_handle)
{
  uri_queue * entry = uri_queue_base;

  dprintf(("URIH", "urlutils_find_queue_entry: Called with handle %p\n", uri_handle));

  while (entry && entry->uri_handle != uri_handle) entry = entry->next;

  dprintf(("URIH", "urlutils_find_queue_entry: Returning with entry %p\n", entry));

  return entry;
}
@


1.32
log
@  Load balancer pulled apart. DebugLib support. Temporary debug in place.
Detail:
  This is in the middle of some load balancer changes, but I'm checking it
  in as there's a sweeping source code change to use DebugLib. See Global.c
  for full details. Temporary debug code for the load balancer stuff is
  currently held under undocumented area "test".
Admin:
  This build now identifies itself as 2.08 i2-4 and says Pace on the about:
  page. Run for some time with no unexpected problems. Tried a mixture of
  debug levels successfully.

Version 2.08. Not tagged
@
text
@d153 1
a153 1
/* urlutils_urldscmp()                                        */
@


1.31
log
@
64-wide comments adopted throughout. All headers protected against multiple
inclusion. Use of <> for external headers rather than "". For libraries,
<libname/header.h> is used rather than relying on a complex include path,
where appropriate. Move towards using external URILib rather than the local
copy. Phoenix JavaScript build resources are the only up to date set
currently so don't try others; more work still required on Makefile (e.g.
getting the ROM build working, and internationalisation issues).

Version 2.08. Not tagged
@
text
@a39 5
#ifdef TRACE
  #define DEBUGLIB
#endif
#include <debuglib/debuglib.h>

d1996 1
a1996 3
  #ifdef TRACE
    if (tl & (1u<<21)) Printf("urlutils_dispatch: Called for %p with '%s'\n",b,uri);
  #endif
d2006 1
a2006 3
    #ifdef TRACE
      if (tl & (1u<<21)) Printf("urlutils_dispatch: Memory claim for queue entry failed\n",b,uri);
    #endif
d2013 2
a2014 1
    if (tl & (1u<<13)) Printf("** malloccount (urlutils_dispatch): \0211%d\0217\n",malloccount);
d2016 1
a2016 2
    if (tl & (1u<<21)) Printf("urlutils_dispatch: Claimed queue entry %p\n",entry);
  #endif
d2053 1
a2053 3
    #ifdef TRACE
      if (tl & (1u<<21)) Printf("urlutils_dispatch: Exitting with error\n");
    #endif
d2067 1
a2067 3
    #ifdef TRACE
      if (tl & (1u<<21)) Printf("urlutils_dispatch: Exitting with error\n");
    #endif
d2074 1
a2074 3
  #ifdef TRACE
    if (tl & (1u<<21)) Printf("urlutils_dispatch: Successful\n");
  #endif
d2092 1
a2092 3
  #ifdef TRACE
    if (tl & (1u<<21)) Printf("urlutils_remove_from_queue: Called with handle %p\n", uri_handle);
  #endif
d2107 1
a2107 1
      if (tl & (1u<<21)) Printf("urlutils_remove_from_queue: Exitting with error\n");
d2127 2
a2128 1
    if (tl & (1u<<13)) Printf("** malloccount (uriutils_remove_from_queue): \0212%d\0217\n",malloccount);
d2130 1
a2130 2
    if (tl & (1u<<21)) Printf("urlutils_remove_from_queue: Freeing entry %p\n",entry);
  #endif
d2134 1
a2134 3
  #ifdef TRACE
    if (tl & (1u<<21)) Printf("urlutils_remove_from_queue: Successful\n");
  #endif
d2154 1
a2154 3
  #ifdef TRACE
    if (tl & (1u<<21)) Printf("urlutils_find_queue_entry: Called with handle %p\n", uri_handle);
  #endif
d2158 1
a2158 3
  #ifdef TRACE
    if (tl & (1u<<21)) Printf("urlutils_find_queue_entry: Returning with entry %p\n", entry);
  #endif
@


1.30
log
@Long overdue check-in of intermediate browser build, from continued "out
of hours" work. Forgot to add a few files last time too.

List dialogue box handler complete, and exclusion lists implemented
within the main browser code. Full documentation in Choices file.
Save routine knows all about it but is now getting very slow - must
come up with a better scheme; for now, it puts the hourglass on...

StripExtensions option controls auto stripping of filename extensions.

More sensible ancestor / frame selection for keyboard shortcut items
and the save dialogues - having selected a frame won't lock you into
it for F3 and related shortcuts now (input focus in URL writable ->
get ancestor details, input focus in frame -> get frame details). F4
works in frames. F5 now generally present for 'view source' with a
corresponding menu entry in the File menu.

Odd thing in later Res files; there's no action set for Adjust clicks
on the main ToolAction items in the button bar. Very odd. Nothing
appears to be set in v2.07 either, yet adjust-click works. Even
stranger. Anyway, added in the relevant event details (same as for
Select click in all cases) and this fixes the problem.

Background colours in the TABLE tag ignored the "don't print any
backgrounds" Print Style setting. Fixed. Meanwhile, the "black
text with no backgrounds" option wasn't getting this right either;
fixed this also.

Event logging implemented; HTTP errors and script output via.
window.print extension. No internal error output yet.

Faith:Never behaviour extended. If ever a server sends something with
no content type or an unhandleable type, the browser will try and get a
filetype from the URL. If it gets text or HTML, it'll render the file.
Else it'll save it. Hacks around IIS 4's lack of a content type field
in the Marketeye login stuff, and similar other slightly broken sites.
@
text
@d15 12
a26 11
/***************************************************/
/* File   : URLutils.c                             */
/*                                                 */
/* Purpose: URL manipulation for the browser.      */
/*                                                 */
/* Author : Merlyn Kline for Customer browser     */
/*          This source adapted by A.D.Hodgkinson  */
/*          from various original functions        */
/*                                                 */
/* History: 06-Feb-97: Created.                    */
/***************************************************/
d32 2
a33 1
#include "swis.h"
d35 1
a35 1
#include "URI.h" /* URI handler API, in URILib:h */
d37 7
a43 2
#include "wimp.h"
#include "event.h"
a44 1
#include "svcprint.h"
d69 14
a82 15
/*************************************************/
/* urlutils_urlsscmp()                           */
/*                                               */
/* Compares two URLs, returning 1 if they differ */
/* or 0 if they are the same. Both URLs are      */
/* converted internally to url_descriptions.     */
/*                                               */
/* Parameters: Pointer to a null terminated URL  */
/*             string;                           */
/*                                               */
/*             Pointer to a second null termina- */
/*             ted URL string.                   */
/*                                               */
/* Returns:    0 if the URLs match, else 1.      */
/*************************************************/
d115 15
a129 16
/*************************************************/
/* urlutils_urldscmp()                           */
/*                                               */
/* Compares two URLs, returning 1 if they differ */
/* or 0 if they are the same. The first URL is   */
/* specified as a url_description, the second    */
/* URL is converted internally.                  */
/*                                               */
/* Parameters: Pointer to a url_description      */
/*             filled in with the URL details;   */
/*                                               */
/*             Pointer to a second null termina- */
/*             ted URL string.                   */
/*                                               */
/* Returns:    0 if the URLs match, else 1.      */
/*************************************************/
d157 15
a171 16
/*************************************************/
/* urlutils_urldscmp()                           */
/*                                               */
/* Compares two URLs, returning 1 if they differ */
/* or 0 if they are the same. Both URLs are      */
/* specified as url_description structures.      */
/*                                               */
/* Parameters: Pointer to a url_description      */
/*             filled in with the URL details;   */
/*                                               */
/*             Another url_description pointer,  */
/*             filled in with the details of a   */
/*             second URL.                       */
/*                                               */
/* Returns:    0 if the URLs match, else 1.      */
/*************************************************/
d189 17
a205 20
/*************************************************/
/* urlutils_return_description()                 */
/*                                               */
/* Given a URL string, returns a url_description */
/* structure which contains more accessible      */
/* details on the URL contents.                  */
/*                                               */
/* The block itself and all filled in fields are */
/* allocated with malloc(), and any additions to */
/* the structure should be allocated in the same */
/* way.                                          */
/*                                               */
/* Parameters: Pointer to a null terminated URL  */
/*             string.                           */
/*                                               */
/* Returns:    Pointer to a url_description      */
/*             structure filled in with details  */
/*             of the string, or NULL if         */
/*             allocation failed.                */
/*************************************************/
d228 1
a228 1
            0,
d233 1
a233 1
            sizeof(url_description) / 4)) goto urlutils_return_description_free_and_exit;
d279 1
a279 1
            0,
d284 1
a284 1
            sizeof(url_description) / sizeof(char *))) goto urlutils_return_description_free_and_exit;
d299 11
a309 14
/*************************************************/
/* urlutils_free_description()                   */
/*                                               */
/* Frees a url_description and all memory        */
/* associated with it.                           */
/*                                               */
/* The function expects all filled in fields in  */
/* the structure to point to malloced blocks, as */
/* this is the way that                          */
/* urlutils_return_description allocates it.     */
/*                                               */
/* Parameters: Pointer to a url_description      */
/*             structure.                        */
/*************************************************/
d321 36
a356 44
/*************************************************/
/* urlutils_matches_special()                    */
/*                                               */
/* Given a URL description and a string with a   */
/* comma separated list of entries describing    */
/* match parameters, return 1 if the URL meets   */
/* any of the match criteria. The match string   */
/* should be in a writeable buffer and will be   */
/* corrupted on exit. The string consists of:    */
/*                                               */
/* 1. An optional hostname; either fully         */
/*    qualified (e.g. 'wwww.acorn.com') or       */
/*    partially if starting with a dot (e.g.     */
/*    .acorn.com' to match any host with a name  */
/*    ending in '.acorn.com').                   */
/*                                               */
/* 2. An optional port following the host name,  */
/*    separated by a colon (e.g. 'www:3172').    */
/*    Note that specifying the default port for  */
/*    whatever fetch protocol is in use will     */
/*    never match (e.g. 'www:80' would never     */
/*    match for an HTTP fetch of server 'www')   */
/*    so this is only useful for matching        */
/*    unusual port values.                       */
/*                                               */
/* 3. An optional path fragment, which is        */
/*    matched against the left hand side of the  */
/*    URL (e.g. 'www/this/that' would match any  */
/*    path 'this/that', 'this/that/more',        */
/*    'this/thatandmore.gif', etc.).             */
/*                                               */
/* Parameters: Pointer to a url_description      */
/*             filled in with details of the URL */
/*             to examine;                       */
/*                                               */
/*             Pointer to a string with the      */
/*             match parameters in it, comma     */
/*             separated if many are needed,     */
/*             which must be in a writeable      */
/*             buffer.                           */
/*                                               */
/* Returns:    1 if there's a match, else 0. The */
/*             given match string is corrupted.  */
/*************************************************/
d437 25
a461 29
/*************************************************/
/* urlutils_match_by_token()                     */
/*                                               */
/* Similar to urlutils_matches_special, but has  */
/* a more accessible API. Given a URL and a      */
/* Choices file token name, see if the list of   */
/* specifiers expected to be in the value of the */
/* Choices file token matches the given URL. Has */
/* to expand the URL to a url_description and go */
/* through the List dialogue box lookup routines */
/* so this isn't all that fast; if there is a    */
/* series of matches to do on the same URL, it   */
/* would be better to make the url_description   */
/* externally and call urlutils_matches_special  */
/* directly.                                     */
/*                                               */
/* Parameters: Pointer to the URL to check;      */
/*                                               */
/*             Pointer to the Choices file token */
/*             to check against.                 */
/*                                               */
/* Returns:    1 if the value of the token from  */
/*             the Choices file leads to a match */
/*             with the URL. For details on the  */
/*             format, see the Choices file for  */
/*             comments on things like the       */
/*             LOProxyExclusions entry, or see   */
/*             urlutils_matches_special.         */
/*************************************************/
d485 13
a497 15
/*************************************************/
/* urlutils_pathname_to_url()                    */
/*                                               */
/* Takes a pathname, and turns it into a File    */
/* URL, if it isn't one already. The pathname    */
/* that you give is altered directly, so if you  */
/* want to remember the path as well as the URL, */
/* ensure there is a second copy of it in        */
/* another buffer somewhere.                     */
/*                                               */
/* Parameters: Pointer to the pathname;          */
/*                                               */
/*             Size of the buffer the pathname   */
/*             is stored in.                     */
/*************************************************/
d575 13
a587 15
/*************************************************/
/* urlutils_url_to_pathname()                    */
/*                                               */
/* Takes a file:// URL, and turns it into a RISC */
/* OS pathname, if it isn't one already. The URL */
/* that you give is altered directly, so if you  */
/* want to remember the URL as well as the new   */
/* path, ensure there is a second copy of it in  */
/* another buffer somewhere.                     */
/*                                               */
/* Parameters: Pointer to the URL;               */
/*                                               */
/*             Size of the buffer the URL is     */
/*             stored in.                        */
/*************************************************/
d644 12
a655 13
/*************************************************/
/* urlutils_translate_pathname()                 */
/*                                               */
/* Takes a RISC OS-style pathname and turns it   */
/* into a Unix-style pathname, or vice versa.    */
/*                                               */
/* The pathname you give is altered directly, so */
/* if you want to remember the path before       */
/* translation, ensure there is a second copy of */
/* in another buffer somewhere.                  */
/*                                               */
/* Parameters: Pointer to the pathname.          */
/*************************************************/
d681 24
a704 29
/*************************************************/
/* urlutils_leafname_from_url()                  */
/*                                               */
/* Returns a pointer to a string containing a    */
/* possible leafname, based upon the URL passed  */
/* into the function.                            */
/*                                               */
/* Parameters: Pointer to a URL string;          */
/*                                               */
/*             Pointer to a buffer into which to */
/*             place the leafname (not the same  */
/*             as the URL string);               */
/*                                               */
/*             Size of the buffer.               */
/*                                               */
/* Returns:    Will fill the buffer in with some */
/*             leafname, even if one could not   */
/*             be worked out from the URL.       */
/*             Returns the buffer pointer for    */
/*             convenience (even though the      */
/*             caller will almost certainly know */
/*             this).                            */
/*                                               */
/* Assumes:    Neither pointer may be NULL. The  */
/*             buffer must be at least 2 bytes   */
/*             in size. If either condition is   */
/*             not met, NULL is returned and the */
/*             buffer is left untouched.         */
/*************************************************/
d1001 12
a1012 12
/*************************************************/
/* urlutils_host_name_from_url()                 */
/*                                               */
/* Extracts the host name from a given URL.      */
/*                                               */
/* Parameters: Pointer to the URL string;        */
/*                                               */
/*             Pointer to a buffer to write the  */
/*             host name into;                   */
/*                                               */
/*             Size of the buffer.               */
/*************************************************/
d1040 13
a1052 15
/*************************************************/
/* urlutils_filetype_from_url()                  */
/*                                               */
/* Examines a URL and returns a RISC OS filetype */
/* based on the filename extension in the URL.   */
/*                                               */
/* FileType_TEXT is returned if no absolute      */
/* determination can be made (e.g. no filename   */
/* extension!).                                  */
/*                                               */
/* Parameters: Pointer to a null-terminated URL  */
/*             string.                           */
/*                                               */
/* Returns:    A RISC OS filetype.               */
/*************************************************/
d1137 17
a1153 19
/*************************************************/
/* urlutils_create_hotlist_url()                 */
/*                                               */
/* Creates a URL though which a hotlist file may */
/* be fetched. This is done by looking at a      */
/* system variable '<App>$HotlistURL'. If that   */
/* isn't set it looks at '<App>$HotlistURIFile'  */
/* which can hold the path of a URI file to      */
/* load. Lastly, it looks at the Choices file    */
/* token 'HotlistPath', where a RISC OS pathname */
/* pointing to the file should be placed. This   */
/* will be turned into a URL for fetching, so    */
/* care must be taken over the path used.        */
/*                                               */
/* Parameters: Pointer to a buffer to place the  */
/*             URL in (not in a flex block!);    */
/*                                               */
/*             Size of the buffer.               */
/*************************************************/
d1214 15
a1228 16
/*************************************************/
/* urlutils_create_home_url()                    */
/*                                               */
/* Creates a URL though which a home page may be */
/* fetched. This is done by looking at a system  */
/* variable '<App>$HomeURL'. If that isn't set,  */
/* it looks at '<App>$HomeURIFile', which can    */
/* hold the path of a URI file to load. Lastly,  */
/* it looks at the Choices file token            */
/* 'HomePage'.                                   */
/*                                               */
/* Parameters: Pointer to a buffer to place the  */
/*             URL in (not in a flex block!);    */
/*                                               */
/*             Size of the buffer.               */
/*************************************************/
d1289 16
a1304 20
/*************************************************/
/* urlutils_fix_url()                            */
/*                                               */
/* Takes a URL and 'fixes' it, e.g. appends a    */
/* '/' character to a URL which is missing one.  */
/* The contents of the buffer you give with the  */
/* URL inside are altered directly, so if you    */
/* want to remember the old URL, ensure there is */
/* a second copy of it in another buffer         */
/* somewhere.                                    */
/*                                               */
/* Parameters: Pointer to the URL;               */
/*                                               */
/*             Size of the buffer the URL is     */
/*             stored in.                        */
/*                                               */
/* Returns:    Pointer to the fixed URL (which   */
/*             at the moment is the buffer that  */
/*             you passed in).                   */
/*************************************************/
d1386 19
a1404 22
/*************************************************/
/* urlutils_relativise_url()                     */
/*                                               */
/* HTMLLib has a call to take a base URL and a   */
/* relative URL and produce a canonical result   */
/* based on the combination of the two. This     */
/* does the same (it is based on the HTMLLib     */
/* code) but doesn't need an HTMLLib memory      */
/* context to operate in - the HTMLLib call is   */
/* useful when context based memory allocation   */
/* is handy.                                     */
/*                                               */
/* Parameters: Pointer to a base URL;            */
/*                                               */
/*             Pointer to a relative URL.        */
/*                                               */
/* Returns:    Pointer to a malloc'd URL (so it  */
/*             must be eventually free'd by the  */
/*             caller) which is the canonical    */
/*             result of combining the base and  */
/*             relative URLs.                    */
/*************************************************/
d1459 41
a1499 47
/*************************************************/
/* urlutils_load_uri_file()                      */
/*                                               */
/* Version 1.00 files:                           */
/*                                               */
/* Loads a URI file. Will take ANT URL files     */
/* too. The given buffer will be filled with a   */
/* null-terminated URI from the file.            */
/*                                               */
/* The load terminates when the buffer is full   */
/* except for the last byte (to allow for a      */
/* forced terminator), or a control code is met  */
/* in the URI file. Note that the buffer is      */
/* initialised to hold null bytes before the URI */
/* file is opened.                               */
/*                                               */
/* For URI files, you may also try to read a     */
/* title string.                                 */
/*                                               */
/* If there is an error opening the file or the  */
/* file is empty, the contents of the buffer are */
/* undefined.                                    */
/*                                               */
/* Version 1.01 files:                           */
/*                                               */
/* As above, but will also automatically scan    */
/* past the URL looking for command lines and    */
/* act upon them with no external notification.  */
/* For example, 'open <url>' will lead to a new  */
/* window being created.                         */
/*                                               */
/* Parameters: Pointer to the buffer for the     */
/*             URL;                              */
/*                                               */
/*             Size of the buffer;               */
/*                                               */
/*             Pointer to the buffer for the     */
/*             title (if any), or NULL;          */
/*                                               */
/*             Size of the buffer (or zero);     */
/*                                               */
/*             Pointer to the pathname of the    */
/*             URI file.                         */
/*                                               */
/* Assumes:    The buffers and path must NOT be  */
/*             the same area in memory.          */
/*************************************************/
d1530 18
a1547 21
/*************************************************/
/* urlutils_extract_uri()                        */
/*                                               */
/* Looks at a URI file loaded into a buffer, and */
/* overwrites it with the URL contents extracted */
/* from the body. Will also look for command     */
/* lines in version 1.01 lines, and act upon     */
/* them.                                         */
/*                                               */
/* Parameters: Pointer to the buffer holding the */
/*             URI file;                         */
/*                                               */
/*             Size of the file (the buffer is   */
/*             assumed to be at least this size  */
/*             but not assumed to be larger).    */
/*                                               */
/* Returns:    Contents of the buffer are        */
/*             updated to hold a null terminated */
/*             URI followed by a null terminated */
/*             title string, if there is one.    */
/*************************************************/
d1699 11
a1709 12
/*************************************************/
/* urlutils_internal_extra()                     */
/*                                               */
/* Returns an offset into a given string at      */
/* which extra data in an internal URL may be    */
/* found.                                        */
/*                                               */
/* Parameters: Pointer to the URL string.        */
/*                                               */
/* Returns:    Offset for the extra data, or 0   */
/*             if none is found.                 */
/*************************************************/
d1725 11
a1735 12
/*************************************************/
/* urlutils_internal_tail()                      */
/*                                               */
/* Returns an offset into a given string at      */
/* which tail data (typically a URL leafname)    */
/* may be found.                                 */
/*                                               */
/* Parameters: Pointer to the URL string.        */
/*                                               */
/* Returns:    Offset for the tail data, or 0 if */
/*             none is found.                    */
/*************************************************/
d1761 14
a1774 15
/*************************************************/
/* urlutils_set_displayed()                      */
/*                                               */
/* On the basis of a given internal URL, sets    */
/* the 'displayed' field of a given browser_data */
/* structure.                                    */
/*                                               */
/* Knows also about JavaScript URLs and sets the */
/* 'displayed' field for those too.              */
/*                                               */
/* Parameters: Pointer to a browser_data struct  */
/*             that is to be altered;            */
/*                                               */
/*             Pointer to the internal URL.      */
/*************************************************/
d1809 13
a1821 15
/*************************************************/
/* urlutils_check_protocols()                    */
/*                                               */
/* Checks a given URL to see if the fetch        */
/* protocol it specifies can be handled.         */
/*                                               */
/* Parameters: Pointer to the URL string.        */
/*                                               */
/* Returns:    1 if the URL can be handled (i.e. */
/*             the protocol at the start of the  */
/*             URL matches one that the Messages */
/*             file says a module which is       */
/*             currently running copes with),    */
/*             else 0.                           */
/*************************************************/
d1855 14
a1868 16
/*************************************************/
/* urlutils_cycle_protocol()                     */
/*                                               */
/* Given a URL, add in the HTTP protocol         */
/* specifier if none is already present, or      */
/* cycle through those in order of appearance in */
/* the protocols list in Controls.               */
/*                                               */
/* Parameters: Pointer to the URL string;        */
/*                                               */
/*             Size of the buffer the URL string */
/*             lies in (the string will be       */
/*             updated).                         */
/*                                               */
/* Returns:    1 if the URL was changed, else 0. */
/*************************************************/
d1976 18
a1993 18
/*************************************************/
/* urlutils_dispatch()                           */
/*                                               */
/* Puts a given URI into the URI queue and sends */
/* it out to the URI handler.                    */
/*                                               */
/* Parameters: Pointer to a browser_data struct  */
/*             for which the URI relates;        */
/*                                               */
/*             Pointer to null-terminated URI    */
/*             string (not in a movable block,   */
/*             so not, e.g., in a flex block);   */
/*                                               */
/*             URI queue flags (see URIutils.h). */
/*                                               */
/* Assumes:    That the caller has already made  */
/*             sure the URI handler is present.  */
/*************************************************/
d2052 1
a2052 1
  e = uri_dispatch(URI_Dispatch_Inform,
d2071 1
a2071 1
  if (return_code != URI_Dispatch_RequestAccepted)
d2094 8
a2101 9
/*************************************************/
/* urlutils_remove_from_queue()                  */
/*                                               */
/* Removes a specified entry from the list of    */
/* uri_queue structures, freeing the memory      */
/* allocated for it.                             */
/*                                               */
/* Parameters: The URI handle of the entry.      */
/*************************************************/
d2158 10
a2167 12
/*************************************************/
/* urlutils_find_queue_entry()                   */
/*                                               */
/* Finds an entry in the list of uri_queue       */
/* structures.                                   */
/*                                               */
/* Parameters: The URI handle of the entry.      */
/*                                               */
/* Returns:    Pointer to the entry, or NULL if  */
/*             no entry with that handle could   */
/*             be found.                         */
/*************************************************/
@


1.29
log
@Intermediate check-in; building a browser from this gives you something
between 2.07 and 2.08. Only the Phoenix JavaScript resources are fully
up to date.

I *think* these are the changes since the last check-in:

When saved as a Draw file, horizontal rules were plotted one page width
too far to the right (wonder when that started happening?!). Fixed. In
addition, DrawFiles now accepted as OBJECTs - they weren't in the
recognised filetype list before. Doh.

Table size calculator tables_count_table would overestimate the number
of cells where ROWSPAN was present and there were other rows below the
one spanned. Fixed. In certain odd cases (e.g. optimised image exports
as HTML tables (!!) from the Gimp) this can save vast amounts of RAM.

Fixed problem where printing stops in the middle of a document. Redraw
engine pagination code was written in the days where lines couldn't
have gaps between them; they can now. If a gap fell at the bottom of
a page the engine would look down, see no line straddling or touching
the page edge, and assume there was nothing more. This case is now
correctly handled.

Made sure desktop and testbed Browse Res files had up-to-date Encoding
menus (v2.07 Phoenix has different menus from v2.07 Browse by oversight).

URL auto-completion piggy-backed onto manual completion code; any string
without '.', '/' or ':' in it gets run through completion to see if a
more meaningful item can be produced - "www" special cased out though.

New List dialogue box handler, used for proxy exclusions etc.
(incomplete), complete with appropriate Res file objects.
@
text
@d45 1
d47 1
a186 126
/* urlutils_matches_special()                    */
/*                                               */
/* Given a URL description and a string with a   */
/* comma separated list of entries describing    */
/* match parameters, return 1 if the URL meets   */
/* any of the match criteria. The match string   */
/* should be in a writeable buffer and will be   */
/* corrupted on exit. The string consists of:    */
/*                                               */
/* 1. A fully qualified host name without any    */
/*    port number (e.g. "www.acorn.com").        */
/*                                               */
/* 2. A fully qualified host name followed by a  */
/*    "/" and the left hand part of a pathname;  */
/*    e.g. "www.acorn.com/clan" - the full host  */
/*    and the left hand part of the given URL's  */
/*    path is compared with this.                */
/*                                               */
/* 3. A partial host name beginning with '.' -   */
/*    the right hand side is matched. Allows     */
/*    more general domain matches (e.g.          */
/*    ".co.uk").                                 */
/*                                               */
/* So, ".co.uk" matches any protocol and path    */
/* for any host "<xxx>.co.uk". "www.acorn.com"   */
/* matches any protocol and path for host        */
/* "www.acorn.com" only. Finally,                */
/* "www.acorn.com/clan" matches any protocol for */
/* host "www.acorn.com" only, and then will only */
/* match if the path of the URL consists of at   */
/* least "/clan". Note that this would also      */
/* match, say, "/clandestine" too - it's just a  */
/* simple length limited string comparison.      */
/*                                               */
/* Parameters: Pointer to a url_description      */
/*             filled in with details of the URL */
/*             to examine;                       */
/*                                               */
/*             Pointer to a string with the      */
/*             match parameters in it, comma     */
/*             separated if many are needed,     */
/*             which must be in a writeable      */
/*             buffer.                           */
/*                                               */
/* Returns:    1 if there's a match, else 0. The */
/*             given match string is corrupted.  */
/*************************************************/

int urlutils_matches_special(const url_description * d, char * writeable)
{
  if (d && writeable)
  {
    char * at;

    do
    {
      /* Get each comma separated section individually */

      at = strtok(writeable, ","), writeable = NULL;

      if (at)
      {
        /* Compare only the right hand side of the host name if the */
        /* entry starts with a '.' (e.g. ".co.uk").                 */

        if (*at == '.')
        {
          int hlen   = d->host ? strlen(d->host) : 0;
          int offset = hlen - strlen(at);

          if (
               offset >= 0 &&
               d->host     &&
               !utils_strcasecmp(d->host + offset, at)
             )
             return 1;
        }

        /* Compare the whole host if the entry doesn't start with '.'; */
        /* but may include a '/' if we want a partial path match too.  */

        else
        {
          char * slash = strchr(at, '/');

          /* If we don't have a slash, just match the host */

          if (!slash)
          {
            if (
                 d->host &&
                 !utils_strcasecmp(d->host, at)
               )
               return 1;
          }

          /* Otherwise, match the full host, and the left hand side of */
          /* the path.                                                 */

          else
          {
            int len;

            *slash = '\0', slash++;
            len = strlen(slash);

            if (
                 d->host                        &&
                 d->path                        &&
                 !utils_strcasecmp(d->host, at) &&
                 !utils_strncasecmp(d->path, slash, len)
               )
               return 1;

            else *(--slash) = '/';
          }
        }
      }
    }
    while (at);
  }

  return 0;
}

/*************************************************/
d325 176
d947 2
a948 1
      /* Is there a filetype for this extension? */
d951 1
a951 2
           !utils_strcasecmp(leaf + chars, ".cgi") /* Special case '.cgi' - always strip it */
           ||
d953 6
a958 2
             !mimemap_extension_to_riscos(leaf + chars, &filetype) &&
             filetype != FileType_DATA
d1071 4
d1499 2
d1519 8
d1546 1
a1546 5
  FILE * fp;
  int    byte, counter;
  int    type, found;

  /* Warning - heavy use of 'goto's coming up shortly...! */
d1553 1
a1553 15
  /* Does the file exist? */

  if (
       _swix(OS_File,
             _INR(0,1) | _OUT(0) | _OUT(6),

             23, /* Read catalogue info for named, stamped object */
             path,

             &found,
             &type)
     )
     return;

  /* 'found' should be 1 (a file, rather than not found, a directory, etc.). */
d1555 1
a1555 1
  if (found != 1) return;
d1557 1
a1557 1
  /* Open the file */
d1559 2
a1560 1
  fp = fopen(path, "rb");
d1562 1
a1562 1
  if (fp)
d1564 2
a1565 114
    byte = getc(fp);

    /* For URL files, go straight to URL reading - they're just */
    /* a terminated, or unterminated URL in a file.             */

    if (type != FileType_URI) goto urlutils_load_uri_file_read_uri;

    /* If it is a URI file, it must start with 'URI'. */

    if (byte != 'U') goto urlutils_load_uri_file_not_a_uri_file;

    byte = getc(fp);
    if (byte != 'R') goto urlutils_load_uri_file_not_a_uri_file;

    byte = getc(fp);
    if (byte != 'I') goto urlutils_load_uri_file_not_a_uri_file;

    /* Get to first character after the 'I' */

    byte = getc(fp);

    /* Now find the version number - skip white space */

urlutils_load_uri_file_skip_white_space_1:

    while (byte != EOF && byte < ' ') byte = getc(fp);

    /* If we've hit a hash, this is a comment line - terminated by white */
    /* space or end of file.                                             */

    if (byte == '#')
    {
      /* Now want to *find* the white space to skip the comment */

      while (byte != EOF && byte >= ' ') byte = getc(fp);

      /* If we're not at the end of the file, loop back and continue */
      /* skipping white space.                                       */

      if (byte != EOF) goto urlutils_load_uri_file_skip_white_space_1;
    }

    /* By now, we're either at EOF or the start of the first real entry */
    /* after 'URL', which will be the file version. URI file versions   */
    /* are guaranteed backwards compatible, so we can skip this bit.    */

    while (byte != EOF && byte >= ' ') byte = getc(fp);

    /* Now we want to get to the URI, so again, skip white space */
    /* and comment lines. After that, we'll be on the first byte */
    /* of the URI (or end of file, if it's broken).              */

urlutils_load_uri_file_skip_white_space_2:

    while (byte != EOF && byte < ' ') byte = getc(fp);

    if (byte == '#')
    {
      while (byte != EOF && byte >= ' ') byte = getc(fp);

      if (byte != EOF) goto urlutils_load_uri_file_skip_white_space_2;
    }

    /* Load the URI component - assume everything from here up */
    /* to any control chracter or EOF is part of the URI. Note */
    /* that 'byte' already contains the first character.       */

urlutils_load_uri_file_read_uri:

    counter = 0;

    while (byte != EOF && byte >= ' ' && counter < size - 1)
    {
      buffer[counter++] = byte;
      byte              = getc(fp);
    }

    /* If it's a single '*', the URI is not present */

    if (!strcmp(buffer, "*")) *buffer = 0;

    /* We may still have a title to read... */

    if (type == FileType_URI && tbuffer && tsize)
    {
      /* Once more, skip any white space or comments */

urlutils_load_uri_file_skip_white_space_3:

      while (byte != EOF && byte < ' ') byte = getc(fp);

      if (byte == '#')
      {
        while (byte != EOF && byte >= ' ') byte = getc(fp);

        if (byte != EOF) goto urlutils_load_uri_file_skip_white_space_3;
      }

      /* Now read the title */

      counter = 0;

      while (byte != EOF && byte >= ' ' && counter < size - 1)
      {
        tbuffer[counter++] = byte;
        byte               = getc(fp);
      }

      /* If it's a single '*', the URI is not present */

      if (!strcmp(tbuffer, "*")) *tbuffer = 0;
    }

    fclose(fp);
d1568 1
a1568 3
  return;

  /* Error condition exits */
d1570 1
a1570 16
urlutils_load_uri_file_not_a_uri_file:

  /* Not a URI / URL file */

  if (fp) fclose(fp);

  erb.errnum = Utils_Error_Custom_Message;

  StrNCpy0(erb.errmess,
           lookup_token("NotAURI:This is not a valid URI file.",
                        0,
                        0));

  show_error_ret(&erb);

  return;
d1578 3
a1580 1
/* from the body.                                */
@


1.28
log
@Another intermediate version, rather more stable than the last I hope.

Lazy clearing of backgrounds - pages with the same background image or
colour won't be cleared to grey when going from one to the next anymore.

BODY element onLoad script attribute implemented properly (beyond the
Customer hackery).

Images use independent flex blocks for URL and transient fetch data;
greatly improved data throughput in image system as a result. Image
renumbering implemented - speeds up closing of pages / frames with
many images. Image xref is still rather slow though and images with
a 0 width or height specified in the HTML still cause an incorrectly
formatted page to appear.

Have, I think, fixed the "stops anti-aliasing" bug. Noticed that some
background images are not being processed as Fast (e.g. at the
Fibblesnork Lego Guide) - that old problem has reappeared, then.

Background images would cross reference when two pages had the same
background colour set in <body> elements but one was configured to use
document colours and one wasn't (so xref should not occur). Code was
looking at b->background_colour; corrected to call redraw_backcol(b).

Titles were added to the history according to the fetch URL not the
display URL, though the former is more likely to be in the history due
to the code execution order in the fetcher; changed to see whether this
improves upon the rather hit and miss addition of titles.

The 'about:' page now gets entered into the history (makes for much more
sensible behaviour if it is configured as a Home page, for example).
@
text
@d185 126
@


1.27
log
@Another intermediate check-in, resources may not be up to date; items
most likely to be buildable are PhoenixJ and BrowseD. Done because I'm
about to make some rather dodgy changes to code otherwise unchanged
since the Customer browser and I may well have to back them out...

In Handlers.c now set the HFlags_HasBeenVisited bit of a token at the point
it is first clicked on. Means the link returns to a "visited" colour after
the highlight flash immediately. This will persist for as long as the browser
window is kept open on that page, though if the URL doesn't end up making it
into the history for whatever reason it would "unhighlight" on reload; fair
enough, really. The highlight is window-local, so there are no redraw worries
for other open windows with links to the same URL (though other same-URL
links on the same page aren't updated either).

All forms submissions force a reload (principally for eudoramail.com, but
many other sites have similar requirements).

!MkClean and !MkClnAll didn't correctly call the utility to strip Makefile
dependencies. Fixed.

On fetch closedown, fetchpage_preprocess_token could be called on a token
which had already been run through the preprocessor. Now checks the flags
word before proceeding.

Image RAM cache and garbage collection system implemented - see new Choices
file entries CollectAfter, FreeRAMLimit and UnusedImageLimit to get an
overview. This contains groundwork for JavaScript image array support.

More JavaScript support improvements. Any one window object will know its
parent, top, this, etc.; frames array working except for a frameset created
via. multiple documents; opener for something created with window.open is
currently not set and don't know why (property is being created, pointer to
valid object is held, but JS engine returns 'null'. Ho hum) - JSChain won't
work yet, then.
@
text
@d1807 1
a1807 1
/* Urlutils_check_protocols()                    */
@


1.26
log
@Everyone else seems to be checking lots of stuff in lately, so I've
decided to join in. This is an intermediate check-in and so not all
resources etc. will be up to date. You should be able to make Phoenix
and a debug build out of it. As a reminder, to make a JavaScript build:

 * Build JSLib and NSPRLib. Recommend you leave -DUSEMEMLIB in there (as
   used by default) so you can watch it leak into a dynamic area... :-)
   If you do this, you'll need to build MemLib too, of course. If you
   do NOT use MemLib, *undefine JS_USING_MEMLIB in Main.c*!
 * Run !MkClean. This now strips dynamic dependencies from the MakeFile
   automatically, to save you having to do it yourself.
 * Run one of the TaskObey files with the "J" suffix, e.g. !DeskBrwsJ -
   this uses the same .o directory for object files and exports to the
   same position in the Targets directory as the non-JavaScript build,
   but it does produce a unique binary in 'abs' and symbols table in
   'syms'.
 * Sourcing an appropriate !Run (with increased WimpSlot value), !Boot
   and About resource is done automatically.
 * Some, but not all of the !xxxD (debug) TaskObey files will make
   JavaScript versions in passing - check the JSUFFIX value on the Make
   command line parameters in the file.

This'll only work on RISC OS 3.1 due to the use of MemLib.

Here's the change list:

Included MNG icons in sprites files; added Sprites23 for some builds.
Added in ANT URL file icon (b28) derived from URI file icon, because
the Save dialogue can need it.

No, you do *not* need to define the same keyboard shortcuts in each
frame since the ancestor keeps the input focus and we've basically
dropped non-nested Wimp support. Maintaining no less than 4 lists of
identical shortcuts was a pain. Some Res files now only have the
lists in the main browser window and button bar objects (these two
are both required still).

Ursula build Markers button arrangement changed from 1x3 horizontal to
2x2 tilted, as in Phoenix, by popular demand.

Couple of hotlist bugs fixed; dragging an item and deleteing it with
Ctrl+X didn't terminate the drag, and deleteting an item underneath a
menu opened for it didn't close the menu.

'SendReferer' option added to all Choices files, all set to 'always'.
Put just beneath 'Clone' as it refers to header items, though really,
both Clone and SendReferer should probably be in the "Fetch controls"
section rather than "Multiuser environments and proxying"! Front-end
control of this is available.

In image_export_original, save_save_source, save_transfer_source and
save_save_object, flex_set_budge(0) was called to lock the heap but the
return value wasn't stored. flex_set_budge(1) was then used to unlock
the heap. All calls now remember and restore the old value, which is
both safer in case one calls another and allows the flex_set_budge
call in Main.c to have an application-wide meaning, as intended.

Some restructuring to the data load and RAM transfer sections of
Protocols.c; remote hotlist builds wouldn't allow files to be loaded
to browser windows before, and can now drop URL, URI or text files to
the Open URL dialogue.

New option "MinimumFontSize", lets the 'size' attribute of the 'font'
element be overridden. Default value is 1, to allow the full range of
values for the attribute. Setting to 7, for example, would give font
size 7 text at all times. Another new option, "ToggleOnXOnly", to
make Toggle Size only extend the window vertically (with Ctrl then
being used to toggle to genuine full size, rather than vice versa).
All Choices files updated to hold both of these options; only the
first has front-end control available (see debug build Res file).

JavaScript Document object exists; frames array etc. working. Can now
just about use "http://www.acorn.com/~ahodgkin/jschain/" but it does
abort after a bit - problems with frames again, I suspect. Is is pretty
slow, too. Can now press Escape to terminate a script.

Main.c erroneously referred to Controls file entry "StopWebServe" as
"StopWebProxy". Fixed.

Keyboard shortcuts to raise SaveFile are now possible in a general sense;
the code before was in the ToBeShown handler and just checked for a parent
component of -1. It then assumed "save frame HTML source". Now there's the
savefile_raise_from_shortcut function, which together with the seven new
event codes in SaveFile.h allows saving of HTML source and frame location,
export of links, images, backgrounds and the page as text or draw, to all
be invoked by keyboard shortcuts. Some Res files have some of these defined.

In reformat_check_height, the first check to see if setpara should be set
references a field in tpLast without checking if it is NULL. Whilst the
'line > 0' check should mean that tpLast wasn't NULL anyway, a direct
call to the function from outside of the reformatter might have tripped
up on this - the check for tpLast != NULL is now made.

Adjust-click on close icon in window showing file: URL attempts to open
the parent Filer window.

Reformatter used to try and find a selectable token if keyboard control
was enabled in a really stupid place - could make reformatting become
very slow if no selectables were present, especially if the page had a
few tables on it. Preprocessor now does this (since it goes through all
of the tokens anyway), the reformatter just doing a last check to ensure
no frames have obscured the selectable and if so, it tries to move it.
Done in the reformatter as generating a line array implies the data really
is visible.

Ctrl+Tab URL completion now builds a full list of matches from the hotlist
and history and can cycle through them (Ctrl+Shift+Tab stepping backwards).

Will give a real error rather than just "Data Abort" if it goes wrong
now. Someone somewhere is setting bit 30 of the error which confused
the replacement signal handler. Flag bits are now masked off (as they
should've been to start with).
@
text
@d1235 76
@


1.25
log
@Check-in of Browse v2.06; using very small log file to try and avoid
CVS crashing. Some of the Resources may well be out of date due to CVS
locks being in place after earlier server-end core dumps, which I can't
remove myself.

I'll try and check one file in at the end with the full change log so
people know what's happened (it's reached about 16K...) - I'll make
that the TaskObey file '!All' in the top level directory. So for the
full log, look for the changes on this file.
@
text
@d1731 1
a1731 1
/* urlutils_check_protocols()                    */
d1752 8
@


1.24
log
@All !Run[D], Choices, Messages, Controls and Res files are up to date.

RefoKeep and RefoHold options added to, respectively, try and maintain
the line at the top of the visible area when reformatting, and not shrink
the vertical extent at the start of a reformat to try and avoid flicker
to the top of the page and back down again when RefoKeep is on. Choices
front-end implemented, which also allows RefoWait and RefoTime to be set.
Unfortunately for various reasons this doesn't help the page jumping when
unsized images come in (but RefoHold can improve matters...) - roll on
the image history.

DragToScroll and NoScrollBars options added for frames; included new
pointer type, Mouse_Shape_DTS, so relevant Controls file entries done
and Sprites[22] files updated as required. Noticed some builds have
a low-res ptr_link with a mask - mask removed.

Named anchor following fixed up somewhat - anchors near the bottom of
the page shouldn't be displayed, and then pulled down when the fetcher
releases null polls and ensures the y extent is correct (this through
implementing the min_height field in the browser_data structure).

RefoHang was never implemented and there seems little point to it now,
so the entry for it has been removed from the global choices structure
and all Choices files.

Markers menus should work properly now (in last check-in they would not
update correctly if Adjust was used on the entries).

URI handler usage now a lot more sensible, with configuration of how the
browser uses the module from both a Utils menu submenu (sic) and the
Choices dialogue.

Slightly dodgy 'hang around waiting for user input' stuff for the Cookies
dialogue box: All fetches are suspended; the fetcher remembers some info
about its state at the time the cookie came in, and restores it later; it
will only do this for one fetch at a time. It's necessary to single-thread
the fetcher at this point anyway, since other fetches may have a
dependency on the cookie that is hanging in mid-air at that point. As part
of this, some of the fetcher code has been split out into separate
functions (to try and 'black box' the code a bit). Anyway, Cookie Query
dialogue box now implemented with appropriate Choices file entry and
UI work in the Choices dialogue box.

Phoenix build Choices rearranged. Can now choose when the image history
is saved from the front end. Added also MSIE 4-style table option menu
for JPEG support (OS only, OS if it can handle it, internal only).

Should be a bit faster at loading the history - though 95% of the time
is spent in SWI URL_ParseURL. URL descriptions are stored more
efficiently as part of this - one malloc block instead of several
small blocks. The minimum block size for malloc blocks typically leads
to a significantly smaller startup wimpslot depending on the visit
history size.

Nasty bug in image system fixed. If an image size came in and a reformat
was to take place, the line the image lies in is found and the reformat
progresses from there. Unforunately, this didn't check to see if the
token can't be found in the line list, so it'd reformat from the top
of the page...! This would happen if, for example, an image halfway down
the page came in whilst a reformat for an image higher up had just begun.

In Choices.c, made choices_set_timetype_field, choices_set_uri_field,
choices_set_plugin_field, choices_set_cookie_field, and
choices_set_jpeg_field static (so they're not declared in Choices.h now).

Two memory leaks plugged in URL comparison routines in URLutils.c
(calling free() url_description instead of urlutils_free_descripton()).

Client pull reload handler was setting the reload flag if reloading
the same page, but forgetting to turn on reload_lock so
fetchpage_postprocessed was clearing the reload state... Similarly,
Ctrl+Shift+SELECT-Click on a link when the Controls file 'UseSmall'
entry is 'no' would not have reloaded as it should. Both fixed.

Frames shouldn't be so keen on acquiring horizontal scroll bars and never
letting them go when their width is decreased now. Frames set up for
'scrolling="yes"' will not start with no scroll bars and then gain them
shortly afterwards, causing flicker and two reformats - they'll start
with, and continue to hold, both scroll bars.

Pointer shouldn't flicker when over a frame border whilst other fetches
are progressing now.
@
text
@d44 1
d752 1
a752 1
    if (found && found - 1 == e) goto return_generic;
d754 3
a756 2
    /* OK, we have a string. If found is NULL, then we don't have a */
    /* filename extension to strip                                  */
d758 1
a758 4
    if (!found)
    {
      strncpy(leaf, url + e, size - 1);
    }
d760 3
a762 1
    /* Otherwise, strip the extension if a filetype is found for it */
d764 1
a764 1
    else
d772 2
d775 2
a776 2
             mimemap_extension_to_riscos(url + found, &filetype) ||
             filetype == FileType_DATA
a777 1
           && utils_strcasecmp(url + found, ".cgi") /* Special case '.cgi' - always strip it */
a779 6
        /* Don't strip it */

        strncpy(leaf, url + e, size - 1);
      }
      else
      {
d782 1
a782 2
        if (chars > size - 1) chars = size - 1;
        strncpy(leaf, url + e, chars);
d1688 3
d1715 13
a1727 1
  else b->displayed = Display_Fetched_Page;
d1748 2
a1749 3
  int  protocols = 0;
  int  i;
  char p[24];
d1753 1
a1753 5
  /* Find the number of possible protocols */

  protocols = atoi(lookup_control("ProtocolMax", 1, NULL));

  /* Exit if not found / not a sensible number */
d1755 1
a1755 5
  if (protocols <= 0) return 0;

  /* Loop round all protocols */

  for (i = 1; i <= protocols; i++)
d1757 6
a1762 32
    /* Look up the module name by building a MessageTrans  */
    /* token of the appropriate format, and call OS_Module */
    /* 18 (lookup module) for it; if the SWI doesn't       */
    /* raise an error, the module was found.               */

    sprintf(p, "ProtocolM%d", i);

    if (!_swix(OS_Module,
               _INR(0,1),

               18,
               lookup_control(p, 1, NULL)))
    {
      /* Module is present, so check the protocol */

      sprintf(p, "ProtocolU%d", i);

      lookup_control(p, 1, NULL);

      /* If the protocol identifier can be found... */

      if (tokens[0] != '!')
      {
        /* Compare it to the same number of characters in */
        /* the given URL. If it matches, we can deal with */
        /* the URL.                                       */

        if (!utils_strncasecmp(tokens, url, strlen(tokens))) return 1;

        /* Otherwise, loop on to the next protocol... */
      }
    }
d1789 6
a1794 6
  int  protocols = 0;
  int  in_use    = 0;
  int  have_any  = 0;
  int  have_one  = 0;
  int  i, ulen, plen;
  char p[24];
a1797 8
  /* Find the number of possible protocols */

  protocols = atoi(lookup_control("ProtocolMax", 1, NULL));

  /* Exit if not found / not a sensible number */

  if (protocols <= 0) return 0;

d1800 1
a1800 1
  for (i = 1; i <= protocols; i++)
d1802 1
a1802 6
    /* Look up the module name by building a MessageTrans  */
    /* token of the appropriate format, and call OS_Module */
    /* 18 (lookup module) for it; if the SWI doesn't       */
    /* raise an error, the module was found.               */

    sprintf(p, "ProtocolM%d", i);
d1804 1
a1804 5
    if (!_swix(OS_Module,
               _INR(0,1),

               18,
               lookup_control(p, 1, NULL)))
d1806 1
a1806 7
      /* Module is present, so check the protocol */

      sprintf(p, "ProtocolU%d", i);

      lookup_control(p, 1, NULL);

      /* If the protocol identifier can be found... */
d1808 1
a1808 16
      if (tokens[0] != '!')
      {
        have_any = 1;

        /* Compare it to the same number of characters in */
        /* the given URL. If it matches, flag this.       */

        if (!strncmp(tokens, url, strlen(tokens)))
        {
          in_use = i, have_one = 1;

          break;
        }

        /* Otherwise, loop on to the next protocol... */
      }
d1811 1
d1813 3
a1815 1
  /* If we haven't got any available protocols (!) exit */
d1817 2
a1818 1
  if (!have_any) return 0;
d1820 2
a1821 1
  /* Get rid of any existing protocol... */
a1822 1
  if (have_one)
d1824 1
a1824 1
    char * separator = (char *) (((int) url) + strlen(tokens));
d1826 5
a1830 1
    memmove(url, separator, strlen(url) - (((int) separator) - ((int) url)) + 1);
d1833 2
a1834 3
  /* Find the first/next protocol */

  have_any = 0;
d1836 1
a1836 1
  while (!have_any)
d1838 1
a1838 4
    /* If nothing was found in the first loop (the URL doesn't  */
    /* specify a protocol, or it wasn't recognised) then in_use */
    /* starts at 0; we thus increment to 1, which is what we    */
    /* want. So there's no special casing needed here.          */
d1840 3
a1842 1
    in_use ++;
d1844 7
a1850 1
    if (in_use > protocols) in_use = 1;
d1852 1
a1852 1
    /* Again, see if the protocol is available */
d1854 1
a1854 7
    sprintf(p, "ProtocolM%d", in_use);

    if (!_swix(OS_Module,
               _INR(0,1),

               18,
               lookup_control(p, 1, NULL)))
d1856 1
a1856 1
      /* Module is present, so check the protocol */
d1858 6
a1863 1
      sprintf(p, "ProtocolU%d", in_use);
d1865 1
a1865 1
      lookup_control(p, 1, NULL);
d1867 4
a1870 3
      /* If the protocol identifier can be found, flag it */

      if (tokens[0] != '!') have_any = 1;
d1877 3
a1879 1
  plen = strlen(tokens); /* (The protocol) */
d1881 1
a1881 1
  if (ulen + plen + 1 > size) return have_one; /* Yikes, if it won't fit we may have thrown out an existing protocol... */
d1883 1
a1883 1
  memmove(url + plen, url, ulen + 1);
d1885 2
a1886 1
  strncpy(url, tokens, plen);
@


1.23
log
@Programming warehouse link removed from all hotlists - the page has gone.

Some compile-time hacks in place to use MemLib, a dynamic area based
malloc replacement which shrinks its heap when possible. All builds
have these switched off at the moment. Seemed to work with just Browse,
though there would be problems with message blocks stored in dynamic
areas because of the Wimp's '&3800000' check - however, it failed when
HTMLLib was made to use it, too. Don't know why yet.

ItemInfo.[c/h] source added, with Res file additions for testbed Browse
and Phoenix.

Small fetch windows now work properly regardless of toolbar settings
in the Choices.

Reload now reloads all images too, rather than only reloading them for
as long as the main page was being fetched.

Added a simple 'Find' facility.

Realised that event handlers in eventlib are called in reverse order
of registration, so the miscellaneous event handler is now registered
first rather than last.

Multiuser code added (most only active if SINGLE_USER is undefined). As
part of this, hotlist code now knows about read-only items (done for the
Customer-style 'Resources' file, but works generally anyway).
handle_add_hotlist doesn't try to save the hotlist itself anymore (the
hotlist_add function does all that through hotlist_modified anyway).

Customer build Choices and Controls updated slightly (e.g. ClaimHelp
off, hotlist to save on quit only).

Customer build now uses Phoenix-style buttons. Sprites files which
worked at the time (but will probably be out of date now) and included
most of the original Customer-style sprites are in
'Utils.Icons.Customer'.

Choices, Messages and Res files for all builds now stripped down to only
single user items or single plus multiuser for Customer build and testbed
build. Before, all contained a few multiuser bits in at least the Choices
file if not more.

Grammatical error ("Fetching frames contents" (sic.)) corrected in
default message, Toolbars.c, and all of the Messages files.

Customer build brought back to a servicable level (including
implementation of the Find dialogue box with animation and fixing
up authorisation and 'Stop' state in the tristate). Quite a few
missing #ifndef REMOTE_HOTLIST bits from hotlist code added...

Customer build will not use <Choices$Write> or Boot:Choices for any
file finding now. UseProxy defaults to 'yes', MaxImages to 2. Res
file includes Proxy Address setting (save_save_choices() now writes
the ProxyAddress line).
@
text
@d101 2
a102 2
  free(url_d1);
  free(url_d2);
d145 1
a145 1
  free(url_d2);
d208 4
d232 2
a233 1
  /* Expect the canonicalised form at the very least */
d237 17
a253 1
  new->full = malloc((int) new->full);
d256 1
a256 7
  new->protocol = malloc((int) new->protocol);
  new->host     = malloc((int) new->host);
  new->port     = malloc((int) new->port);

  new->user     = malloc((int) new->user);
  new->password = malloc((int) new->password);
  new->account  = malloc((int) new->account);
d258 3
a260 1
  new->path     = malloc((int) new->path);
d262 8
a269 2
  new->query    = malloc((int) new->query);
  new->fragment = malloc((int) new->fragment);
d281 1
a281 1
            sizeof(url_description) / 4)) goto urlutils_return_description_free_and_exit;
a315 10
  free(url_d->protocol);
  free(url_d->host);
  free(url_d->port);
  free(url_d->user);
  free(url_d->password);
  free(url_d->account);
  free(url_d->path);
  free(url_d->query);
  free(url_d->fragment);

@


1.22
log
@*Don't* try to load FilterManager 0.18 in !Run[D] files. Requires
WindowManager 3.98. Sets URI handler environment variables for
http, ftp and gopher.

Fixed 'doesn't reformat for unsized images' bug - only happens when the
deferred reformatter is enabled, hadn't remembered to check this in my
debug build where this is turned off. Oops.

Caret position in forms could get left behind despite attempts to rectify
this in v1.31 - now fixed (and faster, fortunately).

Hourglass + percentage displayed for History and Image History when
loading - it can take a while for very big histories, though in
practice you only see the visit history loading (has to do a lot
more work, and is thus quite a bit slower than the image history).

POST forms worked when targetted to frames, but were broken when
not targetted! (Forms data inherited from one browser to the same
browser; ended up freeing the flex block...). Fixed.

Now support 303 response code (redirect to GET). Treated as 301, i.e.
not support if STRICT_PARSER is defined, otherwise drops through to
the 302 handling code.

Pointer shouldn't get stuck in odd shapes when going to a new page now;
it gets reset to a standard shape every time the null handler that
checks the position is called, though (whether or not the handler thinks
the pointer is over a different token, if that token is NULL, it sets
the standard shape). A possible work around would be for a browser to
remember the pointer shape too; that's for the future, though.

Early stage table formatting functions could blow themselves apart if
tables_count_table decided there were no rows, columns or both. A
net table size of zero cells is now dealt with; slow, partial table
fetches in multiple windows with image loading turned on will now
*hopefully* be stable, where v1.31 would have bombed out repeatedly.

A nested frameset within one document will now inherit the border
width (frame spacing) and border colour of its parent. This is done
by copying the maxlen and indent fields of the parent token over
the child, and note it's done in the browser (fetch_preprocess_token),
not HTMLLib.

Border colour on a FRAMESET now used, with the first colour on any
FRAME within it overriding, as in NN 4 and MSIE 4.

<LI> bullets really do stick to the text next to them now (I'd done
that in an experimental piece of code and forgotten to merge it back
before the last check-in).

Browse$HotlistURL/URIFile and Browse$HomeURL/URIFile now work from
_TaskName in the Messages file, and are thus of the generic form
<App>$HotlistURL etc. - Docs.Notes and Docs.User updated appropriately.

Event 0x11d00 through to 0x11d7f will make the browser look up Controls
file entries 'JumpTo00' through to 'JumpTo7f' and read a URL from them.
This will be fetched in the ancestor window of the source of the event,
or a new window if such an ancestor can't be found [for Daytona demo].

NB: Nasty frames-related crash at http://www.teledanmark.dk/menu/start.htm
is *not* fixed in this source. NOBR is not supported.
@
text
@d1694 1
d1696 1
d1699 2
@


1.21
log
@Check for WindowManager 3.97 and ensure Unicode$Path is set in all
!Run[D] files, don't set the Alias$@@PrintType_FF4 variable, and updated
Customer build ROM obey file variants. Various other changes to
the Run files for new module versions, updated paths to support
new positions of choices, hotlist and histories (see later), etc.

!Sprites[22] files hold small !app icons for some variants, and
an ic_browse sprite. Some variants now have a Sprites and Sprites22
file instead of just Sprites, with the former containing various
mode 12 or 15 specific sprites.

Text files dragged to the URL writable are treated as ANT URL files. This
relies on URLBarWrit (Toolbars.h) being a unique ID, which it should be,
but beware of the Hotlist and Choices numberspaces...

INPUT TYPE=BUTTON supported. Form items without a FORM tag are now shown
(as MSIE 4, but not NN 4).

'*', '-', '@@', '_' and '.' are not escaped when submitting forms now. The
Web interface to the IMDb now works.

INPUT TYPE=HIDDEN items will not affect the line height anymore - so
http://www.hotmail.com/ now has correctly aligned writable icons, for
example. Similarly, TAG_FORM and TAG_FORM_END items could push up
line height and don't anymore.

HRs with a specified pixel width will now influence the size of a table
cell (they didn't before).

BRs now checked by tagno field when the browser needs to know something
was an actual BR tag rather than just a line break signal, and by the
style bit entry when only the indication of a line break is required.

Table widths of 0 or 0% are ignored.

Trace.c updated to report height and background fields in a table_stream.

fm_putsl() writes a terminator into the string; the Forms.c routines were
calling this for displaying INPUT TYPE=PASSWORD fields using the FE_PassCode
literal string (a line of stars). This write into a read only data area
would make the debugger fault the access. A local char array is now used
instead, to get round this (note the use of var[]=literal rather than
var[sizeof(literal)]; strcpy(var, literal) due to some weird compiler bug
that copies the wrong thing into 'var' under some (undefined...)
circumstances).

Text areas don't scroll back to the top line when clicked in anymore;
single line writables don't scroll back to the left either. When
reentering a text area from 'above', the caret appears at the top line
rather than 'somewhere further down'...

ARROWS_MOVE_OUT compile time option at the top of Forms.c defines whether
you must press Tab/Shift+Tab to move between writable fields in forms or
if up/down will drop out of them, though if keyboard control is on this
is enforced (or you get trapped inside the form!).

urlutils_filetype_from_url now uses MimeMap module.

If fetcher is told a page is text, it'll check for a filename extension and
may choose to use this instead (e.g. it may find it's HTML instead). This
is to try and get around duff servers... (e.g. http://www.batalarms.co.uk/).

Save dialogues shouldn't flicker when options that don't change the
filetype are selected (before, the draggable sprite was always reset for
each selection). Noticed the erroneous setting of a static variable in
SaveFile.c by a call to this by SaveObject.c, and so added a flag to
savefile_set_filetype to deal with this - would have been possible to get
the wrong filetype sent to applications or at best the wrong filetype
sprite in the dialogue without that.

The caret shouldn't jump out of a form back to the URL writable if the page
reformats now.

Table background colours now supported (as in the colour you see in the
border space if the cellspacing is large enough; this is as in MSIE, not
as in Navigator). Drawfile output routines updated accordingly.

Corrected erroneous use of wimpt_dx() / wimpt_dy() in a couple of places
in Images.c, which meant that (say) 1x1 images didn't work correctly in
medium resolution display modes.

Now have support for save as text (component ID and event 0x12) and save
as Draw (component ID and event 0x13) buttons. Dubious conditions for
greying and ungreying the print, save source and view source buttons and
menu options sorted out as part of implementing the same for the two new
buttons; added greying out of their associated menu items in passing.

Turned kerning on in draw file objects (does mean a rather heinous
increase in file size, but this is the only way to ensure the draw file
matches the visible page).

Comments before functions in SaveDraw.c are now complete and up to date.

Image and visit histories now generate a crude hash number to speed up
searching for items. It does give a speed increase, though it's a
disappointingly small one.

Issue of left/right margins and cellpaddings sorted out. Now have
redraw_left/right_margin for finding out the basic gap you must leave.
redraw_left/right_gap then gives any extra indentation for LI, BLOCKQUOTE
or whatever. The last two can be subtracted from the display width to
get an available page width for any section of text. Note that
redraw_left_gap replaces redraw_margin. The redraw_start_x function
uses the above to work out where a line's left hand edge should be,
taking account of left/right/centre alignment. HRs have been fixed now
(they were quite broken in v1.30, I think) based on this new model and
the behaviour of MSIE/NN 4.

Fixed width of cells with no contents - cell padding values wouldn't
have worked properly as the reformatter returns 0 rather than the left
hand margin size if given no stream.

Removed FM_Absolute flags for Font_Paint (spotted by DBrown) - sets bit
2, which is reserved...?

IMG width and height in % terms now works correctly; a % of available
width (after margins and indents) or height on the main page or for
a table cell, if the image lies in one. Because of the chicken-and-egg
problem with the latter, the cell must specify a width and/or height
for things to work properly. If this is not done, you'll usually end
up with a 1:1 scaled image (as in Navigator 4, rather than ending up
with no image or even no cell (!), as in MSIE 4).

HEIGHT attribute on a TABLE tag is supported, but only in a crude
fashion; the extra height (if there is any) is distributed over the
rows in a linear fashion. This is probably all you have to do in
practice, but I haven't checked. To maintain a notion of min/max
height as well as width would of course require a great deal more
work...

If using client pull to reload a page with a fragment ('...#name')
specified, then the reload wouldn't work on the same page; it'd just
jump to the fragment position. This won't happen if b->reloading is
set now (so works in conjunction with client pull on the same page
forcing a non-cached fetch). Similarly, if POSTing to such a URL,
a fetch will proceed (both these fixes done originally for
http://jupiter.beseen.com/chat/rooms/g/1678/).

browser_inherit split to browser_inherit and browser_inherit_post_data;
the code for the latter didn't clear any post_data in the child before
copying from the parent either, and could cause flex errors (now fixed).

Res file for Ursula ('Desktop' Browse) build tweaked - bits in the
font choices dialogue renamed, and button bar rearranged to hold the
new Save As Draw button. Other builds have had Save As Draw and
Save As Text buttons added, or not, depending upon availability of
suitable sprites, required UI simplicity, etc.

Now have:

  Browse$ChoicesFile
  Browse$ControlsFile
  Browse$ChoicesSave
  Browse$ControlsSave

(the last two are new) for loading and saving of the Choices or Controls
files. If unset, <App$Dir>.Choices or <App$Dir>.Controls will be set.
E.g., you could set Browse$ChoicesFile to be:

  <App$Dir>.Choices,Choices:WWW.(app).Choices

for loading and

  <Choices$Write>.WWW.(app).Choices

for saving. (The browser never saves Controls at the moment, so the
relevant variable above isn't effectively implemented, but could be
in future). Similarly, to support asymetric loading/saving of the Hotlist,
there are HotlistSave, HistorySave and ImageHistorySave entries in Choices
to complement HotlistPath, HistoryPath and ImageHistoryPath (which are used
for loading). save_save_choices will create directories as needed to obtain
the given path (and has also been fixed in various areas that hadn't been
tested out until now; e.g. zero termination of the AppName$ChoicesFile
variable expansion...). !Run[D] files updated appropriately.

Table widthing code rewritten. Slower, but a lot better on the whole.
Still has some problems - still needs a final 'make sure nothing is
below minimum width' scan, which it should be possible to do without.
No time to fix this at present!

The reformatter will now 'glue together' an LI token followed by any
non-LI token; so a bullet point followed by an item should not be able to
have a line break inserted after the bullet because of very tight width
constraints (it could before - yuk...).

'about:' brings up a page about the browser and any Plug-Ins, as with
Navigator (for example).

URI files support titles, as per spec. version 8. Saving a current
location to the Hotlist will thus give a sensible title now (unless
you're in a frame, so there's no title to get...). Of course, v1.00
files without a title still work.

Note that NOBR is *not* supported in this build and this combined with
the new table widther may cause problems on some sites (e.g. Microsoft's
home page!).
@
text
@d975 2
a976 2
/* system variable 'Browse$HotlistURL'. If that  */
/* isn't set it looks at 'Browse$HotlistURIFile' */
d993 1
d1003 3
d1009 5
a1013 5
            "Browse$HotlistURL", /* Variable name                      */
            buffer,              /* Buffer                             */
            size,                /* Buffer size, -1 to check it exists */
            0,                   /* Name pointer (0 for 1st call)      */
            4);                  /* Variable type (4 = literal string) */
d1019 3
d1025 1
a1025 1
              "Browse$HotlistURIFile",
d1054 2
a1055 2
/* variable 'Browse$HomeURL'. If that isn't set, */
/* it looks at 'Browse$HomeURIFile', which can   */
d1069 1
d1079 3
d1085 5
a1089 5
            "Browse$HomeURL", /* Variable name                      */
            buffer,           /* Buffer                             */
            size,             /* Buffer size, -1 to check it exists */
            0,                /* Name pointer (0 for 1st call)      */
            4);               /* Variable type (4 = literal string) */
d1095 3
d1101 1
a1101 1
              "Browse$HomeURIFile",
@


1.20
log
@Not all resources are up to date in this check-in, and documentation
both within source and stuff in 'Docs' is out of date or missing - I
was very pushed for time on this one... Hopefully will do another
'tidy up' check-in before close on Friday; until then, beware of
anything other than the Ursula (Desktop browser) build. Anyway...

Export As Draw done. As part of this, FONT SIZE and SUP / SUB adjustment
of font size is done in fm_token_font_info rather than fm_find_token_font.

Bullets and switches are plotted as indirected sprite items, rather than
indirected text + sprite items - this relied on being in a redraw loop to
pick the sprites up from the local pool (failed during printing).

URI files now have a LF line ending rather than CR... '*' recognised
as an empty field when loading via. RAM transfer now (only worked for
loading from disc before).

Gave placeholder bounding boxes 4 OS units more minimum extra gap
vertically and reduced horizontal addition to this value * 1.5, rather
than * 2 (see reformat_get_placeholder_size).

Background image tiling starts at ymax - h + 4, rather than ymax, so
there isn't the bottom line of pixels from the top tile always present
at the top of the window. The '+4' is for caution's sake.

Can now save a frame's HTML source, that of its parent or its ancestor,
and the same for the URI pointing to those documents - see Menus.h for
the relevant component IDs that should lead to the SaveFile dialogue.

Have hopefully fixed timeout = 0 values (i.e. 'forever') on things
like LinkTo; before, image fetches could override the state (so you'd
only ever see brief flickers of a given URL as the pointer went over
a link).

Save File dialogue will remember the state of option or radio buttons
for a given parent component origin and restore that state when the
dialogue is next opened from the same place (stops turning on saving
as a URL file also turning on 'save background images' for Draw file
export, etc.).

Use of a META tag to reload the *same* page now sets the 'reloading'
flag in the browser so that it doesn't go through a proxy - otherwise
pages which are meant to update periodically through client pull
don't work, as they keep coming out of the cache.

Can now handle images specifying just a width or height in the HTML
(other dimension is scaled accordingly, but note that the placeholder
size must still be 'dumb' until the image data comes in). An image
will now override an image history size entry for the same entry
with a different size.
@
text
@d889 2
a890 1
  // For now, hard code it. In future, use a mime mapper module.
d892 1
a892 1
  int len;
d894 1
a894 2
  if (!url || !*url) return NULL;
  else len = strlen(url);
d896 1
a896 1
  /* Document types */
d898 1
a898 53
  if (ExtensionMatches(url, len, ".html"))  return FileType_HTML;
  if (ExtensionMatches(url, len, ".htm"))   return FileType_HTML;
  if (ExtensionMatches(url, len, ".txt"))   return FileType_TEXT;
  if (ExtensionMatches(url, len, ".shtml")) return FileType_HTML;
  if (ExtensionMatches(url, len, ".shtm"))  return FileType_HTML;
  if (ExtensionMatches(url, len, ".pdf"))   return FileType_PDF;
  if (ExtensionMatches(url, len, ".doc"))   return FileType_WORD;
  if (ExtensionMatches(url, len, ".ps"))    return FileType_PS;
  if (ExtensionMatches(url, len, ".eps"))   return FileType_PS;
  if (ExtensionMatches(url, len, ".wri"))   return FileType_DOS;
  if (ExtensionMatches(url, len, ".xls"))   return FileType_XLS;

  /* Images */

  if (ExtensionMatches(url, len, ".gif"))   return FileType_GIF;
  if (ExtensionMatches(url, len, ".jpg"))   return FileType_JPEG;
  if (ExtensionMatches(url, len, ".jpeg"))  return FileType_JPEG;
  if (ExtensionMatches(url, len, ".tiff"))  return FileType_TIFF;
  if (ExtensionMatches(url, len, ".tif"))   return FileType_TIFF;
  if (ExtensionMatches(url, len, ".png"))   return FileType_PNG;

  /* Archives */

  if (ExtensionMatches(url, len, ".zip"))   return FileType_ARC;
  if (ExtensionMatches(url, len, ".arc"))   return FileType_ARC;
  if (ExtensionMatches(url, len, ".spk"))   return FileType_ARC;
  if (ExtensionMatches(url, len, ".arj"))   return FileType_ARC;
  if (ExtensionMatches(url, len, ".gz"))    return FileType_GZ;
  if (ExtensionMatches(url, len, ".tar"))   return FileType_ARC;
  if (ExtensionMatches(url, len, ".zoo"))   return FileType_ARC;

  /* Sounds */

  if (ExtensionMatches(url, len, ".wav"))   return FileType_WAVE;
  if (ExtensionMatches(url, len, ".arm"))   return FileType_ARMA;
  if (ExtensionMatches(url, len, ".mod"))   return FileType_MOD;

  /* Movies */

  if (ExtensionMatches(url, len, ".mov"))   return FileType_AVI;
  if (ExtensionMatches(url, len, ".avi"))   return FileType_AVI;
  if (ExtensionMatches(url, len, ".qt"))    return FileType_AVI;
  if (ExtensionMatches(url, len, ".qtvr"))  return FileType_AVI;
  if (ExtensionMatches(url, len, ".rpl"))   return FileType_ARMO;
  if (ExtensionMatches(url, len, ".rep"))   return FileType_ARMO;

  /* Miscellaneous */

  if (ExtensionMatches(url, len, ".bin"))   return FileType_DATA;
  if (ExtensionMatches(url, len, ".dat"))   return FileType_DATA;
  if (ExtensionMatches(url, len, ".data"))  return FileType_DATA;
  if (ExtensionMatches(url, len, ".exe"))   return FileType_DOS;
  if (ExtensionMatches(url, len, ".com"))   return FileType_DOS;
d900 1
a900 1
  /* Otherwise, return text */
d902 66
a967 1
  return FileType_TEXT;
d1037 1
a1037 1
      urlutils_load_uri_file(buffer, size, path);
d1106 1
a1106 1
      urlutils_load_uri_file(buffer, size, path);
d1226 3
d1233 2
a1234 1
/* Parameters: Pointer to the buffer;            */
d1238 5
d1246 1
a1246 1
/* Assumes:    The buffer and path must NOT be   */
d1250 1
a1250 1
void urlutils_load_uri_file(char * buffer, size_t size, char * path)
d1253 1
a1253 1
  int    byte, counter = 0;
d1261 3
a1263 1
  /* Find the filetype */
a1280 4
  /* Don't load if not the correct type */

  if (type != FileType_URI && type != FileType_URL) return;

d1292 1
a1292 1
    if (type == FileType_URL) goto urlutils_load_uri_file_read_uri;
d1356 2
a1363 2
    fclose(fp);

d1367 34
d1441 2
a1442 1
/*             URI.                              */
d1447 3
a1449 1
  int copy, counter;
d1453 2
a1454 1
  /* Ensure it starts with 'URI' */
d1456 6
a1461 1
  if (strncmp(buffer, "URI", 3)) goto urlutils_extract_uri_not_a_uri_file;
d1527 2
a1530 2
  copy = 0;

d1543 1
a1543 1
  if (copy && copy < file_size) buffer[copy] = 0;
d1546 14
a1559 1
  /* If we've ended up with just a single star, the field is blank */
d1561 8
a1568 1
  if (!strcmp(buffer, "*")) *buffer = 0;
d1570 2
a1571 1
  return;
d1573 1
a1573 1
urlutils_extract_uri_not_a_uri_file:
d1575 8
a1582 1
  /* Not a URI / URL file */
d1584 3
a1586 1
  erb.errnum = Utils_Error_Custom_Message;
d1588 1
a1588 4
  StrNCpy0(erb.errmess,
           lookup_token("NotAURI:This is not a valid URI file.",
                        0,
                        0));
d1590 1
a1590 1
  show_error_ret(&erb);
d1682 1
@


1.19
log
@Note that the 'Docs' documentation (possibly contrary to previous
log messages) still hasn't been updated with the new SaveFile
stuff, and function header comments have yet to be written for
SaveFile.c.

Fixed urlutils_pathname_to_url - OS_GSTrans doesn't like the same
input buffer as output buffer (fairly obvious, but I was living in
the hope of not having to duplicate the input path string).

Image history will not cache scrap file images anymore. Browser's
image handling library won't cross reference them either.

When dragging a single item from the hotlist to a Filer window, the
code now checks Ctrl - if held down, a URL file is written, else a
URI file. The state of any option buttons or radios in the last
Save File dialogue that was opened is no longer relevant...!

history_save_as_html could write out broken files when titles
for items in the History were not present. Fixed.

Hourglass switched on for hotlist and history saving as HTML;
hotlist_save_entries no longer closes the output file on error
(it should be done by the caller, since the caller is responsible
for opening the file and passing the FILE * pointer to
hotlist_save_entries).
@
text
@d45 1
d216 32
d250 9
a258 3
  new->full = malloc(strlen(url_s) + 1);
  if (!new->full) goto urlutils_return_description_free_and_exit;
  strcpy(new->full, url_s);
d418 21
a438 1
  int len;
d440 1
a440 1
  /* Find the length of the File module protocol specifier */
d442 1
a442 1
  len = strlen(FileMethod); /* (urlutils.h) */
d444 4
a447 2
  /* If the first part of the string doesn't match the FileMethod */
  /* specifier (see URLutils.h) then we can't do anything.        */
d449 3
a451 1
  if (!url || strncmp(url, FileMethod, len)) return;
d453 4
a456 1
  /* Copy over the file: specifier and any '/'s */
d458 2
a459 1
  while (url[len] == '/') len++;
d461 2
a462 1
  memmove(url, url + len, buffersize - len);
d1482 4
@


1.18
log
@Bug report prompted me to do this - now ignore <p> tags straight after
<li> tags, so '<ul><li><p>Some text' works as the author (or automatic
generator, more commonly) intended.

A <p> tag before a table will be acted upon now (it was ignored before).
Something like <li><p><table...> will give a line break and paragraph
space after the <li> despite the changes mentioned above, as in other browsers.
Both browsers differ from Navigator, where the table appears alongside
the <li> tag.

Multiple BR tags work as in MSIE / Navigator (they don't collapse to
zero height anymore).

For the above, line height (and so, <br><br> or <p> spacing) is now
calculated inside reformat_text_line_height, and is used with either
a token to get the text height at a given size (e.g. for general line
spacing or multiple BR tags) or NULL for normal size text (e.g. for
P spacing, though this value is in practice later scaled by 7/8ths in
reformat_check_height). Note this behaviour is exhibited by MSIE 4;
v3 gave two BRs the same spacing as one P (i.e. not font size
dependent).

Save dialogues can have an option button or couple of radios to
switch between various formats (e.g. URI or URL, sprite or original
format). See 'Docs.Notes' for more. The back-end to this is now
implemented (i.e. at the moment, save as URI or URL, save as original
image format). Note that when saving background images, a leafname
based on the original fetch URL is now offered rather than a generic
'Background'.

Internal URL scheme changed to be all lower case, so relativisation
through URL_Fetcher still makes sense... :-/

Holding down 'shift' when clicking on stop reverses the interpretation
of the Controls file 'StopWebServe' entry.

Fixed row / column count for exporting tables as text; fixed a few
bits and pieces of internal URL scheme stuff which got broken when
HTMLLib started using URL_Fetcher's relativisation; this includes
automatic expansion of system variables in pathnames, in
urlutils_pathname_to_url.
@
text
@d287 2
a288 1
  int len;
d290 2
a291 1
  /* If the path is expressed as a system variable, expand it */
d293 1
a293 2
  _swix(OS_GSTrans,
        _INR(0,2),
d295 7
a301 3
        path,
        path,
        buffersize);
d303 3
a305 1
  /* Terminate the string at any control code */
d307 12
a318 3
  for (len = 0; len < buffersize; len++)
  {
    if (path[len] < 32)
d320 10
a329 2
      path[len] = 0;
      break;
d331 2
d334 2
@


1.17
log
@There are a few known significant problems with this code but it's being
checked in so the Choices can be worked on. Note that Res files etc. are
not up to date across all builds. Progress is as follows...

Bug report prompted me to do this - now ignore <p> tags straight after
<li> tags, so '<ul><li><p>Some text' works as the author (or automatic
generator, more commonly) intended.

A <p> tag before a table will be acted upon now (it was ignored before).
Something like <li><p><table...> will give a line break and paragraph
space after the <li> despite the changes mentioned above, as in other browsers.
Both browsers differ from Navigator, where the table appears alongside
the <li> tag.

Multiple BR tags work as in MSIE / Navigator (they don't collapse to
zero height anymore).

For the above, line height (and so, <br><br> or <p> spacing) is now
calculated inside reformat_text_line_height, and is used with either
a token to get the text height at a given size (e.g. for general line
spacing or multiple BR tags) or NULL for normal size text (e.g. for
P spacing, though this value is in practice later scaled by 7/8ths in
reformat_check_height). Note this behaviour is exhibited by MSIE 4;
v3 gave two BRs the same spacing as one P (i.e. not font size
dependent).

Save dialogues can have an option button or couple of radios to
switch between various formats (e.g. URI or URL, sprite or original
format). See 'Docs.Notes' for more. The back-end to this is now
implemented (i.e. at the moment, save as URI or URL, save as original
image format). Note that when saving background images, a leafname
based on the original fetch URL is now offered rather than a generic
'Background'.

Internal URL scheme changed to be all lower case, so relativisation
through URL_Fetcher still makes sense... :-/

Holding down 'shift' when clicking on stop reverses the interpretation
of the Controls file 'StopWebServe' entry.

Fixed row / column count for exporting tables as text; fixed a few
bits and pieces of internal URL scheme stuff which got broken when
HTMLLib started using URL_Fetcher's relativisation.
@
text
@d289 20
d352 2
@


1.16
log
@Implemented Message_PlugIn_ReshapeRequest, Message_PlugIn_Status and
Message_PlugIn_Busy. Plug-in code more robust when given invalid
browser instance handles by the plug-in.

Line spacing is now calculated on the basis of the normal style base serif
font, with all other fonts being forced into that line height. This does
mean that an unusually tall (say) sans serif font may get clipped. It
appears to be the only way to get around wildly different baseline
depths returned from the font metrics - you can't work out line spacing
based on each different font style; the line spacing will vary.

Table heighting (as opposed to widthing...) improved considerably; rowspan
can no longer cause very tall cells in odd places. Having trouble getting
rid of the single pixel breaks between vertically adjacent cells, though
I've not tried too hard. Widthing, though, seems fairly badly broken at
present... :-/

Set/clear of page_is_text flag made more robust (it looked as though there
was the potential for this to get stuck in a set state, though I've never
see the front-end behave in a manner which indicates this is the case).
The reformatter will now decrease leading if this flag is set (plain text
pages look daft with a line spacing that is OK for 'rich' text pages).
No reformatting is done if the page width changes by dragging on the
resize icon, though toggle size / full screen will still reformat even
if the contents are only text (browser needs to sort out various width
flags at this point).

Cut down on excessive redrawing when reformatting due to a change in
window dimensions is not done. If display_width hasn't changed, then no
redraw is needed. If this causes redraw problems, then whatever is
changing display_width needs investigating. It shouldn't be kludged
(basically) by forcing a redraw instead of a reformat.

TT/PRE/etc. text can now have a non-100% aspect ratio. 80-90% looks
best (ArcWeb, for example, uses 86%). New option 'TTAspect' in
the Choices files.

Debug builds link to a non-debug Unicode library now; stops stderr
being dumped to the bottom left of the screen if you've not redirected
it in the Run file.

RISC OS 3.1 seems to need more initial WimpSlot than later OS versions.
The 64 deep nested table set gives a 'No stack for trap handler' error
(which it really means in this case!) without 800K, even though 3.71
is happy with just 640K. So, the !Run file checks if Boot$OSVersion
is exactly 300, 310 or 311, and sets the WimpSlot accordingly.

!Run[D] files now require latest fetcher module versions (URL 0.21,
File 0.31, HTTP 0.58).
@
text
@d1225 4
@


1.15
log
@Image history - sizes of images are remembered for future reference (if
the sizes aren't specified in the HTML, they can be looked for in the
image history instead to minimise reformatting requirements). Choices
file options ImageHistoryPath, ImageExpiryAge, ImageMaxSize and
SaveImageHistory added to support this (all have a direct analogy to
the global History items of the same name after removing 'Image').

Text area items are now the correct height for the number of rows
specified in the HTML, don't scroll a line too early, and have the
caret placed at the start of the text when moved into from above
or at the end when moved into from below (rather than always at
the end, which was behaviour inherited from single line writables,
where this is desirable). The top of the text area is aligned to
the top of any line of text on the same line, with the text area
dropping below the text, rather than the bottom of the area matching
the text baseline and extending upwards.

Filename extensions for download files are only stripped if an
attempt to convert to a RISC OS filetype through the Mime Mapper module
does not return an error or Data (0xffd) filetype. '.cgi' is a special
case which is always stripped.

Altered heading styles - all are bold, none are italic, H3 is as big
as H2 was, H2 is a little larger, and others scale down to H6 being
the size as normal text (but, as I say, bold).

Sorted out tables and forms. We can just look for tagno=TAG_FORM, and
get rid of the wobbly form_flag; also discarded the redundant
reprocess_table flag in fetch_preprocess_token. Two separate forms
in consecutive table cells (for example) which used to fail - they
were submitted as one single form - will now work correctly.

Fixed nasty bug in FontManage.c where font size 7 would intermittently
fail. The stupid font sizes that it could ask the Font Manager for may
be responsible for the occasional Font Manager crashes that have been
noticed. Array for font sizes was declared as [Limits_FontSizes], but
indices 1 to Limits_FontSizes are actually used - so needed a '+ 1'
in the declaration... :-/

Replaced the case insensitive string comparison functions in Utils.c
with more efficient versions by S.Brodie.

MAXLENGTH specifier in INPUT tags is now supported. If unspecified or
specifically zero, the browser overrides and allows any length.
@
text
@d1535 1
a1535 1
        if (!strncmp(tokens, url, strlen(tokens))) return 1;
@


1.14
log
@This is an intermediate check-in to allow work on Choices for the new
table options and History choices as detailed below. Res files are not
up to date except where indicated and there are several known bugs that
will be fixed before the 'final' v1.27 is created. Any work on resources
should only be done for the testbed !Browse.

Client side image maps implemented. There is code to draw highlighted
borders in CSIM.c, but this is not wired in yet; other than that,
the implementation is functionally complete. As part of this, centralised
the fetching of a targetted URL taking into account user request of a
new view and full screen mode, in fetchpage_fetch_targetted. The forms
library now uses this too, so form buttons respond to both adjust-clicks
and TARGET attributes.

Fixed APPLET handling where '.class' isn't present in the CODE attribute.

Paragraphs squashed at the top of cells/pages - browser would insert white
space before.

Now append a ' ' to the end of History menu items to prevent the Wimp
thinking the end of entries represents a keyboard shortcut (e.g. 'Home').

Netscape's handling of 'meta http-equiv="refresh"' is to start counting
when the fetch has completed and everything else has died down. The browser
will now not start counting until the animation handler is deregistered
(so formatting is complete) to show similar behaviour (note that this
checks the main handler, not the 'idle but returning to first frame'
drift handler).

URLs from requests for fetches by Plug-Ins are now relativised.

Page width change tolerance prior to reformat upped from 16 to 32 OS
units. Hoping to provoke a loosely connected bug with this change!

TableOuter, TableInner and SeeFetches choices added to all Choices
files, with appropriate loading and saving code in Main.c and Save.c.
AuthorFTP and AuthorFSh messages added for FTP authentication, and
dialogue handling code (the component in FetchHTML.c) updated to
recognise an FTP fetch and alter the dialogue presentation
appropriately.

All Messages file version numbers taken up to 1.27 (20 Nov 1997).

Following a UseNet suggestion, Ctrl+Toggle Size will increase the window
size to fill the screen vertically only; horizontal size/positioning is
not changed.

Shift+Tab in the URL writable will cycle through alternative fetcher
protocols (from both the Controls file and checking the fetcher modules
are actually present).

Hotlist doesn't require '://' in URLs when loading HTML, just ':/' - so
'file:/' URLs now will be reloaded correctly.

History system rewritten completely. GHistSize and VHistSize options
removed, and replaced by MaxSize and ExpiryAge. Now have global history
menus with most recently visited items at the top, and local history
menus which reflect the path that forward/back buttons would take.
Browsers are robust to background expiry of the History though this is
not implemented - date expiry and size checks are carried out on
history_record only. This does mean that with two windows open one could
have the history expired underneath it whilst another fetched, though;
the code handles this and update toolbars (greying items) as necessary.
It is possible to have the history limits so tight that even one entry
will not fit and again the code copes with this, though values read
from Choices are limit checked to ensure rather more useful results!

Implemented 'Save' button in save dialogues. Remembers pathnames and just
replaces the leaf now (hard coded exceptions for <Wimp$Scrap>... and
<Wimp$ScrapDir>...) - it did before, but only if you'd typed the path
in. Not many people did, given that you couldn't press Return or click on
a Save button to use that path...

In a similar vein, files of type Data or DOS will be checked for a '/xxx'
type extension and the MimeMap module will be used to find a more meaningful
filetype. If this can be handled, the file is loaded. This only works for
files dragged to the browser - the behaviour with inline data in web pages
will depend on the File module, and similarly, if File doesn't spot what is
going on and claims that the object is data, the browser will just open a
save dialogue for it.

!RunD files taken up to 3072K WimpSlot.

Hotlist's saved HTML page title wasn't internationalised - is now. This
opened up a significant can of worms; on file write error, the file would
never be closed, and if a caller of the save or load functions passed
in a filename held in the global Messages lookup buffer then subsequent
lookups in the callees would corrupt that filename. All sorted out now.

Local (not very useful) or global (useful) histories can be saved as HTML,
which opens up the possibility of sending your history to the hotlist
by saving to it. Local and global histories can also be emptied, though
this is probably not a feature that current release Desktop browsers need.
Inheritance of local history and certain UI features is now done more or
less for all cases where one browser window spawns another, too.

Vertical alignment on images is rather less ropey than it was (e.g.
ALIGN=TOP stands half a chance of working) but is still far from perfect.
This was part of fixing a nasty little bug in Redraw.c's setting of
an image position via. image_set_token_image_position, which was making
(amongst possibly many other things) client side image maps fail.
Image update where images had large borders was affected by a similar
problem too (more cans with more worms...).

Fixed image background filler functions; two problems. When cross
referenced images were replaced by base images in a browser because the
original owner was closing down, the original owner browser would stay
registered with ImageLib. Fixed; secondly, when images were deleted from
the image array causing those above to be renumbered, images registered
with ImageLib did not have their numbers updated (this was the one that
lead to the visible drop out of background images with PNGs on the Acorn
Internet home page when there were two views of the page and the first
was closed). This is now also sorted out.
@
text
@d44 1
d460 9
d622 2
a623 1
    /* OK, we have a string */
d629 3
d635 13
d649 9
a657 2
      if (chars > size - 1) chars = size - 1;
      strncpy(leaf, url + e, chars);
d660 2
a661 1
    /* Right, that's the worst of it over...! */
@


1.13
log
@More reformatter code bugs fixed; this one regarding width of items. Any
kerned string was overestimated (causing redraw bugs and caret position
problems in forms, apart from other minor bits elsewhere) and the default
size of a writable icon wasn't especially clever.

Crude Plug-In support; just about manages Java, but can't fetch on
behalf of Plug-In (for example). Had to change the default file access
URL construction to be 'file:/' instead of 'file://', or local file
fetches that reference Java applets won't work. This is in its very
early stages, and is being checked in mostly so that various Choices
issues can be worked on.
@
text
@d59 210
d1510 146
@


1.12
log
@Big steps forward in vertical white space handling as a result of
improvements in HTMLLib in this area ( -> all versions now 1.22 beta-2).
As a result, the 'last_space' field in browser_data struct has been
removed. Note that this relies quite heavily on setting of the PCDATA
bit in the 'style' field of an HStream and the automatic collapsing
of (for example) multiple P tags inside HTMLLib.

Trace.c improved to recognise various bits in the 'style' field of an
HStream structure.

Phoenix defaults altered to a more 'standard' set of choices; Trinity
as the serif font, with a slightly larger default font size. This is
because there's a good chance it might get released to a wider audience
than Acorn internal (though the animation and icon bar sprites will
have to change before then...).

MiscDefs updated for new SWI numbers in HTTP module; !Run[D] files thus
updated to require HTTP 0.42 or later. At this point, all earlier
modules are not backwards compatible in terms of direct calls to the
HTTP module, though this only affects cookies_process_cookie at present.
At the same time, checks for System$Path, InetDBase$Path, and setting
of Inet$MimeMappings if not already defined have been added to the Run
files along with RMEnsures of Resolver and MimeMap.

Object and PlugIn c/h pairs created to handle OBJECT, EMBED and APPLET,
and the RISC OS Plug-In interface respectively. Not part of the build
process yet. Addition of 'odata' field in browser_data struct and
definition of chunk CK_OBJB for memory_set_chunk_size() are in support
of this.
@
text
@d78 1
a78 1
  len = strlen(FileMethod ProtocolSeparator); /* (urlutils.h) */
d84 1
a84 1
  if (strncmp(path, FileMethod ProtocolSeparator, len))
d87 1
a87 1
    strncpy(path, FileMethod ProtocolSeparator, len);
@


1.11
log
@Version in Messages taken to 1.22 (03 Oct).

Updated Res files in appropriate builds to hold various (similar) Choices
designs.

Choices related menus were flagged as Shared, but none of the dialogues
(including ColourDBox) were - potential future problems, though shouldn't
cause any leaks at present. This has been sorted out anyway.

Encoding function encoding_init no longer returns an error from
toolbox_create_object, so the Encoding menu and all those attached
to it do not have to be present (e.g. the Customer build).

SUB, SUP, STRIKE and U supported. U underlines the baseline of the body text
font, whilst STRIKE will go through roughly the middle of the lower case
chars even if the font is SUP or SUB. Note that Navigator appears to shift
the underline point for SUB and SUP; it may be necessary to copy this
behaviour, but testing on real sites must proceed before that. There could
also be a problem with the automatic lowering of font size, which Navigator
doesn't do, so any FONT SIZE = -n commands could make it too small. Again,
this needs testing on real sites.

'http://' is added to URLs with no protocol specified, unless they start with
'ftp.', in which case the new behaviour is to add 'ftp://'.

Choices code altered to do less error checking on components! They should be
able to be missing without raising errors. Referencing of the subwindow
array changed from *(subwindows + number) to subwindows[number].

Made trace_tag_name code look pretty...

reformat_useless_token now checks tagno is non-zero.

User Agent string setting now done through URL_GetURL, on a per-session
basis.

Ellipsis character removed from all Messages files, replaced with '...'.
There's little difference between the two in an outline font, and in System
font the latter looks much better. Smart quotes left in, as they look
better in all cases.
@
text
@d227 34
a260 1
    /* Set 'a' to point at the last character in the string */
d262 10
a271 1
    int a = l - 1;
d273 3
a275 2
    /* Look backwards through the string until a forward */
    /* slash is found, or we get to the string's start   */
d277 6
a282 1
    while ((url[a] != '/') && (a > 0)) a--;
d284 1
a284 3
    /* If we're not at the start of the string, c[a] will be */
    /* the forward slash found by the above - advance 'a' by */
    /* one (to point just past the slash).                   */
d286 2
a287 1
    if (a) a++;
d289 6
a294 6
    /* If 'a' is greater than or equal to the string length */
    /* minus one, there was a forward slash at the end of   */
    /* the URL string - i.e. the URL was specified without  */
    /* a leafname. In that case, offer 'Index' as a likely  */
    /* filename to match the real remote file (purely an    */
    /* aesthetic decision).                                 */
d296 1
a296 1
    if (a >= (l - 1))
d298 1
a298 2
      lookup_token("NoURLleaf:Index",0,0);
      strncpy(leaf, tokens, size - 1);
a299 12
    else
    {
      /* Otherwise, we've found the leafname but need to strip */
      /* off the extension (if present) as for this save, it   */
      /* will always be .html, .htm or whatever and since the  */
      /* file is filetyped the extension isn't needed. So set  */
      /* b to point to the last character in the string and    */
      /* search backwards for a full stop, up to the start of  */
      /* the leafname as found above.                          */
      /*                                                       */
      /* The extra check for a hash character ensures anchor   */
      /* names, if present, are also stripped.                 */
d301 6
a306 1
      int b = l - 1;
d308 1
a308 1
      while (!(url[b] == '.' || url[b] == '#') && (b > a)) b--;
d310 3
a312 2
      /* If on a hash character, may need to back up further if there's also */
      /* a filename extension.                                               */
d314 3
a316 1
      if (url[b] == '#' && b > a)
d318 2
a319 1
        int c = b;
d321 1
a321 1
        while (!(url[c] == '.') && (c > a)) c--;
d323 1
a323 2
        if (url[c] == '.' && c > a) b = c;
      }
d325 4
a328 2
      /* b now either points to the extension including the */
      /* dot, or is equal to a (if there was no extension). */
d330 1
a330 1
      if (b > a)
d332 1
a332 4
        /* We have in 'a' the first character of the leafname, and */
        /* in 'b' the position of the start of the extension,      */
        /* including the dot. Copy the string between a and b      */
        /* (including a but not b) into the leafname buffer.       */
d334 2
a335 2
        if (b - a > size - 1) strncpy(leaf, url + a, size - 1);
        else                  strncpy(leaf, url + a, b - a);
a336 4
      else
      {
        /* In this case we have a leafname but no extension, so   */
        /* copy the string over.                                  */
d338 76
a413 2
        strncpy(leaf, url + a, size - 1);
      }
d415 9
d435 2
d758 6
a763 1
  int len, shl, flen, fshl, blen;
a764 1
  len  = strlen(HTTPmethod ProtocolSeparator);
d766 1
a767 1
  flen = strlen(FTPmethod ProtocolSeparator);
d769 4
d785 1
a785 1
    /* at the start. Else insert HTTP.                                */
d787 1
a787 1
    if (!strncmp(buffer, "ftp.", 4))
d791 5
@


1.10
log
@Implemented dialogue based choices.
@
text
@d440 1
a440 1
  if (ExtensionMatches(url, len, ".gz"))    return FileType_ARC;
d600 1
a600 1
      
d636 7
a642 1
  int len, shl;
d644 1
a644 2
  len = strlen(HTTPmethod ProtocolSeparator);
  shl = strlen(HTTPmethod);
d646 1
a646 3
  /* If the first part of the string doesn't match the HTTPmethod */
  /* followed by ProtocolSeparator specifier (see URLutils.h)     */
  /* then insert this text at the front of the URL.               */
d648 5
a652 1
  if (!strchr(buffer,':') && strlen(buffer) < buffersize - len)
d654 13
a666 2
    memmove(buffer + len, buffer, buffersize - len);
    strncpy(buffer, HTTPmethod ProtocolSeparator, len);
@


1.9
log
@Now working on source merged with Kevin Bracey's internationalisation
support. UNIFONT is undefined in the Make File for now. All Res and
Choices files updated appropriately.

Having sorted out the old Choices and Messages to form Choices, Controls
and Messages, this build has had the same cleaning up done internally.
This includes greater consistency in naming schemes and the removal of
the inconsitent choices items - e.g. Choices file entries saying 'delay
images' and 'plain backgrounds' where internally all the flags say 'show
images' and 'show backgrounds'. ChoiceDefs.h and CtrlDefs.h added to
clarify the meaning of some fields, though usage of these is not 100%
in the source (there are cases where parameters are passed through to
functions as ints, and those functions still check these against hard
coded values rather than the #define stuff).

Fetcher status return bits (connected, sent request, etc.) now reflected
in status bar. Progress during fetchs to files are reported by %, where
the size of the object is known. Exceeding 100% drops back to a byte
counter, in case the estimated size was wrong. The progress counter
may be updated after specific delays, rather than 'as often as possible',
to reduce flicker (as requested by D.Brown some time ago).

I've done a small rewrite of the fetch prioritisation scheme in FetchPage.c;
how well this performs in general use across different processor speeds
remains to be tested, but certainly it has some advantages. For each small
fetch window before the rewrite, a 4cs tight loop was entered - this gave a
noticable and substantial drain to the Desktop performance if more than one
was opened. Now, several can be up at once with little hit. The actual file
fetch is on half the priority it was before, with all others taken back
just a bit - e.g. from 20cs per poll to 15cs per poll for flat out
reformatting. You don't seem to lose much time on the format in practice,
and the Desktop feels quite a bit lighter at the same time. There's the
potential for smoother frameset loading in this scheme, too.

When Shift+Clicking on a link meant you still fetched inside the main
browser window, several fetches could occur in a frameset - one per frame.
However, now that you can only do this by clicking on a link that leads to
non-displayable data - or by turning off the small fetch windows by
setting UseSmall to 'no' in Choices - a bug where fetchpage_preprocessed
would stop such fetches as new ones were started was revealed.
The API to frames_abort_fetching has now been extended to include a
'stop file spooling too' flag, allowing a fix to be made by having
fetchpage_preprocess's calls not set this (and it doesn't check the
savelink flag is unset before proceeding, since frames_abort_fetching
does that implicitly now).

Had left the RAM transfer buffer at 16 bytes (from testing) accidentally...
Oops. Upped it to 4K. In addition, when loading data by RAM transfer,
the browser didn't notice if a RAMFetch bounced during the transfer. It
would be treated as a 'first' RAMFetch bounce, basically, and try to go to
file transfer - oops. Fixed.
@
text
@d598 4
a601 3
      /* the HotlistPath string from the Messages file instead.       */

      strncpy(buffer, lookup_choice("HomePage",1,0), size - 1);
@


1.8
log
@First a minor warning - the various Res files are out of sync in this build.
Only the Browse resources are currently valid.

Added Utils.Icons - has a few archives inside containing the resources
(well, some of them) used to build various UI sprites for various builds.
Archived because these are unlikely to change much, and putting them on
CVS was a move to, well, archive the stuff...

SaveDBox objects vanquished and requirements in !Run[D] files removed. The
data save code fits much more neatly in amongst the data load protocol
stuff now (with the slight exception of having to split the SaveObject
source into SaveObject and SaveFile - the former handles multiple persistent
dialogues for Shift+Click on links and the like, the latter handles 'one at
a time' transient dialogues for save source and similar). Export Link is now
supported, too, and writes a 'proper' version URI file. You'll find that
double-clicking on old URI files will work as the URI handler picks them up,
whilst new version ones don't; however, dragging onto the browser will only
work with new version files. Note that support for saving and loading URL
files (ANT suite stuff) is present too, so old URI files can be typed as URL
files if you want to keep them working without modification - the URI
handler itself will hopefully support the defined URI file format soon;
double-clicking on old URI files will stop working at that point. Note
there are *lots* of changes in every Res file to support all this. This may
all seem a bit pointless to some, but the changes do in fact make it very
easy to add new save dialogues all over the place. Certainly much easier
than with the previous system, anyway. In fact, post script, image
'save as sprite' took about half an hour, which I hope proves the worth
of the new system.

Merged in newer hotlist code with support for drag cancelling with Escape
(all relevant Res files appropriately updated) and cancelling scrolling
when you've reached the window scroll limit. Had to move some of the
Wimp message handling stuff to the central Protocols source, as clashes
were occuring, and also the hotlist routines were using independent saving
code - a lot of duplicated effort. This was fair enough as at the time the
Hotlist code was written, the Save code couldn't be used in the way it is
now.

New Save Source and Print buttons on the toolbar of some builds.

Phoenix Sprites file made more efficient - the Acorn base section has been
split from the animated upper region. Browse build has a new grey fade
sprite at the back, which is less grainy than the previous one and only
uses 16 colours (with a 16 greyscale palette).

Not really a bug, bug the routine to start an image fetch for INPUT
TYPE=IMAGE forms items only did so if the src field (or equivalent, for
this tag type) was non-NULL. In fact, you should always call image_new_image
and let that handle the rest, otherwise other sections of the code will fail
as they try to obtain an image number for a given HStream and get -1 back.
This problem only generally manifested itself when loading an HTML file to
the browser straight from an application, as many src fields become NULL
when the relativisation routines find nothing to relativise to...

Authentication got broken somewhere along the line - this has been fixed
(in HTMLLib and the browser).

Ctrl+Click on a cross referenced image updates *all* copies, not just the
one with the image data attached.

Next big step: Rip up TBEvents.h and rebuild that whole approach somewhat.
To all those working on the code, my apologies but this means all Res files
will receive a very large number of alterations and there will be extensive
code changes too (mostly naming convention stuff), in more or less all
source files. I am endeavouring to ensure that the new numberspace
convention does not clash with the work being done by Kevin on
internationalisation.
@
text
@d686 2
a687 1
/* too.                                          */
@


1.7
log
@File fetches now set DEADDEAD during the fetch, Data if it is aborted, or
an appropriate filetype when finished. If the fetcher routines return a
zero or data filetype, the browser looks at a set of hard coded filename
extensions to try and determine if there's a better filetype to use
(urlutils_filetype_from_url) - since this is a centralised routine it can
use a Mime mapping system (or be removed entirely) as and when one becomes
available.

You can now drag URI / URL files to the Hotlist window to add them to the
list. They are added roughly where dragged to. (NB, note that I renamed
the function to return the window ID - just being picky; it matches other
similar functions now). Oh, and hotlist_add_position actually works now ;-)

The global history will save when titles are added, as well as when a URL
is added. Before, a browser crash could mean a title got dropped out
of the history file even if SaveHistory was set to 'always'.

SaveObject sources have been added but nothing references them or links
them in yet - they're not finished. Mostly checking this one in because
of the hotlist changes.
@
text
@d43 1
a43 1
#include "Save.h"  /* (For filetype definitions)        */
d437 1
d685 2
a686 4
/* Takes the given file, opens it, and copies    */
/* its contents to the given buffer. This is     */
/* intended for URI files, where the contents    */
/* may be a URL string with no terminator.       */
d688 1
a688 1
/* The copy terminates when the buffer is full   */
d696 2
a697 2
/* file is empty, the first byte of the buffer   */
/* will be zero.                                 */
d714 1
d716 3
d721 24
d749 31
a779 1
    do
d781 41
a821 2
      byte = getc(fp);
      if (byte != EOF && byte >= ' ') buffer[counter++] = byte;
a822 1
    while (byte != EOF && byte >= ' ' && counter < size - 1);
d826 151
@


1.6
log
@This version is being checked in because the Hotlist manager in the test
build provokes a Wimp bug. All the variant resource files are out of sync
and there are several outstanding bugs in the main code, so I'd personally
avoid this build like the plague unless you're mad enough to want to
examine the Wimp problem ;-)
@
text
@d43 1
d47 4
d388 81
@


1.5
log
@Created Protocols source file and moved a lot of message handling from
handle_messages - the latter now serves as a high level distributor to
lower level functions in Protocols. Incidentally, URL files (as used by
the ANT suite) can be loaded by dragging to the browser in the same way
as URI files - Not A Lot Of People Know That, etc.

Merged new hotlist display type Res file to existing resources, added
support for DataSave message so items can be dragged from the hotlist
to a specific window (RAM transfer for URI and URL files; ScrapFile for
HTML and Text but deleted afterwards and there are appropriate guards
to stop Reload just saying 'not found'; images run through ScrapFile and
there is no choice but to leave them there and do a conventional fetch).

All !RunD files now give a WimpSlot of 2304K. Some small changes to
the Argo and Ursula build Res files to make the menu trees more sensible.
Controls files now take 'file:/' instead of 'file://' in Protocols
section. Definitions at top of URLutils.c *not* altered, as then you
end up with invalid URLs - so it will accept 'file:/', but always generate
'file://'. This is because some browsers exports 'file:/'. Sigh.

make_no_[..._]memory_error functions now return a _kernel_oserror * rather
than void. It's always &erb returned, but it enables users to use a more
elegant 'return make_no_memory_error(1);', say, rather than something
like 'make_no_memory_error(1); return &erb;'. I obviously should've written
it like that at the outset, but never mind. All callers have been
appropriately updated.

The urlutils_leafname_from_url function now replaces illegal characters
(A7000 Welcome Guide p54...) in the leaf with legal alternatives.

Internal URL scheme is now a bit cleaner, with everything properly defined
in URLutils.h. All references to http:, file: and ftp:, with or without
a following '//' use the definitions in here now.

More tidying and some reorganising of Hotlist source. Auto-open delay is
now a Choices item. Some dependencies on statics removed (e.g. the
counting functions don't accumulate into the global item_number now).
The redraw functions used Wimp_TextOp - oops, so this has been amended
to use whatever is supported on your Wimp. This is now in a new function
(utils_text_width()), which the History menu routines also use (there was
a bug in the width routine there anyway, which is therefore fixed in
passing). Several other routines used Wimp_TextOp directly too, and
they have been altered to use the new function as well.

In hotlist code, one of the larger changes is in the API to hotlist_draw_r()
(formerly _hotlist_draw()) which now takes item widths and heights as
parameters - discovering these is quite slow, so doing it every time the
function calls itself recursively is a little less efficient than
passing the values in from elsewhere. Note that underscore prefixed
functions are being slowly renamed to _r suffixed functions, to match
the convention established by Tony Cheal with is table routines. This
makes it much more obvious when something is recursive, as the same
naming convention is used in every browser source file.

Finally, note that I intend to ditch SaveDBox and use an alternate window
with manual control of the messaging in Protocols.c. This will allow
various improvements which at present the SaveDBox operational methods
preclude. I'm going to have to do at least an alternate Window object for
the SaveDBox module to use soon in any case. Getting rid of SaveDBox will
help reduce, if only slightly, demands on the RMA.
@
text
@a66 4
/*                                               */
/* Returns:    Pointer to the URL (which at the  */
/*             moment is the buffer that you     */
/*             passed in).                       */
d69 1
a69 1
char * urlutils_pathname_to_url(char * path, int buffersize)
d94 41
a134 1
  return path;
d141 6
a146 5
/* into a Unix-style pathname, e.g. by swapping  */
/* '/' for '.'. The pathname you give is altered */
/* directly, so if you want to remember the path */
/* before translation, ensure there is a second  */
/* copy of it in another buffer somewhere.       */
a148 4
/*                                               */
/* Returns:    Pointer to the translated path    */
/*             (which at the moment is the       */
/*             buffer that you passed in).       */
d151 1
a151 1
char * urlutils_translate_pathname(char * path)
d172 1
a172 1
  return path;
@


1.4
log
@Very long log entry alert - but hey, beats 'Bug fixed' (sorry, Richard) ;-)

Open URL implementation more or less complete, though may undergo UI
revision at a later date to allow named frames to be targetted. Hope to use
the ideas in this code as the foundation for other general dialogues.

In token stream dump for TRACE builds, table head items were not indented
as far as they should have been - this is fixed; and manual toolbar redraw
routines have been removed. They never worked, were commented out, and
would never be used in that form anyway.

DragBox source added, but it isn't at all complete and won't work - this is
an 'in spare time' thing. We need custom drag boxes constrained to windows
for the hotlist, and unconstrained for frame border resizing... Hey ho.

Ancestor window extents match visible areas if there are frames (no more
scrolling framesets...!). Frame resizing works whilst new documents fetch
without pulling the extent down now. However, frame horizontal extents
never shrink until a reload which is nasty, and this is all due for a
rewrite. Frames border redrawing routine moved out of Redraw.c and into
Frames.c. Bug regarding the mouse rectangle and frame border widths
(rectangle was too large, so you could squash the edges) for edge-drag
frame resizes fixed.

Window width change reformat tolerance fixed; you could creep the window
width down or up forever without any reformat, and centred objects would
move but not be redrawn (thereby giving rise to subsequent redraw errors).

Filetype on objects saved through Shift+Click correct. Save Source dialogue
recognises if that source is plain text, rather than assuming HTML. A
browser that fetches a file remembers the old store size it had before the
save, so even though the data is now ditched, it reports the same amount of
data fetched afterwards (looked awful when this could, for example,
suddenly say '0' after a file save). Progress indicator is now fully aware
of one or many file saves inside a frameset and reports the number of
saves, a colon, and the cumulative saved data count, instead of reporting
the sum total of fetched data in all frames, including non-file save stuff
(note that for just 1 save, '1:' is not shown as a special case for the
most common condition). A bug related to this, where you could in fact only
do one fetch per frame*set*, has been corrected (only one fetch allowed per
frame still, this is unlikely to ever change).

Hotlist support added (D.Brown's source), with various bits of integration
and modification still in progress there. Note additions to the Messages
files. On the subject of Messages, the whole mucky business about what
goes in Messages or Choices (and a few bugs where lookup_choice was used
instead of lookup_token or vice versa) has been sorted out. Messages
contains, more or less, just that. Choices contains user configurable
stuff which generally can't mess things up too badly. A new file, Controls,
is a Messages file holding the non-user configurable choices, which can
generally make things go badly wrong if misused. A lot of these are tied
to the Res file. StrongED users can get these to automatically fold out
the various sections (EMail me for details). Sorry, but at the time of
writing, Zap doesn't do folding... =8*P

Two bugs with images. Asking for images to be shown in browser B when
browser A uses the same ones and was loaded first didn't work correctly,
and now does (a bit weird - browser A does the fetch and browser B does the
display...). Second one occurred when the background image was also used on
the page as a foreground image. This has been fixed by flagging background
images in the image_info structure, and checking this before cross
referencing. This bit also allowed the image_restart_fetches API to be
extended, so that just background or foreground images may be fetched if
they weren't already and the user asked the browser to show them. Before,
the whole lot had to be fetched together (so turning on 'display
backgrounds' will now kick off an image fetch if required, you don't
need to reload the page anymore).

Makefile copy options tweaked to be 'newer' (so if you're testing with some
temporary Choices file or something, it won't write over it at the end of
every export), and REMOTE_HOTLIST flag added for Customer builds - means
the Hotlist.c functions aren't needed; the old, hotlist-by-file method is
used. Added support for Customer build (see later), though there were very
few additions needed in practice.

Table printing fixed - in many ways it wasn't broken, it was image printing
causing the oddities ever since the global image pool was introduced (this
is, again, fixed). The 'reformat to fit page' option didn't work as coded
any more; tables store cell addresses in the HStreams, so you can't then do
a background reformat in a different browser. Hence, it now has to reformat
to the page width, print, then put the page back again, all in the actual
displayed browser. This doesn't feel as slow in use as it perhaps should,
considering what is going on... Note that a line of a defined fraction (see
Print.h) of page height will now split over page boundaries, so tall images
or tall tables don't cause problems now (aside from the obvious problem of
having the line split over a page at all!). There was a bug in the routine
to print from a given start point until 'n' pages had been filled, in that
it always filled 'n + 1' - now fixed. Finally, as part of the printing
tweaks, a new dialogue exists - PrintStyle - with a similarly named source
file added to deal with it.

Global history auto save / load done, but only to the Choices file path -
the whole browser is still strictly single user at present, with all the
extra work for a multiuser Customer environment yet to be done. This has
shown up a global history corruption problem which I haven't fixed yet.

Rationalising TBEvents.h - things are migrating out of it, and into more
appropriate sources (e.g. definitions relating to the Open URL dialogue are
going into OpenURL.h, etc.). Event codes were at one stage deliberately
diverged in numberspace from the component IDs of typical gadgets raising
the events, to avoid anyone getting confused and thinking the IDs and event
codes must match. However, this is in fact unlikely and it is much easier
to remember the fewer numbers that result from tying the two together where
possible. This has resulted in changes to event codes raised in the
following objects of all Res files: Authorise, Find, OpenURL, and
PrintStyle.

And finally - !Run[D] files for all variants updated to require the latest
toolbox and fetcher modules. All Res files updated for hotlists etc. and
sprites files updated appropriately. All Messages, Choices and Controls
files brought in sync., and an Customer build has been added (based on the
Desktop build binary with different resources).

That's all for now...
@
text
@a45 6
/* Local definitions */

#define FILEMETHOD "file://"
#define HTTPMETHOD "http://"
#define HTTPMSHORT "http:"

d77 1
a77 1
  len = strlen(FILEMETHOD);
d79 3
a81 4
  /* If the first part of the string doesn't match the FILEMETHOD */
  /* specifier (see top of this file for FILEMETHOD's definition) */
  /* then insert this text and convert the rest of the path to a  */
  /* file URL.                                                    */
d83 1
a83 1
  if (strncmp(path,FILEMETHOD,len))
d86 1
a86 1
    strncpy(path, FILEMETHOD, len);
d277 33
d334 1
a334 1
  p = strstr(url, "//");
d517 2
a518 2
  len = strlen(HTTPMETHOD);
  shl = strlen(HTTPMSHORT);
d520 2
a521 2
  /* If the first part of the string doesn't math the HTTPMETHOD  */
  /* specifier (see top of this file for HTTPMETHOD's definition) */
d527 1
a527 1
    strncpy(buffer, HTTPMETHOD, len);
d533 1
a533 1
  /* front of the string matches the HTTPMSHORT specifier (again */
d539 1
a539 1
  if (strlen(buffer) < buffersize - 2 && !strncmp(buffer, HTTPMSHORT, shl))
d695 8
a702 6
    if      (!strncmp(iurl + Int_URL_Len, "PExtImage", 9)) b->displayed = Display_External_Image;
    else if (!strncmp(iurl + Int_URL_Len, "PExtImNoH", 9)) b->displayed = Display_External_Image;
    else if (!strncmp(iurl + Int_URL_Len, "GoBack",    6)) b->displayed = Display_Previous_Page;
    else if (!strncmp(iurl + Int_URL_Len, "GoRecover", 9)) b->displayed = Display_Recovered_Page;
    else if (!strncmp(iurl + Int_URL_Len, "GoHome",    6)) b->displayed = Display_Home_Page;
    else b->displayed = Display_Fetched_Page; // Catch all for now...
d708 1
a708 1
/* urlutils_set_displayed()                      */
d823 1
a823 3
    make_no_fetch_memory_error(15);

    return &erb;
d828 1
a828 1
    if (tl & (1u<<13)) Printf("** malloccount (urlutils_dispatch): \0216%d\0217\n",malloccount);
d951 1
a951 1
    if (tl & (1u<<13)) Printf("** malloccount (uriutils_remove_from_queue): \0216%d\0217\n",malloccount);
@


1.3
log
@Updated Makefile to work better in folding text editors. More or less rewrote
Limits.h, and ensured consistent comment styling throughout all sources.
Fetch.c/h split to Fetch, FetchHTML and URLveneer. URLstat.c/h produced to
cope with this. OpenURL and Find sources created from bits in the Windows
source file that shouldn't have been there... These will get filled out
shortly. Note that a few functions in Fetch are due to be renamed and moved;
probably to Tokenutils.
@
text
@d705 1
a705 1
  protocols = atoi(lookup_token("ProtocolMax", 1, NULL));
d726 1
a726 1
               lookup_token(p, 1, NULL)))
d732 1
a732 1
      lookup_token(p, 1, NULL);
@


1.2
log
@Checking in mostly because its Friday... Quite a few little bug fixes
(adding up to a greater whole), which include removal of the dastardly
'invalid image number' errors that trace builds would raise from time to
time. Frame highlights are now better controlled (releaseably so).
Generally, this build represents the first genuinely promising version
of the browser for quite some time, despite the known library problems
with comment handling etc.
@
text
@d17 1
d19 1
d22 3
a24 3
/*          from various original functions, with  */
/*          new additions.                         */
/* History: 06-Feb-97: Created                     */
d42 1
a42 1
#include "Fetch.h"
d70 1
d157 1
d161 1
d240 12
d342 1
d390 1
a390 1
      char path[2048];
d411 1
d458 1
a458 1
      char path[2048];
d478 1
d556 1
d558 1
d661 1
d670 1
d699 1
a699 1
  char p[16];
d802 1
a802 1
    if (tl & (1u<<13)) Printf("** malloccount: %d\n",malloccount);
d925 1
a925 1
    if (tl & (1u<<13)) Printf("** malloccount: %d\n",malloccount);
a967 2

/*************************************************/
@


1.1
log
@First commit to CVS, at version 1.16 (Customer build).
@
text
@d332 2
d336 3
a338 1
  /* See if the variable exists */
d400 2
d404 3
a406 1
  /* See if the variable exists */
@
