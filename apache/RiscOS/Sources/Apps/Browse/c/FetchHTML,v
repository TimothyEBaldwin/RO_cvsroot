head	1.43;
access;
symbols
	Browse-2_16:1.43
	Browse-2_15:1.43
	Browse-2_14:1.43
	Browse-2_13:1.43
	Browse-2_12:1.43
	Browse-2_11:1.42
	Browse-2_10:1.42
	Browse-2_09:1.42
	ahodgkin_208_i4_2:1.41
	ahodgkin_208_i4:1.38
	ahodgkin_208_i3:1.37
	ahodgkin_208_i2:1.37
	ahodgkin_208_i1:1.37
	ahodgkin_207release:1.35
	ahodgkin_206release:1.32
	ahodgkin_205release:1.31
	ahodgkin_204release:1.31
	ahodgkin_202release:1.30
	ahodgkin_201release:1.29
	ahodgkin_200release:1.29
	ahodgkin_133beta:1.29
	ahodgkin_132beta:1.28
	ahodgkin_131beta:1.27
	ahodgkin_130beta:1.25
	ahodgkin_129:1.25
	ahodgkin_128beta:1.24
	ahodgkin_128alpha:1.24
	ahodgkin_127beta2:1.23
	ahodgkin_127beta:1.23
	ahodgkin_126beta:1.21
	ahodgkin_AW97patch:1.19
	ahodgkin_AW97:1.17;
locks; strict;
comment	@# @;


1.43
date	2006.03.13.22.06.19;	author ahodgkin;	state Exp;
branches;
next	1.42;

1.42
date	2005.04.26.09.42.34;	author ahodgkin;	state Exp;
branches;
next	1.41;

1.41
date	2000.11.14.08.45.05;	author ahodgkin;	state Exp;
branches;
next	1.40;

1.40
date	2000.05.31.15.58.31;	author ahodgkin;	state Exp;
branches;
next	1.39;

1.39
date	2000.03.03.11.11.33;	author ahodgkin;	state Exp;
branches;
next	1.38;

1.38
date	2000.03.03.09.20.03;	author ahodgkin;	state Exp;
branches;
next	1.37;

1.37
date	99.09.02.13.10.17;	author ahodgkin;	state Exp;
branches;
next	1.36;

1.36
date	99.03.30.15.51.40;	author ahodgkin;	state Exp;
branches;
next	1.35;

1.35
date	98.09.23.13.18.02;	author ahodgkin;	state Exp;
branches;
next	1.34;

1.34
date	98.09.07.11.46.41;	author ahodgkin;	state Exp;
branches;
next	1.33;

1.33
date	98.07.23.13.26.37;	author sbrodie;	state Exp;
branches;
next	1.32;

1.32
date	98.07.09.10.27.03;	author ahodgkin;	state Exp;
branches;
next	1.31;

1.31
date	98.04.16.08.14.09;	author ahodgkin;	state Exp;
branches;
next	1.30;

1.30
date	98.03.20.12.12.29;	author ahodgkin;	state Exp;
branches;
next	1.29;

1.29
date	98.02.13.17.31.59;	author ahodgkin;	state Exp;
branches;
next	1.28;

1.28
date	98.02.06.13.54.59;	author ahodgkin;	state Exp;
branches;
next	1.27;

1.27
date	98.01.31.10.55.13;	author ahodgkin;	state Exp;
branches;
next	1.26;

1.26
date	98.01.23.11.11.53;	author ahodgkin;	state Exp;
branches;
next	1.25;

1.25
date	97.12.12.11.17.46;	author ahodgkin;	state Exp;
branches;
next	1.24;

1.24
date	97.12.02.16.13.42;	author ahodgkin;	state Exp;
branches;
next	1.23;

1.23
date	97.11.20.16.04.30;	author ahodgkin;	state Exp;
branches;
next	1.22;

1.22
date	97.11.19.10.28.50;	author ahodgkin;	state Exp;
branches;
next	1.21;

1.21
date	97.10.30.17.11.00;	author ahodgkin;	state Exp;
branches;
next	1.20;

1.20
date	97.10.27.18.19.55;	author kbracey;	state Exp;
branches;
next	1.19;

1.19
date	97.10.22.13.15.50;	author ahodgkin;	state Exp;
branches;
next	1.18;

1.18
date	97.10.17.14.15.54;	author dbrown;	state Exp;
branches;
next	1.17;

1.17
date	97.10.16.13.23.07;	author ahodgkin;	state Exp;
branches;
next	1.16;

1.16
date	97.10.09.10.52.01;	author ahodgkin;	state Exp;
branches;
next	1.15;

1.15
date	97.10.08.12.17.25;	author kbracey;	state Exp;
branches;
next	1.14;

1.14
date	97.10.06.15.18.22;	author ahodgkin;	state Exp;
branches;
next	1.13;

1.13
date	97.10.03.18.30.54;	author ahodgkin;	state Exp;
branches;
next	1.12;

1.12
date	97.10.03.09.19.02;	author ahodgkin;	state Exp;
branches;
next	1.11;

1.11
date	97.09.26.12.35.56;	author ahodgkin;	state Exp;
branches;
next	1.10;

1.10
date	97.09.22.07.43.10;	author ahodgkin;	state Exp;
branches;
next	1.9;

1.9
date	97.09.18.12.37.11;	author kbracey;	state Exp;
branches;
next	1.8;

1.8
date	97.09.18.08.58.56;	author ahodgkin;	state Exp;
branches;
next	1.7;

1.7
date	97.09.14.19.18.13;	author ahodgkin;	state Exp;
branches;
next	1.6;

1.6
date	97.09.12.17.19.19;	author ahodgkin;	state Exp;
branches;
next	1.5;

1.5
date	97.09.09.14.13.10;	author ahodgkin;	state Exp;
branches;
next	1.4;

1.4
date	97.09.03.07.48.59;	author ahodgkin;	state Exp;
branches;
next	1.3;

1.3
date	97.08.31.18.38.12;	author ahodgkin;	state Exp;
branches;
next	1.2;

1.2
date	97.08.28.16.07.52;	author ahodgkin;	state Exp;
branches;
next	1.1;

1.1
date	97.08.18.09.23.51;	author ahodgkin;	state Exp;
branches;
next	;


desc
@@


1.43
log
@  PDF export, some major redraw structural changes, updated resources,
  new build system, extensive Makefile modifications, const/restrict
  additions, various bug fixes.
Detail:
  PDF export facility. SEE Docs.User FOR DETAILS (important!). Includes
  UI for headers/footers in Choices and option switch in Print dialogue
  box. Minor bug fixes include printing bullet points and, at long last,
  the "print dialogue box contents are not set up" problem. Redraw engine
  now based entirely on function pointers. Draw export routine replaces
  screen output functions with Draw output functions; PDF does similar.
  Coordinate scaling system in Scale.c/h to help. Makefile changes: Now
  supports a more consistent set of build variants and has minimal
  duplication of object and library lists. New build system: !Mk...
  script files removed, FrontEnd tool !MkBrowse replaces it. See !ReadMe
  (replacing old ReadMe) in root for details. Requires FrontEnd 1.29,
  HTMLLib 0.02 and ImageLib 0.04 (by CVS VersionNum). Updated resources:
  Some attempt to bring all variants to a working level, but not much
  testing. Only the Phoenix JavaScript capable builds (Unicode or normal)
  are fully up to date, though, including PDF UI additions. Many other
  minor tweaks, and extensive use of const and restrict qualifiers
  propagated through source code in response to their use in the new
  redraw system.
Admin:
  Draw and PDF export tested quite heavily. Appears to work well. Text
  file 'Docs.User' describes limitations. Note required new module and
  library versions listed above. Note that only JavaScript capable
  Phoenix resources are updated and only Phoenix was heavily tested.

Version 2.12. Tagged as 'Browse-2_12'
@
text
@/* Copyright 1997 Acorn Computers Ltd
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**************************************************************/
/* File:    FetchHTML.c                                       */
/*          (C) 2000 Pace Micro Technology PLC                */
/*          All rights reserved                               */
/*                                                            */
/* Purpose: Fetch functions that deal with HTMLLib data       */
/*          (getting more of it, freeing it, and so forth).   */
/*          Compare with higher higher level Fetch.h and      */
/*          FetchPage.h.                                      */
/*                                                            */
/* Author:  A.D.Hodgkinson.                                   */
/*                                                            */
/* History: 17-Aug-1997 (ADH): Created.                       */
/*          25-May-2000 (ADH): 64-wide comments adopted.      */
/**************************************************************/

#include <stdlib.h>
#include <stdio.h>
#include <string.h>

#include <kernel.h>
#include <swis.h>
#include <tboxlibs/flex.h>

#include <HTMLLib/HTMLLib.h>

#include <tboxlibs/wimp.h>
#include <tboxlibs/event.h>

#include "Global.h"
#include "MiscDefs.h"
#include "Utils.h"

#include "About.h"
#include "Authorise.h"
#include "Browser.h"
#include "Cookies.h"
#include "Encoding.h"
#include "EventLogs.h"
#include "Fetch.h" /* (Which itself includes URLstat.h) */
#include "Filetypes.h"
#include "History.h"
#include "JavaScript.h"
#include "List.h"
#include "Save.h" /* (For Save_ScrapFile only)*/
#include "URLutils.h"
#include "URLveneer.h"

#include "FetchHTML.h"
#include "ChoiceDefs.h"

/* Local structures */

typedef struct fetcher_state
{
  unsigned int handle;

  int          status;

  int          read;
  int          remaining;

} fetcher_state;

/* Statics */

static char          * fetch_buffer  = NULL; /* Address of buffer for getting data from the URL module in html_get_next_token. */

static int             fetch_waiting = 0;
static fetcher_state   fetch_state;

/* Local definitions */

#define FetchBufferSize 32768 /* Size of buffer for getting data from the URL module in html_get_next_token. */

/* Local compilation options */

#define DUMP_HEADERS "<Wimp$Scrap>.Headers"
#undef DUMP_HEADERS

/* Static function prototyps */

static _kernel_oserror * html_allocate_fetch_buffer (void);

static void              html_set_proxy             (unsigned int handle,  const char * url);

static void              html_extract_header_info   (browser_data * b, flex_ptr source);

static _kernel_oserror * html_build_internal_page   (browser_data * b, flex_ptr source, urlstat * up, char * url, char * ref_url, int ref_size);
static _kernel_oserror * html_transfer_to_store     (browser_data * b, flex_ptr source, urlstat * up, int r, int * size);

/**************************************************************/
/* html_allocate_fetch_buffer()                               */
/*                                                            */
/* Assuming fetch_buffer is NULL, malloc a block of           */
/* FetchBufferSize assigning the address to this static,      */
/* raising an error if the malloc fails.                      */
/**************************************************************/

static _kernel_oserror * html_allocate_fetch_buffer(void)
{
  fetch_buffer = malloc(FetchBufferSize); /* See top of this file */

  if (!fetch_buffer)
  {
    dprintf(("Fetc", "html_allocate_fetch_buffer: Exiting with error\n"));

    return make_no_cont_memory_error(8);
  }

  return NULL;
}

/**************************************************************/
/* html_set_proxy()                                           */
/*                                                            */
/* For a given URL and fetch handle, look in the Choices file */
/* for proxy details - if something relevant is found, set    */
/* this proxy for the session.                                */
/*                                                            */
/* For fetches with a protocol (scheme) matching HTTPmethod   */
/* (URLUtils.h), the tokens UseProxy and ProxyAddress are     */
/* looked for in Choices. For other fetches, the protocol     */
/* name is appended to the above; for example, an 'ftp:'      */
/* fetch would look for 'UseProxyftp' and 'ProxyAddressftp'.  */
/*                                                            */
/* If the "UseProxy..." entry is "yes" (case insensitive),    */
/* the "ProxyAddress..." entry is tried. If this is found,    */
/* the proxy is set.                                          */
/*                                                            */
/* Should the URL_Fetcher call made to set the proxy return   */
/* an error, this error is reported immediately; this         */
/* function then exits cleanly (no errors are thrown any      */
/* higher up).                                                */
/*                                                            */
/* In addition, "LOProxyExclusions" and other relevant        */
/* protocol-specific exclusion lists are looked at to see if  */
/* proxying should be avoided. See the Choices file for more. */
/*                                                            */
/* Parameters: Fetch handle for the session;                  */
/*                                                            */
/*             URL being fetched                              */
/**************************************************************/

static void html_set_proxy(unsigned int handle,  const char * url)
{
  url_description * d             = urlutils_return_description(url);
  char            * full_protocol = NULL;

  int               use_front_end = 1;

  char              t1[128];
  char              t2[128];

  if (d && d->host && d->protocol)
  {
    char * exclusions;
    int    result;

    /* First thing; see if the domain is listed as one we should not proxy. */
    /* lookup_choice is defined as looking up into a local buffer, so we    */
    /* can write zero terminators in this to make the searching easier. Do  */
    /* need to make sure the buffer contents are invalidated first.         */

    exclusions = list_get_malloc_list_string("LOProxyExclusions");

    if (exclusions)
    {
      result = urlutils_matches_special(d, exclusions);
      free(exclusions), exclusions = NULL;
      if (result) goto html_set_proxy_exit;
    }

    /* Any protocol specific exclusions? */

    strcpy(t1, "LOProxyExclude");

    if (strlen(t1) + strlen(d->protocol) + 1 < sizeof(t1))
    {
      strcat(t1, d->protocol);

      exclusions = list_get_malloc_list_string(t1);

      if (exclusions)
      {
        result = urlutils_matches_special(d, exclusions);
        free(exclusions), exclusions = NULL;
        if (result) goto html_set_proxy_exit;
      }
    }

    /* Now shift from things that exclude proxies, to things that specify  */
    /* them. These are the names we use for HTTP (backwards compatible...) */

    strcpy(t1, "UseProxy");
    strcpy(t2, "ProxyAddress");

    /* If we don't have an HTTP protocol, construct an appropriate */
    /* Choices file token name.                                    */

    full_protocol = malloc(strlen(d->protocol) + 2);
    if (!full_protocol) goto html_set_proxy_exit;

    /* First append a ':' to the url_description's protocol name, */
    /* so we can compare it to the HTTPmethod scheme string - we  */
    /* don't want to use a length-limited comparison as this may  */
    /* foul up with (e.g.) 'http:' and 'https:'. This is also the */
    /* way that url_set_proxy wants the method specifying.        */

    strcpy(full_protocol, d->protocol);
    strcat(full_protocol, ":");

    if (utils_strcasecmp(full_protocol, HTTPmethod))
    {
      /* The protocol didn't match, so if it'll fit, append the protocol */
      /* name to the token names filled into t1 and t2 above. If they    */
      /* won't fit, exit.                                                */

      if (strlen(t1) + strlen(d->protocol) + 1 < sizeof(t1))
      {
        strcat(t1, d->protocol);
      }
      else goto html_set_proxy_exit;

      if (strlen(t2) + strlen(d->protocol) + 1 < sizeof(t2))
      {
        strcat(t2, d->protocol);
      }
      else goto html_set_proxy_exit;

      use_front_end = 0;
    }

    /* We either want to use the HTTP settings - in which case the front-end */
    /* Choices may have changed, so we should read those and not Choices -   */
    /* or we may want to go to the Choices file directly.                    */

    if (use_front_end)
    {
      if (choices.use_proxy) show_error_ret(url_set_proxy(0,
                                                          handle,
                                                          choices.proxy_address,
                                                          HTTPmethod,
                                                          0));
    }
    else
    {
      /* t1 and t2 now say whether or not to use a proxy, and which */
      /* proxy to use, respectively. So, do we use a proxy?         */

      if (utils_strcasecmp(lookup_choice(t1, 0, 0), "yes")) goto html_set_proxy_exit;

      /* Do we know which one? */

      if (!strcmp(lookup_choice(t2, 0, 0), "!")) goto html_set_proxy_exit;

      /* We have a proxy to use, so set it */

      show_error_ret(url_set_proxy(0,
                                   handle,
                                   lookup_choice(t2, 0, 0),
                                   full_protocol,
                                   0));
    }
  }

  /* Exit, freeing the URL description as we go */

html_set_proxy_exit:

  if (d)             urlutils_free_description(d);
  if (full_protocol) free(full_protocol);

  return;
}

/**************************************************************/
/* html_get()                                                 */
/*                                                            */
/* Fetches and optionally starts parsing HTML.                */
/*                                                            */
/* Parameters: Pointer to URL to fetch;                       */
/*                                                            */
/*             Pointer to a pointer for extra data for POST   */
/*             etc. (allows this to be in a flex block);      */
/*                                                            */
/*             Pointer to an int into which a handle for this */
/*             fetch will be placed;                          */
/*                                                            */
/*             The fetch method, e.g. POST or GET;            */
/*                                                            */
/*             Pointer to the user name for MailServ (if in a */
/*             multiuser environment);                        */
/*                                                            */
/*             1 to allow parsing, else 0;                    */
/*                                                            */
/*             1 to allow proxying, else 0 (e.g. to force a   */
/*             refetch, rather than going via. a cache).      */
/**************************************************************/

_kernel_oserror * html_get(char * url, char ** extradata, int * handle, int method,
                           char * user, int allowparse, int proxy, const char * referer)
{
  _kernel_oserror * e;
  int               ok;
  unsigned int      h;

  dprintf(("Fetc", "html_get: Called\n"));

  *handle = 0;

  /* Register the session with the URL module */

  e = url_register(0, &h);

  /* Deal with proxying if necessary */

  if (!e) html_set_proxy(h, url);

//  if (!e && choices.use_proxy)
//  {
//    char   method[64];
//    char * method_ptr;
//    int    method_len;
//
//    /* Extract the fetch method from the proxy address */
//
//    method_ptr = strstr(choices.proxy_address, ":");
//
//    if (method_ptr)
//    {
//      method_len = (int) method_ptr - (int) choices.proxy_address + 1;
//      if (method_len > sizeof(method) - 1) method_len = sizeof(method) - 1;
//      strncpy(method, choices.proxy_address, method_len);
//      method[method_len] = 0;
//    }
//    else strncpy(method, "http:", sizeof(method));
//
//    e = url_set_proxy(0, h, choices.proxy_address, method, 0);
//  }

  if (!e)
  {
    urlstat * up;

    dprintf(("Fetc", "html_get: Session registered, ID is %d\n",h));

    e = urlstat_add_entry(1, &up);

    if (e)
    {
      url_deregister(0,h);
      return e;
    }

    /* Initialise the new structure */

    up->session    = *handle = (int) h; /* The fetch's session handle                      */
    up->type       = TYPE_HTMLFILE;     /* Type of file - state it is an HTML file for now */
    up->fetching   = 1;                 /* We are still fetching                           */
    up->method     = method;            /* Current fetch method                            */
    up->extradata  = NULL;              /* Filled in later, if there is extra data         */
    up->allowparse = allowparse;        /* Do we parse the data?                           */

    /* If there is any extra data for POST or whatever, deal with it. */
    /* The POST request entries must come first in the extra header   */
    /* info, so that the browser can make the assumption that         */
    /* everything from Content-Type forwards may be stripped in the   */
    /* event of a redirection when the current fetch method is POST.  */

    if (extradata && *extradata)
    {
      int len;

      len = strlen(*extradata);

      /* Allocate space for the extra data, the anchor stored in up->extradata */

      dprintf(("LMem", "html_get: flex_alloc %d for 'extradata' store\n",len + 3));

      if (!flex_alloc((flex_ptr) &up->extradata, len + 3))
      {
        url_deregister(0,h);

        return make_no_fetch_memory_error(2);
      }
      else
      {
        char head[80];

        #ifdef TRACE
          flexcount += (len + 3);
          dprintf(("CFle", "**   flexcount: %d\n",flexcount));
        #endif

        /* CR+LF into the top of the new block of memory */

        up->extradata[0] = '\r';
        up->extradata[1] = '\n';

        /* Copy the extra data under the CR+LF */

        strcpy(up->extradata + 2, *extradata);

        /* Header entry for the extra data - again, the removal routines in the */
        /* fetcher's redirection code assume that this comes after Content-Type */
        /* and the body content comes after this, to make life easy there.      */

        sprintf(head, "Content-Length: %d", len);

        /* Insert the header entries above the extra data already in the block. */

        ok = html_insert_header(head, (flex_ptr) &up->extradata);

        /* (html_insert_header returns 1 for success, 0 for memory claim failure) */

        if (!ok)
        {
          url_deregister(0, h);

          return make_no_fetch_memory_error(3);
        }

        StrNCpy0(head, "Content-Type: application/x-www-form-urlencoded");
        ok = html_insert_header(head, (flex_ptr) &up->extradata);

        if (!ok)
        {
          url_deregister(0, h);

          return make_no_fetch_memory_error(4);
        }
      }
    }

    #ifndef SINGLE_USER

      /* If user details are given, insert the appropriate header entry */

      if (user)
      {
        char head[Limits_Multi_UserName + 80];

        sprintf(head, "Mailserv-User: %s", user);
        ok = html_insert_header(head, (flex_ptr) &up->extradata);

        if (!ok)
        {
          url_deregister(0, h);

          return make_no_fetch_memory_error(5);
        }
      }

    #endif

    /* If we aren't to use a proxy - actually, this is Customer-speak */
    /* for no cache - say so in the header, in various ways.           */

    if (!proxy)
    {
      /* For Customer compatability first, most servers will get the */
      /* second, and newer servers prefer the last.                   */

      ok         = html_insert_header("X-NoProxy:",             (flex_ptr) &up->extradata);
      if (ok) ok = html_insert_header("Pragma:no-cache",        (flex_ptr) &up->extradata);
      if (ok) ok = html_insert_header("Cache-Control:no-cache", (flex_ptr) &up->extradata);

      if (!ok)
      {
        url_deregister(0, h);

        return make_no_fetch_memory_error(6);
      }
    }

    /* Add referrer if required */

    if (referer && choices.send_referer != Choices_SendReferer_Never)
    {
      char * ptr;

      switch (choices.send_referer)
      {
        default:
        case Choices_SendReferer_WhenHTTP:
        {
          if (strncmp(referer, "http:", 5) != 0) break;

          /* (Fall through) */
        }

        case Choices_SendReferer_Always:
        {
          ptr = malloc(sizeof("Referer: ") + strlen(referer));

          if (ptr)
          {
            sprintf(ptr, "Referer: %s", referer);
            ok = html_insert_header(ptr, (flex_ptr) &up->extradata);
            free(ptr);
            if (!ok)
            {
              url_deregister(0, h);
              return make_no_fetch_memory_error(5);
            }
          }
        }
        break;
      }
    }

    /* Last but not least, do, er, something... */

    {
      char   c = 0;
      char * p = NULL;

      /* If non-zero on exit, p will point to the position of a hash */
      /* in the URL (i.e., this finds out if an anchor is specified) */

      p = fetch_find_name_tag(url);

      /* If there is a hash, turn it into a zero for now so the string */
      /* contains just the URL and not the anchor.                     */

      if (p) c = *p, *p = 0;

      e = url_get_url(URL_GetURL_AgentGiven, /* Should use a custom User Agent */
                      h,                     /* Session handle                 */
                      method,                /* Fetch method                   */
                      url,                   /* URL to get                     */
                      &up->extradata,        /* Any extra data for POST etc.   */
                      NULL,                  /* (Would be a status word)       */
                      2);                    /* Mode; 2 = header and data      */

      /* Put the hash back if was removed earlier. */

      if (p) *p = c;
    }
  }

  #ifdef TRACE

    if (!e) dprintf(("Fetc", "html_get: Successful\n"));
    else    dprintf(("Fetc", "html_get: Exitting with an error\n"));

  #endif

  return e;
}

/**************************************************************/
/* html_insert_header()                                       */
/*                                                            */
/* Inserts a string into the header for an HTML fetch (for    */
/* POST). Puts it at the top.                                 */
/*                                                            */
/* Parameters: Pointer to the null terminated string to       */
/*             insert (this ends up CR+LF terminated in the   */
/*             header);                                       */
/*                                                            */
/*             Pointer to a flex anchor, which points to      */
/*             existing header data or is NULL if there is no */
/*             header at the time of the function call.       */
/*                                                            */
/* Returns:    1 if successful, or 0; you must externally     */
/*             generate an error appropriate to the memory    */
/*             claim having failed.                           */
/**************************************************************/

int html_insert_header(const char * header, flex_ptr data)
{
  if (header)
  {
    int ok, s, len;

    len = strlen(header) + 2;

    /* 'data' points to an anchor; if this isn't null, find the */
    /* size of the block the anchor points to                   */

    if (*data) s = flex_size(data);
    else s = 0;

    /* If the block is > 0 bytes, extend it to a block big      */
    /* enough to hold the extra header data, else allocate a    */
    /* new block to hold it. Note that s will be zero if a new  */
    /* block was allocated, else it holds the old block size.   */

    #ifdef TRACE
      if (s) dprintf(("LMem", "html_insert_header: flex_extend to %d for header store\n",len + s));
      else   dprintf(("LMem", "html_insert_header: flex_alloc %d for header store\n",len + 1));
    #endif

    if (s) ok = flex_extend(data, len + s);
    else   ok = flex_alloc(data, len + 1); /* Note len *plus 1*. */

    if (!ok) return 0;

    #ifdef TRACE
      if (s) flexcount += len;
      else   flexcount += (len + 1);
      dprintf(("CFle", "**   flexcount: %d\n",flexcount));
    #endif

    /* Shuffle the header data down to make room for the new    */
    /* stuff at the top, if there was any data there to move.   */

    dprintf(("Stre", "\0213html_insert_header: memove from &%08X to &%08X for %d bytes\0217\n",((int) (*data)) + len, (int) (*data), s));

    if (s) memmove((void *) (((int) (*data)) + len), *data, s);

    /* Copy the new data into the top of the header. Don't want */
    /* to overflow so use strncpy for extra caution...          */

    strncpy(*data, header, len - 2);

    /* Terminate the string with CR+LF                          */

    ((char *) (*data))[len - 2] = '\r';
    ((char *) (*data))[len - 1] = '\n';

    /* If s is zero, i.e. a new block was created here, make    */
    /* sure it ends in zero (so C will think the string has     */
    /* ended properly if a string is read from the buffer). We  */
    /* can reference (array)[len] as the block allocation was   */
    /* done to len plus 1 bytes (see above).                    */

    if (!s) ((char *) (*data))[len] = 0;
  }

  return 1;
}

/**************************************************************/
/* html_close()                                               */
/*                                                            */
/* Closes the specified handle, aborting any fetch and        */
/* freeing up memory relating to it.                          */
/*                                                            */
/* Parameters: A fetch handle (usually from the               */
/*             browser_data->fetch_handle field).             */
/**************************************************************/

_kernel_oserror * html_close(int handle)
{
  urlstat * up;

  dprintf(("Fetc", "html_close: Called\n"));

  url_deregister(0, handle);

  /* If the Fetcher was waiting for some reason - e.g. a Cookies  */
  /* dialogue - we want to clear the stacked state or it will     */
  /* lock itself out (the stored fetch handle will not be matched */
  /* again).                                                      */

  if (fetch_waiting && fetch_state.handle == handle) fetch_waiting = 0;

  /* It's another linked list traversal... As long as we aren't at the */
  /* end of the list, and we haven't reached the item relating to this */
  /* fetch, keep looking.                                              */

  up = urlstat_find_entry(handle);

  /* After the above loop, 'up' points to the structure for this */
  /* fetch or is null; in the latter case, give an error.        */

  if (!up)
  {
    erb.errnum = Utils_Error_Custom_Fatal;

    StrNCpy0(erb.errmess,
             lookup_token("StrNotFd:Internal error: Can't find structure in %0.",
                          0,
                          "html_close"));

    dprintf(("Fetc", "html_close: Exiting with error\n"));

    return &erb;
  }

  /* If there is HTMLLib derived data attached, deal with this */

  if (up->stream)
  {
    unsigned int   context = HtmlReturnContext(up->stream);
    browser_data * browser = last_browser;

    /* Should Never Happen...! */

    if (!context)
    {
      erb.errnum = Utils_Error_Custom_Fatal;

      StrNCpy0(erb.errmess,
               lookup_token("NoContxt:Serious internal error - Block is already free or was not HtmlAlloc'd in html_close; must exit immediately.",
                            0,
                            0));

      return &erb;
    }

    /* Ensure that any HStream pointers inside any current browser_data */
    /* structures are not part of this stream - if so, clear them.      */

    while (browser)
    {
      /* For now, just a few selected items */

      if (browser->selected && HtmlReturnContext(browser->selected) == context)
      {
        /* We're throwing away the HStream list, so there's no point */
        /* trying to redraw anything (for all we know the line list  */
        /* could've gone by now as well). So don't call              */
        /* browser_clear_selection!                                  */

        browser->selected = NULL;
      }

      if (browser->highlight && HtmlReturnContext(browser->highlight) == context)
      {
        /* Similarly (see above), don't call browser_clear_highlight here */

        browser->highlight = NULL;
      }

      if (browser->pointer_over && HtmlReturnContext(browser->pointer_over) == context) browser->pointer_over = NULL;

      /* Don't forget the main document stream and related bits... */

      if (browser->stream && HtmlReturnContext(browser->stream) == context)
      {
        /* urlbdata and similar may or may not point into the token stream; */
        /* this is an implementation decision that this function will not   */
        /* assume. Therefore, the caller is responsible for clearing these  */
        /* fields before calling this function if the data that the fields  */
        /* point to is part of the stream that we are freeing.              */

        browser->stream = NULL;
      }

      /* Move on to the next browser */

      browser = browser->previous;
    }

    #ifdef TRACE
      if (up->stream)
      {
        dprintf(("LMem", "html_close: Calling HtmlStreamFree on %p\n", up->stream));
        dprintf(("Stre", "\0212html_close: Closing stream %p\0217\n",  up->stream));
      }
    #endif

    HtmlStreamFree(up->stream);
  }

  /* If there is extra context data allocated, free it */

  if (up->context)
  {
    dprintf(("LMem", "html_close: free block %p for 'context' field of 'urlstat' structure\n",up->context));

    HtmlEndParse(up->context);
    up->context = NULL;
  }

  #ifdef TRACE
    if (up->extradata)
    {
      dprintf(("LMem", "html_close: flex_free block %p for 'extradata' field of 'urlstat' structure\n",&up->extradata));
      flexcount -= flex_size((flex_ptr) &up->extradata);
      dprintf(("CFle", "**   flexcount: %d\n",flexcount));
    }
  #endif

  /* If there is extra flex data attched, free this too */

  if (up->extradata) flex_free((flex_ptr) &up->extradata);

  /* Finally, get rid of the structure itself */

  urlstat_remove_entry(up);

  dprintf(("Fetc", "html_close: Successful\n"));

  return NULL;
}

/**************************************************************/
/* html_extract_header_info()                                 */
/*                                                            */
/* Get information from HTTP response headers, e.g. the       */
/* Last-modified date.                                        */
/*                                                            */
/* Parameters: Pointer to a browser_data struct relevant to   */
/*             the headers;                                   */
/*                                                            */
/*             Flex anchor for a block holding the HTTP       */
/*             response headers to look through.              */
/**************************************************************/

static void html_extract_header_info(browser_data * b, flex_ptr headers)
{
  int     size, current;
  int     found;
  char ** cast = (char **) headers;

  /* Sanity check */

  if (
       !b
       ||

       #ifdef JAVASCRIPT
         !b->bcx
         ||
       #endif

       !headers
       ||
       !*headers
     )
     return;

  /* May not have a zero terminator; must not go off end of block */

  size = flex_size(headers);

  /* Look for header entries either from offset zero, or after */
  /* a '\r\n'. The Fetcher specs say we'll get back HTTP 1.0   */
  /* compliant headers, so we know it'll be CR+LF at the end   */
  /* of each item.                                             */

  found = 0;

  for (current = 0; current < size; current ++)
  {
    if (current == 0)
    {
      /* A header line is either at the top of the block... */

      found = 1;
    }
    else
    {
      /* ...or we have to look for it */

      found = 0;

      /* Keep looping around until we run out of block or */
      /* stop getting '\r\n' pairs.                       */

      while (current < size && (*cast)[current] == '\r')
      {
        /* If we have '\r', look for a '\n' after it */

        current++;
        if (current >= size) break;

        if ((*cast)[current] == '\n') found ++;

        current++;
      }

      /* If we ran off the block or had more than one consecutive */
      /* '\r\n' (end of headers), exit.                           */

      if (current >= size || found > 1) break;
    }

    /* Did we find a header line? */

    if (found == 1)
    {
      int old_budge;
      int lm_len = sizeof("last_modified: ") - 1;

      /* Only do the case insensitive comparisons if we won't fall out of */
      /* the buffer! Lock flex as we'll be passing in a pointer to a flex */
      /* block and the heap might want to shift across the function call. */

      old_budge = flex_set_budge(0);

      if (
           lm_len + current < size &&
           !utils_strncasecmp((*cast) + current,
                              "last-modified: ",
                              lm_len)
         )
      {
        int lm_contents_len = 0;
        int local_current   = current + lm_len;

        flex_set_budge(old_budge);

        /* Since there's only the one string extraction going on here, */
        /* I'll keep this inline. You'd want to take it out as a       */
        /* function if more header entries were to be thus parsed of   */
        /* course.                                                     */

        while (local_current < size)
        {
          if ((*cast)[local_current++] >= ' ') lm_contents_len ++;
          else break;
        }

        free (b->last_modified);

        if (lm_contents_len > 0) b->last_modified = malloc(lm_contents_len + 1);
        else                     b->last_modified = NULL;

        if (b->last_modified)
        {
          strncpy(b->last_modified, (*cast) + current + lm_len, lm_contents_len);
          b->last_modified[lm_contents_len] = '\0';

          #ifdef JAVASCRIPT

            /* Try to help JavaScript out with funny last modified dates */

            javascript_fix_invalid_date_format(b->last_modified);

          #endif
        }
      }
      else /* if (...), else if (...), etc. for other checks - none for now though */
      {
        /* Restore flex budge state either way */

        flex_set_budge(old_budge);
      }
    }
  }
}

/**************************************************************/
/* html_build_internal_page()                                 */
/*                                                            */
/* Build an internal page, in such a way that the fetcher     */
/* (html_get_next_token) will think it has got the data       */
/* through a call to url_read_data and the fetch has          */
/* finished.                                                  */
/*                                                            */
/* This code used to be in-line, and so the function is       */
/* highly specialised... Munging of fetch flags etc. is left  */
/* to the fetcher to try and make this more independent.      */
/*                                                            */
/* Parameters: Pointer to a browser_data struct relevant to   */
/*             the fetch;                                     */
/*                                                            */
/*             flex_ptr for the intended source store in      */
/*             which the page is built;                       */
/*                                                            */
/*             Pointer to the fetch's urlstat struct to avoid */
/*             wasting time finding it from the browser_data  */
/*             pointer;                                       */
/*                                                            */
/*             Actual URL being fetched (may not be the same  */
/*             as the reference base URL);                    */
/*                                                            */
/*             Pointer to a copy of the URL in a buffer (the  */
/*             contents may be updated) - the caller should   */
/*             be using this as the reference base URL at all */
/*             times;                                         */
/*                                                            */
/*             Size of that buffer.                           */
/**************************************************************/

static _kernel_oserror * html_build_internal_page(browser_data * b, flex_ptr source, urlstat * up,
                                                  char * url, char * ref_url, int ref_size)
{
  int    ok;
  char * extra = "";
  char * tail  = "";
  int    len, exoff, toff;

  /* Unless we know we should keep it, get rid of any existing source */

  if (*source && b->displayed != Display_JavaScript_Info) flex_free(source);

  /* Work out the length that the HTML file we're about to generate will be */

  switch (b->displayed)
  {
    case Display_JavaScript_Info:
    {
      len             = 0;
      b->page_is_text = 1;
      up->type        = TYPE_TEXTFILE;
    }
    break;

    case Display_External_Image:
    {
      int protolen;

      /* Look up the token embedded in the URL */

      lookup_token(url + Int_URL_Len, 1, 0);

      /* Find a ':' separating extra information and point just past it */

      exoff = urlutils_internal_extra(url);
      if (exoff) extra = url + exoff;

      len = strlen(tokens) + 1;

      if (*extra)
      {
        toff = urlutils_internal_tail(url);
        if (toff) tail = url + toff;
      }

      /* Is this a system variable name for fetching, e.g. Wimp$Scrap? */

      protolen = strlen(FileMethod ProtocolSepShort "<"); /* (URLutils.h) */

      if (
           !strncmp(extra,
                    FileMethod ProtocolSepShort "<",
                    protolen)
           &&
           extra[strlen(extra) - 1] == '>'
         )
      {
        int              required;
        _kernel_swi_regs r;

        /* We'll have to trash the ref_url block. We know ref_url is at     */
        /* least as long as URL, so extract the system variable name to it. */

        strncpy(ref_url, extra + protolen, strlen(extra) - protolen - 1); /* -1 to skip the closing '>' */
        ref_url[strlen(extra) - protolen - 1] = 0;

        /* Now find out how long the expanded form would be */

        r.r[0] = (int) ref_url;
        r.r[1] = (int) NULL;
        r.r[2] = -1;
        r.r[3] = 0;
        r.r[4] = 0;

        /* _swix will not work correctly for this particular SWI if */
        /* requiring the returned R2 value. Something to do with    */
        /* the call relying on generating an error, but _swix spots */
        /* it and pulls out earlier than the call expects. Or some  */
        /* such thing...                                            */

        _kernel_swi(OS_ReadVarVal, &r, &r);

        required = -r.r[2];

        /* Woah - system variable wasn't defined... */

        if (!required)
        {
          erb.errnum = Utils_Error_Custom_Normal;

          strcpy(erb.errmess, "<");
          strcat(erb.errmess, ref_url);
          strcat(erb.errmess, ">");
          strcat(erb.errmess, lookup_token("NotDefined: not defined.",0,0));

          return &erb;
        }

        if (required < 0 || required >= ref_size - 1) /* -1 = allow for terminator */
        {
          /* Well, we sort of haven't got enough memory. Ahem. */

          return make_no_memory_error(8);
        }

        /* Otherwise, expand the variable (_swix is OK here as we don't */
        /* want any returned register value).                           */

        _swix(OS_ReadVarVal,
              _INR(0,4),

              ref_url,
              ref_url,
              ref_size,
              0,
              4);

        /* Ensure it is terminated correctly */

        ref_url[required - 1] = 0;

        /* Turn it into a fetchable URL */

        urlutils_pathname_to_url(ref_url, ref_size);

        /* Point to this URL */

        extra = url = ref_url;
      }

      /* Note that this is a very slow function call... */

      len = utils_len_printf(tokens, extra, extra, tail);

      if (len < 0)
      {
        /* If the above fails, do our best to calculate the length. */
        /* This will always overestimate the size (safer to do this */
        /* than underestimate!).                                    */

        len = strlen(tokens) + 1;

        /* For external images, need to fit the extra data in twice, and */
        /* try to find a filename separator for a picture caption (put   */
        /* this in 'tail').                                              */

        if (*extra) len += strlen(extra) * 2 + strlen(tail) + 2;
      }
    }
    break;

    case Display_Scrap_File:
    {
      int found, type;

      /* Find the file length */

      _swix(OS_File,
            _INR(0,1) | _OUT(0) | _OUT(4) | _OUT(6),

            23, /* Read catalogue info for named, stamped object */
            Save_ScrapFile,

            &found,
            &len,
            &type);

      if (found != 1)
      {
        erb.errnum = Utils_Error_Custom_Normal;

        /* Error message will either be 'can't find the page', or, if this is */
        /* a frame and the frame source matches the fetching URL, 'can't find */
        /* the frame'.                                                        */

        if (
             b->ancestor          &&
             b->frame             &&
             b->frame->src        &&
             browser_fetch_url(b) &&
             !strcmp(b->frame->src, browser_fetch_url(b))
           )
        {
          StrNCpy0(erb.errmess,
                   lookup_token("WhatFrame:The sending application could not supply the page contents for this frame.",
                                0,
                                0));
        }
        else
        {
          StrNCpy0(erb.errmess,
                   lookup_token("WhatScrap:Cannot find the page to load; the sending application may have died.",
                                0,
                                0));
        }

        return &erb;
      }

      /* Is this a text file? */

      if (type == FileType_TEXT)
      {
        b->page_is_text = 1;
        up->type        = TYPE_TEXTFILE;
      }
      else b->page_is_text = 0;
    }
    break;

    case Display_About_Page:
    {
      len = 0;
    }
    break;
  }

  /* If required, claim memory for the page; complain if this fails */

  if (len) ok = flex_alloc(source, len);
  else     ok = 1;

  if (!ok)
  {
    dprintf(("Fetc", "html_build_internal_page: Exiting with error\n"));

    return make_no_cont_memory_error(1);
  }

  /* Construct the page in the claimed block (or build it in a */
  /* new block).                                               */

  switch (b->displayed)
  {
    case Display_About_Page:
    {
      RetError(about_build_page(source));
    }
    break;

    case Display_External_Image:
    {
      memset(*source, 0, len);
      sprintf(*source, tokens, extra, extra, tail);
    }
    break;

    case Display_Scrap_File:
    {
      FILE * file;

      /* Load and delete the scrap file */

      file = fopen(Save_ScrapFile, "rb");

      if (!file) RetLastE;

      if (fread(*source, 1, len, file) < len)
      {
        StrLastE;

        fclose(file);

        return &erb;
      }

      fclose(file);
      remove(Save_ScrapFile);
    }
    break;
  }

  return NULL;
}

/**************************************************************/
/* html_transfer_to_store()                                   */
/*                                                            */
/* Another ex-fetcher function (see for example               */
/* html_build_internal_page), this time to move data from     */
/* fetch_buffer to the given source store.                    */
/*                                                            */
/* Parameters: Pointer to a browser_data struct relevant to   */
/*             the fetch;                                     */
/*                                                            */
/*             flex_ptr for the current (or intended, if no   */
/*             data has been fetched in this session before)  */
/*             source store;                                  */
/*                                                            */
/*             Pointer to the fetch's urlstat struct to avoid */
/*             wasting time finding it from the browser_data  */
/*             pointer;                                       */
/*                                                            */
/*             Amount of data that was read into the fetch    */
/*             buffer in bytes;                               */
/*                                                            */
/*             Pointer to int into which the number of bytes  */
/*             fetched so far is placed (worked out from the  */
/*             size of the source store after moving data     */
/*             into it), or NULL if you're not interested.    */
/**************************************************************/

static _kernel_oserror * html_transfer_to_store(browser_data * b, flex_ptr source, urlstat * up, int r, int * size)
{
  int ok, oldsize;

  /* 'fetched' is a flag which if set indicates at least 1 byte has been */
  /* got so far. If fetched is zero, and there is data in the source     */
  /* store (i.e. 'source' is not NULL) then free up the store as it does */
  /* not hold any valid data (must be from an old fetch).                */

  if (!up->fetched && *source)
  {
    #ifdef TRACE
      dprintf(("LMem", "html_transfer_to_store: (1) flex_free block %p which held page source\n",source));
      flexcount -= flex_size(source);
      dprintf(("CFle", "**   flexcount: %d\n",flexcount));
    #endif

    flex_free(source);
    *source = NULL;
  }

  /* Signal that there's definitely data fetched now. */

  up->fetched = 1;

  /* If there's store allocated at this point, it holds valid source; extend */
  /* it by the number of bytes read from the url_read_data call. Else, alloc */
  /* a new buffer to hold the data.                                          */

  #ifdef TRACE
    if (*source) dprintf(("LMem", "html_transfer_to_store: flex_extend by %d to %d for page source store\n",r,flex_size(source) + r));
    else         dprintf(("LMem", "html_transfer_to_store: flex_alloc %d for page source store\n",r));
  #endif

  if (*source)
  {
    oldsize = flex_size(source);
    ok = flex_extend(source, oldsize + r);
  }
  else
  {
    oldsize = 0;
    ok = flex_alloc(source, r);
  }

  #ifdef TRACE
    flexcount += r;
    dprintf(("CFle", "**   flexcount: %d\n",flexcount));
  #endif

  if (size) *size = oldsize + r;

  /* Report an error if the allocation failed */

  if (!ok)
  {
    dprintf(("Fetc", "html_transfer_to_store: Exiting with error\n"));

    return make_no_cont_memory_error(1);
  }

  /* The data block has been created/extended successfully, so copy the */
  /* data from the url_read_data call into it.                          */

  dprintf(("Stre", "\0216html_transfer_to_store: memcpy from %p to %p for %d bytes\0217\n",((char *) (*source)) + oldsize, fetch_buffer, r));

  memcpy(((char *) (*source)) + oldsize, fetch_buffer, r);

  return NULL;
}
/**************************************************************/
/* html_get_next_token()                                      */
/*                                                            */
/* Gets a chunk of document source from a given fetch handle, */
/* and may generate new HStream structures as the document is */
/* passed over to the HTML library parser.                    */
/*                                                            */
/* Parameters: Pointer to a browser_data struct relevant to   */
/*             the fetch or NULL;                             */
/*                                                            */
/*             The fetch handle;                              */
/*                                                            */
/*             Pointer to int into which the number of bytes  */
/*             still to be fetched is placed;                 */
/*                                                            */
/*             Pointer to int into which the number of bytes  */
/*             fetched so far is placed;                      */
/*                                                            */
/*             Pointer to an HStream *, into which the        */
/*             address of the base of the token list is       */
/*             written, or NULL to signal 'not ready';        */
/*                                                            */
/*             Pointer to an int, into which a reason code is */
/*             placed:                                        */
/*                                                            */
/*             0: Token has been received OK,                 */
/*             1: We are waiting for something,               */
/*             2: A redirect has been detected (in this case, */
/*                *remaining will point at the new URL),      */
/*             3: This data is not parseable (in this case,   */
/*                *remaining holds a filetype);               */
/*                                                            */
/*             Pointer to pointer to the store for the whole  */
/*             of the data fetched so far (if any), be it an  */
/*             HTML document, image, or whatever;             */
/*                                                            */
/*             Pointer to string holding the URL that is      */
/*             being fetched;                                 */
/*                                                            */
/*             1 if this is an image fetch, else 0 for HTML   */
/*             or unknown.                                    */
/*                                                            */
/* Assumes:    That if the browser_data struct pointer is     */
/*             NULL, the fetch is not for an internal URL.    */
/*             The other pointers must NOT be NULL unless it  */
/*             is specifically stated that they may be in the */
/*             parameters list.                               */
/**************************************************************/

_kernel_oserror * html_get_next_token(browser_data * b, unsigned int handle, int * remaining, int * size,
                                      HStream ** token, int * waiting, flex_ptr source, char * url, int image)
{
  /* Because this is a fairly large and complex state machine, and the code */
  /* is not at all clean due to a long and colourful development history,   */
  /* there are highlight comment blocks throughout to give an overview of   */
  /* what each section of the code is doing.                                */

  _kernel_oserror * e = NULL;
  urlstat         * up;

  char              ref_url[Limits_URL];

  int               read = 0;

  /**************************************************/
  /* Entry point - set up initial state information */
  /**************************************************/

  dprintf(("Fetc", "html_get_next_token: Called\n"));

  /* Start in the default state of having no HStream to pass back */
  /* through *token. Signal that we're waiting for now, and       */
  /* ensure a fetch buffer is allocated.                          */

  if (token) *token = NULL;
  *waiting          = 1;

  if (!fetch_buffer) RetError(html_allocate_fetch_buffer());

  /* If there are cookies pending, jump straight out! */

  if (cookies_pending())
  {
    /* If we've not got a dialogue box open, something went wrong - */
    /* cookies got queued without the browser knowing. So accept    */
    /* the whole lot and get on with the fetch!                     */

    if (!cookies_dialogue_open())
    {
      RetError(cookies_accept_all());
    }
    else goto html_get_next_token_waiting_jump_point;
  }

  /* Get the urlstat structure for this fetch */

  up = urlstat_find_entry(handle);

  if (!up)
  {
    erb.errnum = Utils_Error_Custom_Fatal;

    StrNCpy0(erb.errmess,
             lookup_token("StrNotFd:Internal error: Can't find structure in %0.",
                          0,
                          "html_get_next_token"));

    dprintf(("Fetc", "html_get_next_token: Exiting with error\n"));

    return &erb;
  }

  /**************************************************/
  /* Get data - read from the remote host or kludge */
  /* (sorry, I mean, create...) data with the       */
  /* internal URL scheme                            */
  /**************************************************/

  /* Only look for an anchor and use url_read_data for URLs which */
  /* are not internal or are direct data saves.                   */

  StrNCpy0(ref_url, url);

  if (image || b->displayed == Display_Fetched_Page || b->save_link)
  {
    /* This *isn't* an internal URL, so sort out named  */
    /* anchors etc., and read data from the server.     */
    /*                                                  */
    /* Want to make sure we work on a URL which doesn't */
    /* have an anchor in it, so copy over the url to    */
    /* a local buffer and if there's a '#' marking an   */
    /* anchor, replace it with a string terminator.     */

    int    status = 0;
    char * p      = fetch_find_name_tag(ref_url);

    if (p) *p = 0;

    /* If there isn't an authorisation request in progress, and the fetch  */
    /* is apparently in progress, and the authorisation status isn't '1'   */
    /* (which means 'doing'), get some data from the URL module. The       */
    /* url_read_data call puts the number of bytes read into 'read'.       */

    if (!authorising && up->fetching && (up->authorised != 1))
    {
      /* If the fetcher state store is clear, read data.                   */
      /*                                                                   */
      /* Otherwise, don't do the read call but recover state info from the */
      /* store and carry on as if we'd just called url_read_data normally. */
      /* This is used for things such as cookies - if a cookie coms in and */
      /* the user has asked to be notified of each one, everything must    */
      /* be suspended until the user deals with the cookie.                */

      if (!fetch_waiting)
      {
        e = url_read_data(0,               /* Flags - must be 0 at present */
                          handle,          /* Session handle               */
                          fetch_buffer,    /* Buffer to receive data       */
                          FetchBufferSize, /* The buffer's size            */
                          &status,         /* Protocol status              */
                          &read,           /* Number of bytes read         */
                          remaining);      /* Number of bytes left to get  */

        /* Deal with the size information */

        if (*remaining > 0 && !b->data_size) b->data_size = *remaining + read;
      }

      /* Make sure we only restore fetch state for the correct */
      /* fetch handle!                                         */

      else if (handle == fetch_state.handle)
      {
        fetch_waiting = 0;

        status = fetch_state.status;
        read   = fetch_state.read;

        if (remaining) *remaining = fetch_state.remaining;
      }

      /* If we weren't called for the right handle, have to keep */
      /* waiting until we are.                                   */

      else goto html_get_next_token_waiting_jump_point;

      /* Deal with cookies - if we have a cookie pending, we'll need to  */
      /* store fetcher state and jump out as described above.            */

      if (!e && (status & (1u<<16)))
      {
        e = cookies_process_cookie(b);

        /* If we have any cookies still pending, store fetcher state and */
        /* jump out of the function (well, almost, there may be some     */
        /* tidy-up needed so we do a 'goto' (boo, hiss) to a label near  */
        /* the end).                                                     */

        if (!e && cookies_pending())
        {
          fetch_state.handle    = handle;

          fetch_state.status    = status;
          fetch_state.read      = read;
          fetch_state.remaining = remaining ? *remaining : 0;

          fetch_waiting         = 1;

          goto html_get_next_token_waiting_jump_point;
        }
      }

      /**************************************************/
      /* Shuffle data from the fetch buffer to the      */
      /* source store, if we got any data above and     */
      /* there was no error.                            */
      /**************************************************/

      if (!e && read)
      {
        RetError(html_transfer_to_store(b,
                                        source,
                                        up,
                                        read,
                                        size));
      }
    }
  }
  else if (up->fetching) /* Don't repeat this over and over... */
  {
    /**************************************************/
    /* Handle internal URLs.                          */
    /**************************************************/

    RetError(html_build_internal_page(b,
                                      source,
                                      up,
                                      url,
                                      ref_url,
                                      sizeof(ref_url)));

    /* Set up fetch flags to say that a fetch has been completed */

    up->identified = 1;
    up->allowparse = 1;
    up->fetched    = 1;
    up->fetching   = 0;

    if (remaining) *remaining = 0;
  }

  /* If we're not authorising the transfer and data has been fetched, proceed normally */

  if (!authorising && up->fetched)
  {
    unsigned int   hf  = 0;
    HStream      * new = NULL;

    /* If the stream has been identified as HTML... */

    if (up->identified)
    {
      /* Really need to make our minds up at this point about the */
      /* encoding. fetch_start may have set priority to default   */
      /* to clear out any old HTTP header info, but without       */
      /* changing the encoding, as the menu should only change    */
      /* when the document comes in. That's now, folks.           */

      if (b->encoding_priority == priority_default)
      {
        b->encoding = choices.encoding;
        encoding_update_menus(b);
      }

      /* If there's no parsing context, get one by calling HtmlParse - */
      /* this initialises the HTML parser, getting it ready to parse a */
      /* document (though it need not be present at this stage).       */
      /*                                                               */
      /* First time round, this won't be called as the stream hasn't   */
      /* been identified with HtmlIdentify yet.                        */

      if (up->context == NULL)
      {
        /* Just when you thought it was time to get going, exclusions lists */
        /* rear their ugly and disturbingly time consuming heads...         */

        int               tables  = 0;
        int               scripts = 0;
        char            * list;
        url_description * d       = urlutils_return_description(ref_url);

        if (d)
        {
          list = list_get_malloc_list_string("LONoTables");
          if (list) tables = urlutils_matches_special(d, list) ? 0 : choices.support_tables;
          free(list);

          #ifdef JAVASCRIPT
            list = list_get_malloc_list_string("LONoScripts");
            if (list) scripts = urlutils_matches_special(d, list) ? 0 : choices.support_js;
            free(list);
          #else
            (void) scripts;
          #endif

          urlutils_free_description(d);
        }

        /* Right, *now* we can kick off the parser. */

        up->context = HtmlParse(ref_url,                /* Full page URL, so parser can handle relative links */
                                0,                      /* Length of document - zero at present (not known)   */
                                up->type,               /* Return type from the HtmlIdentify call             */
                                choices.support_frames, /* 1 to have FRAMESETs parsed, else 0                 */
                                choices.support_object, /* 1 to handle OBJECT etc., else get alt. HTML stream */
                                tables,                 /* 1 to handle TABLE etc., else 0                     */

                                #ifdef JAVASCRIPT
                                  scripts,              /* 1 to handle <SCRIPT> contents, calling the script  */
                                #else                   /* callback function as necessary and ignoring the    */
                                  0,                    /* contents of <NOSCRIPT>, else 0.                    */
                                #endif

                                b->encoding,
                                b->encoding_priority);

        if (up->context)
        {
          HtmlSetEncodingCallback (up->context, encoding_changed_by_meta,   b);
          HtmlSetBaseCallback     (up->context, browser_base_callback,      b);

          #ifdef JAVASCRIPT
            HtmlSetScriptCallback (up->context, javascript_script_callback, b);
          #endif
        }

        read = *source ? flex_size(source) : 0;
      }

      /* If there is new data in the source store (size = read) and no error at */
      /* present, attempt to parse the chunk of data with HtmlGetStream.        */

      if (read && !e)
      {
        new = HtmlGetStream(up->context,        /* Parser context, from HtmlParse            */
                            (char **) source,   /* Pointer to start of the complete document */
                            read,               /* Size of the chunk that has been added     */
                            &hf);               /* Flags from HTMLLib, e.g. 'have more data' */

        up->stream = new;

        dprintf(("Stre", "\0211(New stream for %p, %p)\0217\n", b, up->stream));
      }

      if (!new)
      {
        /* There are no new HTML library structures */

        if (up->lasttoken)
        {
          /* There is no new data, but lasttoken indicates there are more tokens */
          /* left in the token stream from earlier calls that haven't been dealt */
          /* with. So move to the next one.                                      */

          up->lasttoken     = up->lasttoken->next;
          if (token) *token = up->lasttoken;
        }
      }
      else
      {
        /* There are some new HTML library structures. */

        if (!(hf & HTML_GOT_MORE_IN_A_TABLE))
        {
          /* The flag is unset, so the structures were added to the main token */
          /* stream and not to part of a table structure.                      */

          if (up->lasttoken)
          {
            /* Even though there are new structures, we still have older ones */
            /* that are not dealt with, so move to the next one (the remote   */
            /* server is sending us data than we're processing it - yay!).    */

            up->lasttoken     = up->lasttoken->next;
            if (token) *token = up->lasttoken;
          }
          else
          {
            /* There are no earlier structures left to deal with, so start on */
            /* the first of the new batch.                                    */

            up->lasttoken     = new;
            if (token) *token = up->lasttoken;
          }
        }
        else
        {
          /* The HTML_GOT_MORE_IN_A_TABLE flag is set, so structures were added to */
          /* a table arrangement, as well as (possibly) the main stream after it.  */

          if (!up->lasttoken)
          {
            /* We weren't waiting to process anything from an earlier call, so */
            /* start on this new table structure.                              */

            up->lasttoken     = new;
            if (token) *token = up->lasttoken;
          }
          else
          {
            /* We have undealt with structures from a previous fetch. Now, if */
            /* we are already on the same table structure as returned by the  */
            /* HtmlGetStream call, then stay there (i.e. process the new data */
            /* inside the table). Otherwise, move on.                         */

            if (up->lasttoken != new) up->lasttoken = up->lasttoken->next;
            if (token) *token = up->lasttoken;
          }
        }
      }

      /* If we've moved on to, or were already on no token, then whether or */
      /* not the fetch is still in progress determines whether or not we're */
      /* waiting. Otherwise, we aren't waiting for anything.                */

      if (!up->lasttoken) *waiting = !!up->fetching;
      else                *waiting = 0;
    }
    else if (up->authorised != 1)
    {
      /* The stream hasn't been identified as HTML, text or whatever, */
      /* but there isn't an authorisation in progress.                */

      int    s, o = 0;
      char * redirect;
      int    code;
      int    type;
      int    parseable;

      /* Get the fetch status */

      if (image || b->displayed == Display_Fetched_Page || b->save_link)
      {
        e = url_status(0, handle, &s, NULL, NULL);
        if (e) return e;
      }
      else s = URL_Status_Done;

      redirect  = NULL;
      type      = TYPE_UNKNOWN;
      parseable = 0;

      /* HttpStripHeaders, when passed a pointer to some document data, */
      /* and an offest into that stream, returns the offset into the    */
      /* stream at which it starts assuming HTTP style headers (if      */
      /* there is such a point).                                        */

      o = *source ? HttpStripHeaders((char *) *source, flex_size(source)) : 0;

      /* If o is 0, there were no HTTP headers. If o is -1, there wasn't */
      /* enough data to tell. Else, there were headers, and o is the     */
      /* offset into the stream of the data that follows those headers.  */

      if (o > 0)
      {
        int encoding;

        #ifdef DUMP_HEADERS
          {
            FILE * file;
            int    byte;

            file = fopen("<Wimp$ScrapDir>.Headers", "ab");

            if (file)
            {
              if (!image) fprintf(file, "For URL '%s', received header:\r\n\r\n", url);
              else        fprintf(file, "For image '%s', received header:\r\n\r\n", url);

              for (byte = 0; byte < o; byte++)
              {
                fputc((int) (*((char *) (((int) *source) + byte))), file);
              }

              fclose(file);
            }
          }
        #endif

        /* We may have some local interest in the headers, e.g. for */
        /* last modified dates.                                     */

        html_extract_header_info(b, (flex_ptr) source);

        /* There are HTTP style headers in the data */
        /* stream; try to identify that stream.     */

        code = HtmlIdentify(ref_url,                     /* Allow relative redirections to work  */
                            (char *) *source,            /* Pointer to head of data stream       */
                            flex_size(source),           /* Amount of data in the stream         */
                            (s & URL_Status_Done) != 0,  /* Is it a complete stream? 1 = yes     */
                            &redirect,                   /* Will point to a URL if code = 302    */
                            &type,                       /* Will hold a filetype                 */
                            &parseable,                  /* Will say if the data is parseable    */
                            &encoding);                  /* Will say if it specified an encoding */

        /* Set the encoding if specified in the HTTP header */

        if (encoding && up->allowparse && b->encoding_priority < priority_http)
        {
          b->encoding_priority = priority_http;
          b->encoding          = encoding;

          encoding_update_menus(b);
        }

        /* Discard the stuff before the HTTP style headers by moving the data over them */

        if (o != flex_size(source))
        {
          dprintf(("Stre", "\0213html_get_next_token: memove from %p to %p for %d bytes\0217\n",
                           *source,
                           (char*) (((int) *source) + o),
                           flex_size(source) - o));

          memmove(*source,
                  (char*) (((int) *source) + o),
                  flex_size(source) - o);

          /* Set o to the size of the data stream that is now in use, */
          /* and shrink the source store to this size.                */

          #ifdef TRACE
            dprintf(("LMem", "html_get_next_token: flex_extend to shrink source code store by %d to %d\n",o,flex_size(source) - o));
            flexcount -= o;
            dprintf(("CFle", "**   flexcount: %d\n",flexcount));
          #endif
        }

        o = flex_size(source) - o;

        /* If the size of the store minus o is less than 0, HttpStripHeaders */
        /* has failed completely and we must get out before everything else  */
        /* comes down...!                                                    */

        if (o < 0)
        {
          erb.errnum = Utils_Error_Custom_Fatal;

          StrNCpy0(erb.errmess,
                   lookup_token("HSHOvrrn:Serious internal error - HttpStripHeaders has failed; must exit immediately.",
                                0,
                                0));

          show_error_cont(&erb); /* This will cause exit(EXIT_FAILURE) eventually. */
        }

        flex_extend(source, o); /* (Which shrinks the source store) */

        switch (code)
        {
          #ifndef STRICT_PARSER

            /* Moved permanently - drop through to redirection code. Only */
            /* do this if not in a STRICT_PARSER build, as in the latter  */
            /* case slightly broken links (missing '/'s off the ends, and */
            /* so-on) aren't hidden by the browser moving on.             */

            case 301:

            /* Redirect to a GET request; this means 'definitely don't  */
            /* repost POST forms data' unlike 302 where you're supposed */
            /* to but we don't because Navigator doesn't and some sites */
            /* expect this broken behaviour (see below). So we can just */
            /* drop through to the 302 case, unless we're strict.       */

            case 303:

          #endif


          /* Redirect; 'redirect' is a pointer to a new URL. */

          case 300:
          case 302:
          {
            /* Log the redirection */

            if (choices.ev_http_messages != 0)
            {
              char tagname[8];

              sprintf(tagname, "HTTP%d:30x (Moved)", code);
              lookup_token(tagname, 0, 0);

              if (strlen(url) + strlen(tokens) + 3 < sizeof(tokens))
              {
                strcat(tokens, ": ");
                strcat(tokens, url);
              }

              if (strlen(redirect ? redirect : "<NULL>") + strlen(tokens) + 5 < sizeof(tokens))
              {
                strcat(tokens, " -> ");
                strcat(tokens, redirect ? redirect : "<NULL>");
              }

              /* Let this fail silently */

              eventlogs_log_message(b, eventlogs_http_message, tokens);
              *tokens = '\0';
            }

            if (redirect == NULL) redirect = "";

            /* Stop the current fetch and free the source store,   */
            /* remembering to invalidate the anchor pointing to it */

            url_stop(0, handle);

            #ifdef TRACE
              dprintf(("LMem", "html_get_next_token: (2) flex_free block %p which held page source\n",source));
              flexcount -= flex_size(source);
              dprintf(("CFle", "**   flexcount: %d\n",flexcount));
            #endif

            flex_free(source);
            *source = NULL;

            /* Ensure POST requests are now cleared (we shouldn't continue */
            /* POSTing to redirected URLs - er, because Netscape Navigator */
            /* doesn't, even though we technically should.)                */

            if (up->method == URL_Method_http_POST)
            {
              /* When the headers are built, the POST data (starting with a Content-Type */
              /* entry) is put in first and everything else is inserted above it. As the */
              /* comments on this code say, this is organised so we can simplify things  */
              /* here and just chop off everything at Content-Type and below, rather     */
              /* than having to carefully remove the appropriate header lines and body. */

              if (up->extradata)
              {
                int    len;
                int    oldbudge;
                char * strip;


                oldbudge = flex_set_budge(0);

                #ifdef DUMP_HEADERS
                  {
                    FILE * file;

                    file = fopen("<Wimp$ScrapDir>.Headers", "ab");

                    if (file)
                    {
                      fprintf(file, "Redirection from POST\r\nThere is this extra data before stripping POST-specific info:\r\n\r\n[%s]\r\n\r\n", up->extradata);

                      fclose(file);
                    }
                  }
                #endif

                strip = strstr(up->extradata, "Content-Type: ");

                if (strip)
                {
                  /* How much do we want to keep? */

                  len = strip - up->extradata + 1; /* + 1 so we can put in a string terminator where the 'C' was */

                  #ifdef TRACE
                    {
                      int rmv = flex_size((flex_ptr) &up->extradata) - len;
                      flexcount -= rmv;
                      dprintf(("CMal", "**   flexcount: %d\n",flexcount));
                    }
                  #endif

                  /* Resize the block */

                  flex_extend((flex_ptr) &up->extradata, len);

                  *strip = 0;
                }

                #ifdef DUMP_HEADERS
                  {
                    FILE * file;

                    file = fopen("<Wimp$ScrapDir>.Headers", "ab");

                    if (file)
                    {
                      fprintf(file, "Redirection from POST\r\nThere is this extra data after stripping POST-specific info:\r\n\r\n[%s]\r\n\r\n", up->extradata);

                      fclose(file);
                    }
                  }
                #endif

                flex_set_budge(oldbudge);
              }

              /* Change the fetch method to GET */

              up->method = URL_Method_http_GET;
            }

            /* Set the fetch's urlstat structure to say that */
            /* no data has been fetched                      */

            up->fetched = 0;

            /* Start a fetch on the new URL */

            e = url_get_url(URL_GetURL_AgentGiven, /* Use a custom User Agent string      */
                            handle,                /* Session handle                      */
                            up->method,            /* Fetch method                        */
                            redirect,              /* URL to get                          */
                            &up->extradata,        /* Extra data for POST etc.            */
                            NULL,                  /* We're ignoring the returned status  */
                            2);                    /* Mode 2 = fetch both header and data */

            /* Return any errors that url_get_url generated */

            if (e) return e;

            /* This function returns the address of the new URL in   */
            /* 'remaining', flagging this with a waiting status of 2 */
            /* - and yes, this is quite odd.                         */

            *waiting   = 2;
            *remaining = (int) redirect; /* Not redirect_to, as it may be freed now */
          }
          break;

          case 400:
          case 403:
          case 404:
          case 405:
          case 406:
          case 408:
          case 409:
          case 410:
          case 411:
          case 412:
          case 413:
          case 414:
          case 415:
          {
            /* For images or HTTP message event logging, create the required message */

            if (image != 0 || choices.ev_http_messages != 0)
            {
              char tagname[8];

              sprintf(tagname, "HTTP%d:40x (Access)", code);

              erb.errnum = Utils_Error_Custom_Message;

              StrNCpy0(erb.errmess,
                       lookup_token(tagname,
                                    0,
                                    0));

              if (strlen(url) + strlen(erb.errmess) + 3 < sizeof(erb.errmess))
              {
                strcat(erb.errmess, ": ");
                strcat(erb.errmess, url);
              }

              RetError(eventlogs_log_message(b, eventlogs_http_message, erb.errmess));
            }

            /* Images return client failure codes as errors */

            if (image) return &erb;

            /* Otherwise, show the page */

            else
            {
              /* Well this is the ugly bit; there's no structured */
              /* way to drop through to the 200 case...           */

              parseable = TYPE_HTMLFILE;

              // This is, of course, completely unacceptable. ;-)

              goto parse_the_page;
            }
          }
          break;

          /* Authorise; the server requested authorisation before it */
          /* would deliver the page.                                 */

          case 401:
          {
            char * realm;
            char   host     [Limits_HostName];
            char   username [Limits_AuthUserWrit];
            char   password [Limits_AuthPassWrit];
            int    po;

            /* Try to find the host and realm */

            urlutils_host_name_from_url(ref_url, host, sizeof(host));

            /* (The realm will lie in the string pointed to by */
            /* 'redirect', between two double quotes).         */

            realm = authorise_read_realm(redirect);

            /* If we've already tried this, then the authorisation failed, */
            /* so display whatever authorisation failure page the server   */
            /* sent with the 401 response.                                 */

            if (up->authorised >= 2)
            {
              authorise_forget(host, realm);

              erb.errnum = Utils_Error_Custom_Message;

              StrNCpy0(erb.errmess,
                       lookup_token("BadAuthor:Authorisation failed; you must use a valid user name and password.",
                                    0,
                                    0));

              return &erb;
            }

            /* Ditch any document data got so far, we don't need it now */
            /* (it only contains e.g. header information).              */

            if (source)
            {
              flex_free((flex_ptr) source);
              *source = NULL;
            }

            up->fetched = 0;

            /* Stop the URL module trying to get anything else, and set */
            /* the flag to say we're authorising this fetch.            */

            url_stop(0, handle);
            up->authorised = 1;

            /* If there is a user name and / or password available already, */
            /* use that and authenticate immediately.                       */

            *username = *password = 0;

            po = authorise_find_user_name(host, realm);

            if (po >= 0)
            {
              StrNCpy0(username, authorise + po);

              po = authorise_find_password(host, realm);

              if (po >= 0)
              {
                StrNCpy0(password, authorise + po);
              }

              fetch_authorisation_proceed(b, up, realm, url);
            }

            /* Otherwise, get this information from a dialogue box and */
            /* allow the authentication to happen later, when the user */
            /* has done relevant things with the dialogue.             */

            else
            {
              char     prompt[Limits_AuthPrompt];
              int      f, is_ftp;
              ObjectId dbox;

              /* Ensure the authorisation dialogue is created and event handlers */
              /* are registered for it.                                          */

              e = authorise_create_dialogue((void *) b, &dbox);
              if (e != NULL) return e;

              /* If this is an image fetch, associate the image fetch handle with */
              /* the dialogue box                                                 */

              if (image)
              {
                e = toolbox_set_client_handle(0, dbox, (void *) handle);
                if (e != NULL) return e;
              }

              /* Is this an FTP fetch? */

              if (!strncmp(browser_fetch_url(b), FTPmethod, strlen(FTPmethod))) is_ftp = 1;
              else                                                              is_ftp = 0;

              /* -4 corrects for %s being replaced by host / realm strings, plus */
              /* a terminator at the end of the whole lot.                       */

              f = strlen(realm) + strlen(host); /* (But no terminators needed for these, so no '+ 1's) */

              if (!is_ftp) lookup_token("Authorise:Please enter a user name and a password for %%s at %%s.",0,0);
              else         lookup_token("AuthorFTP:Please enter a password for %%s.",0,0);

              f += ((signed int) strlen(tokens)) - 4 + 1; /* Minus 4 for two lots of '%s', plus 1 for terminator */

              /* If the string is too big for the prompt or null, put a */
              /* simple version in instead.                             */

              if (f <= 0 || f > sizeof(prompt))
              {
                if (is_ftp) lookup_token("AuthorFSh:Please enter a password.",0,0);
                else        lookup_token("AuthorShr:Please enter a user name and a password.",0,0);

                e = button_set_value(0, dbox, AuthPrompt, tokens);
              }
              else
              {
                if (is_ftp) sprintf(prompt, tokens, host);
                else        sprintf(prompt, tokens, realm, host);

                e = button_set_value(0, dbox, AuthPrompt, prompt);
              }

              if (e) return e;

              /* Show the dialogue */

              RetError(toolbox_show_object(Toolbox_ShowObject_AsMenu,
                                           dbox,
                                           Toolbox_ShowObject_Centre,
                                           NULL,
                                           b->self_id,
                                           -1));

              /* If using FTP, put the user name in the writable field */
              /* and grey it out. Else just empty the field.           */

              if (is_ftp)
              {
                /* Let errors happen silently here */

                writablefield_set_value(0,
                                        dbox,
                                        AuthUserWrit,
                                        realm);

                set_gadget_state(dbox, AuthUserWrit, 1);
              }
              else e = writablefield_set_value(0, dbox, AuthUserWrit, "");

              if (e) return e;

              /* Empty the password writable */

              RetError(writablefield_set_value(0, dbox, AuthPassWrit, ""));

              /*set the authorising flag */

              menusrc = Menu_Authorise, authorising = 1;
            }
          }
          break;

          /* Catch anything else 'just in case'. Guess that the data */
          /* is parseable and let this drop through to the ordinary  */
          /* URL handling code.                                      */

          default: parseable = TYPE_HTMLFILE; /* ...so no 'break' */

          /* An ordinary URL. */

          case 200:
          {
parse_the_page:

            /* If the urlstat structure says not to parse this data, flag it as */
            /* an unknown type to prevent parsing.                              */

            if (!up->allowparse) parseable = TYPE_UNKNOWN;

            b->page_is_text = 0;

            if (b->save_link)
            {
              /* If saving out the link, flag as not parseable whatever HTMLLib said */

              *waiting = 3;
            }
            else
            {
              /* If the data is apparently parseable, flag the status as 'waiting' */
              /* else flag it as 'not parseable'.                                  */

              switch (parseable)
              {
                /* For an unknown type, do we have faith in the server? */

                default:
                case TYPE_UNKNOWN:
                {
                  if (choices.faith == Choices_Faith_Never)
                  {
                    type = urlutils_filetype_from_url(browser_fetch_url(b));

                    if (
                         type == FileType_TEXT ||
                         type == FileType_HTML
                       )
                    {
                      parseable = TYPE_HTMLFILE;
                      *waiting  = 1;
                      break;
                    }
                  }
                }

                case TYPE_IMAGEFILE: *waiting = 3;
                break;

                /* For a text file, check the filename extension. It may */
                /* be that the server is sending garbage Content-Type    */
                /* headers, and we'll choose the filename extension over */
                /* this (initially for "http://www.batalarms.co.uk/").   */
                /* However, some servers really do mean text/plain when  */
                /* they say it; others send text/plain for HTML and      */
                /* plain text but get other bits right. It's a mess, so  */
                /* use the 'Faith' Choices option to determine the final */
                /* behaviour here.                                       */
                /*                                                       */
                /* If the server says something is HTML, we'll trust it. */

                case TYPE_TEXTFILE:
                {
                  /* No faith in the server */

                  if (choices.faith == Choices_Faith_Never)
                  {
                    type = urlutils_filetype_from_url(browser_fetch_url(b));

                    /* If the URL indicates that it's text, display it as text */

                    if (type == FileType_TEXT)
                    {
                      b->page_is_text = 1;
                      *waiting        = 1;
                    }

                    /* If the URL indicates that it's HTML, display it as HTML */

                    else if (type == FileType_HTML)
                    {
                      parseable = TYPE_HTMLFILE;
                      *waiting  = 1;
                    }

                    /* For anything else, treat it as an unknown object */

                    else
                    {
                      parseable = TYPE_UNKNOWN,
                      *waiting  = 3;
                    }
                  }

                  /* Some faith in the server */

                  else if (choices.faith == Choices_Faith_Sometimes)
                  {
                    type = urlutils_filetype_from_url(browser_fetch_url(b));

                    /* If the URL indicates that it's text, display it as text */

                    if (type == FileType_TEXT)
                    {
                      b->page_is_text = 1;
                      *waiting        = 1;
                    }

                    /* For anything else, treat it as HTML */

                    else
                    {
                      parseable = TYPE_HTMLFILE;
                      *waiting  = 1;
                    }
                  }

                  /* Complete faith in the server - if it says this is text, display it as text */

                  else
                  {
                    b->page_is_text = 1;
                    *waiting        = 1;
                  }
                }
                break;

                case TYPE_HTMLFILE: *waiting = 1;
                break;
              }
            }

            if (parseable == TYPE_IMAGEFILE && !b->save_link)
            {
              /* For images, stop the current fetch and 'redirect' to */
              /* an internal page which will fetch the image inline.  */
              /* This is inefficient as you start to fetch the image  */
              /* twice; on slow servers, something of a killer...     */
              /* Unfortunately, pressure of time (yet *again*)        */
              /* precludes a more elegant solution for the moment.    */

              url_stop(0, handle);

              #ifdef TRACE
                dprintf(("LMem", "html_get_next_token: (2) flex_free block %p which held page source\n",source));
                flexcount -= flex_size(source);
                dprintf(("CFle", "**   flexcount: %d\n",flexcount));
              #endif

              flex_free(source);
              *source = NULL;

              /* Set the fetch's urlstat structure to say that */
              /* no data has been fetched                      */

              up->fetched = 0;

              /* Want to only offer a 'back to previous page' link if you can indeed go back. */
              /* Because this page can itself add to the history, we shouldn't check the      */
              /* 'history_can_go_backwards' function result as this may return 0, even though */
              /* by the time this new page has fetched you *can* go back. So check whether or */
              /* not the local history is empty. However, if you've stepped back to the front */
              /* of the history, then you shouldn't give a 'back' link... So need to also see */
              /* if, should history_can_go_backwards return 0, history_can_go_forwards does   */
              /* as well.                                                                     */

              if (
                   !history_empty(b) &&
                   (
                     history_can_go_backwards(b) ||
                     (
                       !history_can_go_backwards(b) &&
                       !history_can_go_forwards(b)
                     )
                   )
                 )
                 redirect = Internal_URL ForExternalHImage; /* Have a 'Go back' link */

              else redirect = Internal_URL ForExternalNImage; /* No 'Go back' link     */

              /* Start a fetch on the new URL */

              e = url_get_url(URL_GetURL_AgentGiven, /* Use a custom User Agent string      */
                              handle,                /* Session handle                      */
                              up->method,            /* Fetch method                        */
                              redirect,              /* URL to get                          */
                              &up->extradata,        /* Extra data for POST etc.            */
                              NULL,                  /* We're ignoring the returned status  */
                              2);                    /* Mode 2 = fetch both header and data */

              if (e) return e;

              b->displayed = Display_External_Image;

              /* This function returns the address of the new URL in   */
              /* 'remaining', flagging this with a waiting status of 2 */
              /* - and yes, this is quite odd.                         */

              *waiting   = 2;
              *remaining = (int) redirect;
            }
            else
            {
              *remaining = type;

              /* Set the type according to the parseable flag */

              up->type = parseable;

              /* Flag that we've identified the stream */

              up->identified = 1;
            }
          }
          break;

          /* If 0, haven't identified the stream yet */

          case 0:
          break;

        /* Closure of 'switch' statement checking the return code */
        /* from the HtmlIdentify call                             */
        }

      /* Closure of 'if' statement that checked there was recognised data */
      /* following HTTP style headers in the data stream                  */
      }

    /* Closure of 'if' statement that checked the urlstat structure  */
    /* to see if authorisation was in progress (and only proceeded   */
    /* if it was not)                                                */
    }

  /* Closure of 'if' statement that followed the url_read_data    */
  /* function call and associated memory allocation procedures,   */
  /* and only proceeded if data had been fetched and authoristion */
  /* was not flagged as being in progress.                        */
  }

  /* If we're not in the middle of authorisation, there hasn't */
  /* been an error, and the urlstat structure for the fetch    */
  /* flags that fetching is still in progress, ask the URL     */
  /* module if things are finished yet. If so, do the relevant */
  /* tidying up and unset the 'fetch in progress' flag.        */

  if (!e && up->authorised != 1 && !authorising && up->fetching)
  {
    int s;

    if (image || b->displayed == Display_Fetched_Page || b->save_link)
    {
      e = url_status(0, handle, &s, NULL, NULL);
      if (e) return e;

      if (s & URL_Status_Done)
      {
dprintf(("temp", "Shutting down %p, status = %08x\n",up,s));
        up->fetching = 0;
        *waiting     = 0;
      }
    }
  }

  /* If we've been passed somewhere to put the size of the store, */
  /* and if the store is present, return the size of it.          */

  if (size) *size = (*source) ? flex_size(source) : 0;

html_get_next_token_waiting_jump_point:

  #ifdef TRACE

    if (!e) dprintf(("Fetc", "html_get_next_token: Successful\n"));
    else    dprintf(("Fetc", "html_get_next_token: Exitting with an error\n"));

  #endif

  /* Exit, passing on any error if there is one */

  return (e);
}
@


1.42
log
@  Huge pile of changes bringing relatively ancient sources up to date.
Detail:
  This check-in includes Phoenix version 2.11 (26-Apr-2005); only the
  debug and JavaScript builds of Phoenix have been tested and resources
  will definitely be out of date for other versions. The various "!..."
  scripts have been updated to require a minimum of 2MB with no maximum
  limit for building, as CC 5.60 is quite RAM hungry.
Admin:
  Phoenix 2.11 JS builds OK, works reasonably well. Many outstanding
  issues of course, as this is a very outdated browser now.

Version 2.09. Tagged as 'Browse-2_09'
@
text
@a1520 1
dprintf(("temp", "Read data within %p, %d read\n",up,read));
a2068 16
            /* Customer specific */

            #ifdef CUSTOMER_SPECIAL

              if (
                   !strcmp(redirect,"http://www.customer.com/login.html")  ||
                   !strcmp(redirect,"http://www.customer.com/index.html")
                 )
              {
                // Send out cookie...

                redirect = (char *) "http://www.customer.com/simple.html";
              }

            #endif

@


1.41
log
@  Load balancer pulled apart. DebugLib support. Temporary debug in place.
Detail:
  This is in the middle of some load balancer changes, but I'm checking it
  in as there's a sweeping source code change to use DebugLib. See Global.c
  for full details. Temporary debug code for the load balancer stuff is
  currently held under undocumented area "test".
Admin:
  This build now identifies itself as 2.08 i2-4 and says Pace on the about:
  page. Run for some time with no unexpected problems. Tried a mixture of
  debug levels successfully.

Version 2.08. Not tagged
@
text
@d88 1
a88 1
#define FetchBufferSize 16384 /* Size of buffer for getting data from the URL module in html_get_next_token. */
d92 1
d220 1
a220 1
    /* don't want to use a length-limited comparisson as this may */
a542 1
dprintf(("temp", "url_get_url for %p, url = '%s'\n",up,url));
d1947 1
a1947 1
            if (eventlogs_what_to_log() & EventLogs_Log_HTTPMessages)
d1969 1
d2130 1
a2130 1
            if (image || (eventlogs_what_to_log() & EventLogs_Log_HTTPMessages))
@


1.40
log
@
64-wide comments adopted throughout. All headers protected against multiple
inclusion. Use of <> for external headers rather than "". For libraries,
<libname/header.h> is used rather than relying on a complex include path,
where appropriate. Move towards using external URILib rather than the local
copy. Phoenix JavaScript build resources are the only up to date set
currently so don't try others; more work still required on Makefile (e.g.
getting the ROM build working, and internationalisation issues).

Version 2.08. Not tagged
@
text
@a43 5
#ifdef TRACE
  #define DEBUGLIB
#endif
#include <debuglib/debuglib.h>

d119 1
a119 3
    #ifdef TRACE
      if (tl & (1u<<6)) Printf("html_allocate_fetch_buffer: Exiting with error\n");
    #endif
d321 1
a321 3
  #ifdef TRACE
    if (tl & (1u<<6)) Printf("html_get: Called\n");
  #endif
d359 1
a359 3
    #ifdef TRACE
      if (tl & (1u<<6)) Printf("html_get: Session registered, ID is %d\n",h);
    #endif
d392 1
a392 3
      #ifdef TRACE
        if (tl & (1u<<12)) Printf("html_get: flex_alloc %d for 'extradata' store\n",len + 3);
      #endif
d406 1
a406 1
          if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d542 1
d558 4
a561 5
    if (tl & (1u<<6))
    {
      if (!e) Printf("html_get: Successful\n");
      else Printf("html_get: Exitting with an error\n");
    }
d606 2
a607 5
      if (tl & (1u<<12))
      {
        if (s) Printf("html_insert_header: flex_extend to %d for header store\n",len + s);
        else   Printf("html_insert_header: flex_alloc %d for header store\n",len + 1);
      }
d618 1
a618 1
      if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d624 1
a624 3
    #ifdef TRACE
      if (tl & (1u<<18)) Printf("\0213html_insert_header: memove from %p to %p for %d bytes\0217\n",((int) (*data)) + len, *data, s);
    #endif
d664 1
a664 3
  #ifdef TRACE
    if (tl & (1u<<6)) Printf("html_close: Called\n");
  #endif
d693 1
a693 3
    #ifdef TRACE
      if (tl & (1u<<6)) Printf("html_close: Exiting with error\n");
    #endif
d766 2
a767 2
        if (tl & (1u<<12)) Printf("html_close: Calling HtmlStreamFree on %p\n",up->stream);
        if (tl & (1u<<18)) Printf("\0212Closing stream %p\0217\n",up->stream);
d778 1
a778 3
    #ifdef TRACE
      if (tl & (1u<<12)) Printf("html_close: free block %p for 'context' field of 'urlstat' structure\n",up->context);
    #endif
d787 1
a787 1
      if (tl & (1u<<12)) Printf("html_close: flex_free block %p for 'extradata' field of 'urlstat' structure\n",&up->extradata);
d789 1
a789 1
      if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d801 1
a801 3
  #ifdef TRACE
    if (tl & (1u<<6)) Printf("html_close: Successful\n");
  #endif
d1210 1
a1210 3
    #ifdef TRACE
      if (tl & (1u<<6)) Printf("html_build_internal_page: Exiting with error\n");
    #endif
d1300 1
a1300 1
      if (tl & (1u<<12)) Printf("html_transfer_to_store: (1) flex_free block %p which held page source\n",source);
d1302 1
a1302 1
      if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d1318 2
a1319 5
    if (tl & (1u<<12))
    {
      if (*source) Printf("html_transfer_to_store: flex_extend by %d to %d for page source store\n",r,flex_size(source) + r);
      else         Printf("html_transfer_to_store: flex_alloc %d for page source store\n",r);
    }
d1335 1
a1335 1
    if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d1344 1
a1344 3
    #ifdef TRACE
      if (tl & (1u<<6)) Printf("html_transfer_to_store: Exiting with error\n");
    #endif
d1352 1
a1352 3
  #ifdef TRACE
    if (tl & (1u<<18)) Printf("\0216html_transfer_to_store: memcpy from %p to %p for %d bytes\0217\n",((char *) (*source)) + oldsize, fetch_buffer, r);
  #endif
d1426 1
a1426 3
  #ifdef TRACE
    if (tl & (1u<<6)) Printf("html_get_next_token: Called\n");
  #endif
d1465 1
a1465 3
    #ifdef TRACE
      if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
    #endif
d1521 1
d1710 1
a1710 3
        #ifdef TRACE
          if (tl & (1u<<18)) Printf("\0211(New stream for %p, %p)\0217\n", b, up->stream);
        #endif
d1879 4
a1882 6
          #ifdef TRACE
            if (tl & (1u<<18)) Printf("\0213html_get_next_token: memove from %p to %p for %d bytes\0217\n",
                                    *source,
                                    (char*) (((int) *source) + o),
                                    flex_size(source) - o);
          #endif
d1892 1
a1892 1
            if (tl & (1u<<12)) Printf("html_get_next_token: flex_extend to shrink source code store by %d to %d\n",o,flex_size(source) - o);
d1894 1
a1894 1
            if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d1979 1
a1979 1
              if (tl & (1u<<12)) Printf("html_get_next_token: (2) flex_free block %p which held page source\n",source);
d1981 1
a1981 1
              if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d2035 1
a2035 1
                      if (tl & (1u<<13)) Printf("**   flexcount: %d\n",flexcount);
d2496 1
a2496 1
                if (tl & (1u<<12)) Printf("html_get_next_token: (2) flex_free block %p which held page source\n",source);
d2498 1
a2498 1
                if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
d2609 1
d2621 2
d2624 4
a2627 5
    if (tl & (1u<<6))
    {
      if (!e) Printf("html_get_next_token: Successful\n");
      else Printf("html_get_next_token: Exitting with an error\n");
    }
a2628 2

html_get_next_token_waiting_jump_point:
@


1.39
log
@
Authorisation works for image fetches. Previously authorise_authorise
assumed any check was for a browser page. Now looks at the dialogue box
client handle, which is 0 for the page or a fetch handle for an image.
The urlstat structure this relates to now has lasttoken filled in for
the token the image represents, which gives the URL to which the
user name and password relate.
@
text
@d15 15
a29 12
/***************************************************/
/* File   : FetchHTML.c                            */
/*                                                 */
/* Purpose: Fetch functions that deal with HTMLLib */
/*          data (getting more of it, freeing it,  */
/*          and so forth). Compare with higher     */
/*          higher level Fetch.c and FetchPage.c.  */
/*                                                 */
/* Author : A.D.Hodgkinson                         */
/*                                                 */
/* History: 17-Aug-97: Created from Fetch.c.       */
/***************************************************/
d35 13
a47 2
#include "swis.h"
#include "flex.h"
a48 6
#include "HTMLLib.h" /* HTML library API, Which will include html2_ext.h, tags.h and struct.h */

#include "wimp.h"
#include "event.h"

#include "svcprint.h"
d110 7
a116 8
/*************************************************/
/* html_allocate_fetch_buffer()                  */
/*                                               */
/* Assuming fetch_buffer is NULL, malloc a block */
/* of FetchBufferSize assigning the address to   */
/* this static, raising an error if the malloc   */
/* fails.                                        */
/*************************************************/
d134 30
a163 34
/*************************************************/
/* html_set_proxy()                              */
/*                                               */
/* For a given URL and fetch handle, look in the */
/* Choices file for proxy details - if something */
/* relevant is found, set this proxy for the     */
/* session.                                      */
/*                                               */
/* For fetches with a protocol (scheme) matching */
/* HTTPmethod (URLUtils.h), the tokens UseProxy  */
/* and ProxyAddress are looked for in Choices.   */
/* For other fetches, the protocol name is       */
/* appended to the above; for example, an 'ftp:' */
/* fetch would look for 'UseProxyftp' and        */
/* 'ProxyAddressftp'.                            */
/*                                               */
/* If the "UseProxy..." entry is "yes" (case     */
/* insensitive), the "ProxyAddress..." entry is  */
/* tried. If this is found, the proxy is set.    */
/*                                               */
/* Should the URL_Fetcher call made to set the   */
/* proxy return an error, this error is reported */
/* immediately; this function then exits cleanly */
/* (no errors are thrown any higher up).         */
/*                                               */
/* In addition, "LOProxyExclusions" and other    */
/* relevant protocol-specific exclusion lists    */
/* are looked at to see if proxying should be    */
/* avoided. See the Choices file for more.       */
/*                                               */
/* Parameters: Fetch handle for the session;     */
/*                                               */
/*             URL being fetched                 */
/*************************************************/
d297 23
a319 28
/*************************************************/
/* html_get()                                    */
/*                                               */
/* Fetches and optionally starts parsing HTML.   */
/*                                               */
/* Parameters: Pointer to URL to fetch;          */
/*                                               */
/*             Pointer to a pointer for extra    */
/*             data for POST etc. (allows this   */
/*             to be in a flex block);           */
/*                                               */
/*             Pointer to an int into which a    */
/*             handle for this fetch will be     */
/*             placed;                           */
/*                                               */
/*             The fetch method, e.g. POST or    */
/*             GET;                              */
/*                                               */
/*             Pointer to the user name for      */
/*             MailServ (if in a multiuser       */
/*             environment);                     */
/*                                               */
/*             1 to allow parsing, else 0;       */
/*                                               */
/*             1 to allow proxying, else 0 (e.g. */
/*             to force a refetch, rather than   */
/*             going via. a cache).              */
/*************************************************/
d580 18
a597 20
/*************************************************/
/* html_insert_header()                          */
/*                                               */
/* Inserts a string into the header for an HTML  */
/* fetch (for POST). Puts it at the top.         */
/*                                               */
/* Parameters: Pointer to the null terminated    */
/*             string to insert (this ends up    */
/*             CR+LF terminated in the header);  */
/*                                               */
/*             Pointer to a flex anchor, which   */
/*             points to existing header data or */
/*             is NULL if there is no header at  */
/*             the time of the function call.    */
/*                                               */
/* Returns:    1 if successful, or 0; you must   */
/*             externally generate an error      */
/*             appropriate to the memory claim   */
/*             having failed.                    */
/*************************************************/
d668 9
a676 10
/*************************************************/
/* html_close()                                  */
/*                                               */
/* Closes the specified handle, aborting any     */
/* fetch and freeing up memory relating to it.   */
/*                                               */
/* Parameters: A fetch handle (usually from the  */
/*             browser_data->fetch_handle        */
/*             field).                           */
/*************************************************/
d832 12
a843 13
/*************************************************/
/* html_extract_header_info()                    */
/*                                               */
/* Get information from HTTP response headers,   */
/* e.g. the Last-modified date.                  */
/*                                               */
/* Parameters: Pointer to a browser_data struct  */
/*             relevant to the headers;          */
/*                                               */
/*             Flex anchor for a block holding   */
/*             the HTTP response headers to look */
/*             through.                          */
/*************************************************/
d853 14
a866 1
  if (!b || !b->bcx || !headers || !*headers) return;
d979 32
a1010 36
/*************************************************/
/* html_build_internal_page()                    */
/*                                               */
/* Build an internal page, in such a way that    */
/* the fetcher (html_get_next_token) will think  */
/* it has got the data through a call to         */
/* url_read_data and the fetch has finished.     */
/*                                               */
/* This code used to be in-line, and so the      */
/* function is highly specialised... Munging of  */
/* fetch flags etc. is left to the fetcher to    */
/* try and make this more independent.           */
/*                                               */
/* Parameters: Pointer to a browser_data struct  */
/*             relevant to the fetch;            */
/*                                               */
/*             flex_ptr for the intended source  */
/*             store in which the page is built; */
/*                                               */
/*             Pointer to the fetch's urlstat    */
/*             struct to avoid wasting time      */
/*             finding it from the browser_data  */
/*             pointer;                          */
/*                                               */
/*             Actual URL being fetched (may not */
/*             be the same as the reference base */
/*             URL);                             */
/*                                               */
/*             Pointer to a copy of the URL in   */
/*             a buffer (the contents may be     */
/*             updated) - the caller should be   */
/*             using this as the reference base  */
/*             URL at all times;                 */
/*                                               */
/*             Size of that buffer.              */
/*************************************************/
d1289 26
a1314 31
/*************************************************/
/* html_transfer_to_store()                      */
/*                                               */
/* Another ex-fetcher function (see for example  */
/* html_build_internal_page), this time to move  */
/* data from fetch_buffer to the given source    */
/* store.                                        */
/*                                               */
/* Parameters: Pointer to a browser_data struct  */
/*             relevant to the fetch;            */
/*                                               */
/*             flex_ptr for the current (or      */
/*             intended, if no data has been     */
/*             fetched in this session before)   */
/*             source store;                     */
/*                                               */
/*             Pointer to the fetch's urlstat    */
/*             struct to avoid wasting time      */
/*             finding it from the browser_data  */
/*             pointer;                          */
/*                                               */
/*             Amount of data that was read into */
/*             the fetch buffer in bytes;        */
/*                                               */
/*             Pointer to int into which the     */
/*             number of bytes fetched so far is */
/*             placed (worked out from the size  */
/*             of the source store after moving  */
/*             data into it), or NULL if you're  */
/*             not interested.                   */
/*************************************************/
d1393 48
a1440 58

/*************************************************/
/* html_get_next_token()                         */
/*                                               */
/* Gets a chunk of document source from a given  */
/* fetch handle, and may generate new HStream    */
/* structures as the document is passed over to  */
/* the HTML library parser.                      */
/*                                               */
/* Parameters: Pointer to a browser_data struct  */
/*             relevant to the fetch or NULL;    */
/*                                               */
/*             The fetch handle;                 */
/*                                               */
/*             Pointer to int into which the     */
/*             number of bytes still to be       */
/*             fetched is placed;                */
/*                                               */
/*             Pointer to int into which the     */
/*             number of bytes fetched so far is */
/*             placed;                           */
/*                                               */
/*             Pointer to an HStream *, into     */
/*             which the address of the base of  */
/*             the token list is written, or     */
/*             NULL to signal 'not ready';       */
/*                                               */
/*             Pointer to an int, into which a   */
/*             reason code is placed:            */
/*                                               */
/*             0: Token has been received OK,    */
/*             1: We are waiting for something,  */
/*             2: A redirect has been detected   */
/*                (in this case, *remaining will */
/*                point at the new URL),         */
/*             3: This data is not parseable (in */
/*                this case, *remaining holds a  */
/*                filetype);                     */
/*                                               */
/*             Pointer to pointer to the store   */
/*             for the whole of the data fetched */
/*             so far (if any), be it an HTML    */
/*             document, image, or whatever;     */
/*                                               */
/*             Pointer to string holding the URL */
/*             that is being fetched;            */
/*                                               */
/*             1 if this is an image fetch, else */
/*             0 for HTML or unknown.            */
/*                                               */
/* Assumes:    That if the browser_data struct   */
/*             pointer is NULL, the fetch is not */
/*             for an internal URL. The other    */
/*             pointers must NOT be NULL unless  */
/*             it is specifically stated that    */
/*             they may be in the parameters     */
/*             list.                             */
/*************************************************/
d1694 7
a1700 3
          list = list_get_malloc_list_string("LONoScripts");
          if (list) scripts = urlutils_matches_special(d, list) ? 0 : choices.support_js;
          free(list);
d1975 1
a1975 1
            /* drop through to the 302 case.                            */
d1981 1
d1984 1
@


1.38
log
@Further printing tweaks. Font colours inside anchors now work (must be
built with the 02-Mar-2000 HTMLLib or later). Event log won't show guts
of internal URLs for just-born browser windows if displaying the list
by URL. Empty Location headers don't redirect down zero page and give a
nasty internal error; raise "no fetcher service found" instead.
@
text
@d2309 10
a2318 1
              if (e) return e;
@


1.37
log
@Long overdue check-in of intermediate browser build, from continued "out
of hours" work. Forgot to add a few files last time too.

List dialogue box handler complete, and exclusion lists implemented
within the main browser code. Full documentation in Choices file.
Save routine knows all about it but is now getting very slow - must
come up with a better scheme; for now, it puts the hourglass on...

StripExtensions option controls auto stripping of filename extensions.

More sensible ancestor / frame selection for keyboard shortcut items
and the save dialogues - having selected a frame won't lock you into
it for F3 and related shortcuts now (input focus in URL writable ->
get ancestor details, input focus in frame -> get frame details). F4
works in frames. F5 now generally present for 'view source' with a
corresponding menu entry in the File menu.

Odd thing in later Res files; there's no action set for Adjust clicks
on the main ToolAction items in the button bar. Very odd. Nothing
appears to be set in v2.07 either, yet adjust-click works. Even
stranger. Anyway, added in the relevant event details (same as for
Select click in all cases) and this fixes the problem.

Background colours in the TABLE tag ignored the "don't print any
backgrounds" Print Style setting. Fixed. Meanwhile, the "black
text with no backgrounds" option wasn't getting this right either;
fixed this also.

Event logging implemented; HTTP errors and script output via.
window.print extension. No internal error output yet.

Faith:Never behaviour extended. If ever a server sends something with
no content type or an unhandleable type, the browser will try and get a
filetype from the URL. If it gets text or HTML, it'll render the file.
Else it'll save it. Hacks around IIS 4's lack of a content type field
in the Marketeye login stuff, and similar other slightly broken sites.
@
text
@d2008 1
a2008 1
              if (strlen(redirect) + strlen(tokens) + 5 < sizeof(tokens))
d2011 1
a2011 1
                strcat(tokens, redirect);
d2018 2
@


1.36
log
@Intermediate check-in; building a browser from this gives you something
between 2.07 and 2.08. Only the Phoenix JavaScript resources are fully
up to date.

I *think* these are the changes since the last check-in:

When saved as a Draw file, horizontal rules were plotted one page width
too far to the right (wonder when that started happening?!). Fixed. In
addition, DrawFiles now accepted as OBJECTs - they weren't in the
recognised filetype list before. Doh.

Table size calculator tables_count_table would overestimate the number
of cells where ROWSPAN was present and there were other rows below the
one spanned. Fixed. In certain odd cases (e.g. optimised image exports
as HTML tables (!!) from the Gimp) this can save vast amounts of RAM.

Fixed problem where printing stops in the middle of a document. Redraw
engine pagination code was written in the days where lines couldn't
have gaps between them; they can now. If a gap fell at the bottom of
a page the engine would look down, see no line straddling or touching
the page edge, and assume there was nothing more. This case is now
correctly handled.

Made sure desktop and testbed Browse Res files had up-to-date Encoding
menus (v2.07 Phoenix has different menus from v2.07 Browse by oversight).

URL auto-completion piggy-backed onto manual completion code; any string
without '.', '/' or ':' in it gets run through completion to see if a
more meaningful item can be produced - "www" special cased out though.

New List dialogue box handler, used for proxy exclusions etc.
(incomplete), complete with appropriate Res file objects.
@
text
@d50 1
d85 1
a85 1
#define FetchBufferSize 8192 /* Size of buffer for getting data from the URL module in html_get_next_token. */
d118 1
a118 1
      if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
d152 4
a155 14
/* In addition, a token "ProxyExclusions" is     */
/* looked for - this should contain a comma      */
/* separated list of domains for which no        */
/* proxying is done. Each domain should begin    */
/* with a '.'. The domains are compared with the */
/* right hand part of the host name in the URL   */
/* and if there's a match, no proxying will be   */
/* done. If a domain name does not being with a  */
/* '.', it is taken to be a host name, and an    */
/* exact match of the complete host name (albeit */
/* a case insensitive one) is required to block  */
/* proxying. This allows URLs that rely on the   */
/* local domain (e.g. "www", "www.internal") to  */
/* be excluded from proxying without ambiguity.  */
d182 1
a182 1
    exclusions = list_get_malloc_list_string("ProxyExclusions");
d193 1
a193 1
    strcpy(t1, "ProxyExclude");
d1234 1
a1234 1
      if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
d1330 1
a1330 1
      if (tl & (1u<<12)) Printf("html_get_next_token: (1) flex_free block %p which held page source\n",source);
d1350 2
a1351 2
      if (*source) Printf("html_get_next_token: flex_extend by %d to %d for page source store\n",r,flex_size(source) + r);
      else         Printf("html_get_next_token: flex_alloc %d for page source store\n",r);
d1378 1
a1378 1
      if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
d1388 1
a1388 1
    if (tl & (1u<<18)) Printf("\0216html_get_next_token: memcpy from %p to %p for %d bytes\0217\n",((char *) (*source)) + oldsize, fetch_buffer, r);
d1692 23
d1720 1
a1720 1
                                choices.support_tables, /* 1 to handle TABLE etc., else 0                     */
d1723 1
a1723 1
                                  choices.support_js,   /* 1 to handle <SCRIPT> contents, calling the script  */
a1967 2
        /* Interpret the codes returned by HtmlIdentify. */

d1993 26
d2159 58
d2392 2
d2414 2
d2418 17
@


1.35
log
@Another intermediate check-in, resources may not be up to date; items
most likely to be buildable are PhoenixJ and BrowseD. Done because I'm
about to make some rather dodgy changes to code otherwise unchanged
since the Customer browser and I may well have to back them out...

In Handlers.c now set the HFlags_HasBeenVisited bit of a token at the point
it is first clicked on. Means the link returns to a "visited" colour after
the highlight flash immediately. This will persist for as long as the browser
window is kept open on that page, though if the URL doesn't end up making it
into the history for whatever reason it would "unhighlight" on reload; fair
enough, really. The highlight is window-local, so there are no redraw worries
for other open windows with links to the same URL (though other same-URL
links on the same page aren't updated either).

All forms submissions force a reload (principally for eudoramail.com, but
many other sites have similar requirements).

!MkClean and !MkClnAll didn't correctly call the utility to strip Makefile
dependencies. Fixed.

On fetch closedown, fetchpage_preprocess_token could be called on a token
which had already been run through the preprocessor. Now checks the flags
word before proceeding.

Image RAM cache and garbage collection system implemented - see new Choices
file entries CollectAfter, FreeRAMLimit and UnusedImageLimit to get an
overview. This contains groundwork for JavaScript image array support.

More JavaScript support improvements. Any one window object will know its
parent, top, this, etc.; frames array working except for a frameset created
via. multiple documents; opener for something created with window.open is
currently not set and don't know why (property is being created, pointer to
valid object is held, but JS engine returns 'null'. Ho hum) - JSChain won't
work yet, then.
@
text
@d54 1
d96 2
d183 3
d188 2
a189 1
    /* can write zero terminators in this to make the searching easier.     */
d191 1
a191 1
    char * exclusions = lookup_choice("ProxyExclusions", 0, 0);
d193 1
a193 1
    if (*exclusions && strcmp(exclusions, "!"))
d195 4
a198 3
      char * next;
      int    offset;
      int    hlen = strlen(d->host);
d200 1
a200 1
      /* Go through each item in the comma-separated list */
d202 1
a202 4
      do
      {
        next = strstr(exclusions, ",");
        if (next) *next = '\0';
d204 3
a206 3
        /* Compare only the right hand side of the host name */
        /* if the entry starts with a '.', or compare the    */
        /* whole thing if not.                               */
d208 1
a208 3
        if (*exclusions == '.')
        {
          offset = hlen - strlen(exclusions);
d210 5
a214 20
          if (offset >= 0 && !utils_strcasecmp(d->host + offset, exclusions))
          {
            /* A domain match - exit without proxying */

            goto html_set_proxy_exit;
          }
        }
        else
        {
          if (!utils_strcasecmp(d->host, exclusions))
          {
            /* Whole host matches - exit without proxying */

            goto html_set_proxy_exit;
          }
        }

        /* If we have another item, advance to read it */

        if (next) exclusions = next + 1;
a215 1
      while (next);
d218 2
a219 1
    /* These are the names we use for HTTP (backwards compatible...) */
d847 135
d1882 5
d2325 5
d2335 1
a2335 1
                  type = urlutils_filetype_from_url(browser_fetch_url(b));
d2337 1
a2337 1
                  if (type == FileType_TEXT)
d2339 25
a2363 2
                    b->page_is_text = 1;
                    *waiting        = 1;
d2365 4
a2368 1
                  else if (type == FileType_HTML)
d2370 17
a2386 2
                    parseable = TYPE_HTMLFILE;
                    *waiting  = 1;
d2388 3
d2393 2
a2394 2
                    parseable = TYPE_UNKNOWN,
                    *waiting  = 3;
@


1.34
log
@Everyone else seems to be checking lots of stuff in lately, so I've
decided to join in. This is an intermediate check-in and so not all
resources etc. will be up to date. You should be able to make Phoenix
and a debug build out of it. As a reminder, to make a JavaScript build:

 * Build JSLib and NSPRLib. Recommend you leave -DUSEMEMLIB in there (as
   used by default) so you can watch it leak into a dynamic area... :-)
   If you do this, you'll need to build MemLib too, of course. If you
   do NOT use MemLib, *undefine JS_USING_MEMLIB in Main.c*!
 * Run !MkClean. This now strips dynamic dependencies from the MakeFile
   automatically, to save you having to do it yourself.
 * Run one of the TaskObey files with the "J" suffix, e.g. !DeskBrwsJ -
   this uses the same .o directory for object files and exports to the
   same position in the Targets directory as the non-JavaScript build,
   but it does produce a unique binary in 'abs' and symbols table in
   'syms'.
 * Sourcing an appropriate !Run (with increased WimpSlot value), !Boot
   and About resource is done automatically.
 * Some, but not all of the !xxxD (debug) TaskObey files will make
   JavaScript versions in passing - check the JSUFFIX value on the Make
   command line parameters in the file.

This'll only work on RISC OS 3.1 due to the use of MemLib.

Here's the change list:

Included MNG icons in sprites files; added Sprites23 for some builds.
Added in ANT URL file icon (b28) derived from URI file icon, because
the Save dialogue can need it.

No, you do *not* need to define the same keyboard shortcuts in each
frame since the ancestor keeps the input focus and we've basically
dropped non-nested Wimp support. Maintaining no less than 4 lists of
identical shortcuts was a pain. Some Res files now only have the
lists in the main browser window and button bar objects (these two
are both required still).

Ursula build Markers button arrangement changed from 1x3 horizontal to
2x2 tilted, as in Phoenix, by popular demand.

Couple of hotlist bugs fixed; dragging an item and deleteing it with
Ctrl+X didn't terminate the drag, and deleteting an item underneath a
menu opened for it didn't close the menu.

'SendReferer' option added to all Choices files, all set to 'always'.
Put just beneath 'Clone' as it refers to header items, though really,
both Clone and SendReferer should probably be in the "Fetch controls"
section rather than "Multiuser environments and proxying"! Front-end
control of this is available.

In image_export_original, save_save_source, save_transfer_source and
save_save_object, flex_set_budge(0) was called to lock the heap but the
return value wasn't stored. flex_set_budge(1) was then used to unlock
the heap. All calls now remember and restore the old value, which is
both safer in case one calls another and allows the flex_set_budge
call in Main.c to have an application-wide meaning, as intended.

Some restructuring to the data load and RAM transfer sections of
Protocols.c; remote hotlist builds wouldn't allow files to be loaded
to browser windows before, and can now drop URL, URI or text files to
the Open URL dialogue.

New option "MinimumFontSize", lets the 'size' attribute of the 'font'
element be overridden. Default value is 1, to allow the full range of
values for the attribute. Setting to 7, for example, would give font
size 7 text at all times. Another new option, "ToggleOnXOnly", to
make Toggle Size only extend the window vertically (with Ctrl then
being used to toggle to genuine full size, rather than vice versa).
All Choices files updated to hold both of these options; only the
first has front-end control available (see debug build Res file).

JavaScript Document object exists; frames array etc. working. Can now
just about use "http://www.acorn.com/~ahodgkin/jschain/" but it does
abort after a bit - problems with frames again, I suspect. Is is pretty
slow, too. Can now press Escape to terminate a script.

Main.c erroneously referred to Controls file entry "StopWebServe" as
"StopWebProxy". Fixed.

Keyboard shortcuts to raise SaveFile are now possible in a general sense;
the code before was in the ToBeShown handler and just checked for a parent
component of -1. It then assumed "save frame HTML source". Now there's the
savefile_raise_from_shortcut function, which together with the seven new
event codes in SaveFile.h allows saving of HTML source and frame location,
export of links, images, backgrounds and the page as text or draw, to all
be invoked by keyboard shortcuts. Some Res files have some of these defined.

In reformat_check_height, the first check to see if setpara should be set
references a field in tpLast without checking if it is NULL. Whilst the
'line > 0' check should mean that tpLast wasn't NULL anyway, a direct
call to the function from outside of the reformatter might have tripped
up on this - the check for tpLast != NULL is now made.

Adjust-click on close icon in window showing file: URL attempts to open
the parent Filer window.

Reformatter used to try and find a selectable token if keyboard control
was enabled in a really stupid place - could make reformatting become
very slow if no selectables were present, especially if the page had a
few tables on it. Preprocessor now does this (since it goes through all
of the tokens anyway), the reformatter just doing a last check to ensure
no frames have obscured the selectable and if so, it tries to move it.
Done in the reformatter as generating a line array implies the data really
is visible.

Ctrl+Tab URL completion now builds a full list of matches from the hotlist
and history and can cycle through them (Ctrl+Shift+Tab stepping backwards).

Will give a real error rather than just "Data Abort" if it goes wrong
now. Someone somewhere is setting bit 30 of the error which confused
the replacement signal handler. Flag bits are now masked off (as they
should've been to start with).
@
text
@d1584 7
@


1.33
log
@Added capability to send Referer headers, together with new options to
allow this to be sent: a) Always, b) Never, c) when the URL referred to
is an http URL.  Default is c.  There is no frontend editing capability
for this option.  This addition means that various counters and sites
that rely on referer to indicate a resource upon which an operation is
to be carried out will now work (eg. rating a web site on Geocities).
@
text
@d345 1
a345 1
                           char * user, int allowparse, int proxy, const char *referer)
d527 1
d530 2
a531 1
      char *ptr;
d536 1
d538 4
a541 1
          /*FALLTHROUGH*/
d543 1
d545 1
d557 2
d776 5
a780 1
        browser_clear_selection(browser, 0);
d786 2
a787 1
        browser_clear_highlight(browser, 0);
@


1.32
log
@Check-in of Browse v2.06; using very small log file to try and avoid
CVS crashing. Some of the Resources may well be out of date due to CVS
locks being in place after earlier server-end core dumps, which I can't
remove myself.

I'll try and check one file in at the end with the full change log so
people know what's happened (it's reached about 16K...) - I'll make
that the TaskObey file '!All' in the top level directory. So for the
full log, look for the changes on this file.
@
text
@d59 1
d345 1
a345 1
                           char * user, int allowparse, int proxy)
d526 26
d614 1
a614 1
int html_insert_header(char * header, flex_ptr data)
@


1.31
log
@All !Run[D], Choices, Messages, Controls and Res files are up to date.

RefoKeep and RefoHold options added to, respectively, try and maintain
the line at the top of the visible area when reformatting, and not shrink
the vertical extent at the start of a reformat to try and avoid flicker
to the top of the page and back down again when RefoKeep is on. Choices
front-end implemented, which also allows RefoWait and RefoTime to be set.
Unfortunately for various reasons this doesn't help the page jumping when
unsized images come in (but RefoHold can improve matters...) - roll on
the image history.

DragToScroll and NoScrollBars options added for frames; included new
pointer type, Mouse_Shape_DTS, so relevant Controls file entries done
and Sprites[22] files updated as required. Noticed some builds have
a low-res ptr_link with a mask - mask removed.

Named anchor following fixed up somewhat - anchors near the bottom of
the page shouldn't be displayed, and then pulled down when the fetcher
releases null polls and ensures the y extent is correct (this through
implementing the min_height field in the browser_data structure).

RefoHang was never implemented and there seems little point to it now,
so the entry for it has been removed from the global choices structure
and all Choices files.

Markers menus should work properly now (in last check-in they would not
update correctly if Adjust was used on the entries).

URI handler usage now a lot more sensible, with configuration of how the
browser uses the module from both a Utils menu submenu (sic) and the
Choices dialogue.

Slightly dodgy 'hang around waiting for user input' stuff for the Cookies
dialogue box: All fetches are suspended; the fetcher remembers some info
about its state at the time the cookie came in, and restores it later; it
will only do this for one fetch at a time. It's necessary to single-thread
the fetcher at this point anyway, since other fetches may have a
dependency on the cookie that is hanging in mid-air at that point. As part
of this, some of the fetcher code has been split out into separate
functions (to try and 'black box' the code a bit). Anyway, Cookie Query
dialogue box now implemented with appropriate Choices file entry and
UI work in the Choices dialogue box.

Phoenix build Choices rearranged. Can now choose when the image history
is saved from the front end. Added also MSIE 4-style table option menu
for JPEG support (OS only, OS if it can handle it, internal only).

Should be a bit faster at loading the history - though 95% of the time
is spent in SWI URL_ParseURL. URL descriptions are stored more
efficiently as part of this - one malloc block instead of several
small blocks. The minimum block size for malloc blocks typically leads
to a significantly smaller startup wimpslot depending on the visit
history size.

Nasty bug in image system fixed. If an image size came in and a reformat
was to take place, the line the image lies in is found and the reformat
progresses from there. Unforunately, this didn't check to see if the
token can't be found in the line list, so it'd reformat from the top
of the page...! This would happen if, for example, an image halfway down
the page came in whilst a reformat for an image higher up had just begun.

In Choices.c, made choices_set_timetype_field, choices_set_uri_field,
choices_set_plugin_field, choices_set_cookie_field, and
choices_set_jpeg_field static (so they're not declared in Choices.h now).

Two memory leaks plugged in URL comparison routines in URLutils.c
(calling free() url_description instead of urlutils_free_descripton()).

Client pull reload handler was setting the reload flag if reloading
the same page, but forgetting to turn on reload_lock so
fetchpage_postprocessed was clearing the reload state... Similarly,
Ctrl+Shift+SELECT-Click on a link when the Controls file 'UseSmall'
entry is 'no' would not have reloaded as it should. Both fixed.

Frames shouldn't be so keen on acquiring horizontal scroll bars and never
letting them go when their width is decreased now. Frames set up for
'scrolling="yes"' will not start with no scroll bars and then gain them
shortly afterwards, causing flicker and two reformats - they'll start
with, and continue to hold, both scroll bars.

Pointer shouldn't flicker when over a frame border whilst other fetches
are progressing now.
@
text
@d53 1
d92 2
d123 192
a359 2
// Sort out the proxying code properly!...

d362 1
a362 7
  if (!e && choices.use_proxy)
  {
    char   method[64];
    char * method_ptr;
    int    method_len;

    /* Extract the fetch method from the proxy address */
d364 21
a384 13
    method_ptr = strstr(choices.proxy_address, ":");

    if (method_ptr)
    {
      method_len = (int) method_ptr - (int) choices.proxy_address + 1;
      if (method_len > sizeof(method) - 1) method_len = sizeof(method) - 1;
      strncpy(method, choices.proxy_address, method_len);
      method[method_len] = 0;
    }
    else strncpy(method, "http:", sizeof(method));

    e = url_set_proxy(0, h, choices.proxy_address, method, 0);
  }
d751 15
d861 3
a863 1
  if (*source) flex_free(source);
d869 8
a1007 2
      if (*source) flex_free(source);

d1114 2
d1117 2
a1118 1
        RetLastE;
d1545 9
a1553 1
        if (up->context) HtmlSetEncodingCallback(up->context, encoding_changed_by_meta, b);
@


1.30
log
@Programming warehouse link removed from all hotlists - the page has gone.

Some compile-time hacks in place to use MemLib, a dynamic area based
malloc replacement which shrinks its heap when possible. All builds
have these switched off at the moment. Seemed to work with just Browse,
though there would be problems with message blocks stored in dynamic
areas because of the Wimp's '&3800000' check - however, it failed when
HTMLLib was made to use it, too. Don't know why yet.

ItemInfo.[c/h] source added, with Res file additions for testbed Browse
and Phoenix.

Small fetch windows now work properly regardless of toolbar settings
in the Choices.

Reload now reloads all images too, rather than only reloading them for
as long as the main page was being fetched.

Added a simple 'Find' facility.

Realised that event handlers in eventlib are called in reverse order
of registration, so the miscellaneous event handler is now registered
first rather than last.

Multiuser code added (most only active if SINGLE_USER is undefined). As
part of this, hotlist code now knows about read-only items (done for the
Customer-style 'Resources' file, but works generally anyway).
handle_add_hotlist doesn't try to save the hotlist itself anymore (the
hotlist_add function does all that through hotlist_modified anyway).

Customer build Choices and Controls updated slightly (e.g. ClaimHelp
off, hotlist to save on quit only).

Customer build now uses Phoenix-style buttons. Sprites files which
worked at the time (but will probably be out of date now) and included
most of the original Customer-style sprites are in
'Utils.Icons.Customer'.

Choices, Messages and Res files for all builds now stripped down to only
single user items or single plus multiuser for Customer build and testbed
build. Before, all contained a few multiuser bits in at least the Choices
file if not more.

Grammatical error ("Fetching frames contents" (sic.)) corrected in
default message, Toolbars.c, and all of the Messages files.

Customer build brought back to a servicable level (including
implementation of the Find dialogue box with animation and fixing
up authorisation and 'Stop' state in the tristate). Quite a few
missing #ifndef REMOTE_HOTLIST bits from hotlist code added...

Customer build will not use <Choices$Write> or Boot:Choices for any
file finding now. UseProxy defaults to 'yes', MaxImages to 2. Res
file includes Proxy Address setting (save_save_choices() now writes
the ProxyAddress line).
@
text
@d59 13
d74 4
a77 1
static char * fetch_buffer = NULL; /* Address of buffer for getting data from the URL module in html_get_next_token. */
d87 32
d482 7
d607 413
d1034 1
a1034 1
/*             fetched is played;                */
d1080 5
a1085 1
  int               r = 0;
d1087 1
d1090 6
d1101 2
a1102 1
  /* through *token.                                              */
d1105 1
d1107 1
a1107 1
  /* Until we know better, signal that we're waiting */
d1109 1
a1109 1
  *waiting = 1;
d1111 1
a1111 3
  /* Ensure a fetch buffer is allocated */

  if (!fetch_buffer)
d1113 3
a1115 1
    fetch_buffer = malloc(FetchBufferSize); /* See top of this file */
d1117 1
a1117 1
    if (!fetch_buffer)
d1119 1
a1119 5
      #ifdef TRACE
        if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
      #endif

      return make_no_cont_memory_error(8);
d1121 1
d1144 6
d1157 3
a1159 2
    int status = 0;

d1165 2
a1166 1
    char * p = fetch_find_name_tag(ref_url);
d1168 1
a1168 1
    if (p) * p = 0;
d1170 4
a1173 5
    /* If there isn't an authorisation request in progress, and the  */
    /* fetch is apparently in progress, and the authorisation status */
    /* isn't '1' (which means 'doing'), get some data from the URL   */
    /* module. The url_read_data call puts the number of bytes read  */
    /* into r.                                                       */
d1177 7
a1183 4
      e = url_read_data(0,               /* Flags - must be 0 at present */
                        handle,          /* Session handle               */
                        fetch_buffer,    /* Buffer to receive data       */
                        FetchBufferSize, /* The buffer's size            */
d1185 9
a1193 2
                        &status,         /* Protocol status              */
                        &r,              /* Number of bytes read         */
d1195 1
a1195 1
                        remaining);      /* Number of bytes left to get  */
d1197 2
a1198 17
      /* Deal with cookies */

      if (!e && (status & (1u<<16))) e = cookies_process_cookie(b);

      /* Deal with the size information */

      if (*remaining > 0 && !b->data_size) b->data_size = *remaining + r;
    }
  }
  else if (up->fetching) /* Don't repeat this over and over... */
  {
    /* This is an internal URL, so treat specially */

    int    ok;
    char * extra = "";
    char * tail  = "";
    int    len, exoff, toff;
d1200 2
a1201 1
    if (*source) flex_free(source);
d1203 1
a1203 5
    /* Work out the length that the HTML file we're about to generate will be */

    switch (b->displayed)
    {
      case Display_External_Image:
d1205 1
a1205 1
        int protolen;
d1207 2
a1208 1
        /* Look up the token embedded in the URL */
d1210 2
a1211 49
        lookup_token(url + Int_URL_Len, 1, 0);

        /* Find a ':' separating extra information and point just past it */

        exoff = urlutils_internal_extra(url);
        if (exoff) extra = url + exoff;

        len = strlen(tokens) + 1;

        if (*extra)
        {
          toff = urlutils_internal_tail(url);
          if (toff) tail = url + toff;
        }

        /* Is this a system variable name for fetching, e.g. Wimp$Scrap? */

        protolen = strlen(FileMethod ProtocolSepShort "<"); /* (URLutils.h) */

        if (
             !strncmp(extra,
                      FileMethod ProtocolSepShort "<",
                      protolen)
             &&
             extra[strlen(extra) - 1] == '>'
           )
        {
          int              required;
          _kernel_swi_regs r;

          /* We'll have to trash the ref_url block. We know ref_url is at     */
          /* least as long as URL, so extract the system variable name to it. */

          strncpy(ref_url, extra + protolen, strlen(extra) - protolen - 1); /* -1 to skip the closing '>' */
          ref_url[strlen(extra) - protolen - 1] = 0;

          /* Now find out how long the expanded form would be */

          r.r[0] = (int) ref_url;
          r.r[1] = (int) NULL;
          r.r[2] = -1;
          r.r[3] = 0;
          r.r[4] = 0;

          /* _swix will not work correctly for this particular SWI if */
          /* requiring the returned R2 value. Something to do with    */
          /* the call relying on generating an error, but _swix spots */
          /* it and pulls out earlier than the call expects. Or some  */
          /* such thing...                                            */
d1213 2
a1214 1
          _kernel_swi(OS_ReadVarVal, &r, &r);
d1216 1
a1216 1
          required = -r.r[2];
d1218 2
a1219 55
          /* Woah - system variable wasn't defined... */

          if (!required)
          {
            erb.errnum = Utils_Error_Custom_Normal;

            strcpy(erb.errmess, "<");
            strcat(erb.errmess, ref_url);
            strcat(erb.errmess, ">");
            strcat(erb.errmess, lookup_token("NotDefined: not defined.",0,0));

            return &erb;
          }

          if (required < 0 || required >= sizeof(ref_url) - 1) /* -1 = allow for terminator */
          {
            /* Well, we sort of haven't got enough memory. Ahem. */

            return make_no_memory_error(8);
          }

          /* Otherwise, expand the variable (_swix is OK here as we don't */
          /* want any returned register value).                           */

          _swix(OS_ReadVarVal,
                _INR(0,4),

                ref_url,
                ref_url,
                sizeof(ref_url),
                0,
                4);

          /* Ensure it is terminated correctly */

          ref_url[required - 1] = 0;

          /* Turn it into a fetchable URL */

          urlutils_pathname_to_url(ref_url, sizeof(ref_url));

          /* Point to this URL */

          extra = url = ref_url;
        }

        /* Note that this is a very slow function call... */

        len = utils_len_printf(tokens, extra, extra, tail);

        if (len < 0)
        {
          /* If the above fails, do our best to calculate the length. */
          /* This will always overestimate the size (safer to do this */
          /* than underestimate!).                                    */
d1221 1
a1221 12
          len = strlen(tokens) + 1;

          /* For external images, need to fit the extra data in twice, and */
          /* try to find a filename separator for a picture caption (put   */
          /* this in 'tail').                                              */

          if (*extra) len += strlen(extra) * 2 + strlen(tail) + 2;
        }
      }
      break;

      case Display_Scrap_File:
d1223 1
a1223 3
        int found, type;

        if (*source) flex_free(source);
d1225 4
a1228 1
        /* Find the file length */
d1230 1
a1230 11
        _swix(OS_File,
              _INR(0,1) | _OUT(0) | _OUT(4) | _OUT(6),

              23, /* Read catalogue info for named, stamped object */
              Save_ScrapFile,

              &found,
              &len,
              &type);

        if (found != 1)
d1232 1
a1232 26
          erb.errnum = Utils_Error_Custom_Normal;

          /* Error message will either be 'can't find the page', or, if this is */
          /* a frame and the frame source matches the fetching URL, 'can't find */
          /* the frame'.                                                        */

          if (
               b->ancestor          &&
               b->frame             &&
               b->frame->src        &&
               browser_fetch_url(b) &&
               !strcmp(b->frame->src, browser_fetch_url(b))
             )
          {
            StrNCpy0(erb.errmess,
                     lookup_token("WhatFrame:The sending application could not supply the page contents for this frame.",
                                  0,
                                  0));
          }
          else
          {
            StrNCpy0(erb.errmess,
                     lookup_token("WhatScrap:Cannot find the page to load; the sending application may have died.",
                                  0,
                                  0));
          }
d1234 3
a1236 2
          return &erb;
        }
d1238 1
a1238 1
        /* Is this a text file? */
d1240 1
a1240 4
        if (type == FileType_TEXT)
        {
          b->page_is_text = 1;
          up->type        = TYPE_TEXTFILE;
a1241 1
        else b->page_is_text = 0;
a1242 1
      break;
d1244 13
a1256 3
      case Display_About_Page:
      {
        len = 0;
a1257 1
      break;
d1259 13
d1273 1
a1273 4
    /* If required, claim memory for the page; complain if this fails */

    if (len) ok = flex_alloc(source, len);
    else     ok = 1;
a1274 56
    if (!ok)
    {
      #ifdef TRACE
        if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
      #endif

      return make_no_cont_memory_error(1);
    }

    /* Construct the page in the claimed block (or build it in a */
    /* new block).                                               */

    switch (b->displayed)
    {
      case Display_About_Page:
      {
        RetError(about_build_page(source));
      }
      break;

      case Display_External_Image:
      {
        memset(*source, 0, len);
        sprintf(*source, tokens, extra, extra, tail);
      }
      break;

      case Display_Scrap_File:
      {
        FILE * file;

        /* Load and delete the scrap file */

        file = fopen(Save_ScrapFile, "rb");

        if (!file) RetLastE;

        if (fread(*source, 1, len, file) < len)
        {
          fclose(file);
          RetLastE;
        }

        fclose(file);
        remove(Save_ScrapFile);
      }
      break;
    }

    /* Set up fetch flags to say that a fetch has been completed; since */
    /* we've filled in the document source store here, say that zero    */
    /* bytes have been fetched (otherwise code below will try to copy   */
    /* data out of the fetch_buffer block).                             */

    r              = 0;
    remaining      = 0;
a1278 61
  }

  /* If there isn't an error, and more than zero bytes have been read, */
  /* deal with the data (if any) returned from the above call.         */

  if (r && !e)
  {
    int ok, oldsize;

    /* 'fetched' is a flag which if set indicates at least 1 byte has been */
    /* got so far. If fetched is zero, and there is data in the source     */
    /* store (i.e. 'source' is not NULL) then free up the store as it does */
    /* not hold any valid data (must be from an old fetch).                */

    if (!up->fetched && *source)
    {
      #ifdef TRACE
        if (tl & (1u<<12)) Printf("html_get_next_token: (1) flex_free block %p which held page source\n",source);
        flexcount -= flex_size(source);
        if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
      #endif

      flex_free(source);
      *source = NULL;
    }

    /* Signal that there's definitely data fetched now. */

    up->fetched = 1;

    /* If there's store allocated at this point, it holds valid source; extend */
    /* it by the number of bytes read from the url_read_data call. Else, alloc */
    /* a new buffer to hold the data.                                          */

    #ifdef TRACE
      if (tl & (1u<<12))
      {
        if (*source) Printf("html_get_next_token: flex_extend by %d to %d for page source store\n",r,flex_size(source) + r);
        else         Printf("html_get_next_token: flex_alloc %d for page source store\n",r);
      }
    #endif

    if (*source)
    {
      oldsize = flex_size(source);
      ok = flex_extend(source, oldsize + r);
    }
    else
    {
      oldsize = 0;
      ok = flex_alloc(source, r);
    }

    #ifdef TRACE
      flexcount += r;
      if (tl & (1u<<14)) Printf("**   flexcount: %d\n",flexcount);
    #endif

    if (size) *size = oldsize + r;

    /* Report an error if the allocation failed */
d1280 1
a1280 17
    if (!ok)
    {
      #ifdef TRACE
        if (tl & (1u<<6)) Printf("html_get_next_token: Exiting with error\n");
      #endif

      return make_no_cont_memory_error(1);
    }

    /* The data block has been created/extended successfully, so copy the */
    /* data from the url_read_data call into it.                          */

    #ifdef TRACE
      if (tl & (1u<<18)) Printf("\0216html_get_next_token: memcpy from %p to %p for %d bytes\0217\n",((char *) (*source)) + oldsize, fetch_buffer, r);
    #endif

    memcpy(((char *) (*source)) + oldsize, fetch_buffer, r);
d1326 1
a1326 1
        r = *source ? flex_size(source) : 0;
d1329 2
a1330 2
      /* If there is new data in the source store (size = r) and no error at */
      /* present, attempt to parse the chunk of data with HtmlGetStream.     */
d1332 1
a1332 1
      if (r && !e)
d1336 1
a1336 1
                            r,                  /* Size of the chunk that has been added     */
d2092 2
@


1.29
log
@RefoSingle option added to Controls.

Precautions taken in table code to avoid divide by zero errors.

Framesets defining more frames than the frameset implies, for whatever
reason, should never cause a crash now - just report a 'Frames definition
is badly nested' error (if STRICT_PARSER defined). Along the same lines,
in a single document defining a set of nested frames, two /FRAMESETs in
succession could cause a fairly nasty crash. Fixed.

TIFFs do not get loaded by double-click now.

If holding down SHIFT to save a link contents to disc, you can also hold
down CTRL to bypass the cache (sets the browser's reloading flag). Noticed
when testing this that windows_create_browser didn't take account of the
Controls file 'UseSmall' entry when adjust-shift-clicking on links. It
does now.

There is now a complete and up to date set of interactive help messages
built into the Ursula, Customer and Phoenix build Res files.
@
text
@d241 1
a241 1
    /* If user details are given, insert the appropriate header entry */
d243 1
a243 3
    if (user)
    {
      char head[Limits_Multi_UserName + 80];
d245 6
a250 2
      sprintf(head, "Mailserv-User: %s", user);
      ok = html_insert_header(head, (flex_ptr) &up->extradata);
d252 3
a254 3
      if (!ok)
      {
        url_deregister(0, h);
d256 2
a257 1
        return make_no_fetch_memory_error(5);
d259 2
a260 1
    }
@


1.28
log
@*Don't* try to load FilterManager 0.18 in !Run[D] files. Requires
WindowManager 3.98. Sets URI handler environment variables for
http, ftp and gopher.

Fixed 'doesn't reformat for unsized images' bug - only happens when the
deferred reformatter is enabled, hadn't remembered to check this in my
debug build where this is turned off. Oops.

Caret position in forms could get left behind despite attempts to rectify
this in v1.31 - now fixed (and faster, fortunately).

Hourglass + percentage displayed for History and Image History when
loading - it can take a while for very big histories, though in
practice you only see the visit history loading (has to do a lot
more work, and is thus quite a bit slower than the image history).

POST forms worked when targetted to frames, but were broken when
not targetted! (Forms data inherited from one browser to the same
browser; ended up freeing the flex block...). Fixed.

Now support 303 response code (redirect to GET). Treated as 301, i.e.
not support if STRICT_PARSER is defined, otherwise drops through to
the 302 handling code.

Pointer shouldn't get stuck in odd shapes when going to a new page now;
it gets reset to a standard shape every time the null handler that
checks the position is called, though (whether or not the handler thinks
the pointer is over a different token, if that token is NULL, it sets
the standard shape). A possible work around would be for a browser to
remember the pointer shape too; that's for the future, though.

Early stage table formatting functions could blow themselves apart if
tables_count_table decided there were no rows, columns or both. A
net table size of zero cells is now dealt with; slow, partial table
fetches in multiple windows with image loading turned on will now
*hopefully* be stable, where v1.31 would have bombed out repeatedly.

A nested frameset within one document will now inherit the border
width (frame spacing) and border colour of its parent. This is done
by copying the maxlen and indent fields of the parent token over
the child, and note it's done in the browser (fetch_preprocess_token),
not HTMLLib.

Border colour on a FRAMESET now used, with the first colour on any
FRAME within it overriding, as in NN 4 and MSIE 4.

<LI> bullets really do stick to the text next to them now (I'd done
that in an experimental piece of code and forgotten to merge it back
before the last check-in).

Browse$HotlistURL/URIFile and Browse$HomeURL/URIFile now work from
_TaskName in the Messages file, and are thus of the generic form
<App>$HotlistURL etc. - Docs.Notes and Docs.User updated appropriately.

Event 0x11d00 through to 0x11d7f will make the browser look up Controls
file entries 'JumpTo00' through to 'JumpTo7f' and read a URL from them.
This will be fetched in the ancestor window of the source of the event,
or a new window if such an ancestor can't be found [for Daytona demo].

NB: Nasty frames-related crash at http://www.teledanmark.dk/menu/start.htm
is *not* fixed in this source. NOBR is not supported.
@
text
@d1100 1
@


1.27
log
@Check for WindowManager 3.97 and ensure Unicode$Path is set in all
!Run[D] files, don't set the Alias$@@PrintType_FF4 variable, and updated
Customer build ROM obey file variants. Various other changes to
the Run files for new module versions, updated paths to support
new positions of choices, hotlist and histories (see later), etc.

!Sprites[22] files hold small !app icons for some variants, and
an ic_browse sprite. Some variants now have a Sprites and Sprites22
file instead of just Sprites, with the former containing various
mode 12 or 15 specific sprites.

Text files dragged to the URL writable are treated as ANT URL files. This
relies on URLBarWrit (Toolbars.h) being a unique ID, which it should be,
but beware of the Hotlist and Choices numberspaces...

INPUT TYPE=BUTTON supported. Form items without a FORM tag are now shown
(as MSIE 4, but not NN 4).

'*', '-', '@@', '_' and '.' are not escaped when submitting forms now. The
Web interface to the IMDb now works.

INPUT TYPE=HIDDEN items will not affect the line height anymore - so
http://www.hotmail.com/ now has correctly aligned writable icons, for
example. Similarly, TAG_FORM and TAG_FORM_END items could push up
line height and don't anymore.

HRs with a specified pixel width will now influence the size of a table
cell (they didn't before).

BRs now checked by tagno field when the browser needs to know something
was an actual BR tag rather than just a line break signal, and by the
style bit entry when only the indication of a line break is required.

Table widths of 0 or 0% are ignored.

Trace.c updated to report height and background fields in a table_stream.

fm_putsl() writes a terminator into the string; the Forms.c routines were
calling this for displaying INPUT TYPE=PASSWORD fields using the FE_PassCode
literal string (a line of stars). This write into a read only data area
would make the debugger fault the access. A local char array is now used
instead, to get round this (note the use of var[]=literal rather than
var[sizeof(literal)]; strcpy(var, literal) due to some weird compiler bug
that copies the wrong thing into 'var' under some (undefined...)
circumstances).

Text areas don't scroll back to the top line when clicked in anymore;
single line writables don't scroll back to the left either. When
reentering a text area from 'above', the caret appears at the top line
rather than 'somewhere further down'...

ARROWS_MOVE_OUT compile time option at the top of Forms.c defines whether
you must press Tab/Shift+Tab to move between writable fields in forms or
if up/down will drop out of them, though if keyboard control is on this
is enforced (or you get trapped inside the form!).

urlutils_filetype_from_url now uses MimeMap module.

If fetcher is told a page is text, it'll check for a filename extension and
may choose to use this instead (e.g. it may find it's HTML instead). This
is to try and get around duff servers... (e.g. http://www.batalarms.co.uk/).

Save dialogues shouldn't flicker when options that don't change the
filetype are selected (before, the draggable sprite was always reset for
each selection). Noticed the erroneous setting of a static variable in
SaveFile.c by a call to this by SaveObject.c, and so added a flag to
savefile_set_filetype to deal with this - would have been possible to get
the wrong filetype sent to applications or at best the wrong filetype
sprite in the dialogue without that.

The caret shouldn't jump out of a form back to the URL writable if the page
reformats now.

Table background colours now supported (as in the colour you see in the
border space if the cellspacing is large enough; this is as in MSIE, not
as in Navigator). Drawfile output routines updated accordingly.

Corrected erroneous use of wimpt_dx() / wimpt_dy() in a couple of places
in Images.c, which meant that (say) 1x1 images didn't work correctly in
medium resolution display modes.

Now have support for save as text (component ID and event 0x12) and save
as Draw (component ID and event 0x13) buttons. Dubious conditions for
greying and ungreying the print, save source and view source buttons and
menu options sorted out as part of implementing the same for the two new
buttons; added greying out of their associated menu items in passing.

Turned kerning on in draw file objects (does mean a rather heinous
increase in file size, but this is the only way to ensure the draw file
matches the visible page).

Comments before functions in SaveDraw.c are now complete and up to date.

Image and visit histories now generate a crude hash number to speed up
searching for items. It does give a speed increase, though it's a
disappointingly small one.

Issue of left/right margins and cellpaddings sorted out. Now have
redraw_left/right_margin for finding out the basic gap you must leave.
redraw_left/right_gap then gives any extra indentation for LI, BLOCKQUOTE
or whatever. The last two can be subtracted from the display width to
get an available page width for any section of text. Note that
redraw_left_gap replaces redraw_margin. The redraw_start_x function
uses the above to work out where a line's left hand edge should be,
taking account of left/right/centre alignment. HRs have been fixed now
(they were quite broken in v1.30, I think) based on this new model and
the behaviour of MSIE/NN 4.

Fixed width of cells with no contents - cell padding values wouldn't
have worked properly as the reformatter returns 0 rather than the left
hand margin size if given no stream.

Removed FM_Absolute flags for Font_Paint (spotted by DBrown) - sets bit
2, which is reserved...?

IMG width and height in % terms now works correctly; a % of available
width (after margins and indents) or height on the main page or for
a table cell, if the image lies in one. Because of the chicken-and-egg
problem with the latter, the cell must specify a width and/or height
for things to work properly. If this is not done, you'll usually end
up with a 1:1 scaled image (as in Navigator 4, rather than ending up
with no image or even no cell (!), as in MSIE 4).

HEIGHT attribute on a TABLE tag is supported, but only in a crude
fashion; the extra height (if there is any) is distributed over the
rows in a linear fashion. This is probably all you have to do in
practice, but I haven't checked. To maintain a notion of min/max
height as well as width would of course require a great deal more
work...

If using client pull to reload a page with a fragment ('...#name')
specified, then the reload wouldn't work on the same page; it'd just
jump to the fragment position. This won't happen if b->reloading is
set now (so works in conjunction with client pull on the same page
forcing a non-cached fetch). Similarly, if POSTing to such a URL,
a fetch will proceed (both these fixes done originally for
http://jupiter.beseen.com/chat/rooms/g/1678/).

browser_inherit split to browser_inherit and browser_inherit_post_data;
the code for the latter didn't clear any post_data in the child before
copying from the parent either, and could cause flex errors (now fixed).

Res file for Ursula ('Desktop' Browse) build tweaked - bits in the
font choices dialogue renamed, and button bar rearranged to hold the
new Save As Draw button. Other builds have had Save As Draw and
Save As Text buttons added, or not, depending upon availability of
suitable sprites, required UI simplicity, etc.

Now have:

  Browse$ChoicesFile
  Browse$ControlsFile
  Browse$ChoicesSave
  Browse$ControlsSave

(the last two are new) for loading and saving of the Choices or Controls
files. If unset, <App$Dir>.Choices or <App$Dir>.Controls will be set.
E.g., you could set Browse$ChoicesFile to be:

  <App$Dir>.Choices,Choices:WWW.(app).Choices

for loading and

  <Choices$Write>.WWW.(app).Choices

for saving. (The browser never saves Controls at the moment, so the
relevant variable above isn't effectively implemented, but could be
in future). Similarly, to support asymetric loading/saving of the Hotlist,
there are HotlistSave, HistorySave and ImageHistorySave entries in Choices
to complement HotlistPath, HistoryPath and ImageHistoryPath (which are used
for loading). save_save_choices will create directories as needed to obtain
the given path (and has also been fixed in various areas that hadn't been
tested out until now; e.g. zero termination of the AppName$ChoicesFile
variable expansion...). !Run[D] files updated appropriately.

Table widthing code rewritten. Slower, but a lot better on the whole.
Still has some problems - still needs a final 'make sure nothing is
below minimum width' scan, which it should be possible to do without.
No time to fix this at present!

The reformatter will now 'glue together' an LI token followed by any
non-LI token; so a bullet point followed by an item should not be able to
have a line break inserted after the bullet because of very tight width
constraints (it could before - yuk...).

'about:' brings up a page about the browser and any Plug-Ins, as with
Navigator (for example).

URI files support titles, as per spec. version 8. Saving a current
location to the Hotlist will thus give a sensible title now (unless
you're in a frame, so there's no title to get...). Of course, v1.00
files without a title still work.

Note that NOBR is *not* supported in this build and this combined with
the new table widther may cause problems on some sites (e.g. Microsoft's
home page!).
@
text
@d1340 8
d1369 2
a1370 3
            /* POSTing to redirected URLs) - basically, we always redirect */
            /* to a GET to be compatable with what everyone else does,     */
            /* rather than what they say they should do...                 */
@


1.26
log
@No change - just checking that ExtEdit is working properly now :-)
@
text
@d45 1
d909 6
d917 1
a917 1
    /* Claim memory for the page; complain if this fails */
d919 2
a920 1
    ok = flex_alloc(source, len);
d931 2
a932 1
    /* Construct the page in the claimed block */
d936 6
d1687 7
d1696 1
a1696 3
                  int filetype;

                  filetype = urlutils_filetype_from_url(browser_fetch_url(b));
d1698 1
a1698 1
                  if (filetype == FileType_TEXT)
d1703 1
a1703 1
                  else if (filetype == FileType_HTML)
d1716 1
a1716 1
                case TYPE_HTMLFILE:  *waiting = 1;
@


1.25
log
@There are a few known significant problems with this code but it's being
checked in so the Choices can be worked on. Note that Res files etc. are
not up to date across all builds. Progress is as follows...

Bug report prompted me to do this - now ignore <p> tags straight after
<li> tags, so '<ul><li><p>Some text' works as the author (or automatic
generator, more commonly) intended.

A <p> tag before a table will be acted upon now (it was ignored before).
Something like <li><p><table...> will give a line break and paragraph
space after the <li> despite the changes mentioned above, as in other browsers.
Both browsers differ from Navigator, where the table appears alongside
the <li> tag.

Multiple BR tags work as in MSIE / Navigator (they don't collapse to
zero height anymore).

For the above, line height (and so, <br><br> or <p> spacing) is now
calculated inside reformat_text_line_height, and is used with either
a token to get the text height at a given size (e.g. for general line
spacing or multiple BR tags) or NULL for normal size text (e.g. for
P spacing, though this value is in practice later scaled by 7/8ths in
reformat_check_height). Note this behaviour is exhibited by MSIE 4;
v3 gave two BRs the same spacing as one P (i.e. not font size
dependent).

Save dialogues can have an option button or couple of radios to
switch between various formats (e.g. URI or URL, sprite or original
format). See 'Docs.Notes' for more. The back-end to this is now
implemented (i.e. at the moment, save as URI or URL, save as original
image format). Note that when saving background images, a leafname
based on the original fetch URL is now offered rather than a generic
'Background'.

Internal URL scheme changed to be all lower case, so relativisation
through URL_Fetcher still makes sense... :-/

Holding down 'shift' when clicking on stop reverses the interpretation
of the Controls file 'StopWebServe' entry.

Fixed row / column count for exporting tables as text; fixed a few
bits and pieces of internal URL scheme stuff which got broken when
HTMLLib started using URL_Fetcher's relativisation.
@
text
@d1672 22
a1693 1
                case TYPE_TEXTFILE:  *waiting = 1, b->page_is_text = 1;
@


1.24
log
@Implemented Message_PlugIn_ReshapeRequest, Message_PlugIn_Status and
Message_PlugIn_Busy. Plug-in code more robust when given invalid
browser instance handles by the plug-in.

Line spacing is now calculated on the basis of the normal style base serif
font, with all other fonts being forced into that line height. This does
mean that an unusually tall (say) sans serif font may get clipped. It
appears to be the only way to get around wildly different baseline
depths returned from the font metrics - you can't work out line spacing
based on each different font style; the line spacing will vary.

Table heighting (as opposed to widthing...) improved considerably; rowspan
can no longer cause very tall cells in odd places. Having trouble getting
rid of the single pixel breaks between vertically adjacent cells, though
I've not tried too hard. Widthing, though, seems fairly badly broken at
present... :-/

Set/clear of page_is_text flag made more robust (it looked as though there
was the potential for this to get stuck in a set state, though I've never
see the front-end behave in a manner which indicates this is the case).
The reformatter will now decrease leading if this flag is set (plain text
pages look daft with a line spacing that is OK for 'rich' text pages).
No reformatting is done if the page width changes by dragging on the
resize icon, though toggle size / full screen will still reformat even
if the contents are only text (browser needs to sort out various width
flags at this point).

Cut down on excessive redrawing when reformatting due to a change in
window dimensions is not done. If display_width hasn't changed, then no
redraw is needed. If this causes redraw problems, then whatever is
changing display_width needs investigating. It shouldn't be kludged
(basically) by forcing a redraw instead of a reformat.

TT/PRE/etc. text can now have a non-100% aspect ratio. 80-90% looks
best (ArcWeb, for example, uses 86%). New option 'TTAspect' in
the Choices files.

Debug builds link to a non-debug Unicode library now; stops stderr
being dumped to the bottom left of the screen if you've not redirected
it in the Run file.

RISC OS 3.1 seems to need more initial WimpSlot than later OS versions.
The 64 deep nested table set gives a 'No stack for trap handler' error
(which it really means in this case!) without 800K, even though 3.71
is happy with just 640K. So, the !Run file checks if Boot$OSVersion
is exactly 300, 310 or 311, and sets the WimpSlot accordingly.

!Run[D] files now require latest fetcher module versions (URL 0.21,
File 0.31, HTTP 0.58).
@
text
@d870 24
a893 4
          StrNCpy0(erb.errmess,
                   lookup_token("WhatScrap:Cannot find the page to load; the sending application may have died.",
                                0,
                                0));
d1705 22
a1726 2
              if (history_can_go_backwards(b)) redirect = Internal_URL ForExternalHImage; /* Have a 'Go back' link */
              else                             redirect = Internal_URL ForExternalNImage; /* No 'Go back' link     */
@


1.23
log
@Following the last check-in - all build resources brought up to date.

Adjust-click on forwards/backwards buttons did not work in the intermediate
build, and now does.

Adjust-click on form submission buttons where the submit method is POST
will now work correctly, as the new view inherits the extradata block
of the old. Failure of this is signalled through
make_no_fetch_memory_error, code 16 (see updated Errors file in Docs).
Note the name change of extradata in this context; more details below.

The passing of forms POST data and extra headers for sending in an
HTTP request via. the URL module was all done through pointers into
flex blocks, and was therefore very unsafe. All relevant functions now
use pointers to pointers to the data.

To remove confusion on the umpteen uses of the word 'extradata', the field
in browser_data has been renamed to 'post_data'. The 'extradata' parameters
used within FetchPage.c were all disconnected from the extra header info /
form POST data stuff that extradata is usually associated with, and have
thus also been renamed, in this case to 'appnddata' (Append Data).

As well as X-NoProxy, the browser sends the 'proper' HTTP headers
Pragma:no-cache and Cache-Control:no-cache.

A redirection from a POST request was not handled correctly; despite
what HTTP specs say, you're supposed to use GET for the new URL. The
browser was, but when it chopped off the redundant header data in the
request didn't terminate it and left Content-Type in anyway...! Fixed.

Ctrl+Tab implemented - URL completion. Comes from the hotlist URLs,
hotlist titles, history hosts, paths, full URLs and lastly titles.
See code comments for more (history_find_match, hotlist_find_match).

TableSupport option added to Choices; it is read, can be set by the
front-end, but doesn't actually do anything else yet.

Reversed Choices' semantics on 'don't expire by...' for History. Added
'needs_redraw' flag to choices_get_contents so that, for example, if the
table border types change, browsers get redrawn.
@
text
@d885 1
d1632 2
d1655 1
a1655 1
                case TYPE_HTMLFILE:  *waiting = 1, b->page_is_text = 0;
@


1.22
log
@This is an intermediate check-in to allow work on Choices for the new
table options and History choices as detailed below. Res files are not
up to date except where indicated and there are several known bugs that
will be fixed before the 'final' v1.27 is created. Any work on resources
should only be done for the testbed !Browse.

Client side image maps implemented. There is code to draw highlighted
borders in CSIM.c, but this is not wired in yet; other than that,
the implementation is functionally complete. As part of this, centralised
the fetching of a targetted URL taking into account user request of a
new view and full screen mode, in fetchpage_fetch_targetted. The forms
library now uses this too, so form buttons respond to both adjust-clicks
and TARGET attributes.

Fixed APPLET handling where '.class' isn't present in the CODE attribute.

Paragraphs squashed at the top of cells/pages - browser would insert white
space before.

Now append a ' ' to the end of History menu items to prevent the Wimp
thinking the end of entries represents a keyboard shortcut (e.g. 'Home').

Netscape's handling of 'meta http-equiv="refresh"' is to start counting
when the fetch has completed and everything else has died down. The browser
will now not start counting until the animation handler is deregistered
(so formatting is complete) to show similar behaviour (note that this
checks the main handler, not the 'idle but returning to first frame'
drift handler).

URLs from requests for fetches by Plug-Ins are now relativised.

Page width change tolerance prior to reformat upped from 16 to 32 OS
units. Hoping to provoke a loosely connected bug with this change!

TableOuter, TableInner and SeeFetches choices added to all Choices
files, with appropriate loading and saving code in Main.c and Save.c.
AuthorFTP and AuthorFSh messages added for FTP authentication, and
dialogue handling code (the component in FetchHTML.c) updated to
recognise an FTP fetch and alter the dialogue presentation
appropriately.

All Messages file version numbers taken up to 1.27 (20 Nov 1997).

Following a UseNet suggestion, Ctrl+Toggle Size will increase the window
size to fill the screen vertically only; horizontal size/positioning is
not changed.

Shift+Tab in the URL writable will cycle through alternative fetcher
protocols (from both the Controls file and checking the fetcher modules
are actually present).

Hotlist doesn't require '://' in URLs when loading HTML, just ':/' - so
'file:/' URLs now will be reloaded correctly.

History system rewritten completely. GHistSize and VHistSize options
removed, and replaced by MaxSize and ExpiryAge. Now have global history
menus with most recently visited items at the top, and local history
menus which reflect the path that forward/back buttons would take.
Browsers are robust to background expiry of the History though this is
not implemented - date expiry and size checks are carried out on
history_record only. This does mean that with two windows open one could
have the history expired underneath it whilst another fetched, though;
the code handles this and update toolbars (greying items) as necessary.
It is possible to have the history limits so tight that even one entry
will not fit and again the code copes with this, though values read
from Choices are limit checked to ensure rather more useful results!

Implemented 'Save' button in save dialogues. Remembers pathnames and just
replaces the leaf now (hard coded exceptions for <Wimp$Scrap>... and
<Wimp$ScrapDir>...) - it did before, but only if you'd typed the path
in. Not many people did, given that you couldn't press Return or click on
a Save button to use that path...

In a similar vein, files of type Data or DOS will be checked for a '/xxx'
type extension and the MimeMap module will be used to find a more meaningful
filetype. If this can be handled, the file is loaded. This only works for
files dragged to the browser - the behaviour with inline data in web pages
will depend on the File module, and similarly, if File doesn't spot what is
going on and claims that the object is data, the browser will just open a
save dialogue for it.

!RunD files taken up to 3072K WimpSlot.

Hotlist's saved HTML page title wasn't internationalised - is now. This
opened up a significant can of worms; on file write error, the file would
never be closed, and if a caller of the save or load functions passed
in a filename held in the global Messages lookup buffer then subsequent
lookups in the callees would corrupt that filename. All sorted out now.

Local (not very useful) or global (useful) histories can be saved as HTML,
which opens up the possibility of sending your history to the hotlist
by saving to it. Local and global histories can also be emptied, though
this is probably not a feature that current release Desktop browsers need.
Inheritance of local history and certain UI features is now done more or
less for all cases where one browser window spawns another, too.

Vertical alignment on images is rather less ropey than it was (e.g.
ALIGN=TOP stands half a chance of working) but is still far from perfect.
This was part of fixing a nasty little bug in Redraw.c's setting of
an image position via. image_set_token_image_position, which was making
(amongst possibly many other things) client side image maps fail.
Image update where images had large borders was affected by a similar
problem too (more cans with more worms...).

Fixed image background filler functions; two problems. When cross
referenced images were replaced by base images in a browser because the
original owner was closing down, the original owner browser would stay
registered with ImageLib. Fixed; secondly, when images were deleted from
the image array causing those above to be renumbered, images registered
with ImageLib did not have their numbers updated (this was the one that
lead to the visible drop out of background images with PNGs on the Acorn
Internet home page when there were two views of the page and the first
was closed). This is now also sorted out.
@
text
@d77 3
a79 2
/*             Pointer to extra data for POST    */
/*             etc.;                             */
d99 1
a99 1
_kernel_oserror * html_get(char * url, char * extradata, int * handle, int method,
d173 1
a173 1
    if (extradata)
d177 1
a177 1
      len = strlen(extradata);
d207 1
a207 1
        strcpy(up->extradata + 2, extradata);
d209 3
a211 3
        /* Header entry for the extra data - again, the removal routines in the  */
        /* fetcher's redirection code assume that this comes before Content-Type */
        /* and the actual body content to make life easy there.                  */
d240 1
a240 1
    /* If user details are given, insert the appopriate header entry */
d257 2
a258 1
    /* If we aren't to use a proxy, say so in the header */
d262 6
a267 1
      ok = html_insert_header("X-NoProxy:", (flex_ptr) &up->extradata);
d297 1
a297 1
                      up->extradata,         /* Any extra data for POST etc.   */
d1209 4
a1212 2
            if (!image) fprintf(file, "For URL '%s', received header:\r\n\r\n", url);
            else        fprintf(file, "For image '%s', received header:\r\n\r\n", url);
d1214 6
a1219 3
            for (byte = 0; byte < o; byte++)
            {
              fputc((int) (*((char *) (((int) *source) + byte))), file);
a1220 2

            fclose(file);
d1325 3
a1327 1
            /* POSTing to redirected URLs)                                 */
d1331 5
a1335 5
              /* When the headers are build, the POST data (starting with a Content-Length */
              /* entry) are put in first and everything else is inserted above it. As the  */
              /* comments on this code say, this is organised so we can simplify things    */
              /* here and just chop off everything at Content-Length and below, rather     */
              /* than having to carefully remove the appropriate header lines and body.   */
d1339 23
a1361 1
                char * strip = strstr(up->extradata, "Content-Length");
a1364 2
                  int len;

d1367 1
a1367 1
                  len = strstr(up->extradata, "Content-Length") - up->extradata; /* Don't use 'strip' in case flex shifted when 'len' was stacked */
d1380 2
d1383 17
d1434 1
a1434 1
                            up->extradata,         /* Extra data for POST etc.            */
d1691 1
a1691 1
                              up->extradata,         /* Extra data for POST etc.            */
@


1.21
log
@Removed 'The Onion' link from some Hotlist files. Time showed that the
site wasn't entirely Family Friendly (TM)... Removed Shift Control (it's
gone offline now), and corrected the Telegraph URL from ...the-telegraph...
to just ...telegraph...

StrongHelp manual generator now tries to work out the number of lines in
the table on the root page more intelligently.

Plug-in support extended to handle Shockwave. Quite a lot of underlying
work for this, including a pseudo cache system for temporary files.

Bug in redraw routines: they plotted background images within table
cells, when nothing should have been drawn. Oops. When background images
in cells are properly supported, this can get sorted out.

Tweaked vertical plot position of HRs (up to 4 OS units too high before due
to rounding).

Various Res file bits and pieces, Ursula build taken up to v1.26 beta
for release on the Browser site. *Note* not all resources are up to date!
This will be done after AW97.
@
text
@d51 2
a52 1
#include "Save.h"  /* (For Save_ScrapFile only)         */
d602 1
a603 1
  urlstat         * up;
d1020 1
a1020 1
  /* If we're not authorising the transfer and data has been fetched... */
a1419 11
            /* Ditch any document data got so far, we don't need it now */
            /* (it only contains e.g. header information).              */

            if (source)
            {
              flex_free((flex_ptr) source);
              *source = NULL;
            }

            up->fetched = 0;

d1421 2
a1422 1
            /* so give an appropriate error.                               */
d1438 11
d1483 1
a1483 1
              int      f;
d1492 5
d1501 4
a1504 1
              lookup_token("Authorise:Please enter a user name and a password for %%s at %%s",0,0);
d1510 1
a1510 1
              if (f < 0 || f > sizeof(prompt))
d1512 3
a1514 1
                lookup_token("AuthorShr:Please enter a user name and a password.",0,0);
d1519 3
a1521 1
                sprintf(prompt, tokens, realm, host);
d1527 24
a1550 1
              /* Empty the user name and password writables */
a1551 1
              e = writablefield_set_value(0, dbox, AuthUserWrit, "");
d1554 3
a1556 2
              e = writablefield_set_value(0, dbox, AuthPassWrit, "");
              if (e) return e;
d1558 1
a1558 1
              /* Show the dialogue and set the authorising flag */
d1560 1
a1560 8
              e = toolbox_show_object(Toolbox_ShowObject_AsMenu,
                                      dbox,
                                      Toolbox_ShowObject_Centre,
                                      NULL,
                                      b->self_id,
                                      -1);
              if (e) return e;
              else menusrc = Menu_Authorise, authorising = 1;
d1569 1
a1569 1
          default: parseable = 1; /* ...so no 'break' */
d1631 2
a1632 2
              if (b->hnum && b->hpos != 1) redirect = Internal_URL ForExternalHImage; /* Have a 'Go back' link */
              else                         redirect = Internal_URL ForExternalNImage; /* No 'Go back' link     */
@


1.20
log
@Added support for getting aspect ratio right in filler function.
Added support for background alpha PNGs.
Passed support_object flag through to HTMLLib.
@
text
@d688 1
d1055 1
a1055 1
                                choices.support_object,
@


1.19
log
@fetch_get_raw_data will notice if up->fetching is zero and return a
'finished' status rather than trying to continue reading data for the
fetch. Fetches should never fall through that far but at least it
will cope if they do.

3D table borders are now supported. 2D borders are used if the
inter-cell spacing is too small to fit the borders in (display resolution
dependent) - the external table border is 2D if the internal borders are,
else 3D. For cellspacing of 0, internal table borders must plot over the
outer edge of pixels inside the cell; for all greater spacings, the
borders take up all or part of the gap between them. The external border
will always fit around the outside of the cells, including the
cellspacing value in the gap between the outer cells and the border.

Anti-alias colour for placeholder ALT text was incorrect. Fixed.

I'd changed 'point' to 'points' in some of the Font Choices dialogues;
now changed back to 'point'.

The routine to find out how large an otherwise unsized object or image
placeholder based on its ALT text has been centralised in Reformat.c,
so that the image and object routines can both access it without
code duplication (this means non-image objects will now have the correct
size if they contain ALT text, rather than assuming a standard default
size as before). ALT text in images that were also objects was never
plotted either, though the placeholder size would have been correct.
This has been fixed.
@
text
@d1054 1
@


1.18
log
@Implemented proxy choices.
@
text
@d686 1
a687 1

d1677 5
a1681 1
      if (s & URL_Status_Done) up->fetching = 0;
@


1.17
log
@Now handles PARAM tags. Sorted out Plug-In bug that was related to Java
setting a 0 by 0 graphics window before calling Wimp_Poll (fixed in Java).
Implemented queue for Plug-Ins so multiple broadcasts aren't sent for
several Objects in one data chunk.

Added Docs directory with some documentation in it. More things to keep
checking for stylistic consistency, horray ;-)

Corrected !Run[D] for Ursula build to need AcornURI but not TaskModule
(URI handler needed for !Mail to pick up mailto: links).

Added display_height field to browser_data, analogous to display_width,
to cope with % sized objects by width and height (see how HRs are
handled in Redraw.c for an example of how it was always fairly easy
with width, but not height until this addition). Though you do have
to reload to get a new size; reformat isn't enough. Must see to this
some time...

Fixed bug where basic typefaces were claimed *before* the Choices file
had been read. For unusual Choices settings, this could create some
'interesting' problems now and again. This was part of narrower scope
work in the Choices code to allow font changing without leaking font
handles (now done; fm_shutdown only ditches fonts, it keeps internal
structures - must then call  fm_lose_fonts for all browsers to get the
bitfields up to date, then rewrite the typeface definitions and reclaim
basic fonts). Noticed that fm_claim_basic_typefaces would claim multiple
instances of the same font if there were several cases of the same font
mapped to different typeface styles - fixed.

Implemented PlugInControl settings, but not SupportObject (fully).
@
text
@d126 1
a126 4
    method_ptr = strstr(lookup_choice("ProxyAddress:http://127.0.0.1/",
                                      0,
                                      0),
                        ":");
d130 1
a130 1
      method_len = (int) method_ptr - (int) tokens + 1;
d132 1
a132 1
      strncpy(method, tokens, method_len);
d137 1
a137 1
    e = url_set_proxy(0, h, tokens, method, 0);
@


1.16
log
@!Run[D] files updated for new fetchers and GopherFetcher; protocols list
in Controls updated for Gopher. Debug builds now require 2760K rather than
2560K. Font$... variables set if not already, in anticipation of font
Choices work.

Additional bits in Choices section of Res file tidied and some name
changes (e.g. Netscape -> Navigator(TM)). Frames support option added
to Choices.

Grouped 'support_frames' under the Fetch Controls section and added
support_object in Global.h; appropriate entries placed in the Choices
files, and are read at startup. At present, though, only the frames
support flag is implemented.

For some reason, Menu was the button to use on history popups if you
wanted to show URLs instead of descriptions (or vice versa, depending
on Choices settings). Now, Select and Menu will show the Choices
defined setting, and Adjust will show the opposite.

History menus are built backwards, so local histories have the most
recently visited pages at the top. Global history has still no real
order to it, but this may be arranged later.

Customer name changed to Customer by request.

Customer browser now gets its own resources (SYSTEM=Customer), but
otherwise is unchanged, with the Ursula build now giving the
'spinning acorn' with a Bookworm-style toolbar. This is used for the
Desktop !Browse build.

!Sprites[22] files updated to include GIF, JPEG and PNG sprites;
!Run[D] files and !Boot files set appropriate File$Type_xxx variables.
Sprites in all sprites files have been checked for unnecessary palettes,
which have been removed where present.
@
text
@d738 1
a738 1
        protolen = strlen(FileMethod ProtocolSeparator "<"); /* (URLutils.h) */
d742 1
a742 1
                      FileMethod ProtocolSeparator "<",
@


1.15
log
@Increased WimpSlot of debug !Browse by 200K.

FRAMES_SUPPORT #define removed.

Optimised fm_token_font_info().

Added support for LI tokens with text (for ordered lists).

Now outdents bullets from indent value, rather than indenting bullets by
the indent value and further indenting text. May need to look at default
Choices files because of this.

Limited the margin to always be non-negative.
@
text
@d1053 4
a1056 4
        up->context = HtmlParse(ref_url,    /* Full page URL, so parser can handle relative links */
                                0,          /* Length of document - zero at present (not known)   */
                                up->type,   /* Return type from the HtmlIdentify call             */
                                1,          /* We want frames                                     */
@


1.14
log
@Calling HtmlEndParse at the end of html_get_next_token and setting
up->context to NULL was wrong; fetch_fetcher would end up recalling
html_get_next_token later which would then call HtmlParse even though
the document parse had just finished! The HtmlEndParse call has now
been moved to fetch_stop.

Altered reformatter to claim fonts inside a browser, rather than
claiming them for nothing and losing them afterwards.

Got rid of TAG == TABLE and ISBODY tests, replacing with tagno == TAG_TABLE.
Removed all references to TD, TH, TR and TABLE in the style word.
@
text
@d1056 1
a1056 7

                                #ifdef FRAMES_SUPPORT
                                  1,
                                #else
                                  0,
                                #endif

@


1.13
log
@Fixed problem that affected some internal URLs, most noticably loading
external images, where up->fetching was set to zero when it should have
been left at 1 (see fetch shutdown code at about line 1670 in FetchHTML.c).

*This* is the source that will be sent to PSI, not the previous release as
stated in the log, though Customer were sent a browser based on this
previous code.
@
text
@d1686 1
a1686 10
      if (s & URL_Status_Done)
      {
        up->fetching = 0;

        if (up->context)
        {
          HtmlEndParse(up->context);
          up->context = NULL;
        }
      }
@


1.12
log
@Version in Messages taken to 1.22 (03 Oct).

Updated Res files in appropriate builds to hold various (similar) Choices
designs.

Choices related menus were flagged as Shared, but none of the dialogues
(including ColourDBox) were - potential future problems, though shouldn't
cause any leaks at present. This has been sorted out anyway.

Encoding function encoding_init no longer returns an error from
toolbox_create_object, so the Encoding menu and all those attached
to it do not have to be present (e.g. the Customer build).

SUB, SUP, STRIKE and U supported. U underlines the baseline of the body text
font, whilst STRIKE will go through roughly the middle of the lower case
chars even if the font is SUP or SUB. Note that Navigator appears to shift
the underline point for SUB and SUP; it may be necessary to copy this
behaviour, but testing on real sites must proceed before that. There could
also be a problem with the automatic lowering of font size, which Navigator
doesn't do, so any FONT SIZE = -n commands could make it too small. Again,
this needs testing on real sites.

'http://' is added to URLs with no protocol specified, unless they start with
'ftp.', in which case the new behaviour is to add 'ftp://'.

Choices code altered to do less error checking on components! They should be
able to be missing without raising errors. Referencing of the subwindow
array changed from *(subwindows + number) to subwindows[number].

Made trace_tag_name code look pretty...

reformat_useless_token now checks tagno is non-zero.

User Agent string setting now done through URL_GetURL, on a per-session
basis.

Ellipsis character removed from all Messages files, replaced with '...'.
There's little difference between the two in an outline font, and in System
font the latter looks much better. Smart quotes left in, as they look
better in all cases.
@
text
@a1684 2
    }
    else s = URL_Status_Done; /* Internal URLs 'fetch' immediately */
d1686 3
a1688 3
    if (s & URL_Status_Done)
    {
      up->fetching = 0;
d1690 5
a1694 4
      if (up->context)
      {
        HtmlEndParse(up->context);
        up->context = NULL;
@


1.11
log
@Added support for HTMLLib HttpEndParse call.

Text items with no VALUE specified in the HTML were not cleared on
hitting a Reset button as the text field of the token is NULL; fixed.
SELECT lists with no default selection item were not being changed
on hitting a Reset button; fixed. In radio groups with no default
selection specified, no item will be selected. This goes against
the HTML 2 spec but allows broken Navigator-esque forms behaviour.
In consequence, radios can be deselected by clicking on the same
one twice. I'd fixed the flickering experienced when doing this
recently, but that, now, is irrelevant, since the state of a radio
must always change.

Reformatter's new 'find width of a SELECT field' didn't account for
the width of <none> and <many> items, and now does (particularly
important for broken items with no OPTION contents).

Under certain circumstances, illegally named targets would open in the
ancestor rather than a new window - a deliberate decision in the code,
but now reversed due to a test suite failure; they'll open in a new
window instead.

Altered the left hand indent handling for lists so that headings and
body text follow the Navigator 48 pixel indent and the bullet point
items drop to the left of the left hand margin, rather than sitting
on the margin with the text indented to the right.

Tightened up the hotlist_load_directory checking of URLs, so that
only those with '://' in - i.e. look fully specified - are accepted.
HTML files are loaded into a new directory now.

Items without a descriptive title in hotlist_new_url will have the URL
substituted in instead. White space before and after descriptions and
after URLs is stripped. Directories with zero length names or null
strings (after white space is stripped) will still be created, with a
generic name (see Messages, token 'HotlistUntitled').
@
text
@a113 7
  /* Set the user agent string, if required */

  if (!e)
  {
    if (choices.clone) e = utils_set_http_agent(0, h);
  }

d288 7
a294 7
      e = url_get_url(0,             /* Flags - must be 0, currently */
                      h,             /* Session handle               */
                      method,        /* Fetch method                 */
                      url,           /* URL to get                   */
                      up->extradata, /* Any extra data for POST etc. */
                      NULL,          /* (Would be a status word)     */
                      2);            /* Mode; 2 = header and data    */
d1385 7
a1391 7
            e = url_get_url(0,             /* Flags (must be 0)                   */
                            handle,        /* Session handle                      */
                            up->method,    /* Fetch method                        */
                            redirect,      /* URL to get                          */
                            up->extradata, /* Extra data for POST etc.            */
                            NULL,          /* We're ignoring the returned status  */
                            2);            /* Mode 2 = fetch both header and data */
d1613 7
a1619 7
              e = url_get_url(0,             /* Flags (must be 0)                   */
                              handle,        /* Session handle                      */
                              up->method,    /* Fetch method                        */
                              redirect,      /* URL to get                          */
                              up->extradata, /* Extra data for POST etc.            */
                              NULL,          /* We're ignoring the returned status  */
                              2);            /* Mode 2 = fetch both header and data */
@


1.10
log
@Now working on source merged with Kevin Bracey's internationalisation
support. UNIFONT is undefined in the Make File for now. All Res and
Choices files updated appropriately.

Having sorted out the old Choices and Messages to form Choices, Controls
and Messages, this build has had the same cleaning up done internally.
This includes greater consistency in naming schemes and the removal of
the inconsitent choices items - e.g. Choices file entries saying 'delay
images' and 'plain backgrounds' where internally all the flags say 'show
images' and 'show backgrounds'. ChoiceDefs.h and CtrlDefs.h added to
clarify the meaning of some fields, though usage of these is not 100%
in the source (there are cases where parameters are passed through to
functions as ints, and those functions still check these against hard
coded values rather than the #define stuff).

Fetcher status return bits (connected, sent request, etc.) now reflected
in status bar. Progress during fetchs to files are reported by %, where
the size of the object is known. Exceeding 100% drops back to a byte
counter, in case the estimated size was wrong. The progress counter
may be updated after specific delays, rather than 'as often as possible',
to reduce flicker (as requested by D.Brown some time ago).

I've done a small rewrite of the fetch prioritisation scheme in FetchPage.c;
how well this performs in general use across different processor speeds
remains to be tested, but certainly it has some advantages. For each small
fetch window before the rewrite, a 4cs tight loop was entered - this gave a
noticable and substantial drain to the Desktop performance if more than one
was opened. Now, several can be up at once with little hit. The actual file
fetch is on half the priority it was before, with all others taken back
just a bit - e.g. from 20cs per poll to 15cs per poll for flat out
reformatting. You don't seem to lose much time on the format in practice,
and the Desktop feels quite a bit lighter at the same time. There's the
potential for smoother frameset loading in this scheme, too.

When Shift+Clicking on a link meant you still fetched inside the main
browser window, several fetches could occur in a frameset - one per frame.
However, now that you can only do this by clicking on a link that leads to
non-displayable data - or by turning off the small fetch windows by
setting UseSmall to 'no' in Choices - a bug where fetchpage_preprocessed
would stop such fetches as new ones were started was revealed.
The API to frames_abort_fetching has now been extended to include a
'stop file spooling too' flag, allowing a fix to be made by having
fetchpage_preprocess's calls not set this (and it doesn't check the
savelink flag is unset before proceeding, since frames_abort_fetching
does that implicitly now).

Had left the RAM transfer buffer at 16 bytes (from testing) accidentally...
Oops. Upped it to 4K. In addition, when loading data by RAM transfer,
the browser didn't notice if a RAMFetch bounced during the transfer. It
would be treated as a 'first' RAMFetch bounce, basically, and try to go to
file transfer - oops. Fixed.
@
text
@d520 1
a520 1
    free(up->context);
d697 1
d1678 5
a1682 10
  /* If no data has been fetched from the url_read_data call   */
  /* from earlier on, and there hasn't been an error flagged   */
  /* so far, and both the general 'authorisation taking place' */
  /* and urlstat-based 'authorisation in progress' flags are   */
  /* clear, ask the URL module for its current status. If it   */
  /* says it has finished (which would explain this set of     */
  /* circumstances - basically, having no data from the        */
  /* url_read_data call but nothing else is wrong), set the    */
  /* urlstat structure flag to say fetching is no longer in    */
  /* progress.                                                 */
d1684 1
a1684 1
  if (!r && !e && up->authorised != 1 && !authorising)
d1695 10
a1704 1
    if (s & URL_Status_Done) up->fetching = 0;
@


1.9
log
@Encoding support added: if UNIFONT is defined then the browser will
attempt to use the system font to render Unicode characters (new
International module required). If not defined, the browser will just
handle Acorn Latin-1 characters, but HTMLLib will convert other encodings
into Latin-1. Must keep the UNIFONT define in sync with HTMLLib (if
defined HTMLLib outputs UTF-8, otherwise Acorn Latin-1).

Still needed:

Reverse encoding (converting form input etc back into the server's
character set).
Reparse when encoding changes.
Setting of charset from an attribute on the <A> tag.
@
text
@d668 1
a668 1
  if (image || b->displayed == Display_Fetched_Page || b->savelink)
a696 1

d700 4
d1043 1
d1046 2
a1047 2
          b->encoding = choices.encoding;
          encoding_update_menus(b);
d1068 1
d1072 1
a1072 2
        if (up->context)
          HtmlSetEncodingCallback(up->context, encoding_changed_by_meta, b);
d1181 1
a1181 1
      if (image || b->displayed == Display_Fetched_Page || b->savelink)
d1205 1
a1205 1
          int encoding;
d1244 1
d1284 1
a1284 1
                   lookup_token("HSHOvrrn:Serious internal error - HtmlStripHeaders has failed; must exit immediately.",
d1563 1
a1563 1
            if (b->savelink)
d1589 1
a1589 1
            if (parseable == TYPE_IMAGEFILE && !b->savelink)
d1692 1
a1692 1
    if (image || b->displayed == Display_Fetched_Page || b->savelink)
@


1.8
log
@Support for ANT URL broadcast message added.

Image deletion routines rewritten; nasty animated GIF bug now gone
(it kept trying to update the cross-referenced image in the browser that
no longer existed, and I've no idea how animated GIFs ever managed to *not*
blow up if a cross referencing browser was shut down; and I've tested
this...). There are now as many image structures as there are total images
in the visible browsers, and no more; cross referenced images in the
to-be-deleted browser have their ownership moved to the cross
referencer before the cross referencee is wiped, with any required fetches
being transferred with them.

Reformatter sped up a bit by getting rid of strlen on the main text field
of tokens in all places bar one, where it is called extremely rarely. This
means direct app-to-app transfer of, say, a 359K text file to the browser
won't run like a drain as it tries to do strlen on a 359K string over and
over again! Most of the time the performance benefits won't really be
noticable, but on the above text file, formatting time went down from
290 seconds before the change to just under 7 seconds, a 41 fold speed
increase or thereabouts (SA110 228MHz).

MakeFile changed to force function name compilation on for debug builds
(-fn in the DD...FLAGS); useful for certain functions such as
register_null_handler, which can now output the name of the function
being registered.

...Which helped show up some nasties in the animation handler and animation
drift handler registration/deregistration process, which have been fixed
(callers of fetchpage_release_nulls were unaware that the drift handler
could be installed, and fragments of old code checking choices.anim_drift
had a value other than 1 or 0 were still hanging around - bit tricky for
a single bit item).

Added support for VALIGN in table cells. Spotted a bug or two in the
'what token is the pointer over' routines as a result, and fixed them - the
worst was in browser_line_at_y, which checked the y coordinate was below
the given one [the mouse], but didn't check the line height to see if the
given y coordinate was *within* the line, rather than just above it. Never
used to matter pre-tables, but a definite concern once multiple line
arrays can exist on one page.
@
text
@d48 1
d1035 11
d1060 1
a1060 1
                                  1);
d1062 1
a1062 1
                                  0);
d1064 5
d1201 2
d1225 17
a1241 7
        code = HtmlIdentify(ref_url,                     /* Allow relative redirections to work */
                            (char *) *source,            /* Pointer to head of data stream      */
                            flex_size(source),           /* Amount of data in the stream        */
                            (s & URL_Status_Done) != 0,  /* Is it a complete stream? 1 = yes    */
                            &redirect,                   /* Will point to a URL if code = 302   */
                            &type,                       /* Will hold a filetype                */
                            &parseable);                 /* Will say if the data is parseable   */
@


1.7
log
@Got the deferred reformatter working properly. It doesn't do that 'OK,
the page is fetched and reformatted, but just to annoy you, I'm going
to wait 5 seconds and then suddenly reformat the whole thing again'
trick anymore. The fetcher was calling the reformatter in a delayed
form even when the reformatter was already running, so it would carry
on past the reformat point or from below what had become and invalidated
line, and some time later, get back to the delayed reformat. Now,
reformatting is only delayed by the fetcher when the reformatter is not
running. In practice this means body text reformats as it fetches, but
large tables will show delayed reformatting - which was exactly the
intended behaviour of the feature when it was originally thought of.

fetch_token_data_address removed; it was only needed in two places,
both of which already knew when to read tp->text and when to ignore
it. Its functionality is duplicated in an 'if' involving reformat_istext,
anyway.

!Run[D] files taken back to requiring HTTP 0.33, since 0.36 introduces
many weird and wonderful problems.

Typo in Messages files, 'All current images (sic.) fetches finished' -
'images' is now 'image'.

Shift+Click saving - you could save to an application. No problem. But
the equivalent (just clicking on a link that led to an unknown datatype
and getting the save dialogue that way) didn't work. It does now.
Another problem was saving to an application that didn't support the
datatype - oops, the dialogue would close but the fetch would sit there
waiting to be told where to save. It doesn't close now (as expected).

NB, doing several simultaneous fetches to a text editor may have problems
as the editors are too clever for their own good. Despite receiving
DataLoad messages for <Wimp$Scrap> for files of different types, sizes
and datestamps, the editors can decide it's still the same file and:

Zap      - Hats off, it gets it right, almost. You do get warned 'Multiple
           copies - one on disc is newer' as everything after the first
           text loads, but they do load, and in separate windows.
StrongED - Does not load the subsequent files, so the browser gives 'Data
           transfer failed' errors and opens up Scrap. Turning off 'Don't
           load same file twice' fixes it - each file is loaded in a new
           window with no warnings. At least in the first case, you don't
           lose data, since the files are kept in Scrap.
Edit     - Each time it loads the file, it *replaces* the other one in
           memory, using the same window for each. This is the worst
           behaviour as it isn't configurable (well, I don't know of a way
           to change it...) and results in data loss as successive texts
           get trounced by the new data.

I can't see how I can fix this in the browser as it's basically silly
behaviour on behalf of the editors. Other applications which don't try
to work out if it's a new file or not are fine!

When conducting image fetches, proxying is allowed unless reloading.
When conducting page fetches, proxying was never allowed - so web cache
stuff would have been, er, interesting. It now sets X-NoProxy: in the
request header when reloading, but otherwise this is not included.

AnimSpeed is, at last, independent of browser poll speed. They used to
be tied together. Guess how the animation code used to work ;-)

'Can't handle this datatype' - deprecated now that save dialogues can be
popped up. The 'can't save objects in full screen mode' error would never
be shown due to a bug, anyway; this now replaces 'can't handle', which
has been removed from all Messages files.

RefoWait, RefoHang and RefoTime moved from Controls back to Choices.

Trying to get rid of strlen in the reformatter - it can get very slow
(e.g. strlen of 8K chunks of text, or if a 330K text file is transferred
from a text editor straight to the browser, strlen of a 330K string...).
There will be unfinished bits of code in the reformatter that may seem
unnecessary - they've just not been plugged in yet (since they don't
actually work). Don't remove them!
@
text
@d113 7
@


1.6
log
@As warned in the last log, pretty much all event codes and component IDs
have now changed along with many of the names, to provide a consistent
name and numberspace for events and components. This also minimises
number clashes (e.g. as was, the Save File origin when opened from a
Hotlist menu with an already-used component ID). To get full details on
this, please carefully read through TBEvents.h.

Res files, Sprites files and Messages files have been updated again both
due to the above, and routine additions (e.g. message support for a few
Hotlist bits and pieces). !Run[D] files updated for FTP 0.11 and
HTTP 0.36.

In the Makefile, the Customer objects list was missing Save - must have
moved something when I should've copied it, when adding in SaveFile or
SaveObject in all probability. Now fixed. Couple of other bits and bobs
fixed in the build environment (e.g. stuff saying !Argo instead of
!Customer). Oh, and I've altered the MakeFile copy options again to the
best compromise I can come up with. Newer is turned on for everything
except !Run[D] and !RunImage, since both of those change between debug
builds - otherwise if you'd built debug and non-debug versions, it was
not possible to switch between them - one version would have the newer
timestamp and thus never get overwritten.

The default hotlist has had a few items added - that'll be about the end
of it, I think; there's more than enough stuff in there now.

Saving of the hotlist from the document menu and of URI files,
directories and selections from the hotlist menu tree is now implemented
- this new save system rocks... Oh, and you can save all images and
backgrounds as sprites.

Saving of items with Shift+Click to other applications directly now
works, and is robust. Unique Scrap filenames are used, with data load
bounces (e.g. if some pra - er, person quits the app they're sending
to) working correctly - that is, give an error, keep the file, rename
it to something safe, and open the directory it lies in. As opposed
to normal app-to-app bounces, where the scrap file is deleted (see
PRM 3-254). This means you can now look at README files in FTP
sites, say, without using a disc intermediate. Or you can send pictures
straight to ChangeFSI, fetch HTML links into editors, and so-on, and
so-on - it's all very funky. Known problems include the ambiguous
'invalid component ID' instead of 'file open' for *normal* (straight to
disc) shift+click saves, and I think I'll introduce a unique name
guarantee of some sort to stop 'file open' in the first place. Odd
that the really tricky part (app-to-app) should be least likely to
suffer from this!
@
text
@d91 3
a93 1
/*             1 to allow proxying, else 0.      */
@


1.5
log
@First a minor warning - the various Res files are out of sync in this build.
Only the Browse resources are currently valid.

Added Utils.Icons - has a few archives inside containing the resources
(well, some of them) used to build various UI sprites for various builds.
Archived because these are unlikely to change much, and putting them on
CVS was a move to, well, archive the stuff...

SaveDBox objects vanquished and requirements in !Run[D] files removed. The
data save code fits much more neatly in amongst the data load protocol
stuff now (with the slight exception of having to split the SaveObject
source into SaveObject and SaveFile - the former handles multiple persistent
dialogues for Shift+Click on links and the like, the latter handles 'one at
a time' transient dialogues for save source and similar). Export Link is now
supported, too, and writes a 'proper' version URI file. You'll find that
double-clicking on old URI files will work as the URI handler picks them up,
whilst new version ones don't; however, dragging onto the browser will only
work with new version files. Note that support for saving and loading URL
files (ANT suite stuff) is present too, so old URI files can be typed as URL
files if you want to keep them working without modification - the URI
handler itself will hopefully support the defined URI file format soon;
double-clicking on old URI files will stop working at that point. Note
there are *lots* of changes in every Res file to support all this. This may
all seem a bit pointless to some, but the changes do in fact make it very
easy to add new save dialogues all over the place. Certainly much easier
than with the previous system, anyway. In fact, post script, image
'save as sprite' took about half an hour, which I hope proves the worth
of the new system.

Merged in newer hotlist code with support for drag cancelling with Escape
(all relevant Res files appropriately updated) and cancelling scrolling
when you've reached the window scroll limit. Had to move some of the
Wimp message handling stuff to the central Protocols source, as clashes
were occuring, and also the hotlist routines were using independent saving
code - a lot of duplicated effort. This was fair enough as at the time the
Hotlist code was written, the Save code couldn't be used in the way it is
now.

New Save Source and Print buttons on the toolbar of some builds.

Phoenix Sprites file made more efficient - the Acorn base section has been
split from the animated upper region. Browse build has a new grey fade
sprite at the back, which is less grainy than the previous one and only
uses 16 colours (with a 16 greyscale palette).

Not really a bug, bug the routine to start an image fetch for INPUT
TYPE=IMAGE forms items only did so if the src field (or equivalent, for
this tag type) was non-NULL. In fact, you should always call image_new_image
and let that handle the rest, otherwise other sections of the code will fail
as they try to obtain an image number for a given HStream and get -1 back.
This problem only generally manifested itself when loading an HTML file to
the browser straight from an application, as many src fields become NULL
when the relativisation routines find nothing to relativise to...

Authentication got broken somewhere along the line - this has been fixed
(in HTMLLib and the browser).

Ctrl+Click on a cross referenced image updates *all* copies, not just the
one with the image data attached.

Next big step: Rip up TBEvents.h and rebuild that whole approach somewhat.
To all those working on the code, my apologies but this means all Res files
will receive a very large number of alterations and there will be extensive
code changes too (mostly naming convention stuff), in more or less all
source files. I am endeavouring to ensure that the new numberspace
convention does not clash with the work being done by Kevin on
internationalisation.
@
text
@d908 1
a908 1
        if (!file) return _kernel_last_oserror();
d913 1
a913 1
          return _kernel_last_oserror();
@


1.4
log
@This log message covers changes from the version before last up until now
- i.e. it includes the changes that were part of the intermediate check-in
done yesterday (02/09/97).

New function to go from URL to pathname in urlutils, also changed return
values on those functions which alter the given buffer to return nothing,
rather than the buffer address (which wasn't helpful).

Fixed nasty in the Message_DataLoad code (it thought all loads were
app to app - oops; can in fact just check your_ref, which is 0 if this
is a DataOpen or DataLoad direct from the Filer. PRM 3-253).

Implemented Load Images and View Source buttons.

Small fetch window - configurable in Choices (UseSmall) is the use of a
special 'small' window for fetches. Configurable as if you Shift+Select
click it'll open one of these, which some people might hate, so you
can turn the feature off and the fetch will progress in the browser
window you clicked on, as normal. Default is for this to be on, since
it matches the behaviour of other browsers. This means all Res files
have been updated, except for the Customer build, which can't fetch
external objects as it is a full screen variant.

New pointers for the hotlist autoscroll, including full specification
of their active point offsets in Controls. This means all Sprites files
have been updated.

New sprites for HTML and URI files, so all !Sprites and !Sprites22 have
been updated.

(Suggested by KBracey) You can now drag objects to the toolbars of a window
to fetch into the ancestor (useful for framesets).

Function windows_close_browser now returns void; it only returned an int as
it used to be a Toolbox event handler and I obviously forgot to get rid of
this when I turned it into a general purpose function.

!Run/!RunD/etc. files updated yet again, since the browser now supports
different application names. Corrected fault where Browse$CookiePath was
being unset - should've been Browse$CookieFile and Browse$CookieFileFormat.
420K is no longer enough, so they've all been given 512K for the non-debug
versions (OK since malloc will fill up any excess allocation before starting
to extend the slot size itself).

Fixed global history bug - the history would become corrupted whenever
it exceeded the maximum size specified in Choices.

Fetcher now supports HTTP return code 301 (Moved Permanently). Wrapped in
#ifndef STRICT_PARSER.

I've started on some general documentation, aside from the overdetailed
PSI memory information (which needs updating). Once this gets some substance
to it and achieves a recognisable, maintainable structure, it'll get added
to CVS - for now, there's no point (you'd have trouble making sense of the
various unsorted fragments!).

Right. Time to get rid of SaveDBox.
@
text
@d49 1
d837 1
a837 1
        int type;
d844 1
a844 1
              _INR(0,1) | _OUT(0) | _OUT(4),
d846 1
a846 1
              17, /* Read catalogue info */
d849 3
a851 2
              &type,
              &len);
d853 1
a853 1
        if (type != 1)
d858 3
a860 1
                   lookup_token("WhatScrap:Cannot find the page to load; the sending application may have died.",0,0));
d864 8
d1473 1
a1473 1
                e = button_set_value(0, dbox, Limits_AuthPrompt, tokens);
d1478 1
a1478 1
                e = button_set_value(0, dbox, Limits_AuthPrompt, prompt);
d1485 1
a1485 1
              e = writablefield_set_value(0, dbox, Limits_AuthUserWrit, "");
d1488 1
a1488 1
              e = writablefield_set_value(0, dbox, Limits_AuthPassWrit, "");
@


1.3
log
@Created Protocols source file and moved a lot of message handling from
handle_messages - the latter now serves as a high level distributor to
lower level functions in Protocols. Incidentally, URL files (as used by
the ANT suite) can be loaded by dragging to the browser in the same way
as URI files - Not A Lot Of People Know That, etc.

Merged new hotlist display type Res file to existing resources, added
support for DataSave message so items can be dragged from the hotlist
to a specific window (RAM transfer for URI and URL files; ScrapFile for
HTML and Text but deleted afterwards and there are appropriate guards
to stop Reload just saying 'not found'; images run through ScrapFile and
there is no choice but to leave them there and do a conventional fetch).

All !RunD files now give a WimpSlot of 2304K. Some small changes to
the Argo and Ursula build Res files to make the menu trees more sensible.
Controls files now take 'file:/' instead of 'file://' in Protocols
section. Definitions at top of URLutils.c *not* altered, as then you
end up with invalid URLs - so it will accept 'file:/', but always generate
'file://'. This is because some browsers exports 'file:/'. Sigh.

make_no_[..._]memory_error functions now return a _kernel_oserror * rather
than void. It's always &erb returned, but it enables users to use a more
elegant 'return make_no_memory_error(1);', say, rather than something
like 'make_no_memory_error(1); return &erb;'. I obviously should've written
it like that at the outset, but never mind. All callers have been
appropriately updated.

The urlutils_leafname_from_url function now replaces illegal characters
(A7000 Welcome Guide p54...) in the leaf with legal alternatives.

Internal URL scheme is now a bit cleaner, with everything properly defined
in URLutils.h. All references to http:, file: and ftp:, with or without
a following '//' use the definitions in here now.

More tidying and some reorganising of Hotlist source. Auto-open delay is
now a Choices item. Some dependencies on statics removed (e.g. the
counting functions don't accumulate into the global item_number now).
The redraw functions used Wimp_TextOp - oops, so this has been amended
to use whatever is supported on your Wimp. This is now in a new function
(utils_text_width()), which the History menu routines also use (there was
a bug in the width routine there anyway, which is therefore fixed in
passing). Several other routines used Wimp_TextOp directly too, and
they have been altered to use the new function as well.

In hotlist code, one of the larger changes is in the API to hotlist_draw_r()
(formerly _hotlist_draw()) which now takes item widths and heights as
parameters - discovering these is quite slow, so doing it every time the
function calls itself recursively is a little less efficient than
passing the values in from elsewhere. Note that underscore prefixed
functions are being slowly renamed to _r suffixed functions, to match
the convention established by Tony Cheal with is table routines. This
makes it much more obvious when something is recursive, as the same
naming convention is used in every browser source file.

Finally, note that I intend to ditch SaveDBox and use an alternate window
with manual control of the messaging in Protocols.c. This will allow
various improvements which at present the SaveDBox operational methods
preclude. I'm going to have to do at least an alternate Window object for
the SaveDBox module to use soon in any case. Getting rid of SaveDBox will
help reduce, if only slightly, demands on the RMA.
@
text
@d1242 11
@


1.2
log
@Very long log entry alert - but hey, beats 'Bug fixed' (sorry, Richard) ;-)

Open URL implementation more or less complete, though may undergo UI
revision at a later date to allow named frames to be targetted. Hope to use
the ideas in this code as the foundation for other general dialogues.

In token stream dump for TRACE builds, table head items were not indented
as far as they should have been - this is fixed; and manual toolbar redraw
routines have been removed. They never worked, were commented out, and
would never be used in that form anyway.

DragBox source added, but it isn't at all complete and won't work - this is
an 'in spare time' thing. We need custom drag boxes constrained to windows
for the hotlist, and unconstrained for frame border resizing... Hey ho.

Ancestor window extents match visible areas if there are frames (no more
scrolling framesets...!). Frame resizing works whilst new documents fetch
without pulling the extent down now. However, frame horizontal extents
never shrink until a reload which is nasty, and this is all due for a
rewrite. Frames border redrawing routine moved out of Redraw.c and into
Frames.c. Bug regarding the mouse rectangle and frame border widths
(rectangle was too large, so you could squash the edges) for edge-drag
frame resizes fixed.

Window width change reformat tolerance fixed; you could creep the window
width down or up forever without any reformat, and centred objects would
move but not be redrawn (thereby giving rise to subsequent redraw errors).

Filetype on objects saved through Shift+Click correct. Save Source dialogue
recognises if that source is plain text, rather than assuming HTML. A
browser that fetches a file remembers the old store size it had before the
save, so even though the data is now ditched, it reports the same amount of
data fetched afterwards (looked awful when this could, for example,
suddenly say '0' after a file save). Progress indicator is now fully aware
of one or many file saves inside a frameset and reports the number of
saves, a colon, and the cumulative saved data count, instead of reporting
the sum total of fetched data in all frames, including non-file save stuff
(note that for just 1 save, '1:' is not shown as a special case for the
most common condition). A bug related to this, where you could in fact only
do one fetch per frame*set*, has been corrected (only one fetch allowed per
frame still, this is unlikely to ever change).

Hotlist support added (D.Brown's source), with various bits of integration
and modification still in progress there. Note additions to the Messages
files. On the subject of Messages, the whole mucky business about what
goes in Messages or Choices (and a few bugs where lookup_choice was used
instead of lookup_token or vice versa) has been sorted out. Messages
contains, more or less, just that. Choices contains user configurable
stuff which generally can't mess things up too badly. A new file, Controls,
is a Messages file holding the non-user configurable choices, which can
generally make things go badly wrong if misused. A lot of these are tied
to the Res file. StrongED users can get these to automatically fold out
the various sections (EMail me for details). Sorry, but at the time of
writing, Zap doesn't do folding... =8*P

Two bugs with images. Asking for images to be shown in browser B when
browser A uses the same ones and was loaded first didn't work correctly,
and now does (a bit weird - browser A does the fetch and browser B does the
display...). Second one occurred when the background image was also used on
the page as a foreground image. This has been fixed by flagging background
images in the image_info structure, and checking this before cross
referencing. This bit also allowed the image_restart_fetches API to be
extended, so that just background or foreground images may be fetched if
they weren't already and the user asked the browser to show them. Before,
the whole lot had to be fetched together (so turning on 'display
backgrounds' will now kick off an image fetch if required, you don't
need to reload the page anymore).

Makefile copy options tweaked to be 'newer' (so if you're testing with some
temporary Choices file or something, it won't write over it at the end of
every export), and REMOTE_HOTLIST flag added for Customer builds - means
the Hotlist.c functions aren't needed; the old, hotlist-by-file method is
used. Added support for Customer build (see later), though there were very
few additions needed in practice.

Table printing fixed - in many ways it wasn't broken, it was image printing
causing the oddities ever since the global image pool was introduced (this
is, again, fixed). The 'reformat to fit page' option didn't work as coded
any more; tables store cell addresses in the HStreams, so you can't then do
a background reformat in a different browser. Hence, it now has to reformat
to the page width, print, then put the page back again, all in the actual
displayed browser. This doesn't feel as slow in use as it perhaps should,
considering what is going on... Note that a line of a defined fraction (see
Print.h) of page height will now split over page boundaries, so tall images
or tall tables don't cause problems now (aside from the obvious problem of
having the line split over a page at all!). There was a bug in the routine
to print from a given start point until 'n' pages had been filled, in that
it always filled 'n + 1' - now fixed. Finally, as part of the printing
tweaks, a new dialogue exists - PrintStyle - with a similarly named source
file added to deal with it.

Global history auto save / load done, but only to the Choices file path -
the whole browser is still strictly single user at present, with all the
extra work for a multiuser Customer environment yet to be done. This has
shown up a global history corruption problem which I haven't fixed yet.

Rationalising TBEvents.h - things are migrating out of it, and into more
appropriate sources (e.g. definitions relating to the Open URL dialogue are
going into OpenURL.h, etc.). Event codes were at one stage deliberately
diverged in numberspace from the component IDs of typical gadgets raising
the events, to avoid anyone getting confused and thinking the IDs and event
codes must match. However, this is in fact unlikely and it is much easier
to remember the fewer numbers that result from tying the two together where
possible. This has resulted in changes to event codes raised in the
following objects of all Res files: Authorise, Find, OpenURL, and
PrintStyle.

And finally - !Run[D] files for all variants updated to require the latest
toolbox and fetcher modules. All Res files updated for hotlists etc. and
sprites files updated appropriately. All Messages, Choices and Controls
files brought in sync., and an Customer build has been added (based on the
Desktop build binary with different resources).

That's all for now...
@
text
@d49 1
d185 2
a186 2
        make_no_fetch_memory_error(2);
        return &erb;
d221 2
a222 2
          make_no_fetch_memory_error(3);
          return &erb;
d231 2
a232 2
          make_no_fetch_memory_error(4);
          return &erb;
d249 2
a250 2
        make_no_fetch_memory_error(5);
        return &erb;
d263 2
a264 2
        make_no_fetch_memory_error(6);
        return &erb;
a623 2
      make_no_cont_memory_error(8);

d628 1
a628 1
      return &erb;
d692 1
a692 1
  else
d703 7
a709 1
    /* Look up the token embedded in the URL */
d711 1
a711 1
    lookup_token(url + Int_URL_Len, 1, 0);
d713 1
a713 1
    /* Find a ':' separating extra information and point just past it */
d715 1
a715 2
    exoff = urlutils_internal_extra(url);
    if (exoff) extra = url + exoff;
d717 2
a718 3
    /* Work out the length that the HTML file we're about to generate will be; */
    /* this will be at least as long as the looked up token, plus a display    */
    /* type dependent extra amount.                                            */
d720 1
a720 1
    len = strlen(tokens) + 1;
a721 4
    switch (b->displayed)
    {
      case Display_External_Image:
      {
d728 85
d833 29
a869 2
      make_no_cont_memory_error(1);

d874 1
a874 1
      return &erb;
d887 21
a984 2
      make_no_cont_memory_error(1);

d989 1
a989 1
      return &erb;
d1548 2
a1549 2
              if (b->hnum && b->hpos != 1) redirect = Internal_URL "PExtImage"; /* Have a 'Go back' link */
              else                         redirect = Internal_URL "PExtImNoH"; /* No 'Go back' link     */
@


1.1
log
@Updated Makefile to work better in folding text editors. More or less rewrote
Limits.h, and ensured consistent comment styling throughout all sources.
Fetch.c/h split to Fetch, FetchHTML and URLveneer. URLstat.c/h produced to
cope with this. OpenURL and Find sources created from bits in the Windows
source file that shouldn't have been there... These will get filled out
shortly. Note that a few functions in Fetch are due to be renamed and moved;
probably to Tokenutils.
@
text
@d654 1
a654 1
  /* are not internal.                                              */
d658 1
a658 1
  if (image || b->displayed == Display_Fetched_Page)
d729 2
d925 1
a925 1
//Printf("new = NULL\n");
d931 1
a931 1
//Printf("up->lasttoken = %p, and returning this: next = %p\n",up->lasttoken,up->lasttoken->next);
d939 1
a939 1
//Printf("new = %p\n",new);
d944 1
a944 1
//Printf("GOT_MORE unset\n");
a949 1
//Printf("up->lasttoken = %p, and returning this: next = %p\n",up->lasttoken,up->lasttoken->next);
d958 1
a958 1
//Printf("up->lasttoken = NULL, returning 'new'\n");
d967 1
a967 1
//Printf("GOT_MORE set\n");
d972 1
a972 1
//Printf("up->lasttoken = NULL< returning 'new'\n");
d982 1
a982 2
//if (up->lasttoken != new) Printf("up->lasttoken != new, returning next: %p\n",up->lasttoken->next);
//else                      Printf("up->lasttoken = new, returning this\n");
d1009 1
a1009 1
      if (image || b->displayed == Display_Fetched_Page)
d1362 2
a1363 1
            if (!up->allowparse) parseable = 0;
d1365 1
a1365 2
            /* If the data is apparently parseable, flag the status as 'waiting' */
            /* else flag it as 'not parseable'.                                  */
d1367 1
a1367 1
            switch (parseable)
d1369 22
a1390 8
              default:
              case TYPE_UNKNOWN:
              case TYPE_IMAGEFILE: *waiting = 3;
              break;

              case TYPE_TEXTFILE:
              case TYPE_HTMLFILE:  *waiting = 1;
              break;
d1496 1
a1496 1
    if (image || b->displayed == Display_Fetched_Page)
@
