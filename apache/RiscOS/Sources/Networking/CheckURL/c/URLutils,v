head	1.3;
access;
symbols
	CheckURL-0_17:1.3
	CheckURL-0_16:1.3
	CheckURL-0_15:1.3
	CheckURL-0_14:1.3
	CheckURL-0_13:1.3
	CheckURL-0_12:1.3
	CheckURL-0_11:1.3
	CheckURL-0_10:1.3
	CheckURL-0_09:1.3
	CheckURL-0_08:1.3
	CheckURL-0_07:1.3
	CheckURL-0_06:1.3
	CheckURL-0_05:1.3
	CheckURL-0_04:1.3
	CheckURL-0_03:1.2
	CheckURL-0_02:1.2
	CheckURL-0_01:1.1.1.1
	initial:1.1.1.1
	TRUNK:1.1.1;
locks; strict;
comment	@# @;


1.3
date	2000.03.28.10.06.58;	author ahodgkin;	state Exp;
branches;
next	1.2;

1.2
date	2000.03.17.17.19.25;	author ahodgkin;	state Exp;
branches;
next	1.1;

1.1
date	2000.03.16.15.04.54;	author ahodgkin;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2000.03.16.15.04.54;	author ahodgkin;	state Exp;
branches;
next	;


desc
@@


1.3
log
@  Bug fix in URL matching, two character error in source file header comments
  corrected.
Detail:
  Paths with colons in had those colons interpreted as port separators; the
  URL_Fetcher module only escapes chars 0-32 and 127 and I'd been relying on
  it doing other characters too. Whilst I was at it, I made the legacy
  support for a comma separated list of the match strings a compile-time
  option and compiled it out as CheckURL never uses this. In addition, every
  source file had a cut-and-paste propagated two character error in the
  source file header comments, which has been corrected.
Admin:
  Confirmed that ROM, RAM and debug builds compile. Tested various port
  and path combinations and modified test suite slightly to ensure that
  whilst ports work, colons in paths will work too.

Version 0.04. Tagged as 'CheckURL-0_04'
@
text
@/* Copyright 2000 Pace Micro Technology plc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**************************************************************/
/* File:    URLutils.c                                        */
/*          (C) 2000 Pace Micro Technology PLC                */
/*          All rights reserved                               */
/*                                                            */
/* Purpose: URL manipulation.                                 */
/*                                                            */
/* Author:  A.D.Hodgkinson.                                   */
/*                                                            */
/* History: 06-Feb-1997 (ADH): Created.                       */
/*          11-Nov-1999 (ADH): Imported fragment to Video     */
/*                             Control.                       */
/*          30-Nov-1999 (ADH): Imported to RTSP OVS.          */
/*          17-Mar-2000 (ADH): Fixed version returned to      */
/*                             Check URL.                     */
/**************************************************************/

#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <stdarg.h>

#include <swis.h>

#ifdef TRACE2
  #define TRACE
#endif
#ifdef TRACE
  #define DEBUGLIB
#endif
#include <debuglib/debuglib.h>

#include "Generic.h"
#include "Utils.h"
#include "URLveneer.h"
#include "URLutils.h"

/* Local definitions */

#define ExtensionMatches(url, len, ext) (len) > strlen(ext) && !strncmp((url) + (len) - strlen(ext), (ext), strlen(ext))

/* Fit within VideoControl's URL_Fetcher derived namings */
/* - these are all in Generic.[c|h] rather than Utils.   */

#define utils_strdup      Strdup
#define utils_strndup     Strndup
#define utils_strcasecmp  Strcmp_ci
#define utils_strncasecmp Strncmp_ci

/**************************************************************/
/* urlutils_urlsscmp()                                        */
/*                                                            */
/* Compares two URLs, returning 1 if they differ or 0 if they */
/* are the same. Both URLs are converted internally to        */
/* url_descriptions.                                          */
/*                                                            */
/* Parameters: Pointer to a null terminated URL string;       */
/*                                                            */
/*             Pointer to a second null terminated URL        */
/*             string.                                        */
/*                                                            */
/* Returns:    0 if the URLs match, else 1.                   */
/**************************************************************/

int urlutils_urlsscmp(const char * url_s1, const char * url_s2)
{
  url_description * url_d1;
  url_description * url_d2;
  int               result;

  /* Sanity check */

  if (!url_s1 && !url_s2) return 0;
  if (!url_s1 || !url_s2) return 1;

  urlutils_return_description(url_s1, &url_d1);
  urlutils_return_description(url_s2, &url_d2);

  if (url_d1 && url_d2)
  {
    result = !!strcmp(url_d1->full, url_d2->full);
  }

  /* No memory, no brain. Hey ho. */

  else result = !!strcmp(url_s1, url_s2);

  urlutils_free_description(url_d1);
  urlutils_free_description(url_d2);

  return result;
}

/**************************************************************/
/* urlutils_urldscmp()                                        */
/*                                                            */
/* Compares two URLs, returning 1 if they differ or 0 if they */
/* are the same. The first URL is specified as a              */
/* url_description, the second URL is converted internally.   */
/*                                                            */
/* Parameters: Pointer to a url_description filled in with    */
/*             the URL details;                               */
/*                                                            */
/*             Pointer to a second null terminated URL        */
/*             string.                                        */
/*                                                            */
/* Returns:    0 if the URLs match, else 1.                   */
/**************************************************************/

int urlutils_urldscmp(const url_description * url_d, const char * url_s)
{
  url_description * url_d2;
  int               result;

  /* Sanity check */

  if (!url_d)                 return 1;
  if (!url_s && !url_d->full) return 0;
  if (!url_s || !url_d->full) return 1;

  urlutils_return_description(url_s, &url_d2);

  if (url_d && url_d2)
  {
    result = !!strcmp(url_d->full, url_d2->full);
  }
  else result = !!strcmp(url_d->full, url_s);

  urlutils_free_description(url_d2);

  return result;
}

/**************************************************************/
/* urlutils_urldscmp()                                        */
/*                                                            */
/* Compares two URLs, returning 1 if they differ or 0 if they */
/* are the same. Both URLs are specified as url_description   */
/* structures.                                                */
/*                                                            */
/* Parameters: Pointer to a url_description filled in with    */
/*             the URL details;                               */
/*                                                            */
/*             Another url_description pointer, filled in     */
/*             with the details of a second URL.              */
/*                                                            */
/* Returns:    0 if the URLs match, else 1.                   */
/**************************************************************/

int urlutils_urlddcmp(const url_description * url_d1, const url_description * url_d2)
{
  /* Sanity check */

  if (!url_d1 && url_d2)  return 1;
  if (!url_d2 && url_d1)  return 1;
  if (!url_d1 && !url_d2) return 0;

  if (!url_d1->full && !url_d2->full) return 0;
  if (!url_d1->full || !url_d2->full) return 1;

  return !!strcmp(url_d1->full, url_d2->full);
}

/**************************************************************/
/* urlutils_return_description()                              */
/*                                                            */
/* Given a URL string, returns a url_description structure    */
/* which contains more accessible details on the URL          */
/* contents.                                                  */
/*                                                            */
/* The block itself and all filled in fields are allocated    */
/* with malloc(), and any additions to the structure should   */
/* be allocated in the same way.                              */
/*                                                            */
/* Parameters: Pointer to a NUL terminated URL string;        */
/*                                                            */
/*             Pointer to url_description * updated on exit,  */
/*             will be NULL for out of memory or any internal */
/*             error (returned directly).                     */
/**************************************************************/

_kernel_oserror * urlutils_return_description(const char * url_s, url_description ** url_d)
{
  _kernel_oserror * e = NULL;
  url_description * ndes;

  size_t            rlen;
  char *            tlen;
  int               plen;

  if (!url_s || !*url_s || !url_d) return NULL;
  *url_d = NULL;

  /* Allocate the structure */

  ndes = calloc(1, sizeof(url_description));
  if (!ndes) return NULL;

  /* Find the item lengths */

  e = _swix(URL_ParseURL,
            _INR(0,5),

            URL_ParseURL_LengthInR5 | URL_ParseURL_HexEscape,
            URL_ParseURL_Reason_FindLengths,
            url_s,
            NULL,
            ndes,
            sizeof(url_description) / sizeof(int));

  if (e != NULL) goto urlutils_return_description_free_and_exit;

  /* Expect the canonicalised form at the very least; ndes->full on */
  /* return from the SWI holds the buffer length required for this  */

  if (!ndes->full) goto urlutils_return_description_free_and_exit;

  /* Allocate a block to hold all of the fields */

  rlen = (int) ndes->full     +
         (int) ndes->protocol +
         (int) ndes->host     +
         (int) ndes->port     +
         (int) ndes->user     +
         (int) ndes->password +
         (int) ndes->account  +
         (int) ndes->path     +
         (int) ndes->query    +
         (int) ndes->fragment;

  if (!rlen) goto urlutils_return_description_free_and_exit;

  tlen       = (char *) ndes->full;
  ndes->full = malloc(rlen);
  if (!ndes->full) goto urlutils_return_description_free_and_exit;

  tlen      += (int) ndes->full;

  if (ndes->protocol) plen = (int) ndes->protocol, ndes->protocol = tlen, tlen += plen;
  if (ndes->host)     plen = (int) ndes->host,     ndes->host     = tlen, tlen += plen;
  if (ndes->port)     plen = (int) ndes->port,     ndes->port     = tlen, tlen += plen;

  if (ndes->user)     plen = (int) ndes->user,     ndes->user     = tlen, tlen += plen;
  if (ndes->password) plen = (int) ndes->password, ndes->password = tlen, tlen += plen;
  if (ndes->account)  plen = (int) ndes->account,  ndes->account  = tlen, tlen += plen;

  if (ndes->path)     plen = (int) ndes->path,     ndes->path     = tlen, tlen += plen;

  if (ndes->query)    plen = (int) ndes->query,    ndes->query    = tlen, tlen += plen;
  if (ndes->fragment) ndes->fragment = tlen;

  /* Fill in the block */

  e = _swix(URL_ParseURL,
            _INR(0,5),

            URL_ParseURL_LengthInR5 | URL_ParseURL_HexEscape,
            URL_ParseURL_Reason_FillBuffers,
            url_s,
            NULL,
            ndes,
            sizeof(url_description) / sizeof(int));

  if (e != NULL)
  {
    goto urlutils_return_description_free_and_exit;
  }
  else
  {
    _kernel_oserror ** re;
    va_list            ap;

    va_start(ap, url_s);

    re = va_arg(ap, _kernel_oserror **);
    if (re != NULL) *re = NULL;

    va_end(ap);
  }

  /* Finished */

  *url_d = ndes;

  return NULL;

  /* Error condition exit routine */

urlutils_return_description_free_and_exit:

  urlutils_free_description(ndes);
  return e;
}

/**************************************************************/
/* urlutils_free_description()                                */
/*                                                            */
/* Frees a url_description and all memory associated with it. */
/*                                                            */
/* The function expects all filled in fields in the structure */
/* to point to malloced blocks, as this is the way that       */
/* urlutils_return_description allocates it.                  */
/*                                                            */
/* Parameters: Pointer to a url_description structure.        */
/**************************************************************/

void urlutils_free_description(url_description * url_d)
{
  /* Not the most demanding code in the world, really */

  if (url_d == NULL) return;

  free(url_d->full);
  free(url_d);

  return;
}

/**************************************************************/
/* urlutils_matches_special()                                 */
/*                                                            */
/* Given a URL description and a string with a comma          */
/* separated list of entries describing match parameters,     */
/* return 1 if the URL meets any of the match criteria. The   */
/* match string should be in a writeable buffer and will be   */
/* corrupted on exit. The string consists of:                 */
/*                                                            */
/* 1. An optional hostname; either fully qualified (e.g.      */
/*    'wwww.acorn.com') or partially if starting with a dot   */
/*    (e.g. .acorn.com' to match any host with a name ending  */
/*    in '.acorn.com').                                       */
/*                                                            */
/* 2. An optional port following the host name, separated by  */
/*    a colon (e.g. 'www:3172'). Note that specifying the     */
/*    default port for whatever fetch protocol is in use will */
/*    never match (e.g. 'www:80' would never match for an     */
/*    HTTP fetch of server 'www') so this is only useful for  */
/*    matching unusual port values.                           */
/*                                                            */
/* 3. An optional path fragment, which is matched against the */
/*    left hand side of the URL (e.g. 'www/this/that' would   */
/*    match any path 'this/that', 'this/that/more',           */
/*    'this/thatandmore.gif', etc.).                          */
/*                                                            */
/* If SUPPORT_COMMAS is undefined, however, the match string  */
/* given is treated as one entity, commas being part of the   */
/* match itself.                                              */
/*                                                            */
/* Parameters: Pointer to a url_description filled in with    */
/*             details of the URL to examine;                 */
/*                                                            */
/*             Pointer to a string with the match parameters  */
/*             in it, comma separated if many are needed,     */
/*             which must be in a writeable buffer.           */
/*                                                            */
/* Returns:    1 if there's a match, else 0. The given match  */
/*             string is corrupted.                           */
/**************************************************************/

#undef SUPPORT_COMMAS

int urlutils_matches_special(const url_description * d, char * writeable)
{
  if (d && writeable)
  {
    char * at;

    char * host = d->host ? d->host : "";
    char * path = d->path ? d->path : "";
    char * port = d->port ? d->port : "";

    #ifdef SUPPORT_COMMAS

      do
      {
        at = strtok(writeable, ","), writeable = NULL;

        if (at)
        {

    #else

        at = writeable;
        {

    #endif

      /* Get each comma separated section individually */

        char * slash = strchr(at, '/');
        char * colon = strchr(at, ':');

        int    match = 0;

        /* If the colon is after the slash, it's not a port, it's part */
        /* of the path.                                                */

        if (slash && colon > slash) colon = NULL;

        /* Overwrite key seperator characters with terminators to make */
        /* subsequent comparisons easier                               */

        if (colon) *colon = '\0', colon++;
        if (slash) *slash = '\0', slash++;

        /* Match port and left hand side of path if required */

        if (!colon) match++;
        else if (!utils_strcasecmp(port, colon)) match++;

        if (!slash) match++;
        else if (!utils_strncasecmp(path, slash, strlen(slash))) match++;

        /* Allow no host (so just match by port or path) */

        if (!*at && (colon || slash)) match++;

        /* Otherwise, do host matching */

        else if (*at)
        {
          /* Compare only the right hand side */

          if (*at == '.')
          {
            int hlen   = strlen(host);
            int offset = hlen - strlen(at);

            if (offset >= 0 && !utils_strcasecmp(host + offset, at)) match++;
          }

          /* Compare the whole thing */

          else
          {
            if (!utils_strcasecmp(host, at)) match++;
          }
        }

        /* Did we match it? */

        if (match == 3) return 1;

        /* No, so restore the string so strtok will continue to work */

        if (slash) *(--slash) = '/';
        if (colon) *(--colon) = ':';
      }

    #ifdef SUPPORT_COMMAS

      }
      while (at != NULL);

    #endif
  }

  return 0;
}
@


1.2
log
@Test harness added, with a few minor bug fixes arising from the test
results. URL_Fetcher handling improved.

Version 0.02. Tagged as 'CheckURL-0_02'
@
text
@d22 1
a22 1
/* Author : A.D.Hodgkinson.                                   */
d359 4
d374 2
d386 16
a401 2
    do
    {
a403 4
      at = strtok(writeable, ","), writeable = NULL;

      if (at)
      {
d409 5
d463 7
a469 2
    }
    while (at);
@


1.1
log
@Initial revision
@
text
@d24 6
a29 1
/* History: 08-Mar-2000 (ADH): Imported to Check URL.         */
d35 1
d39 8
d56 2
a57 2
/* Fit within CheckURL's URL_Fetcher derived namings   */
/* - these are all in Generic.[c|h] rather than Utils. */
d90 2
a91 4
  // Awaiting URL module stuff

  url_d1 = urlutils_return_description(url_s1);
  url_d2 = urlutils_return_description(url_s2);
d135 1
a135 3
  // Awaiting URL module stuff

  url_d2 = urlutils_return_description(url_s);
a174 2
  // Awaiting URL module stuff

d189 1
a189 1
/* Parameters: Pointer to a NUL terminated URL string.        */
d191 3
a193 3
/* Returns:    Pointer to a url_description structure filled  */
/*             in with details of the string, or NULL if      */
/*             allocation failed.                             */
d196 1
a196 1
url_description * urlutils_return_description(const char * url_s)
d198 2
a199 1
  url_description * new;
d205 2
a206 1
  if (!url_s || !*url_s) return NULL;
d210 2
a211 3
  new = calloc(1, sizeof(url_description));

  if (!new) return NULL;
d215 1
a215 1
  if (_swix(URL_ParseURL,
d218 1
a218 1
            0,
d222 4
a225 2
            new,
            sizeof(url_description) / 4)) goto urlutils_return_description_free_and_exit;
d227 2
a228 2
  /* Expect the canonicalised form at the very least; new->full on */
  /* return from the SWI holds the buffer length required for this */
d230 1
a230 1
  if (!new->full) goto urlutils_return_description_free_and_exit;
d234 10
a243 10
  rlen = (int) new->full     +
         (int) new->protocol +
         (int) new->host     +
         (int) new->port     +
         (int) new->user     +
         (int) new->password +
         (int) new->account  +
         (int) new->path     +
         (int) new->query    +
         (int) new->fragment;
d247 3
a249 3
  tlen      = (char *) new->full;
  new->full = malloc(rlen);
  if (!new->full) goto urlutils_return_description_free_and_exit;
d251 1
a251 1
  tlen     += (int) new->full;
d253 3
a255 3
  if (new->protocol) plen = (int) new->protocol, new->protocol = tlen, tlen += plen;
  if (new->host)     plen = (int) new->host,     new->host     = tlen, tlen += plen;
  if (new->port)     plen = (int) new->port,     new->port     = tlen, tlen += plen;
d257 3
a259 3
  if (new->user)     plen = (int) new->user,     new->user     = tlen, tlen += plen;
  if (new->password) plen = (int) new->password, new->password = tlen, tlen += plen;
  if (new->account)  plen = (int) new->account,  new->account  = tlen, tlen += plen;
d261 1
a261 1
  if (new->path)     plen = (int) new->path,     new->path     = tlen, tlen += plen;
d263 2
a264 2
  if (new->query)    plen = (int) new->query,    new->query    = tlen, tlen += plen;
  if (new->fragment) new->fragment = tlen;
d268 1
a268 1
  if (_swix(URL_ParseURL,
d271 1
a271 1
            0,
d275 19
a293 2
            new,
            sizeof(url_description) / sizeof(char *))) goto urlutils_return_description_free_and_exit;
d297 3
a299 1
  return new;
d305 2
a306 3
  urlutils_free_description(new);

  return NULL;
d325 2
a446 73
}

/**************************************************************/
/* urlutils_relativise_url()                                  */
/*                                                            */
/* HTMLLib has a call to take a base URL and a relative URL   */
/* and produce a canonical result based on the combination of */
/* the two. This does the same (it is based on the HTMLLib    */
/* code) but doesn't need an HTMLLib memory context to        */
/* operate in - the HTMLLib call is useful when context based */
/* memory allocation is handy.                                */
/*                                                            */
/* Parameters: Pointer to a base URL;                         */
/*                                                            */
/*             Pointer to a relative URL.                     */
/*                                                            */
/* Returns:    Pointer to a malloc'd URL (so it must be       */
/*             eventually free'd by the caller) which is the  */
/*             canonical result of combining the base and     */
/*             relative URLs.                                 */
/**************************************************************/

char * urlutils_relativise_url(const char * base, const char * link)
{
  _kernel_oserror * e;
  char            * ptr;
  int               blen;
  char            * ret = NULL;

  if (link == NULL) return NULL;

  if (base == NULL)
  {
    ret = utils_strdup(link);
    return ret;
  }

  /* Strip preceeding spaces */

  while (*link == ' ') link++;

  /* Cope with empty link URLs */

  if (*link == '\0') return utils_strdup(base);

  /* Otherwise, just go for it... */

  if (!base) base = "";

  blen = strlen(base) + 4 + (link ? strlen(link) : 0);
  ptr  = malloc(blen);

  if (ptr == NULL) return NULL;

  e = _swix(URL_ParseURL,
            _INR(0,5),

            0,
            URL_ParseURL_Reason_QuickResolve,
            base,
            link,
            ptr,
            blen);

  /* Did the above succeed? */

  if (e != NULL)
  {
    free(ptr);
    return NULL;
  }

  return ptr;
@


1.1.1.1
log
@  First complete version of Check URL.
Detail:
  Check URL allows applications to match URLs against URL fragments to
  perform domain, port and/or path specific activities. This could be
  used in a browser to block advert loading, in Video Control to select
  a protocol module, or in JavaScript to enable or disable the Pace VOD
  extensions, for example. See 2501,846 for details.
Admin:
  This has only been lightly tested, but I believe it's functionally
  complete according to issue 1 of the specification.
@
text
@@
