head	4.2;
access;
symbols
	Kernel-6_15:4.2
	Kernel-6_14:4.2
	Kernel-6_01-3:4.2
	Kernel-6_13:4.2
	Kernel-6_12:4.2
	Kernel-6_11:4.2
	Kernel-6_10:4.2
	Kernel-6_09:4.2
	Kernel-6_08-4_129_2_10:4.2
	Kernel-6_08-4_129_2_9:4.2
	Kernel-6_08:4.2
	Kernel-6_07:4.2
	Kernel-6_06:4.2
	Kernel-6_05-4_129_2_8:4.2
	Kernel-6_05:4.2
	Kernel-6_04:4.2
	Kernel-6_03:4.2
	Kernel-6_01-2:4.2
	Kernel-6_01-4_146_2_1:4.2
	Kernel-6_02:4.2
	Kernel-6_01-1:4.2
	Kernel-6_01:4.2
	Kernel-6_00:4.2
	Kernel-5_99:4.2
	Kernel-5_98:4.2
	Kernel-5_97-4_129_2_7:4.2
	Kernel-5_97:4.2
	Kernel-5_96:4.2
	Kernel-5_95:4.2
	Kernel-5_94:4.2
	Kernel-5_93:4.2
	Kernel-5_92:4.2
	Kernel-5_91:4.2
	Kernel-5_90:4.2
	Kernel-5_89-4_129_2_6:4.2
	Kernel-5_89:4.2
	Kernel-5_88-4_129_2_5:4.2
	Kernel-5_88-4_129_2_4:4.2
	Kernel-5_88:4.2
	Kernel-5_87:4.2
	Kernel-5_86-4_129_2_3:4.2
	Kernel-5_86-4_129_2_2:4.2
	Kernel-5_86-4_129_2_1:4.2
	Kernel-5_86:4.2
	SMP:4.2.0.2
	SMP_bp:4.2
	Kernel-5_85:4.2
	Kernel-5_54-1:4.1
	Kernel-5_84:4.2
	Kernel-5_83:4.2
	Kernel-5_82:4.2
	Kernel-5_81:4.2
	Kernel-5_80:4.2
	Kernel-5_79:4.2
	Kernel-5_78:4.2
	Kernel-5_77:4.2
	Kernel-5_76:4.2
	Kernel-5_75:4.2
	Kernel-5_74:4.2
	Kernel-5_73:4.2
	Kernel-5_72:4.2
	Kernel-5_71:4.2
	Kernel-5_70:4.2
	Kernel-5_69:4.2
	Kernel-5_68:4.2
	Kernel-5_67:4.1
	Kernel-5_66:4.1
	Kernel-5_65:4.1
	Kernel-5_64:4.1
	Kernel-5_63:4.1
	Kernel-5_62:4.1
	Kernel-5_61:4.1
	Kernel-5_60:4.1
	Kernel-5_59:4.1
	Kernel-5_58:4.1
	Kernel-5_57:4.1
	Kernel-5_56:4.1
	Kernel-5_55:4.1
	Kernel-5_54:4.1
	Kernel-5_53:4.1
	Kernel-5_52:4.1
	Kernel-5_51:4.1
	Kernel-5_50:4.1
	Kernel-5_49:4.1
	HAL_merge:1.1.2.4
	Kernel-5_48:4.1
	Kernel-5_35-4_79_2_327:1.1.2.4
	Kernel-5_35-4_79_2_326:1.1.2.4
	Kernel-5_35-4_79_2_325:1.1.2.4
	Kernel-5_35-4_79_2_324:1.1.2.4
	Kernel-5_35-4_79_2_323:1.1.2.4
	Kernel-5_35-4_79_2_322:1.1.2.4
	Kernel-5_35-4_79_2_321:1.1.2.4
	Kernel-5_35-4_79_2_320:1.1.2.4
	Kernel-5_35-4_79_2_319:1.1.2.4
	Kernel-5_35-4_79_2_318:1.1.2.4
	Kernel-5_35-4_79_2_317:1.1.2.4
	Kernel-5_35-4_79_2_316:1.1.2.4
	Kernel-5_35-4_79_2_315:1.1.2.4
	Kernel-5_35-4_79_2_314:1.1.2.4
	Kernel-5_35-4_79_2_313:1.1.2.4
	Kernel-5_35-4_79_2_312:1.1.2.4
	Kernel-5_35-4_79_2_311:1.1.2.4
	Kernel-5_35-4_79_2_310:1.1.2.4
	Kernel-5_35-4_79_2_309:1.1.2.4
	Kernel-5_35-4_79_2_308:1.1.2.4
	Kernel-5_35-4_79_2_307:1.1.2.4
	Kernel-5_35-4_79_2_306:1.1.2.4
	Kernel-5_35-4_79_2_305:1.1.2.4
	Kernel-5_35-4_79_2_304:1.1.2.4
	Kernel-5_35-4_79_2_303:1.1.2.4
	Kernel-5_35-4_79_2_302:1.1.2.4
	Kernel-5_35-4_79_2_301:1.1.2.4
	Kernel-5_35-4_79_2_300:1.1.2.4
	Kernel-5_35-4_79_2_299:1.1.2.4
	Kernel-5_35-4_79_2_298:1.1.2.4
	Kernel-5_35-4_79_2_297:1.1.2.4
	Kernel-5_35-4_79_2_296:1.1.2.4
	Kernel-5_35-4_79_2_295:1.1.2.4
	Kernel-5_35-4_79_2_294:1.1.2.4
	Kernel-5_35-4_79_2_293:1.1.2.4
	Kernel-5_35-4_79_2_292:1.1.2.4
	Kernel-5_35-4_79_2_291:1.1.2.4
	Kernel-5_35-4_79_2_290:1.1.2.4
	Kernel-5_35-4_79_2_289:1.1.2.4
	Kernel-5_35-4_79_2_288:1.1.2.4
	Kernel-5_35-4_79_2_287:1.1.2.4
	Kernel-5_35-4_79_2_286:1.1.2.4
	Kernel-5_35-4_79_2_285:1.1.2.4
	Kernel-5_35-4_79_2_284:1.1.2.4
	Kernel-5_35-4_79_2_283:1.1.2.4
	Kernel-5_35-4_79_2_282:1.1.2.4
	Kernel-5_35-4_79_2_281:1.1.2.4
	Kernel-5_35-4_79_2_280:1.1.2.4
	Kernel-5_35-4_79_2_279:1.1.2.4
	Kernel-5_35-4_79_2_278:1.1.2.4
	Kernel-5_35-4_79_2_277:1.1.2.4
	Kernel-5_35-4_79_2_276:1.1.2.4
	Kernel-5_35-4_79_2_275:1.1.2.4
	Kernel-5_35-4_79_2_274:1.1.2.4
	Kernel-5_35-4_79_2_273:1.1.2.4
	Kernel-5_35-4_79_2_272:1.1.2.4
	Kernel-5_35-4_79_2_271:1.1.2.4
	Kernel-5_35-4_79_2_270:1.1.2.4
	Kernel-5_35-4_79_2_269:1.1.2.4
	Kernel-5_35-4_79_2_268:1.1.2.4
	Kernel-5_35-4_79_2_267:1.1.2.4
	Kernel-5_35-4_79_2_266:1.1.2.4
	Kernel-5_35-4_79_2_265:1.1.2.4
	Kernel-5_35-4_79_2_264:1.1.2.4
	Kernel-5_35-4_79_2_263:1.1.2.4
	Kernel-5_35-4_79_2_262:1.1.2.4
	Kernel-5_35-4_79_2_261:1.1.2.4
	Kernel-5_35-4_79_2_260:1.1.2.4
	Kernel-5_35-4_79_2_259:1.1.2.4
	Kernel-5_35-4_79_2_258:1.1.2.4
	Kernel-5_35-4_79_2_257:1.1.2.4
	Kernel-5_35-4_79_2_256:1.1.2.4
	Kernel-5_35-4_79_2_255:1.1.2.4
	Kernel-5_35-4_79_2_254:1.1.2.4
	Kernel-5_35-4_79_2_253:1.1.2.4
	Kernel-5_35-4_79_2_252:1.1.2.4
	Kernel-5_35-4_79_2_251:1.1.2.4
	Kernel-5_35-4_79_2_250:1.1.2.4
	Kernel-5_35-4_79_2_249:1.1.2.4
	Kernel-5_35-4_79_2_248:1.1.2.4
	Kernel-5_35-4_79_2_247:1.1.2.4
	Kernel-5_35-4_79_2_246:1.1.2.4
	Kernel-5_35-4_79_2_245:1.1.2.4
	Kernel-5_35-4_79_2_244:1.1.2.4
	Kernel-5_35-4_79_2_243:1.1.2.4
	Kernel-5_35-4_79_2_242:1.1.2.4
	Kernel-5_35-4_79_2_241:1.1.2.4
	Kernel-5_35-4_79_2_240:1.1.2.4
	Kernel-5_35-4_79_2_239:1.1.2.4
	Kernel-5_35-4_79_2_238:1.1.2.4
	Kernel-5_35-4_79_2_237:1.1.2.4
	Kernel-5_35-4_79_2_236:1.1.2.4
	Kernel-5_35-4_79_2_235:1.1.2.4
	Kernel-5_35-4_79_2_234:1.1.2.4
	Kernel-5_35-4_79_2_233:1.1.2.4
	Kernel-5_35-4_79_2_232:1.1.2.4
	Kernel-5_35-4_79_2_231:1.1.2.4
	Kernel-5_35-4_79_2_230:1.1.2.4
	Kernel-5_35-4_79_2_229:1.1.2.4
	Kernel-5_35-4_79_2_228:1.1.2.4
	Kernel-5_35-4_79_2_227:1.1.2.4
	Kernel-5_35-4_79_2_226:1.1.2.4
	Kernel-5_35-4_79_2_225:1.1.2.4
	Kernel-5_35-4_79_2_224:1.1.2.4
	Kernel-5_35-4_79_2_223:1.1.2.4
	Kernel-5_35-4_79_2_222:1.1.2.4
	Kernel-5_35-4_79_2_221:1.1.2.4
	Kernel-5_35-4_79_2_220:1.1.2.4
	Kernel-5_35-4_79_2_219:1.1.2.4
	Kernel-5_35-4_79_2_218:1.1.2.4
	Kernel-5_35-4_79_2_217:1.1.2.4
	Kernel-5_35-4_79_2_216:1.1.2.4
	Kernel-5_35-4_79_2_215:1.1.2.4
	Kernel-5_35-4_79_2_214:1.1.2.4
	Kernel-5_35-4_79_2_213:1.1.2.4
	Kernel-5_35-4_79_2_212:1.1.2.4
	Kernel-5_35-4_79_2_211:1.1.2.4
	Kernel-5_35-4_79_2_210:1.1.2.4
	Kernel-5_35-4_79_2_209:1.1.2.4
	Kernel-5_35-4_79_2_208:1.1.2.4
	Kernel-5_35-4_79_2_207:1.1.2.4
	Kernel-5_35-4_79_2_206:1.1.2.4
	Kernel-5_35-4_79_2_205:1.1.2.4
	Kernel-5_35-4_79_2_204:1.1.2.4
	Kernel-5_35-4_79_2_203:1.1.2.4
	Kernel-5_35-4_79_2_202:1.1.2.4
	Kernel-5_35-4_79_2_201:1.1.2.4
	Kernel-5_35-4_79_2_200:1.1.2.4
	Kernel-5_35-4_79_2_199:1.1.2.4
	Kernel-5_35-4_79_2_198:1.1.2.4
	Kernel-5_35-4_79_2_197:1.1.2.4
	Kernel-5_35-4_79_2_196:1.1.2.4
	Kernel-5_35-4_79_2_195:1.1.2.4
	Kernel-5_35-4_79_2_194:1.1.2.4
	Kernel-5_35-4_79_2_193:1.1.2.4
	Kernel-5_35-4_79_2_192:1.1.2.4
	Kernel-5_35-4_79_2_191:1.1.2.4
	Kernel-5_35-4_79_2_190:1.1.2.4
	Kernel-5_35-4_79_2_189:1.1.2.4
	Kernel-5_35-4_79_2_188:1.1.2.4
	Kernel-5_35-4_79_2_187:1.1.2.4
	Kernel-5_35-4_79_2_186:1.1.2.4
	Kernel-5_35-4_79_2_185:1.1.2.4
	Kernel-5_35-4_79_2_184:1.1.2.4
	Kernel-5_35-4_79_2_183:1.1.2.4
	Kernel-5_35-4_79_2_182:1.1.2.4
	Kernel-5_35-4_79_2_181:1.1.2.4
	Kernel-5_35-4_79_2_180:1.1.2.4
	Kernel-5_35-4_79_2_179:1.1.2.4
	Kernel-5_35-4_79_2_178:1.1.2.4
	Kernel-5_35-4_79_2_177:1.1.2.4
	Kernel-5_35-4_79_2_176:1.1.2.4
	Kernel-5_35-4_79_2_175:1.1.2.4
	Kernel-5_35-4_79_2_174:1.1.2.4
	Kernel-5_35-4_79_2_173:1.1.2.4
	Kernel-5_35-4_79_2_172:1.1.2.4
	Kernel-5_35-4_79_2_171:1.1.2.4
	Kernel-5_35-4_79_2_170:1.1.2.4
	Kernel-5_35-4_79_2_169:1.1.2.4
	Kernel-5_35-4_79_2_168:1.1.2.4
	Kernel-5_35-4_79_2_167:1.1.2.4
	Kernel-5_35-4_79_2_166:1.1.2.4
	Kernel-5_35-4_79_2_165:1.1.2.4
	RPi_merge:1.1.2.4
	Kernel-5_35-4_79_2_147_2_23:1.1.2.4
	Kernel-5_35-4_79_2_147_2_22:1.1.2.4
	Kernel-5_35-4_79_2_147_2_21:1.1.2.4
	Kernel-5_35-4_79_2_147_2_20:1.1.2.4
	Kernel-5_35-4_79_2_147_2_19:1.1.2.4
	Kernel-5_35-4_79_2_147_2_18:1.1.2.4
	Kernel-5_35-4_79_2_164:1.1.2.4
	Kernel-5_35-4_79_2_163:1.1.2.4
	Kernel-5_35-4_79_2_147_2_17:1.1.2.4
	Kernel-5_35-4_79_2_147_2_16:1.1.2.4
	Kernel-5_35-4_79_2_147_2_15:1.1.2.4
	Kernel-5_35-4_79_2_162:1.1.2.4
	Kernel-5_35-4_79_2_161:1.1.2.4
	Kernel-5_35-4_79_2_147_2_14:1.1.2.4
	Kernel-5_35-4_79_2_147_2_13:1.1.2.4
	Kernel-5_35-4_79_2_160:1.1.2.4
	Kernel-5_35-4_79_2_159:1.1.2.4
	Kernel-5_35-4_79_2_158:1.1.2.4
	Kernel-5_35-4_79_2_157:1.1.2.4
	Kernel-5_35-4_79_2_156:1.1.2.4
	Kernel-5_35-4_79_2_147_2_12:1.1.2.4
	Kernel-5_35-4_79_2_147_2_11:1.1.2.4
	Kernel-5_35-4_79_2_155:1.1.2.4
	Kernel-5_35-4_79_2_147_2_10:1.1.2.4
	Kernel-5_35-4_79_2_154:1.1.2.4
	Kernel-5_35-4_79_2_153:1.1.2.4
	Kernel-5_35-4_79_2_147_2_9:1.1.2.4
	Kernel-5_35-4_79_2_152:1.1.2.4
	Kernel-5_35-4_79_2_151:1.1.2.4
	Kernel-5_35-4_79_2_147_2_8:1.1.2.4
	Kernel-5_35-4_79_2_147_2_7:1.1.2.4
	Kernel-5_35-4_79_2_150:1.1.2.4
	Kernel-5_35-4_79_2_147_2_6:1.1.2.4
	Kernel-5_35-4_79_2_147_2_5:1.1.2.4
	Kernel-5_35-4_79_2_149:1.1.2.4
	Kernel-5_35-4_79_2_147_2_4:1.1.2.4
	Kernel-5_35-4_79_2_147_2_3:1.1.2.4
	Kernel-5_35-4_79_2_148:1.1.2.4
	Kernel-5_35-4_79_2_147_2_2:1.1.2.4
	Kernel-5_35-4_79_2_147_2_1:1.1.2.4
	RPi:1.1.2.4.0.2
	RPi_bp:1.1.2.4
	Kernel-5_35-4_79_2_98_2_52_2_1:1.1.2.3.2.6
	alees_Kernel_dev:1.1.2.3.2.6.0.2
	alees_Kernel_dev_bp:1.1.2.3.2.6
	Kernel-5_35-4_79_2_147:1.1.2.4
	Kernel-5_35-4_79_2_146:1.1.2.4
	Kernel-5_35-4_79_2_145:1.1.2.4
	Kernel-5_35-4_79_2_144:1.1.2.4
	Kernel-5_35-4_79_2_143:1.1.2.4
	Kernel-5_35-4_79_2_142:1.1.2.4
	Kernel-5_35-4_79_2_141:1.1.2.4
	Kernel-5_35-4_79_2_140:1.1.2.4
	Kernel-5_35-4_79_2_139:1.1.2.4
	Kernel-5_35-4_79_2_138:1.1.2.4
	Kernel-5_35-4_79_2_137:1.1.2.4
	Kernel-5_35-4_79_2_136:1.1.2.4
	Kernel-5_35-4_79_2_135:1.1.2.4
	Kernel-5_35-4_79_2_134:1.1.2.4
	Kernel-5_35-4_79_2_133:1.1.2.4
	Kernel-5_35-4_79_2_132:1.1.2.4
	Kernel-5_35-4_79_2_131:1.1.2.4
	Kernel-5_35-4_79_2_130:1.1.2.4
	Kernel-5_35-4_79_2_129:1.1.2.4
	Kernel-5_35-4_79_2_128:1.1.2.4
	Kernel-5_35-4_79_2_127:1.1.2.4
	Kernel-5_35-4_79_2_126:1.1.2.4
	Kernel-5_35-4_79_2_125:1.1.2.4
	Kernel-5_35-4_79_2_124:1.1.2.4
	Kernel-5_35-4_79_2_123:1.1.2.4
	Cortex_merge:1.1.2.3.2.6
	Kernel-5_35-4_79_2_122:1.1.2.3
	Kernel-5_35-4_79_2_98_2_54:1.1.2.3.2.6
	Kernel-5_35-4_79_2_98_2_53:1.1.2.3.2.6
	Kernel-5_35-4_79_2_98_2_52:1.1.2.3.2.6
	Kernel-5_35-4_79_2_98_2_51:1.1.2.3.2.6
	Kernel-5_35-4_79_2_98_2_50:1.1.2.3.2.5
	Kernel-5_35-4_79_2_98_2_49:1.1.2.3.2.5
	Kernel-5_35-4_79_2_98_2_48:1.1.2.3.2.5
	Kernel-5_35-4_79_2_121:1.1.2.3
	Kernel-5_35-4_79_2_98_2_47:1.1.2.3.2.4
	Kernel-5_35-4_79_2_120:1.1.2.3
	Kernel-5_35-4_79_2_98_2_46:1.1.2.3.2.4
	Kernel-5_35-4_79_2_119:1.1.2.3
	Kernel-5_35-4_79_2_98_2_45:1.1.2.3.2.4
	Kernel-5_35-4_79_2_98_2_44:1.1.2.3.2.4
	Kernel-5_35-4_79_2_118:1.1.2.3
	Kernel-5_35-4_79_2_98_2_43:1.1.2.3.2.4
	Kernel-5_35-4_79_2_117:1.1.2.3
	Kernel-5_35-4_79_2_116:1.1.2.3
	Kernel-5_35-4_79_2_98_2_42:1.1.2.3.2.4
	Kernel-5_35-4_79_2_115:1.1.2.3
	Kernel-5_35-4_79_2_98_2_41:1.1.2.3.2.4
	Kernel-5_35-4_79_2_98_2_40:1.1.2.3.2.4
	Kernel-5_35-4_79_2_114:1.1.2.3
	Kernel-5_35-4_79_2_98_2_39:1.1.2.3.2.4
	Kernel-5_35-4_79_2_98_2_38:1.1.2.3.2.4
	Kernel-5_35-4_79_2_113:1.1.2.3
	Kernel-5_35-4_79_2_112:1.1.2.3
	Kernel-5_35-4_79_2_98_2_37:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_36:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_35:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_34:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_33:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_32:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_31:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_30:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_29:1.1.2.3.2.3
	Kernel-5_35-4_79_2_98_2_28:1.1.2.3.2.2
	Kernel-5_35-4_79_2_98_2_27:1.1.2.3.2.2
	Kernel-5_35-4_79_2_98_2_26:1.1.2.3.2.1
	Kernel-5_35-4_79_2_111:1.1.2.3
	Kernel-5_35-4_79_2_98_2_25:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_24:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_23:1.1.2.3.2.1
	Kernel-5_35-4_79_2_110:1.1.2.3
	Kernel-5_35-4_79_2_98_2_22:1.1.2.3.2.1
	Kernel-5_35-4_79_2_109:1.1.2.3
	Kernel-5_35-4_79_2_98_2_21:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_20:1.1.2.3.2.1
	Kernel-5_35-4_79_2_108:1.1.2.3
	Kernel-5_35-4_79_2_107:1.1.2.3
	Kernel-5_35-4_79_2_98_2_19:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_18:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_17:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_16:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_15:1.1.2.3.2.1
	Kernel-5_35-4_79_2_106:1.1.2.3
	Kernel-5_35-4_79_2_105:1.1.2.3
	Kernel-5_35-4_79_2_104:1.1.2.3
	Kernel-5_35-4_79_2_98_2_14:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_13:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_12:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_11:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_10:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_9:1.1.2.3.2.1
	Kernel-5_35-4_79_2_103:1.1.2.3
	Kernel-5_35-4_79_2_102:1.1.2.3
	Kernel-5_35-4_79_2_98_2_8:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_7:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_6:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_5:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_4:1.1.2.3.2.1
	Kernel-5_35-4_79_2_101:1.1.2.3
	Kernel-5_35-4_79_2_100:1.1.2.3
	Kernel-5_35-4_79_2_99:1.1.2.3
	Kernel-5_35-4_79_2_98_2_3:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_2:1.1.2.3.2.1
	Kernel-5_35-4_79_2_98_2_1:1.1.2.3
	Cortex:1.1.2.3.0.2
	Cortex_bp:1.1.2.3
	Kernel-5_35-4_79_2_98:1.1.2.3
	Kernel-5_35-4_79_2_97:1.1.2.3
	Kernel-5_35-4_79_2_96:1.1.2.3
	Kernel-5_35-4_79_2_95:1.1.2.3
	Kernel-5_35-4_79_2_94:1.1.2.3
	Kernel-5_35-4_79_2_93:1.1.2.3
	Kernel-5_35-4_79_2_92:1.1.2.3
	Kernel-5_35-4_79_2_91:1.1.2.3
	Kernel-5_35-4_79_2_90:1.1.2.3
	Kernel-5_35-4_79_2_89:1.1.2.3
	Kernel-5_35-4_79_2_88:1.1.2.3
	Kernel-5_35-4_79_2_87:1.1.2.3
	Kernel-5_35-4_79_2_86:1.1.2.3
	Kernel-5_35-4_79_2_85:1.1.2.3
	Kernel-5_35-4_79_2_84:1.1.2.3
	Kernel-5_35-4_79_2_83:1.1.2.3
	Kernel-5_35-4_79_2_82:1.1.2.3
	Kernel-5_35-4_79_2_81:1.1.2.3
	Kernel-5_35-4_79_2_80:1.1.2.3
	Kernel-5_35-4_79_2_79:1.1.2.3
	Kernel-5_35-4_79_2_78:1.1.2.3
	Kernel-5_35-4_79_2_77:1.1.2.3
	RO_5_07:1.1.2.3
	Kernel-5_35-4_79_2_76:1.1.2.3
	Kernel-5_35-4_79_2_75:1.1.2.3
	Kernel-5_35-4_79_2_74:1.1.2.3
	Kernel-5_35-4_79_2_73:1.1.2.3
	Kernel-5_35-4_79_2_72:1.1.2.3
	Kernel-5_35-4_79_2_71:1.1.2.3
	Kernel-5_35-4_79_2_70:1.1.2.3
	Kernel-5_35-4_79_2_69:1.1.2.3
	Kernel-5_35-4_79_2_68:1.1.2.3
	Kernel-5_35-4_79_2_67:1.1.2.3
	Kernel-5_35-4_79_2_66:1.1.2.3
	Kernel-5_35-4_79_2_65:1.1.2.3
	Kernel-5_35-4_79_2_64:1.1.2.3
	Kernel-5_35-4_79_2_63:1.1.2.3
	Kernel-5_35-4_79_2_62:1.1.2.3
	Kernel-5_35-4_79_2_61:1.1.2.3
	Kernel-5_35-4_79_2_59:1.1.2.3
	Kernel-5_35-4_79_2_58:1.1.2.3
	Kernel-5_35-4_79_2_57:1.1.2.3
	Kernel-5_35-4_79_2_56:1.1.2.3
	Kernel-5_35-4_79_2_55:1.1.2.3
	Kernel-5_35-4_79_2_54:1.1.2.3
	Kernel-5_35-4_79_2_53:1.1.2.3
	Kernel-5_35-4_79_2_52:1.1.2.3
	Kernel-5_35-4_79_2_51:1.1.2.3
	Kernel-5_35-4_79_2_50:1.1.2.3
	Kernel-5_35-4_79_2_49:1.1.2.2
	Kernel-5_35-4_79_2_48:1.1.2.2
	Kernel-5_35-4_79_2_47:1.1.2.2
	Kernel-5_35-4_79_2_46:1.1.2.2
	Kernel-5_35-4_79_2_45:1.1.2.2
	Kernel-5_35-4_79_2_44:1.1.2.2
	Kernel-5_35-4_79_2_25_2_2:1.1.2.1
	Kernel-5_35-4_79_2_43:1.1.2.2
	Kernel-5_35-4_79_2_42:1.1.2.2
	Kernel-5_35-4_79_2_41:1.1.2.2
	Kernel-5_35-4_79_2_40:1.1.2.2
	Kernel-5_35-4_79_2_39:1.1.2.2
	Kernel-5_35-4_79_2_38:1.1.2.2
	Kernel-5_35-4_79_2_37:1.1.2.1
	Kernel-5_35-4_79_2_36:1.1.2.1
	Kernel-5_35-4_79_2_35:1.1.2.1
	Kernel-5_35-4_79_2_34:1.1.2.1
	Kernel-5_35-4_79_2_33:1.1.2.1
	Kernel-5_35-4_79_2_32:1.1.2.1
	Kernel-5_35-4_79_2_25_2_1:1.1.2.1
	Kernel-5_35-4_79_2_31:1.1.2.1
	Kernel-5_35-4_79_2_30:1.1.2.1
	Kernel-5_35-4_79_2_29:1.1.2.1
	Kernel-5_35-4_79_2_28:1.1.2.1
	Kernel-5_35-4_79_2_27:1.1.2.1
	Kernel-5_35-4_79_2_26:1.1.2.1
	Kernel-5_35-4_79_2_25:1.1.2.1
	Kernel-5_35-4_79_2_24:1.1.2.1
	Kernel-5_35-4_79_2_23:1.1.2.1
	Kernel-5_35-4_79_2_22:1.1.2.1
	Kernel-5_35-4_79_2_21:1.1.2.1
	Kernel-5_35-4_79_2_20:1.1.2.1
	Kernel-5_35-4_79_2_19:1.1.2.1
	Kernel-5_35-4_79_2_18:1.1.2.1
	Kernel-5_35-4_79_2_17:1.1.2.1
	Kernel-5_35-4_79_2_16:1.1.2.1
	Kernel-5_35-4_79_2_15:1.1.2.1
	Kernel-5_35-4_79_2_14:1.1.2.1
	Kernel-5_35-4_79_2_13:1.1.2.1
	Kernel-5_35-4_79_2_12:1.1.2.1
	Kernel-5_35-4_79_2_11:1.1.2.1
	Kernel-5_35-4_79_2_10:1.1.2.1
	HAL:1.1.0.2;
locks; strict;
comment	@# @;


4.2
date	2016.12.13.17.31.01;	author jlee;	state Exp;
branches;
next	4.1;
commitid	xwV3EbxXsXlhCQxz;

4.1
date	2016.06.30.20.07.57;	author jlee;	state Exp;
branches;
next	1.1;
commitid	IWoXxARWeuLDOwcz;

1.1
date	2000.10.16.11.55.38;	author kbracey;	state dead;
branches
	1.1.2.1;
next	;

1.1.2.1
date	2000.10.16.11.55.38;	author kbracey;	state Exp;
branches;
next	1.1.2.2;

1.1.2.2
date	2001.06.18.14.49.42;	author mstephen;	state Exp;
branches;
next	1.1.2.3;

1.1.2.3
date	2002.10.28.16.13.45;	author bavison;	state Exp;
branches
	1.1.2.3.2.1;
next	1.1.2.4;

1.1.2.4
date	2011.11.26.21.11.10;	author jlee;	state Exp;
branches;
next	;
commitid	cI3W0zbtALQG6TIv;

1.1.2.3.2.1
date	2009.02.21.17.41.24;	author jlee;	state Exp;
branches;
next	1.1.2.3.2.2;

1.1.2.3.2.2
date	2010.06.23.22.34.25;	author jlee;	state Exp;
branches;
next	1.1.2.3.2.3;

1.1.2.3.2.3
date	2010.06.24.00.36.29;	author jlee;	state Exp;
branches;
next	1.1.2.3.2.4;

1.1.2.3.2.4
date	2011.06.04.15.54.29;	author jlee;	state Exp;
branches;
next	1.1.2.3.2.5;
commitid	xmzeXYEfZlUPYmmv;

1.1.2.3.2.5
date	2011.08.08.23.28.22;	author jlee;	state Exp;
branches;
next	1.1.2.3.2.6;
commitid	D7rzILnwRRSXoLuv;

1.1.2.3.2.6
date	2011.09.12.20.31.37;	author jlee;	state Exp;
branches;
next	;
commitid	aYOriTZbxBByifzv;


desc
@@


4.2
log
@Add new ARMops. Add macros which map the ARMv7/v8 cache/TLB maintenance mnemonics (as featured in recent ARM ARMs) to MCR ops.
Detail:
  - Docs/HAL/ARMop_API - Document the new ARMops. These ops are intended to help with future work (DMA without OS_Memory 0 "make temp uncacheable", and minimising cache maintenance when unmapping pages) and aren't in use just yet.
  - hdr/Copro15ops - Add new macros for ARMv7+ which map the mnemonics seen in recent ARM ARMs to the corresponding MCR ops. This should make things easier when cross-referencing docs and reduce the risk of typos.
  - hdr/KernelWS - Shuffle kernel workspace a bit to make room for the new ARMops
  - hdr/OSMisc - Expose new ARMops via OS_MMUControl 2
  - s/ARMops - Implement the new ARMops. Change the ARMv7+ ARMops to use the new mnemonic macros. Also get rid of myDSB / myISB usage from ARMv7+ code paths; use DSB/ISB/etc. directly to ensure correct behaviour
  - s/HAL - Mnemonic + ISB/DSB updates. Change software RAM clear to do 16 bytes at a time for kernel workspace instead of 32 to allow the kernel workspace tweaks to work.
Admin:
  Binary diff shows that mnemonics map to the original MCR ops correctly
  Note: Raspberry Pi builds will now emit lots of warnings due to increased DSB/ISB instruction use. However it should be safe to ignore these as they should only be present in v7+ code paths.
  Note: New ARMops haven't been tested yet, will be disabled (or at least hidden from user code) in a future checkin


Version 5.68. Tagged as 'Kernel-5_68'
@
text
@; Copyright 2000 Pace Micro Technology plc
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;
; > Copro15ops

;macros for Coprocessor #15 operations (configuration), which run-time detect
;and cater for ARM 6,7,8,A (A=StrongARM).
;Routines detect which ARM directly by reading ARM ID register (avoids memory reads).

; 24-01-96 MJS Created
; 07-10-96 MJS Updated for proper ARM 810 support (not needed for RO 3.70)
; 10-03-97 MJS A few additions for chocolate flavour screen handling (possible
;              Domain and FSR register use) in Phoebe OS
; 05-02-09 JL  Disable ARM_flush_* when compiling OS for HAL. OS now supports
;              too many ARM versions for cache/TLB flushing to be implemented in
;              simple macros. 

        GET     Hdr:CPU.Arch

ARM_config_cp        CP 15  ;coprocessor number for configuration control

ARM_ID_reg           CN  0  ;processor ID
ARM_control_reg      CN  1  ;control
ARM_tbase_reg        CN  2  ;translation base (MMU)
ARM_domain_reg       CN  3  ;domain access control (MMU)
ARM_FSR_reg          CN  5  ;Fault status reg (MMU, read only on ARM 6/7)
ARM_FAR_reg          CN  6  ;Fault address reg (MMU, read only on ARM 6/7)

ARM67_TLBflush_reg   CN  5  ;TLB flush, ARMs 6 or 7
ARM67_TLBpurge_reg   CN  6  ;TLB purge entry, ARMs 6 or 7
ARM67_cacheflush_reg CN  7  ;cache flush, ARMs 6 or 7
ARMv3_TLBflush_reg   CN  5  ;TLB flush, ARMs 6 or 7
ARMv3_TLBpurge_reg   CN  6  ;TLB purge entry, ARMs 6 or 7
ARMv3_cacheflush_reg CN  7  ;cache flush, ARMs 6 or 7

ARM8A_cache_reg      CN  7  ;cache operations, ARMs 8 or StrongARM
ARM8A_TLB_reg        CN  8  ;TLB operations, ARMs 8 or StrongARM
ARMv4_cache_reg      CN  7  ;cache operations, ARMs 8 or StrongARM
ARMv4_TLB_reg        CN  8  ;TLB operations, ARMs 8 or StrongARM

ARM8_cacheLD_reg     CN  9  ;cache lock-down, ARM 8
ARM8_TLBLD_reg       CN 10  ;TLB lock-down, ARM 8

ARM8_CTC_reg         CN 15  ;Clock and test configuration

ARMA_TCI_reg         CN 15  ;Test,Clock and Idle control

;so that bleedin' AASM will accept the general value for MCR CRm field
C0  CN  0
C1  CN  1
C2  CN  2
C3  CN  3
C4  CN  4
C5  CN  5
C6  CN  6
C7  CN  7
C8  CN  8
C9  CN  9
C10 CN 10
C11 CN 11
C12 CN 12
C13 CN 13
C14 CN 14
C15 CN 15


;
; ----------------- all ARMs ---------------------------------------------
;

;set MMU translation base
        MACRO
        ARM_MMU_transbase $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_tbase_reg,C0,0
        MEND

;set MMU domain access register
        MACRO
        ARM_MMU_domain $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_domain_reg,C0,0
        MEND

;read control register
        MACRO
        ARM_read_control $reg,$cond
        MRC$cond ARM_config_cp,0,$reg,ARM_control_reg,C0,0
        MEND

;set control register
        MACRO
        ARM_write_control $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_control_reg,C0,0
        MEND

;read MMU/external fault status
        MACRO
        ARM_read_FSR $reg,$cond
        MRC$cond ARM_config_cp,0,$reg,ARM_FSR_reg,C0,0
        MEND

;set MMU/external fault status
        MACRO
        ARM_write_FSR $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_FSR_reg,C0,0
        MEND

;read MMU/external fault address
        MACRO
        ARM_read_FAR $reg,$cond
        MRC$cond ARM_config_cp,0,$reg,ARM_FAR_reg,C0,0
        MEND

; set MMU/external fault address
        MACRO
        ARM_write_FAR $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_FAR_reg,C0,0
        MEND

;read ID register to register $id
;bits 15:12 of returned ID will be 0,7,8,10 for ARM 6,7,8,A
        MACRO
        ARM_read_ID $id,$cond
        MRC$cond ARM_config_cp,0,$id,ARM_ID_reg,C0,0
        MEND

;read cache type register to register $type
        MACRO
        ARM_read_cachetype $type,$cond
        MRC$cond ARM_config_cp,0,$type,ARM_ID_reg,C0,1
        MEND

;read ARM 'number' (6,7,8,&A currently) into $num
        MACRO
        ARM_number $num
        ARM_read_ID $num
        ANDS     $num,$num,#&F000
        MOVEQ    $num,#&6000       ;catch and correct daft ARM 6 ID layout
        MOV      $num,$num,LSR #12
        MEND

; check if we're on an ARM 6 - EQ if so
        MACRO
        ARM_6       $tmp, $cond
        ARM_read_ID $tmp, $cond
        TST$cond    $tmp, #&F000
        MEND

;check whether running on emulator - this is subject to change. ARMs before
;ARM 920 ignore op2, and will definitely return something other than "1".
;ARM 920 onwards use op2 0 and 1 - behaviour with other op2 values is as yet
;unknown...
        MACRO
        ARM_on_emulator $tmp,$cond
        MRC$cond ARM_config_cp,0,$tmp,ARM_ID_reg,C0,7
        TEQ$cond $tmp,#1
        MEND

;
; -------------- ARM 6,7 only --------------------------------------------
;

;flush cache
        MACRO
        ARM67_flush_cache $cond
        MCR$cond ARM_config_cp,0,R0,ARM67_cacheflush_reg,C0,0
        MEND

;flush TLB
        MACRO
        ARM67_flush_TLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM67_TLBflush_reg,C0,0
        MEND

;flush TLB entry, virtual address in $reg
        MACRO
        ARM67_flush_TLBentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM67_TLBpurge_reg,C0,0
        MEND

;
; -------------- ARM 810 only ----------------------------------------------
;

 [ {FALSE}

;turn off branch prediction
; - the forced mispredicted branch ensures that the predictor is trapped in
;   this code segment when turned off
; - corrupts $temp and status flags
;
        MACRO
        ARM8_branchpredict_off $temp
01
        ARM_read_control $temp
        BIC $temp,$temp,#&800        ;z bit (branch prediction)
        ARM_write_control $temp
        SEC                          ;set carry flag
        BCC %BT01
        MEND

;turn on branch prediction
        MACRO
        ARM8_branchpredict_on $temp
        ARM_read_control $temp
        ORR $temp,$temp,#&800        ;z bit (branch prediction)
        ARM_write_control $temp
        MEND

;flush branch prediction, which is sufficient for an IMB (instruction memory
;barrier) on ARM 810, BUT...
; - intended for in line use only, where efficiency matters, or SWI call is
;   awkward
; - general code should use SWI OS_SynchroniseCodeAreas to implement
;   an IMB (instruction memory barrier) in future proof, ARM independent way
; - kernel code may use this without regard to which ARM running - ie. assumed
;   harmless on other ARMs
;
        MACRO
        ARM8_branchpredict_flush
        SUB PC,PC,#4        ;flush, because PC is written by data op
        MEND

;clean cache entry
; - segment,index spec in $reg
; - bits 4..6   = segment (0..7)
; - bits 26..31 = index   (0..63)
; - all other bits zero
        MACRO
        ARM8_clean_IDCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C11,1
        MEND

;flush cache entry -  segment,index spec in $reg, as for ARM8_clean_IDCentry
        MACRO
        ARM8_flush_IDCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C7,1
        MEND

;clean and flush cache entry -  segment,index spec in $reg, as for ARM8_clean_IDCentry
;
;if ARM810cleanflushbroken is TRUE, interrupts *must* be currently diabled (see below)
;
        MACRO
        ARM8_cleanflush_IDCentry $reg,$cond
  [ ARM810cleanflushbroken
        ARM8_clean_IDCentry $reg,$cond
        ARM8_flush_IDCentry $reg,$cond
  |
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C15,1
  ]
        MEND

;fully clean and flush cache (assumes no locked-down entries to preserve)
;
;if ARM810cleanflushbroken is TRUE, then we have to make sure interrupts are disabled during
;the sequence of 2 MCRs that make up ARM8_cleanflush_IDCentry, to avoid an interrupt hole.
;The hole occurs if an interrupt fills and dirties the particular cache entry after the clean
;but before the flush. We don't have this problem with StrongARM, because the entry is
;specified by virtual address, and RISC OS only cleans/flushes address space not currently
;involved in interrupts.
;
  [ ARM810cleanflushbroken

        MACRO
        ARM8_cleanflush_IDC $temp,$temp2
        ;for simplicity, disable interrupts during entire operation
        mrs ,$temp2,CPSR
        ORR  $temp,$temp2,#I32_bit
        msr ,CPSR_c,$temp                        ;disable I
        MOV  $temp,#0                            ;initial segment and index
01
        ARM8_cleanflush_IDCentry $temp
        ADD $temp,$temp,#1 :SHL: 26              ;next index
        CMP $temp,#1 :SHL: 26                    ;last index done if index field wrapped to 0
        BHS %BT01
        ADD $temp,$temp,#1 :SHL: 4               ;next segment
        CMP $temp,#8 :SHL: 4                     ;8 segments done?
        BLO %BT01
        msr ,CPSR_c,$temp2                       ;restore I
        MEND

  |

        MACRO
        ARM8_cleanflush_IDC $temp
        MOV $temp,#0                             ;initial segment and index
01
        ARM8_cleanflush_IDCentry $temp
        ADD $temp,$temp,#1 :SHL: 26              ;next index
        CMP $temp,#1 :SHL: 26                    ;last index done if index field wrapped to 0
        BHS %BT01
        ADD $temp,$temp,#1 :SHL: 4               ;next segment
        CMP $temp,#8 :SHL: 4                     ;8 segments done?
        BLO %BT01
        MEND

  ]

;flush whole TLB (actually, same as ARMA_flush_TLBs)
        MACRO
        ARM8_flush_TLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;flush TLB entry, virtual address in $reg
        MACRO
        ARM8_flush_TLBentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_TLB_reg,C7,1
        MEND

;select external Refclk pin as fast clock (dynamic switching, asynchronous)
        MACRO
        ARM8_refclk_fclk $temp
        MRC ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp, $temp,#&1                        ;turn off dynamic bus switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp,$temp,#&2                         ;select asynchronous mode (default) (bit1)
        ORR $temp,$temp,#&4                         ;select REFCLK as the FCLK source (bits3:2)
        BIC $temp,$temp,#&10                        ;ensure L=0 when writing (PLL locked) (bit4)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        NOP
        NOP
        NOP
        NOP
        ORR $temp,$temp,#&1                         ;select dynamic clock switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        MEND

;select PLL output as fast clock (dynamic switching, asynchronous)
        MACRO
        ARM8_pll_fclk $temp
        MRC ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp,$temp,#&1                         ;turn off dynamic bus switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp,$temp,#&2                         ;select asynchronous mode (default) (bit1)
        ORR $temp,$temp,#&C                         ;select PLLClkOut as the FCLK source (bits3:2)
        BIC $temp,$temp,#&10                        ;ensure L=0 when writing (PLL locked) (bit4)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        NOP
        NOP
        NOP
        NOP
        ORR $temp,$temp,#&1                         ;select dynamic clock switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        MEND

 ] ;ARM810support

;
; -------------- StrongARM only ------------------------------------------
;

;clean whole data cache, using 16k private cleaner area at address in
;$cleanaddr
;trashes $cleanaddr,$temp1,$temp2
;
;method:
;clean whole (16k) data cache by reading 16k private cleaner area in 8-word
;(one cache line) steps
;
;note: this routine should NOT be used as is without care - remember
;      1) interrupts should be off (to guarantee this clean is effective)
;      2) DC should be flushed afterwards (to guarantee next clean using
;         private area is effective, ie. all private area flushed out now)
;      see ARMA_fullycleanflush_DC for 'packaged routine'
;
        MACRO
        ARMA_clean_DC $cleanaddr,$temp1,$temp2
        ADD     $temp1,$cleanaddr,#16*1024
10
        LDR     $temp2,[$cleanaddr],#32
        TEQ     $temp1,$cleanaddr
        BNE     %BT10
        MEND

;flush whole data cache
        MACRO
        ARMA_flush_DC $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C6,0
        MEND

;clean data cache entry, virtual addr in $reg
        MACRO
        ARMA_clean_DCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C10,1
        MEND

;flush data cache entry, virtual addr in $reg
        MACRO
        ARMA_flush_DCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C6,1
        MEND

;clean and flush data cache entry, virtual addr in $reg
        MACRO
        ARMA_cleanflush_DCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C14,1
        MEND

;clean data cache for virtual address range from $lo (inclusive) to $hi (exclusive)
;corrupts $lo,$hi
        MACRO
        ARMA_clean_DCrange $lo,$hi
        BIC     $lo,$lo,#31    ;align down to 8-word (1 cache line) boundary
        ADD     $hi,$hi,#31
        BIC     $hi,$hi,#31    ;align up to 8-word boundary
01
        ARMA_clean_DCentry $lo ;clean entry for virtual address $lo
        ADD     $lo,$lo,#32    ;next line
        ARMA_clean_DCentry $lo
        ADD     $lo,$lo,#32
        ARMA_clean_DCentry $lo
        ADD     $lo,$lo,#32
        ARMA_clean_DCentry $lo
        ADD     $lo,$lo,#32
        CMP     $lo,$hi
        BLO     %BT01
        MEND

;drain write buffer
        MACRO
        ARMA_drain_WB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C10,4
        MEND

        MACRO
        ARM_drain_WB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C10,4
        MEND

;flush whole instruction cache
        MACRO
        ARMA_flush_IC $WithoutNOPs,$cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C5,0
      [ "$WithoutNOPs" = ""
        MOV     R0,R0 ; 4 NOPS - up to 4 further instructions may come from IC before flush
        MOV     R0,R0
        MOV     R0,R0
        MOV     R0,R0
      ]
        MEND

;flush whole instruction cache and whole data cache
        MACRO
        ARMA_flush_ICandDC $WithoutNOPs,$cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C7,0
      [ "$WithoutNOPs" = ""
        MOV     R0,R0 ; 4 NOPS - up to 4 further instructions may come from IC before flush
        MOV     R0,R0
        MOV     R0,R0
        MOV     R0,R0
      ]
        MEND

;flush whole instruction TLB
        MACRO
        ARMA_flush_ITLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C5,0
        MEND

;flush whole data TLB
        MACRO
        ARMA_flush_DTLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C6,0
        MEND

;flush whole instruction and data TLBs
        MACRO
        ARMA_flush_TLBs $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;flush data TLB entry, virtual address in $reg
        MACRO
        ARMA_flush_DTLBentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_TLB_reg,C6,1
        MEND

;fully clean and flush DC - see ARMA_clean_DC for more info
        MACRO
        ARMA_fullycleanflush_DC $cleanaddr,$temp1,$temp2,$temp3
        mrs    ,$temp3,CPSR
        ORR     $temp1,$temp3,#I32_bit
        msr    ,CPSR_c,$temp1         ;disable IRQs
        ARMA_clean_DC $cleanaddr,$temp1,$temp2
        ARMA_flush_DC
        msr    ,CPSR_c,$temp3         ;restore IRQ state
        MEND

;enable core clock switching (fast core clock allowed)
        MACRO
        ARMA_fastcoreclock $cond
        MCR$cond ARM_config_cp,0,R0,ARMA_TCI_reg,C1,2
        MEND

;disable core clock switching (core clock is memory clock)
        MACRO
        ARMA_slowcoreclock $cond
        MCR$cond ARM_config_cp,0,R0,ARMA_TCI_reg,C2,2
        MEND

;
; -------------- Additional ARMv7 stuff -----------------------------------
;

; Provided here are ISB, DSB and DMB macros suitable for ARMv6+
; Although ARMv4 & v5 do provide CP15 ops that are compatible with the ARMv6 ops, it's implementation defined whether each processor implements the ops or not (and the ops are unpredictable if unimplemented)
; So to play it safe these macros will complain if used on pre-ARMv6
; For all the macros, set the $quick to something if the value of $temp is
; already zero (this will cut out a pointless MOV)

; Instruction Synchronisation Barrier - required on ARMv6+ to ensure the effects of the following are visible to following instructions:
; * Completed cache, TLB & branch predictor maintenance operations
; * CP14/CP15 writes
        MACRO
        myISB $cond,$temp,$option,$quick
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; ARMv6, use legacy MCR op
       [ "$quick"=""
        MOV$cond $temp,#0
       ]
        MCR$cond p15,0,$temp,c7,c5,4
      |
        ; ARMv7+, use ISB instruction (saves on temp register, but instruction is unconditional)
        ; Shouldn't hurt too much if we just ignore the condition code
        DCI &F57FF06F ; ISB SY
      ]
     ]
        MEND

; Data Synchronisation Barrier - aka drain write buffer/data write barrier. Stalls pipeline until all preceeding memory accesses (including cache/TLB/BTC ops) complete.
        MACRO
        myDSB $cond,$temp,$option,$quick
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; pre-ARMv7, use legacy MCR op
       [ "$quick"=""
        MOV$cond $temp,#0
       ]
        MCR$cond p15,0,$temp,c7,c10,4
      |
        ; ARMv7+, use DSB instruction
       [ "$option"="SY" :LOR: "$option"=""
        DCI &F57FF04F ; DSB SY
       |
       [ "$option"="ST" :LOR: "$option"="SYST"
        DCI &F57FF04E ; DSB ST
       |
       [ "$option"="ISH"
        DCI &F57FF04B ; DSB ISH
       |
       [ "$option"="ISHST"
        DCI &F57FF04A ; DSB ISHST
       |
       [ "$option"="NSH"
        DCI &F57FF047 ; DSB NSH
       |
       [ "$option"="NSHST"
        DCI &F57FF046 ; DSB NSHST
       |
       [ "$option"="OSH"
        DCI &F57FF043 ; DSB OSH
       |
       [ "$option"="OSHST"
        DCI &F57FF042 ; DSB OSHST
       |
        ! 1, "Unrecognised DSB option"
       ]
       ]
       ]
       ]
       ]
       ]
       ]
       ]
      ]
     ]
        MEND

; Data Memory Barrier - More lightweight DSB, ensures memory accesses behave correctly without stalling the pipeline to wait for preceeding accesses to complete. I.e. it's only good for synchronising load/store instructions.
        MACRO
        myDMB $cond,$temp,$option,$quick
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; ARMv6, use legacy MCR op
       [ "$quick"=""
        MOV$cond $temp,#0
       ]
        MCR$cond p15,0,$temp,c7,c10,5
      |
        ; ARMv7+, use DMB instruction
       [ "$option"="SY" :LOR: "$option"=""
        DCI &F57FF05F ; DMB SY
       |
       [ "$option"="ST" :LOR: "$option"="SYST"
        DCI &F57FF05E ; DMB ST
       |
       [ "$option"="ISH"
        DCI &F57FF05B ; DMB ISH
       |
       [ "$option"="ISHST"
        DCI &F57FF05A ; DMB ISHST
       |
       [ "$option"="NSH"
        DCI &F57FF057 ; DMB NSH
       |
       [ "$option"="NSHST"
        DCI &F57FF056 ; DMB NSHST
       |
       [ "$option"="OSH"
        DCI &F57FF053 ; DMB OSH
       |
       [ "$option"="OSHST"
        DCI &F57FF052 ; DMB OSHST
       |
        ! 1, "Unrecognised DMB option"
       ]
       ]
       ]
       ]
       ]
       ]
       ]
       ]
      ]
     ]
        MEND

  [ SupportARMv7

; ARMv7/v8 cache, TLB and branch predictor maintenance operations
; These are named directly after the acronyms that appear in recent ARM ARM
; revisions (and for AArch64, the assembler will even recognise them as
; mnemonics)

; Branch predictor invalidate all (local core only)
        MACRO
        BPIALL$cond
        MCR$cond p15,0,a1,c7,c5,6
        MEND

; Branch predictor invalidate all (inner shareable - MP extensions)
        MACRO
        BPIALLIS$cond
        MCR$cond p15,0,a1,c7,c1,6
        MEND

; Branch predictor invalidate by MVA
        MACRO
        BPIMVA$cond $reg
        MCR$cond p15,0,$reg,c7,c5,7
        MEND

; Data cache clean & invalidate by MVA to point of coherency
        MACRO
        DCCIMVAC$cond $reg
        MCR$cond p15,0,$reg,c7,c14,1
        MEND

; Data cache clean and invalidate by set/way (local core only)
        MACRO
        DCCISW$cond $reg
        MCR$cond p15,0,$reg,c7,c14,2
        MEND

; Data cache clean by MVA to point of coherency
        MACRO
        DCCMVAC$cond $reg
        MCR$cond p15,0,$reg,c7,c10,1
        MEND

; Data cache clean by MVA to point of unification
        MACRO
        DCCMVAU$cond $reg
        MCR$cond p15,0,$reg,c7,c11,1
        MEND

; Data cache clean by set/way (local core only)
        MACRO
        DCCSW$cond $reg
        MCR$cond p15,0,$reg,c7,c10,2
        MEND

; Data cache invalidate by MVA to point of coherency
        MACRO
        DCIMVAC$cond $reg
        MCR$cond p15,0,$reg,c7,c6,1
        MEND

; Data cache invalidate by set/way (local core only)
        MACRO
        DCISW$cond $reg
        MCR$cond p15,0,$reg,c7,c6,2
        MEND

; Instruction cache + branch predictor invalidate all to point of unification (local core only)
        MACRO
        ICIALLU$cond
        MCR$cond p15,0,a1,c7,c5,0
        MEND

; Instruction cache + branch predictor invalidate all to point of unification (inner shareable - MP extensions)
        MACRO
        ICIALLUIS$cond
        MCR$cond p15,0,a1,c7,c1,0
        MEND

; Instruction cache invalidate by MVA to point of unification
        MACRO
        ICIMVAU$cond $reg
        MCR$cond p15,0,$reg,c7,c5,1
        MEND

; Invalidate entire TLB (local core only)
        MACRO
        TLBIALL$cond
        MCR$cond p15,0,a1,c8,c7,0
        MEND

; Invalidate entire TLB (inner shareable - MP extensions)
        MACRO
        TLBIALLIS$cond
        MCR$cond p15,0,a1,c8,c3,0
        MEND

; Invalidate TLB by ASID (local core only)
        MACRO
        TLBIASID$cond $reg
        MCR$cond p15,0,$reg,c8,c7,2
        MEND

; Invalidate TLB by ASID (inner shareable - MP extensions)
        MACRO
        TLBIASIDIS$cond $reg
        MCR$cond p15,0,$reg,c8,c3,2
        MEND

; Invalidate TLB by MVA, all ASID or global (local core only - MP extensions)
        MACRO
        TLBIMVAA$cond $reg
        MCR$cond p15,0,$reg,c8,c7,3
        MEND

; Invalidate TLB by MVA, all ASID or global (inner shareable - MP extensions)
        MACRO
        TLBIMVAAIS$cond $reg
        MCR$cond p15,0,$reg,c8,c3,3
        MEND

; Invalidate TLB by MVA, indicated ASID or global (local core only)
        MACRO
        TLBIMVA$cond $reg
        MCR$cond p15,0,$reg,c8,c7,1
        MEND

; Invalidate TLB by MVA, indicated ASID or global (inner shareable - MP extensions)
        MACRO
        TLBIMVAIS$cond $reg
        MCR$cond p15,0,$reg,c8,c3,1
        MEND

  ] ; SupportARMv7

    END
@


4.1
log
@Merge HAL branch to trunk
Detail:
  This change merges the past 15+ years of HAL branch development back to the trunk.
  This is effectively the end for non-HAL builds of the kernel, as no attempt has been made to maintain it during this merge, and all non-HAL & non-32bit code will soon be removed anyway.
  Rather than list everything that's been added to the HAL branch, it's easier to describe the change in terms of the things that the HAL branch was lacking:
  * Trunk version of Docs/32bit contained updated comments for the SVC stack structure during ErrorV
  * Trunk version of s/HeapMan contained a tweak to try and reduce the number of small free blocks that are created
  * Trunk version of s/Kernel contained a change to only copy 248 bytes of the error string to the error buffer (down from 252 bytes), to take into account the extra 4 bytes needed by the PSR. However this goes against the decision that's been made in the HAL branch that the error buffer should be enlarged to 260 bytes instead (ref: https://www.riscosopen.org/tracker/tickets/201), so the HAL build will retain its current behaviour.
  * Trunk version of s/MsgCode had RMNot32bit error in the list of error messages to count when countmsgusage {TRUE}
  * Trunk version of s/PMF/i2cutils contained support for OS_Memory 5, "read/write value of NVRamWriteSize". Currently the HAL branch doesn't have a use for this (in particular, the correct NVRamWriteSize should be specified by the HAL, so there should be no need for software to change it at runtime), and so this code will remain switched out in the HAL build.
Admin:
  Tested on Raspberry Pi


Version 5.48. Tagged as 'Kernel-5_48'
@
text
@a168 42
 [ :LNOT: HAL
;flush whole TLB (both data and instruction for StrongARM)
;trashes $temp
        MACRO
        ARM_flush_TLB $temp
        ARM_read_ID $temp
        AND      $temp,$temp,#&F000
        CMP      $temp,#&8000   ;ARM 8?
        CMPNE    $temp,#&A000   ;or StrongARM?
        MCRNE    ARM_config_cp,0,R0,ARM67_TLBflush_reg,C0,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;flush whole cache (both data and instruction for StrongARM),
;without worrying about any cache cleaning
;trashes $temp
        MACRO
        ARM_flush_cache $temp
        ARM_read_ID $temp
        AND      $temp,$temp,#&F000
        CMP      $temp,#&8000   ;ARM 8?
        CMPNE    $temp,#&A000   ;or StrongARM?
        MCRNE    ARM_config_cp,0,R0,ARM67_cacheflush_reg,C0,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_cache_reg,C7,0
        MEND

;flush whole TLB and cache (both data and instruction for StrongARM),
;without worrying about any cache cleaning
;trashes $temp
        MACRO
        ARM_flush_cacheandTLB $temp
        ARM_read_ID $temp
        AND      $temp,$temp,#&F000
        CMP      $temp,#&8000   ;ARM 8?
        CMPNE    $temp,#&A000   ;or StrongARM?
        MCRNE    ARM_config_cp,0,R0,ARM67_cacheflush_reg,C0,0
        MCRNE    ARM_config_cp,0,R0,ARM67_TLBflush_reg,C0,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_cache_reg,C7,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND
 ]

d545 1
a545 1
; Data Synchronisation Barrier - aka drain write buffer/data write barrier. Stalls pipeline until all preceeding memory accesses (including cache/TLB/BTC ops complete.
d647 134
@


1.1
log
@file Copro15ops was initially added on branch HAL.
@
text
@d1 690
@


1.1.2.1
log
@More stuff. Up to the desktop now; cache on, working keyboard. Some source
restructuring to start to make splitting it up into several object files more
feasible.
@
text
@a0 537
; Copyright 2000 Pace Micro Technology plc
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;
; > Copro15ops

;macros for Coprocessor #15 operations (configuration), which run-time detect
;and cater for ARM 6,7,8,A (A=StrongARM).
;Routines detect which ARM directly by reading ARM ID register (avoids memory reads).

; 24-01-96 MJS Created
; 07-10-96 MJS Updated for proper ARM 810 support (not needed for RO 3.70)
; 10-03-97 MJS A few additions for chocolate flavour screen handling (possible
;              Domain and FSR register use) in Phoebe OS

ARM_config_cp        CP 15  ;coprocessor number for configuration control

ARM_ID_reg           CN  0  ;processor ID
ARM_control_reg      CN  1  ;control
ARM_tbase_reg        CN  2  ;translation base (MMU)
ARM_domain_reg       CN  3  ;domain access control (MMU)
ARM_FSR_reg          CN  5  ;Fault status reg (MMU, read only on ARM 6/7)
ARM_FAR_reg          CN  6  ;Fault address reg (MMU, read only on ARM 6/7)

ARM67_TLBflush_reg   CN  5  ;TLB flush, ARMs 6 or 7
ARM67_TLBpurge_reg   CN  6  ;TLB purge entry, ARMs 6 or 7
ARM67_cacheflush_reg CN  7  ;cache flush, ARMs 6 or 7
ARMv3_TLBflush_reg   CN  5  ;TLB flush, ARMs 6 or 7
ARMv3_TLBpurge_reg   CN  6  ;TLB purge entry, ARMs 6 or 7
ARMv3_cacheflush_reg CN  7  ;cache flush, ARMs 6 or 7

ARM8A_cache_reg      CN  7  ;cache operations, ARMs 8 or StrongARM
ARM8A_TLB_reg        CN  8  ;TLB operations, ARMs 8 or StrongARM
ARMv4_cache_reg      CN  7  ;cache operations, ARMs 8 or StrongARM
ARMv4_TLB_reg        CN  8  ;TLB operations, ARMs 8 or StrongARM

ARM8_cacheLD_reg     CN  9  ;cache lock-down, ARM 8
ARM8_TLBLD_reg       CN 10  ;TLB lock-down, ARM 8

ARM8_CTC_reg         CN 15  ;Clock and test configuration

ARMA_TCI_reg         CN 15  ;Test,Clock and Idle control

;so that AASM will accept the general value for MCR CRm field
C0  CN  0
C1  CN  1
C2  CN  2
C3  CN  3
C4  CN  4
C5  CN  5
C6  CN  6
C7  CN  7
C8  CN  8
C9  CN  9
C10 CN 10
C11 CN 11
C12 CN 12
C13 CN 13
C14 CN 14
C15 CN 15


;
; ----------------- all ARMs ---------------------------------------------
;

;set MMU translation base
        MACRO
        ARM_MMU_transbase $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_tbase_reg,C0,0
        MEND

;set MMU domain access register
        MACRO
        ARM_MMU_domain $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_domain_reg,C0,0
        MEND

;read control register
        MACRO
        ARM_read_control $reg,$cond
        MRC$cond ARM_config_cp,0,$reg,ARM_control_reg,C0,0
        MEND

;set control register
        MACRO
        ARM_write_control $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_control_reg,C0,0
        MEND

;read MMU fault status
        MACRO
        ARM_read_FSR $reg,$cond
        MRC$cond ARM_config_cp,0,$reg,ARM_FSR_reg,C0,0
        MEND

;read MMU fault address
        MACRO
        ARM_read_FAR $reg,$cond
        MRC$cond ARM_config_cp,0,$reg,ARM_FAR_reg,C0,0
        MEND

;read ID register to register $id
;bits 15:12 of returned ID will be 0,7,8,10 for ARM 6,7,8,A
        MACRO
        ARM_read_ID $id,$cond
        MRC$cond ARM_config_cp,0,$id,ARM_ID_reg,C0,0
        MEND

;read cache type register to register $type
        MACRO
        ARM_read_cachetype $type,$cond
        MRC$cond ARM_config_cp,0,$type,ARM_ID_reg,C0,1
        MEND

;read ARM 'number' (6,7,8,&A currently) into $num
        MACRO
        ARM_number $num
        ARM_read_ID $num
        ANDS     $num,$num,#&F000
        MOVEQ    $num,#&6000       ;catch and correct daft ARM 6 ID layout
        MOV      $num,$num,LSR #12
        MEND

; check if we're on an ARM 6 - EQ if so
        MACRO
        ARM_6       $tmp, $cond
        ARM_read_ID $tmp, $cond
        TST$cond    $tmp, #&F000
        MEND

;check whether running on emulator - this is subject to change. ARMs before
;ARM 920 ignore op2, and will definitely return something other than "1".
;ARM 920 onwards use op2 0 and 1 - behaviour with other op2 values is as yet
;unknown...
        MACRO
        ARM_on_emulator $tmp,$cond
        MRC$cond ARM_config_cp,0,$tmp,ARM_ID_reg,C0,7
        TEQ$cond $tmp,#1
        MEND

;flush whole TLB (both data and instruction for StrongARM)
;trashes $temp
        MACRO
        ARM_flush_TLB $temp
        ARM_read_ID $temp
        AND      $temp,$temp,#&F000
        CMP      $temp,#&8000   ;ARM 8?
        CMPNE    $temp,#&A000   ;or StrongARM?
        MCRNE    ARM_config_cp,0,R0,ARM67_TLBflush_reg,C0,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;flush whole cache (both data and instruction for StrongARM),
;without worrying about any cache cleaning
;trashes $temp
        MACRO
        ARM_flush_cache $temp
        ARM_read_ID $temp
        AND      $temp,$temp,#&F000
        CMP      $temp,#&8000   ;ARM 8?
        CMPNE    $temp,#&A000   ;or StrongARM?
        MCRNE    ARM_config_cp,0,R0,ARM67_cacheflush_reg,C0,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_cache_reg,C7,0
        MEND

;flush whole TLB and cache (both data and instruction for StrongARM),
;without worrying about any cache cleaning
;trashes $temp
        MACRO
        ARM_flush_cacheandTLB $temp
        ARM_read_ID $temp
        AND      $temp,$temp,#&F000
        CMP      $temp,#&8000   ;ARM 8?
        CMPNE    $temp,#&A000   ;or StrongARM?
        MCRNE    ARM_config_cp,0,R0,ARM67_cacheflush_reg,C0,0
        MCRNE    ARM_config_cp,0,R0,ARM67_TLBflush_reg,C0,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_cache_reg,C7,0
        MCREQ    ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;
; -------------- ARM 6,7 only --------------------------------------------
;

;flush cache
        MACRO
        ARM67_flush_cache $cond
        MCR$cond ARM_config_cp,0,R0,ARM67_cacheflush_reg,C0,0
        MEND

;flush TLB
        MACRO
        ARM67_flush_TLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM67_TLBflush_reg,C0,0
        MEND

;flush TLB entry, virtual address in $reg
        MACRO
        ARM67_flush_TLBentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM67_TLBpurge_reg,C0,0
        MEND

;
; -------------- ARM 810 only ----------------------------------------------
;

 [ ARM810support

;turn off branch prediction
; - the forced mispredicted branch ensures that the predictor is trapped in
;   this code segment when turned off
; - corrupts $temp and status flags
;
        MACRO
        ARM8_branchpredict_off $temp
01
        ARM_read_control $temp
        BIC $temp,$temp,#&800        ;z bit (branch prediction)
        ARM_write_control $temp
        SEC                          ;set carry flag
        BCC %BT01
        MEND

;turn on branch prediction
        MACRO
        ARM8_branchpredict_on $temp
        ARM_read_control $temp
        ORR $temp,$temp,#&800        ;z bit (branch prediction)
        ARM_write_control $temp
        MEND

;flush branch prediction, which is sufficient for an IMB (instruction memory
;barrier) on ARM 810, BUT...
; - intended for in line use only, where efficiency matters, or SWI call is
;   awkward
; - general code should use SWI OS_SynchroniseCodeAreas to implement
;   an IMB (instruction memory barrier) in future proof, ARM independent way
; - kernel code may use this without regard to which ARM running - ie. assumed
;   harmless on other ARMs
;
        MACRO
        ARM8_branchpredict_flush
        SUB PC,PC,#4        ;flush, because PC is written by data op
        MEND

;clean cache entry
; - segment,index spec in $reg
; - bits 4..6   = segment (0..7)
; - bits 26..31 = index   (0..63)
; - all other bits zero
        MACRO
        ARM8_clean_IDCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C11,1
        MEND

;flush cache entry -  segment,index spec in $reg, as for ARM8_clean_IDCentry
        MACRO
        ARM8_flush_IDCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C7,1
        MEND

;clean and flush cache entry -  segment,index spec in $reg, as for ARM8_clean_IDCentry
;
;if ARM810cleanflushbroken is TRUE, interrupts *must* be currently diabled (see below)
;
        MACRO
        ARM8_cleanflush_IDCentry $reg,$cond
  [ ARM810cleanflushbroken
        ARM8_clean_IDCentry $reg,$cond
        ARM8_flush_IDCentry $reg,$cond
  |
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C15,1
  ]
        MEND

;fully clean and flush cache (assumes no locked-down entries to preserve)
;
;if ARM810cleanflushbroken is TRUE, then we have to make sure interrupts are disabled during
;the sequence of 2 MCRs that make up ARM8_cleanflush_IDCentry, to avoid an interrupt hole.
;The hole occurs if an interrupt fills and dirties the particular cache entry after the clean
;but before the flush. We don't have this problem with StrongARM, because the entry is
;specified by virtual address, and RISC OS only cleans/flushes address space not currently
;involved in interrupts.
;
  [ ARM810cleanflushbroken

        MACRO
        ARM8_cleanflush_IDC $temp,$temp2
        ;for simplicity, disable interrupts during entire operation
        mrs ,$temp2,CPSR
        ORR  $temp,$temp2,#I32_bit
        msr ,CPSR_c,$temp                        ;disable I
        MOV  $temp,#0                            ;initial segment and index
01
        ARM8_cleanflush_IDCentry $temp
        ADD $temp,$temp,#1 :SHL: 26              ;next index
        CMP $temp,#1 :SHL: 26                    ;last index done if index field wrapped to 0
        BHS %BT01
        ADD $temp,$temp,#1 :SHL: 4               ;next segment
        CMP $temp,#8 :SHL: 4                     ;8 segments done?
        BLO %BT01
        msr ,CPSR_c,$temp2                       ;restore I
        MEND

  |

        MACRO
        ARM8_cleanflush_IDC $temp
        MOV $temp,#0                             ;initial segment and index
01
        ARM8_cleanflush_IDCentry $temp
        ADD $temp,$temp,#1 :SHL: 26              ;next index
        CMP $temp,#1 :SHL: 26                    ;last index done if index field wrapped to 0
        BHS %BT01
        ADD $temp,$temp,#1 :SHL: 4               ;next segment
        CMP $temp,#8 :SHL: 4                     ;8 segments done?
        BLO %BT01
        MEND

  ]

;flush whole TLB (actually, same as ARMA_flush_TLBs)
        MACRO
        ARM8_flush_TLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;flush TLB entry, virtual address in $reg
        MACRO
        ARM8_flush_TLBentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_TLB_reg,C7,1
        MEND

;select external Refclk pin as fast clock (dynamic switching, asynchronous)
        MACRO
        ARM8_refclk_fclk $temp
        MRC ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp, $temp,#&1                        ;turn off dynamic bus switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp,$temp,#&2                         ;select asynchronous mode (default) (bit1)
        ORR $temp,$temp,#&4                         ;select REFCLK as the FCLK source (bits3:2)
        BIC $temp,$temp,#&10                        ;ensure L=0 when writing (PLL locked) (bit4)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        NOP
        NOP
        NOP
        NOP
        ORR $temp,$temp,#&1                         ;select dynamic clock switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        MEND

;select PLL output as fast clock (dynamic switching, asynchronous)
        MACRO
        ARM8_pll_fclk $temp
        MRC ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp,$temp,#&1                         ;turn off dynamic bus switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        BIC $temp,$temp,#&2                         ;select asynchronous mode (default) (bit1)
        ORR $temp,$temp,#&C                         ;select PLLClkOut as the FCLK source (bits3:2)
        BIC $temp,$temp,#&10                        ;ensure L=0 when writing (PLL locked) (bit4)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        NOP
        NOP
        NOP
        NOP
        ORR $temp,$temp,#&1                         ;select dynamic clock switching (bit0)
        MCR ARM_config_cp,0,$temp,ARM8_CTC_reg,C0,0
        MEND

 ] ;ARM810support

;
; -------------- StrongARM only ------------------------------------------
;

;clean whole data cache, using 16k private cleaner area at address in
;$cleanaddr
;trashes $cleanaddr,$temp1,$temp2
;
;method:
;clean whole (16k) data cache by reading 16k private cleaner area in 8-word
;(one cache line) steps
;
;note: this routine should NOT be used as is without care - remember
;      1) interrupts should be off (to guarantee this clean is effective)
;      2) DC should be flushed afterwards (to guarantee next clean using
;         private area is effective, ie. all private area flushed out now)
;      see ARMA_fullycleanflush_DC for 'packaged routine'
;
        MACRO
        ARMA_clean_DC $cleanaddr,$temp1,$temp2
        ADD     $temp1,$cleanaddr,#16*1024
10
        LDR     $temp2,[$cleanaddr],#32
        TEQ     $temp1,$cleanaddr
        BNE     %BT10
        MEND

;flush whole data cache
        MACRO
        ARMA_flush_DC $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C6,0
        MEND

;clean data cache entry, virtual addr in $reg
        MACRO
        ARMA_clean_DCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C10,1
        MEND

;flush data cache entry, virtual addr in $reg
        MACRO
        ARMA_flush_DCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C6,1
        MEND

;clean and flush data cache entry, virtual addr in $reg
        MACRO
        ARMA_cleanflush_DCentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_cache_reg,C14,1
        MEND

;clean data cache for virtual address range from $lo (inclusive) to $hi (exclusive)
;corrupts $lo,$hi
        MACRO
        ARMA_clean_DCrange $lo,$hi
        BIC     $lo,$lo,#31    ;align down to 8-word (1 cache line) boundary
        ADD     $hi,$hi,#31
        BIC     $hi,$hi,#31    ;align up to 8-word boundary
01
        ARMA_clean_DCentry $lo ;clean entry for virtual address $lo
        ADD     $lo,$lo,#32    ;next line
        ARMA_clean_DCentry $lo
        ADD     $lo,$lo,#32
        ARMA_clean_DCentry $lo
        ADD     $lo,$lo,#32
        ARMA_clean_DCentry $lo
        ADD     $lo,$lo,#32
        CMP     $lo,$hi
        BLO     %BT01
        MEND

;drain write buffer
        MACRO
        ARMA_drain_WB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C10,4
        MEND

        MACRO
        ARM_drain_WB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C10,4
        MEND

;flush whole instruction cache
        MACRO
        ARMA_flush_IC $WithoutNOPs,$cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C5,0
      [ "$WithoutNOPs" = ""
        MOV     R0,R0 ; 4 NOPS - up to 4 further instructions may come from IC before flush
        MOV     R0,R0
        MOV     R0,R0
        MOV     R0,R0
      ]
        MEND

;flush whole instruction cache and whole data cache
        MACRO
        ARMA_flush_ICandDC $WithoutNOPs,$cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_cache_reg,C7,0
      [ "$WithoutNOPs" = ""
        MOV     R0,R0 ; 4 NOPS - up to 4 further instructions may come from IC before flush
        MOV     R0,R0
        MOV     R0,R0
        MOV     R0,R0
      ]
        MEND

;flush whole instruction TLB
        MACRO
        ARMA_flush_ITLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C5,0
        MEND

;flush whole data TLB
        MACRO
        ARMA_flush_DTLB $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C6,0
        MEND

;flush whole instruction and data TLBs
        MACRO
        ARMA_flush_TLBs $cond
        MCR$cond ARM_config_cp,0,R0,ARM8A_TLB_reg,C7,0
        MEND

;flush data TLB entry, virtual address in $reg
        MACRO
        ARMA_flush_DTLBentry $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM8A_TLB_reg,C6,1
        MEND

;fully clean and flush DC - see ARMA_clean_DC for more info
        MACRO
        ARMA_fullycleanflush_DC $cleanaddr,$temp1,$temp2,$temp3
        mrs    ,$temp3,CPSR
        ORR     $temp1,$temp3,#I32_bit
        msr    ,CPSR_c,$temp1         ;disable IRQs
        ARMA_clean_DC $cleanaddr,$temp1,$temp2
        ARMA_flush_DC
        msr    ,CPSR_c,$temp3         ;restore IRQ state
        MEND

;enable core clock switching (fast core clock allowed)
        MACRO
        ARMA_fastcoreclock $cond
        MCR$cond ARM_config_cp,0,R0,ARMA_TCI_reg,C1,2
        MEND

;disable core clock switching (core clock is memory clock)
        MACRO
        ARMA_slowcoreclock $cond
        MCR$cond ARM_config_cp,0,R0,ARMA_TCI_reg,C2,2
        MEND


    END
@


1.1.2.2
log
@Reimplement enhancements to kernel Dynamic Area support from
Ursula. Quite a hairy code merge really, so let's hope it is
worth it to someone. What you get (back after 2 or 3 years):
- much more efficient for largish numbers of DAs (relevance
  to current build = approx 0)
- fancy reason codes to support fast update of
  Switcher bar display (relevance = 0)
- support for clamped maximum area sizes, to avoid address
  space exhaustion with big memory (relevance = 0)
- better implementation of shrinkable DAs, performance
  wise (if lots of DAs, relevance = approx 0)
- support for 'Sparse' DAs. Holey dynamic areas, Batman!
  (relevance, go on someone use the darned things)
Moderately development tested on HAL/32bit ARM9 desktop.
Note the Switcher should be compiled to use the new
reason codes 6&7, for fabled desktop builds.

Also, during this work, so I could see the wood for the
trees, redid some source code clean up, removing pre-Medusa
stuff (like I did about 3 years ago on Ursula, sigh). That's
why loads of source files have changed. The new DA stuff
is confined pretty much to hdr.KernelWS and s.ChangeDyn.

Ta.

Version 5.35, 4.79.2.38. Tagged as 'Kernel-5_35-4_79_2_38'
@
text
@d218 1
a218 1
 [ {FALSE}
@


1.1.2.3
log
@In the No26bitCode case (ie when abort handlers are entered in ABT32 mode),
if lazy task swapping was enabled and a data abort occurred that was not a
page translation fault, then the code in AMB_LazyFixUp to map in the whole
application slot was being circumvented, leading to problems for abort
handlers in application space because r14_abt was corrupted by any abort
due to accessing the abort handler itself. The test of the FSR (to
compensate for the FAR being unusable for external aborts) which prompted
the circumvention has therefore been moved inside AMB_LazyFixup.
Also now preserves the FSR and FAR across AMB_LazyFixUp, so they are now
visible from application abort handlers if desired.

Version 5.35, 4.79.2.50. Tagged as 'Kernel-5_35-4_79_2_50'
@
text
@d101 1
a101 1
;read MMU/external fault status
d107 1
a107 7
;set MMU/external fault status
        MACRO
        ARM_write_FSR $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_FSR_reg,C0,0
        MEND

;read MMU/external fault address
a110 6
        MEND

; set MMU/external fault address
        MACRO
        ARM_write_FAR $reg,$cond
        MCR$cond ARM_config_cp,0,$reg,ARM_FAR_reg,C0,0
@


1.1.2.4
log
@Merge Cortex kernel into HAL branch
Detail:
  This is a full merge of the Cortex kernel back into the HAL branch. Since the Cortex kernel is/was just a superset of the HAL branch, at this point in time both branches are identical.
  Main features the HAL branch gains from this merge:
  - ARMv6/ARMv7 support
  - High processor vectors/zero page relocation support
  - objasm 4 warning fixes
  - Improved HAL related functionality:
    - Support for HAL-driven RTCs instead of kernel-driven IIC based ones
    - Support for arbitrary size machine IDs
    - Support for multiple IIC busses
    - Support for any HAL size, instead of hardcoded 64k size
    - Probably some other stuff I've forgotten
  - Probably a few bug fixes here and there
Admin:
  Tested on BB-xM & Iyonix.
  Was successfully flashed to ROM on an Iyonix to test the Cortex branch implementation of the 2010 RTC bug fix.
  IOMD build untested - but has been known to work in the past.


Version 5.35, 4.79.2.123. Tagged as 'Kernel-5_35-4_79_2_123'
@
text
@a24 5
; 05-02-09 JL  Disable ARM_flush_* when compiling OS for HAL. OS now supports
;              too many ARM versions for cache/TLB flushing to be implemented in
;              simple macros. 

        GET     Hdr:CPU.Arch
d54 1
a54 1
;so that bleedin' AASM will accept the general value for MCR CRm field
a163 1
 [ :LNOT: HAL
a202 1
 ]
a547 134
;
; -------------- Additional ARMv7 stuff -----------------------------------
;

; Provided here are ISB, DSB and DMB macros suitable for ARMv6+
; Although ARMv4 & v5 do provide CP15 ops that are compatible with the ARMv6 ops, it's implementation defined whether each processor implements the ops or not (and the ops are unpredictable if unimplemented)
; So to play it safe these macros will complain if used on pre-ARMv6
; For all the macros, set the $quick to something if the value of $temp is
; already zero (this will cut out a pointless MOV)

; Instruction Synchronisation Barrier - required on ARMv6+ to ensure the effects of the following are visible to following instructions:
; * Completed cache, TLB & branch predictor maintenance operations
; * CP14/CP15 writes
        MACRO
        myISB $cond,$temp,$option,$quick
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; ARMv6, use legacy MCR op
       [ "$quick"=""
        MOV$cond $temp,#0
       ]
        MCR$cond p15,0,$temp,c7,c5,4
      |
        ; ARMv7+, use ISB instruction (saves on temp register, but instruction is unconditional)
        ; Shouldn't hurt too much if we just ignore the condition code
        DCI &F57FF06F ; ISB SY
      ]
     ]
        MEND

; Data Synchronisation Barrier - aka drain write buffer/data write barrier. Stalls pipeline until all preceeding memory accesses (including cache/TLB/BTC ops complete.
        MACRO
        myDSB $cond,$temp,$option,$quick
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; pre-ARMv7, use legacy MCR op
       [ "$quick"=""
        MOV$cond $temp,#0
       ]
        MCR$cond p15,0,$temp,c7,c10,4
      |
        ; ARMv7+, use DSB instruction
       [ "$option"="SY" :LOR: "$option"=""
        DCI &F57FF04F ; DSB SY
       |
       [ "$option"="ST" :LOR: "$option"="SYST"
        DCI &F57FF04E ; DSB ST
       |
       [ "$option"="ISH"
        DCI &F57FF04B ; DSB ISH
       |
       [ "$option"="ISHST"
        DCI &F57FF04A ; DSB ISHST
       |
       [ "$option"="NSH"
        DCI &F57FF047 ; DSB NSH
       |
       [ "$option"="NSHST"
        DCI &F57FF046 ; DSB NSHST
       |
       [ "$option"="OSH"
        DCI &F57FF043 ; DSB OSH
       |
       [ "$option"="OSHST"
        DCI &F57FF042 ; DSB OSHST
       |
        ! 1, "Unrecognised DSB option"
       ]
       ]
       ]
       ]
       ]
       ]
       ]
       ]
      ]
     ]
        MEND

; Data Memory Barrier - More lightweight DSB, ensures memory accesses behave correctly without stalling the pipeline to wait for preceeding accesses to complete. I.e. it's only good for synchronising load/store instructions.
        MACRO
        myDMB $cond,$temp,$option,$quick
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; ARMv6, use legacy MCR op
       [ "$quick"=""
        MOV$cond $temp,#0
       ]
        MCR$cond p15,0,$temp,c7,c10,5
      |
        ; ARMv7+, use DMB instruction
       [ "$option"="SY" :LOR: "$option"=""
        DCI &F57FF05F ; DMB SY
       |
       [ "$option"="ST" :LOR: "$option"="SYST"
        DCI &F57FF05E ; DMB ST
       |
       [ "$option"="ISH"
        DCI &F57FF05B ; DMB ISH
       |
       [ "$option"="ISHST"
        DCI &F57FF05A ; DMB ISHST
       |
       [ "$option"="NSH"
        DCI &F57FF057 ; DMB NSH
       |
       [ "$option"="NSHST"
        DCI &F57FF056 ; DMB NSHST
       |
       [ "$option"="OSH"
        DCI &F57FF053 ; DMB OSH
       |
       [ "$option"="OSHST"
        DCI &F57FF052 ; DMB OSHST
       |
        ! 1, "Unrecognised DMB option"
       ]
       ]
       ]
       ]
       ]
       ]
       ]
       ]
      ]
     ]
        MEND

@


1.1.2.3.2.1
log
@  Add support for Cortex cache type. Extend ARM_Analyse to, where appropriate, use CPU feature registers to identify CPU capabilities.
Detail:
  s/ARMops - Support for Cortex multi-level cache (CT_ctype_WB_CR7_Lx). New ARM_Analyse_Fancy to identify CPU capabilities using feature registers.
  s/HAL - Modify pre-ARMop cache code to handle Cortex-syle caches.
  s/MemInfo - Replace ARM_flush_TLB macro call with appropriate ARMop to provide Cortex compatability
  hdr/ARMops - Update list of ARM architectures
  hdr/CoPro15ops - Deprecate ARM_flush_* macros for HAL kernels, as they are no longer capable of flushing all cache types. ARMops should be used instead.
  hdr/KernelWS - Add storage space for multi-level cache properties required for new cache cleaning code.
Admin:
  Tested under qemu-omap3. Still unable to verify on real hardware due to lack of appropriate MMU code. However new OMAP3 HAL code that uses similar cache management functions appears to work fine on real hardware.


Version 5.35, 4.79.2.98.2.2. Tagged as 'Kernel-5_35-4_79_2_98_2_2'
@
text
@a24 3
; 05-02-09 JL  Disable ARM_flush_* when compiling OS for HAL. OS now supports
;              too many ARM versions for cache/TLB flushing to be implemented in
;              simple macros. 
d54 1
a54 1
;so that bleedin' AASM will accept the general value for MCR CRm field
a163 1
 [ :LNOT: HAL
a202 1
 ]
@


1.1.2.3.2.2
log
@Update Cortex kernel to use correct instruction/memory barriers and to perform branch target predictor maintenance. Plus tweak default CMOS settings.
Detail:
  hdr/Copro15ops - Added myISB, myDSB, myDMB macros to provide barrier functionality on ARMv6+
  s/ARMops, s/HAL, s/VMSAv6, s/AMBControl/memmap - Correct barrier operations are now performed on ARMv6+ following CP15 writes. Branch predictors are now also maintained properly.
  s/NewReset - Change default CMOS settings so number of CDFS drives is 0 in Cortex builds. Fixes rogue CDFS icon on iconbar.
Admin:
  Tested on rev C2 beagleboard


Version 5.35, 4.79.2.98.2.27. Tagged as 'Kernel-5_35-4_79_2_98_2_27'
@
text
@a552 126
;
; -------------- Additional ARMv7 stuff -----------------------------------
;

; Provided here are ISB, DSB and DMB macros suitable for ARMv6+
; Although ARMv4 & v5 do provide CP15 ops that are compatible with the ARMv6 ops, it's implementation defined whether each processor implements the ops or not (and the ops are unpredictable if unimplemented)
; So to play it safe these macros will complain if used on pre-ARMv6

; Instruction Synchronisation Barrier - required on ARMv6+ to ensure the effects of the following are visible to following instructions:
; * Completed cache, TLB & branch predictor maintenance operations
; * CP14/CP15 writes
        MACRO
        myISB $cond,$temp
      [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
      |
       [ NoARMv7
        ; ARMv6, use legacy MCR op
        MOV$cond $temp,#0
        MCR$cond p15,0,$temp,c7,c5,4
       |
        ; ARMv7+, use ISB instruction (saves on temp register, but instruction is unconditional)
        ; Shouldn't hurt too much if we just ignore the condition code
        DCI &F57FF06F ; ISB SY
       ]
      ]
        MEND

; Data Synchronisation Barrier - aka drain write buffer/data write barrier. Stalls pipeline until all preceeding memory accesses (including cache/TLB/BTC ops complete.
        MACRO
        myDSB $cond,$temp,$option
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; pre-ARMv7, use legacy MCR op
        MOV$cond $temp,#0
        MCR$cond p15,0,$temp,c7,c10,4
      |
        ; ARMv7+, use DSB instruction
       [ "$option"="SY" :LOR: "$option"=""
        DCI &F57FF04F ; DSB SY
       |
       [ "$option"="ST" :LOR: "$option"="SYST"
        DCI &F57FF04E ; DSB ST
       |
       [ "$option"="ISH"
        DCI &F57FF04D ; DSB ISH
       |
       [ "$option"="ISHST"
        DCI &F57FF04C ; DSB ISHST
       |
       [ "$option"="NSH"
        DCI &F57FF047 ; DSB NSH
       |
       [ "$option"="NSHST"
        DCI &F57FF046 ; DSB NSHST
       |
       [ "$option"="OSH"
        DCI &F57FF043 ; DSB OSH
       |
       [ "$option"="OSHST"
        DCI &F57FF042 ; DSB OSHST
       |
        ! 1, "Unrecognised DSB option"
       ]
       ]
       ]
       ]
       ]
       ]
       ]
       ]
      ]
     ]
        MEND

; Data Memory Barrier - More lightweight DSB, ensures memory accesses behave correctly without stalling the pipeline to wait for preceeding accesses to complete. I.e. it's only good for synchronising load/store instructions.
        MACRO
        myDMB $cond,$temp,$option
     [ NoARMv6
        ! 1, "Don't know what to do on pre-ARMv6!"
     |
      [ NoARMv7
        ; ARMv6, use legacy MCR op
        MOV$cond $temp,#0
        MCR$cond p15,0,$temp,c7,c10,5
      |
        ; ARMv7+, use DMB instruction
       [ "$option"="SY" :LOR: "$option"=""
        DCI &F57FF05F ; DMB SY
       |
       [ "$option"="ST" :LOR: "$option"="SYST"
        DCI &F57FF05E ; DMB ST
       |
       [ "$option"="ISH"
        DCI &F57FF05D ; DMB ISH
       |
       [ "$option"="ISHST"
        DCI &F57FF05C ; DMB ISHST
       |
       [ "$option"="NSH"
        DCI &F57FF057 ; DMB NSH
       |
       [ "$option"="NSHST"
        DCI &F57FF056 ; DMB NSHST
       |
       [ "$option"="OSH"
        DCI &F57FF053 ; DMB OSH
       |
       [ "$option"="OSHST"
        DCI &F57FF052 ; DMB OSHST
       |
        ! 1, "Unrecognised DMB option"
       ]
       ]
       ]
       ]
       ]
       ]
       ]
       ]
      ]
     ]
        MEND

@


1.1.2.3.2.3
log
@Add GET Hdr:CPU.Arch to Kernel copy of Copro15ops, so I don't accidentally break the HAL again

Version 5.35, 4.79.2.98.2.29. Tagged as 'Kernel-5_35-4_79_2_98_2_29'
@
text
@a28 2
        GET     Hdr:CPU.Arch

@


1.1.2.3.2.4
log
@Add hdr.Variables to the C header export, fix ARMv6 issues
Detail:
  Makefile - Added hdr.Variables to the C header export list
  hdr/ARMops, s/ARMops - Added ARM1176JZF-S to the list of known CPUs
  s/ARMops - Fix unaligned memory access in ARM_PrintProcessorType
  hdr/Copro15ops, s/ARMops, s/HAL, s/VMSAv6, s/AMBControl/memmap - Fixed all myDSB/myISB/etc. macro instances to specify a temp register, so that they work properly when building an ARMv6 version of the kernel
Admin:
  Fixes build errors with the latest Draw module.
  Should also allow the kernel to work properly with the new S3C6410 port.
  ARMv6 version builds OK, but no other builds or runtime tests have been made.


Version 5.35, 4.79.2.98.2.38. Tagged as 'Kernel-5_35-4_79_2_98_2_38'
@
text
@a561 2
; For all the macros, set the $quick to something if the value of $temp is
; already zero (this will cut out a pointless MOV)
d567 2
a568 2
        myISB $cond,$temp,$option,$quick
     [ NoARMv6
d570 2
a571 2
     |
      [ NoARMv7
a572 1
       [ "$quick"="q"
a573 1
       ]
d575 1
a575 1
      |
d579 1
a580 1
     ]
d585 1
a585 1
        myDSB $cond,$temp,$option,$quick
a590 1
       [ "$quick"=""
a591 1
       ]
d634 1
a634 1
        myDMB $cond,$temp,$option,$quick
a639 1
       [ "$quick"=""
a640 1
       ]
@


1.1.2.3.2.5
log
@Add zero page relocation support
Detail:
  A whole mass of changes to add high processor vectors + zero page relocation support to the Cortex branch of the kernel
  At the moment the code can only cope with two ZeroPage locations, &0 and &FFFF0000. But with a bit more tweaking those restrictions can probably be lifted, allowing ZeroPage to be hidden at almost any address (assuming it's fixed at compile time). If I've done my job right, these restrictions should all be enforced by asserts.
  There's a new option, HiProcVecs, in hdr/Options to control whether high processor vectors are used. When enabling it and building a ROM, remember:
  * FPEmulator needs to be built with the FPEAnchor=High option specified in the components file (not FPEAnchorType=High as my FPEmulator commit comments suggested)
  * ShareFS needs unplugging/removing since it can't cope with it yet
  * Iyonix users will need to use the latest ROOL boot sequence, to ensure the softloaded modules are compatible (OMAP, etc. don't really softload much so they're OK with older sequences)
  * However VProtect also needs patching to fix a nasty bug there - http://www.riscosopen.org/tracker/tickets/294
  The only other notable thing I can think of is that the ProcessTransfer code in s/ARM600 & s/VMSAv6 is disabled if high processor vectors are in use (it's fairly safe to say that code is obsolete in HAL builds anyway?)
  Fun challenge for my successor: Try setting ZeroPage to &FFFF00FF (or similar) so its value can be loaded with MVN instead of LDR. Then use positive/negative address offsets to access the contents.
  File changes:
  - hdr/ARMops - Modified ARMop macro to take the ZeroPage pointer as a parameter instead of 'zero'
  - hdr/Copro15ops - Corrected $quick handling in myISB macro
  - hdr/Options - Added ideal setting for us to use for HiProcVecs
  - s/AMBControl/allocate, s/AMBControl/growp, s/AMBControl/mapslot, s/AMBControl/memmap, s/AMBControl/service, s/AMBControl/shrinkp, s/Arthur2, s/Arthur3, s/ArthurSWIs, s/ChangeDyn, s/ExtraSWIs, s/HAL, s/HeapMan, s/Kernel, s/MemInfo, s/Middle, s/ModHand, s/MoreSWIs, s/MsgCode, s/NewIRQs, s/NewReset, s/Oscli, s/PMF/buffer, s/PMF/IIC, s/PMF/i2cutils, s/PMF/key, s/PMF/mouse, s/PMF/osbyte, s/PMF/oseven, s/PMF/osinit, s/PMF/osword, s/PMF/oswrch, s/SWINaming, s/Super1, s/SysComms, s/TickEvents, s/Utility, s/vdu/vdu23, s/vdu/vdudriver, s/vdu/vdugrafl, s/vdu/vdugrafv, s/vdu/vdupalxx, s/vdu/vdupointer, s/vdu/vduswis, s/vdu/vduwrch - Lots of updates to deal with zero page relocation
  - s/ARM600 - UseProcessTransfer option. Zero page relocation support. Deleted pre-HAL ClearPhysRAM code to tidy the file up a bit.
  - s/ARMops - Zero page relocation support. Set CPUFlag_HiProcVecs when high vectors are in use.
  - s/KbdResPC - Disable compilation of dead code
  - s/VMSAv6 - UseProcessTransfer option. Zero page relocation support.
Admin:
  Tested with OMAP & Iyonix ROM softloads, both with high & low zero page.
  High zero page hasn't had extensive testing, but boot sequence + ROM apps seem to work.


Version 5.35, 4.79.2.98.2.48. Tagged as 'Kernel-5_35-4_79_2_98_2_48'
@
text
@d575 1
a575 1
       [ "$quick"=""
@


1.1.2.3.2.6
log
@ARMv7 fixes
Detail:
  hdr/Copro15ops:
    - Fixed incorrect encodings of ISH/ISHST variants of DMB/DSB instructions
  s/ARMops, s/HAL, hdr/KernelWS:
    - Replace the ARMv7 cache maintenance code with the example code from the ARMv7 ARM. This allows it to deal with caches with non power-of-two set/way counts, and caches with only one way.
    - Fixed Analyse_WB_CR7_Lx to use the cache level ID register to work out how many caches to query instead of just looking for a 0 result from CSSIDR.
    - Also only look for 7 cache levels, since level 8 doesn't exist according to the ARMv7 ARM.
  s/NewReset:
    - Removed some incorrect/misleading debug output
Admin:
  Tested on rev A2 BB-xM


Version 5.35, 4.79.2.98.2.51. Tagged as 'Kernel-5_35-4_79_2_98_2_51'
@
text
@d608 1
a608 1
        DCI &F57FF04B ; DSB ISH
d611 1
a611 1
        DCI &F57FF04A ; DSB ISHST
d659 1
a659 1
        DCI &F57FF05B ; DMB ISH
d662 1
a662 1
        DCI &F57FF05A ; DMB ISHST
@


