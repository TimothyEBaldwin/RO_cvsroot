head	1.2;
access;
symbols
	Kernel-6_15:1.2
	Kernel-6_14:1.2
	Kernel-6_01-3:1.2
	Kernel-6_13:1.2
	Kernel-6_12:1.2
	Kernel-6_11:1.2
	Kernel-6_10:1.2
	Kernel-6_09:1.2
	Kernel-6_08-4_129_2_10:1.2
	Kernel-6_08-4_129_2_9:1.2
	Kernel-6_08:1.2
	Kernel-6_07:1.2
	Kernel-6_06:1.2
	Kernel-6_05-4_129_2_8:1.2
	Kernel-6_05:1.2
	Kernel-6_04:1.2
	Kernel-6_03:1.2
	Kernel-6_01-2:1.2
	Kernel-6_01-4_146_2_1:1.2
	Kernel-6_02:1.2
	Kernel-6_01-1:1.2
	Kernel-6_01:1.2
	Kernel-6_00:1.2
	Kernel-5_99:1.2
	Kernel-5_98:1.2
	Kernel-5_97-4_129_2_7:1.2
	Kernel-5_97:1.2
	Kernel-5_96:1.2
	Kernel-5_95:1.2
	Kernel-5_94:1.2
	Kernel-5_93:1.2
	Kernel-5_92:1.2
	Kernel-5_91:1.2
	Kernel-5_90:1.2
	Kernel-5_89-4_129_2_6:1.2
	Kernel-5_89:1.2
	Kernel-5_88-4_129_2_5:1.2
	Kernel-5_88-4_129_2_4:1.2
	Kernel-5_88:1.2
	Kernel-5_87:1.2
	Kernel-5_86-4_129_2_3:1.2
	Kernel-5_86-4_129_2_2:1.2
	Kernel-5_86-4_129_2_1:1.2
	Kernel-5_86:1.2
	SMP:1.2.0.2
	SMP_bp:1.2
	Kernel-5_85:1.2
	Kernel-5_54-1:1.2
	Kernel-5_84:1.2
	Kernel-5_83:1.2
	Kernel-5_82:1.2
	Kernel-5_81:1.2
	Kernel-5_80:1.2
	Kernel-5_79:1.2
	Kernel-5_78:1.2
	Kernel-5_77:1.2
	Kernel-5_76:1.2
	Kernel-5_75:1.2
	Kernel-5_74:1.2
	Kernel-5_73:1.2
	Kernel-5_72:1.2
	Kernel-5_71:1.2
	Kernel-5_70:1.2
	Kernel-5_69:1.2
	Kernel-5_68:1.2
	Kernel-5_67:1.2
	Kernel-5_66:1.2
	Kernel-5_65:1.2
	Kernel-5_64:1.2
	Kernel-5_63:1.2
	Kernel-5_62:1.2
	Kernel-5_61:1.2
	Kernel-5_60:1.2
	Kernel-5_59:1.2
	Kernel-5_58:1.2
	Kernel-5_57:1.2
	Kernel-5_56:1.2
	Kernel-5_55:1.2
	Kernel-5_54:1.2
	Kernel-5_53:1.2
	Kernel-5_52:1.2
	Kernel-5_51:1.2
	Kernel-5_50:1.2
	Kernel-5_49:1.2
	HAL_merge:1.1.2.4
	Kernel-5_48:1.2
	Kernel-5_35-4_79_2_327:1.1.2.4
	Kernel-5_35-4_79_2_326:1.1.2.4
	Kernel-5_35-4_79_2_325:1.1.2.4
	Kernel-5_35-4_79_2_324:1.1.2.4
	Kernel-5_35-4_79_2_323:1.1.2.4
	Kernel-5_35-4_79_2_322:1.1.2.4
	Kernel-5_35-4_79_2_321:1.1.2.4
	Kernel-5_35-4_79_2_320:1.1.2.4
	Kernel-5_35-4_79_2_319:1.1.2.4
	Kernel-5_35-4_79_2_318:1.1.2.4
	Kernel-5_35-4_79_2_317:1.1.2.4
	Kernel-5_35-4_79_2_316:1.1.2.4
	Kernel-5_35-4_79_2_315:1.1.2.4
	Kernel-5_35-4_79_2_314:1.1.2.4
	Kernel-5_35-4_79_2_313:1.1.2.4
	Kernel-5_35-4_79_2_312:1.1.2.4
	Kernel-5_35-4_79_2_311:1.1.2.4
	Kernel-5_35-4_79_2_310:1.1.2.4
	Kernel-5_35-4_79_2_309:1.1.2.4
	Kernel-5_35-4_79_2_308:1.1.2.4
	Kernel-5_35-4_79_2_307:1.1.2.4
	Kernel-5_35-4_79_2_306:1.1.2.4
	Kernel-5_35-4_79_2_305:1.1.2.4
	Kernel-5_35-4_79_2_304:1.1.2.4
	Kernel-5_35-4_79_2_303:1.1.2.4
	Kernel-5_35-4_79_2_302:1.1.2.4
	Kernel-5_35-4_79_2_301:1.1.2.4
	Kernel-5_35-4_79_2_300:1.1.2.4
	Kernel-5_35-4_79_2_299:1.1.2.4
	Kernel-5_35-4_79_2_298:1.1.2.4
	Kernel-5_35-4_79_2_297:1.1.2.4
	Kernel-5_35-4_79_2_296:1.1.2.4
	Kernel-5_35-4_79_2_295:1.1.2.4
	Kernel-5_35-4_79_2_294:1.1.2.4
	Kernel-5_35-4_79_2_293:1.1.2.4
	Kernel-5_35-4_79_2_292:1.1.2.4
	Kernel-5_35-4_79_2_291:1.1.2.4
	Kernel-5_35-4_79_2_290:1.1.2.4
	Kernel-5_35-4_79_2_289:1.1.2.4
	Kernel-5_35-4_79_2_288:1.1.2.4
	Kernel-5_35-4_79_2_287:1.1.2.4
	Kernel-5_35-4_79_2_286:1.1.2.4
	Kernel-5_35-4_79_2_285:1.1.2.4
	Kernel-5_35-4_79_2_284:1.1.2.4
	Kernel-5_35-4_79_2_283:1.1.2.4
	Kernel-5_35-4_79_2_282:1.1.2.4
	Kernel-5_35-4_79_2_281:1.1.2.4
	Kernel-5_35-4_79_2_280:1.1.2.4
	Kernel-5_35-4_79_2_279:1.1.2.4
	Kernel-5_35-4_79_2_278:1.1.2.4
	Kernel-5_35-4_79_2_277:1.1.2.4
	Kernel-5_35-4_79_2_276:1.1.2.4
	Kernel-5_35-4_79_2_275:1.1.2.4
	Kernel-5_35-4_79_2_274:1.1.2.4
	Kernel-5_35-4_79_2_273:1.1.2.4
	Kernel-5_35-4_79_2_272:1.1.2.4
	Kernel-5_35-4_79_2_271:1.1.2.4
	Kernel-5_35-4_79_2_270:1.1.2.4
	Kernel-5_35-4_79_2_269:1.1.2.4
	Kernel-5_35-4_79_2_268:1.1.2.4
	Kernel-5_35-4_79_2_267:1.1.2.4
	Kernel-5_35-4_79_2_266:1.1.2.4
	Kernel-5_35-4_79_2_265:1.1.2.4
	Kernel-5_35-4_79_2_264:1.1.2.4
	Kernel-5_35-4_79_2_263:1.1.2.4
	Kernel-5_35-4_79_2_262:1.1.2.4
	Kernel-5_35-4_79_2_261:1.1.2.4
	Kernel-5_35-4_79_2_260:1.1.2.4
	Kernel-5_35-4_79_2_259:1.1.2.4
	Kernel-5_35-4_79_2_258:1.1.2.4
	Kernel-5_35-4_79_2_257:1.1.2.4
	Kernel-5_35-4_79_2_256:1.1.2.4
	Kernel-5_35-4_79_2_255:1.1.2.4
	Kernel-5_35-4_79_2_254:1.1.2.4
	Kernel-5_35-4_79_2_253:1.1.2.4
	Kernel-5_35-4_79_2_252:1.1.2.4
	Kernel-5_35-4_79_2_251:1.1.2.4
	Kernel-5_35-4_79_2_250:1.1.2.4
	Kernel-5_35-4_79_2_249:1.1.2.4
	Kernel-5_35-4_79_2_248:1.1.2.4
	Kernel-5_35-4_79_2_247:1.1.2.4
	Kernel-5_35-4_79_2_246:1.1.2.4
	Kernel-5_35-4_79_2_245:1.1.2.4
	Kernel-5_35-4_79_2_244:1.1.2.4
	Kernel-5_35-4_79_2_243:1.1.2.4
	Kernel-5_35-4_79_2_242:1.1.2.4
	Kernel-5_35-4_79_2_241:1.1.2.4
	Kernel-5_35-4_79_2_240:1.1.2.4
	Kernel-5_35-4_79_2_239:1.1.2.4
	Kernel-5_35-4_79_2_238:1.1.2.4
	Kernel-5_35-4_79_2_237:1.1.2.4
	Kernel-5_35-4_79_2_236:1.1.2.4
	Kernel-5_35-4_79_2_235:1.1.2.4
	Kernel-5_35-4_79_2_234:1.1.2.4
	Kernel-5_35-4_79_2_233:1.1.2.4
	Kernel-5_35-4_79_2_232:1.1.2.4
	Kernel-5_35-4_79_2_231:1.1.2.4
	Kernel-5_35-4_79_2_230:1.1.2.4
	Kernel-5_35-4_79_2_229:1.1.2.4
	Kernel-5_35-4_79_2_228:1.1.2.4
	Kernel-5_35-4_79_2_227:1.1.2.4
	Kernel-5_35-4_79_2_226:1.1.2.4
	Kernel-5_35-4_79_2_225:1.1.2.4
	Kernel-5_35-4_79_2_224:1.1.2.4
	Kernel-5_35-4_79_2_223:1.1.2.4
	Kernel-5_35-4_79_2_222:1.1.2.4
	Kernel-5_35-4_79_2_221:1.1.2.4
	Kernel-5_35-4_79_2_220:1.1.2.4
	Kernel-5_35-4_79_2_219:1.1.2.4
	Kernel-5_35-4_79_2_218:1.1.2.4
	Kernel-5_35-4_79_2_217:1.1.2.4
	Kernel-5_35-4_79_2_216:1.1.2.4
	Kernel-5_35-4_79_2_215:1.1.2.4
	Kernel-5_35-4_79_2_214:1.1.2.4
	Kernel-5_35-4_79_2_213:1.1.2.4
	Kernel-5_35-4_79_2_212:1.1.2.4
	Kernel-5_35-4_79_2_211:1.1.2.4
	Kernel-5_35-4_79_2_210:1.1.2.4
	Kernel-5_35-4_79_2_209:1.1.2.4
	Kernel-5_35-4_79_2_208:1.1.2.4
	Kernel-5_35-4_79_2_207:1.1.2.4
	Kernel-5_35-4_79_2_206:1.1.2.4
	Kernel-5_35-4_79_2_205:1.1.2.4
	Kernel-5_35-4_79_2_204:1.1.2.4
	Kernel-5_35-4_79_2_203:1.1.2.4
	Kernel-5_35-4_79_2_202:1.1.2.4
	Kernel-5_35-4_79_2_201:1.1.2.4
	Kernel-5_35-4_79_2_200:1.1.2.4
	Kernel-5_35-4_79_2_199:1.1.2.4
	Kernel-5_35-4_79_2_198:1.1.2.4
	Kernel-5_35-4_79_2_197:1.1.2.4
	Kernel-5_35-4_79_2_196:1.1.2.4
	Kernel-5_35-4_79_2_195:1.1.2.4
	Kernel-5_35-4_79_2_194:1.1.2.4
	Kernel-5_35-4_79_2_193:1.1.2.4
	Kernel-5_35-4_79_2_192:1.1.2.4
	Kernel-5_35-4_79_2_191:1.1.2.4
	Kernel-5_35-4_79_2_190:1.1.2.4
	Kernel-5_35-4_79_2_189:1.1.2.4
	Kernel-5_35-4_79_2_188:1.1.2.4
	Kernel-5_35-4_79_2_187:1.1.2.4
	Kernel-5_35-4_79_2_186:1.1.2.4
	Kernel-5_35-4_79_2_185:1.1.2.4
	Kernel-5_35-4_79_2_184:1.1.2.4
	Kernel-5_35-4_79_2_183:1.1.2.4
	Kernel-5_35-4_79_2_182:1.1.2.4
	Kernel-5_35-4_79_2_181:1.1.2.4
	Kernel-5_35-4_79_2_180:1.1.2.4
	Kernel-5_35-4_79_2_179:1.1.2.4
	Kernel-5_35-4_79_2_178:1.1.2.4
	Kernel-5_35-4_79_2_177:1.1.2.4
	Kernel-5_35-4_79_2_176:1.1.2.4
	Kernel-5_35-4_79_2_175:1.1.2.4
	Kernel-5_35-4_79_2_174:1.1.2.4
	Kernel-5_35-4_79_2_173:1.1.2.4
	Kernel-5_35-4_79_2_172:1.1.2.4
	Kernel-5_35-4_79_2_171:1.1.2.4
	Kernel-5_35-4_79_2_170:1.1.2.4
	Kernel-5_35-4_79_2_169:1.1.2.4
	Kernel-5_35-4_79_2_168:1.1.2.4
	Kernel-5_35-4_79_2_167:1.1.2.4
	Kernel-5_35-4_79_2_166:1.1.2.4
	Kernel-5_35-4_79_2_165:1.1.2.4
	RPi_merge:1.1.2.4
	Kernel-5_35-4_79_2_147_2_23:1.1.2.4
	Kernel-5_35-4_79_2_147_2_22:1.1.2.4
	Kernel-5_35-4_79_2_147_2_21:1.1.2.4
	Kernel-5_35-4_79_2_147_2_20:1.1.2.4
	Kernel-5_35-4_79_2_147_2_19:1.1.2.4
	Kernel-5_35-4_79_2_147_2_18:1.1.2.4
	Kernel-5_35-4_79_2_164:1.1.2.4
	Kernel-5_35-4_79_2_163:1.1.2.4
	Kernel-5_35-4_79_2_147_2_17:1.1.2.4
	Kernel-5_35-4_79_2_147_2_16:1.1.2.4
	Kernel-5_35-4_79_2_147_2_15:1.1.2.4
	Kernel-5_35-4_79_2_162:1.1.2.4
	Kernel-5_35-4_79_2_161:1.1.2.4
	Kernel-5_35-4_79_2_147_2_14:1.1.2.4
	Kernel-5_35-4_79_2_147_2_13:1.1.2.4
	Kernel-5_35-4_79_2_160:1.1.2.4
	Kernel-5_35-4_79_2_159:1.1.2.4
	Kernel-5_35-4_79_2_158:1.1.2.4
	Kernel-5_35-4_79_2_157:1.1.2.4
	Kernel-5_35-4_79_2_156:1.1.2.4
	Kernel-5_35-4_79_2_147_2_12:1.1.2.4
	Kernel-5_35-4_79_2_147_2_11:1.1.2.4
	Kernel-5_35-4_79_2_155:1.1.2.4
	Kernel-5_35-4_79_2_147_2_10:1.1.2.4
	Kernel-5_35-4_79_2_154:1.1.2.4
	Kernel-5_35-4_79_2_153:1.1.2.4
	Kernel-5_35-4_79_2_147_2_9:1.1.2.4
	Kernel-5_35-4_79_2_152:1.1.2.4
	Kernel-5_35-4_79_2_151:1.1.2.4
	Kernel-5_35-4_79_2_147_2_8:1.1.2.4
	Kernel-5_35-4_79_2_147_2_7:1.1.2.4
	Kernel-5_35-4_79_2_150:1.1.2.4
	Kernel-5_35-4_79_2_147_2_6:1.1.2.4
	Kernel-5_35-4_79_2_147_2_5:1.1.2.4
	Kernel-5_35-4_79_2_149:1.1.2.4
	Kernel-5_35-4_79_2_147_2_4:1.1.2.4
	Kernel-5_35-4_79_2_147_2_3:1.1.2.4
	Kernel-5_35-4_79_2_148:1.1.2.4
	Kernel-5_35-4_79_2_147_2_2:1.1.2.4
	Kernel-5_35-4_79_2_147_2_1:1.1.2.4
	RPi:1.1.2.4.0.6
	RPi_bp:1.1.2.4
	Kernel-5_35-4_79_2_98_2_52_2_1:1.1.2.4
	alees_Kernel_dev:1.1.2.4.0.4
	alees_Kernel_dev_bp:1.1.2.4
	Kernel-5_35-4_79_2_147:1.1.2.4
	Kernel-5_35-4_79_2_146:1.1.2.4
	Kernel-5_35-4_79_2_145:1.1.2.4
	Kernel-5_35-4_79_2_144:1.1.2.4
	Kernel-5_35-4_79_2_143:1.1.2.4
	Kernel-5_35-4_79_2_142:1.1.2.4
	Kernel-5_35-4_79_2_141:1.1.2.4
	Kernel-5_35-4_79_2_140:1.1.2.4
	Kernel-5_35-4_79_2_139:1.1.2.4
	Kernel-5_35-4_79_2_138:1.1.2.4
	Kernel-5_35-4_79_2_137:1.1.2.4
	Kernel-5_35-4_79_2_136:1.1.2.4
	Kernel-5_35-4_79_2_135:1.1.2.4
	Kernel-5_35-4_79_2_134:1.1.2.4
	Kernel-5_35-4_79_2_133:1.1.2.4
	Kernel-5_35-4_79_2_132:1.1.2.4
	Kernel-5_35-4_79_2_131:1.1.2.4
	Kernel-5_35-4_79_2_130:1.1.2.4
	Kernel-5_35-4_79_2_129:1.1.2.4
	Kernel-5_35-4_79_2_128:1.1.2.4
	Kernel-5_35-4_79_2_127:1.1.2.4
	Kernel-5_35-4_79_2_126:1.1.2.4
	Kernel-5_35-4_79_2_125:1.1.2.4
	Kernel-5_35-4_79_2_124:1.1.2.4
	Kernel-5_35-4_79_2_123:1.1.2.4
	Cortex_merge:1.1.2.4
	Kernel-5_35-4_79_2_122:1.1.2.4
	Kernel-5_35-4_79_2_98_2_54:1.1.2.4
	Kernel-5_35-4_79_2_98_2_53:1.1.2.4
	Kernel-5_35-4_79_2_98_2_52:1.1.2.4
	Kernel-5_35-4_79_2_98_2_51:1.1.2.4
	Kernel-5_35-4_79_2_98_2_50:1.1.2.4
	Kernel-5_35-4_79_2_98_2_49:1.1.2.4
	Kernel-5_35-4_79_2_98_2_48:1.1.2.4
	Kernel-5_35-4_79_2_121:1.1.2.4
	Kernel-5_35-4_79_2_98_2_47:1.1.2.4
	Kernel-5_35-4_79_2_120:1.1.2.4
	Kernel-5_35-4_79_2_98_2_46:1.1.2.4
	Kernel-5_35-4_79_2_119:1.1.2.4
	Kernel-5_35-4_79_2_98_2_45:1.1.2.4
	Kernel-5_35-4_79_2_98_2_44:1.1.2.4
	Kernel-5_35-4_79_2_118:1.1.2.4
	Kernel-5_35-4_79_2_98_2_43:1.1.2.4
	Kernel-5_35-4_79_2_117:1.1.2.4
	Kernel-5_35-4_79_2_116:1.1.2.4
	Kernel-5_35-4_79_2_98_2_42:1.1.2.4
	Kernel-5_35-4_79_2_115:1.1.2.4
	Kernel-5_35-4_79_2_98_2_41:1.1.2.4
	Kernel-5_35-4_79_2_98_2_40:1.1.2.4
	Kernel-5_35-4_79_2_114:1.1.2.4
	Kernel-5_35-4_79_2_98_2_39:1.1.2.4
	Kernel-5_35-4_79_2_98_2_38:1.1.2.4
	Kernel-5_35-4_79_2_113:1.1.2.4
	Kernel-5_35-4_79_2_112:1.1.2.4
	Kernel-5_35-4_79_2_98_2_37:1.1.2.4
	Kernel-5_35-4_79_2_98_2_36:1.1.2.4
	Kernel-5_35-4_79_2_98_2_35:1.1.2.4
	Kernel-5_35-4_79_2_98_2_34:1.1.2.4
	Kernel-5_35-4_79_2_98_2_33:1.1.2.4
	Kernel-5_35-4_79_2_98_2_32:1.1.2.4
	Kernel-5_35-4_79_2_98_2_31:1.1.2.4
	Kernel-5_35-4_79_2_98_2_30:1.1.2.4
	Kernel-5_35-4_79_2_98_2_29:1.1.2.4
	Kernel-5_35-4_79_2_98_2_28:1.1.2.4
	Kernel-5_35-4_79_2_98_2_27:1.1.2.4
	Kernel-5_35-4_79_2_98_2_26:1.1.2.4
	Kernel-5_35-4_79_2_111:1.1.2.4
	Kernel-5_35-4_79_2_98_2_25:1.1.2.4
	Kernel-5_35-4_79_2_98_2_24:1.1.2.4
	Kernel-5_35-4_79_2_98_2_23:1.1.2.4
	Kernel-5_35-4_79_2_110:1.1.2.4
	Kernel-5_35-4_79_2_98_2_22:1.1.2.4
	Kernel-5_35-4_79_2_109:1.1.2.4
	Kernel-5_35-4_79_2_98_2_21:1.1.2.4
	Kernel-5_35-4_79_2_98_2_20:1.1.2.4
	Kernel-5_35-4_79_2_108:1.1.2.4
	Kernel-5_35-4_79_2_107:1.1.2.4
	Kernel-5_35-4_79_2_98_2_19:1.1.2.4
	Kernel-5_35-4_79_2_98_2_18:1.1.2.4
	Kernel-5_35-4_79_2_98_2_17:1.1.2.4
	Kernel-5_35-4_79_2_98_2_16:1.1.2.4
	Kernel-5_35-4_79_2_98_2_15:1.1.2.4
	Kernel-5_35-4_79_2_106:1.1.2.4
	Kernel-5_35-4_79_2_105:1.1.2.4
	Kernel-5_35-4_79_2_104:1.1.2.4
	Kernel-5_35-4_79_2_98_2_14:1.1.2.4
	Kernel-5_35-4_79_2_98_2_13:1.1.2.4
	Kernel-5_35-4_79_2_98_2_12:1.1.2.4
	Kernel-5_35-4_79_2_98_2_11:1.1.2.4
	Kernel-5_35-4_79_2_98_2_10:1.1.2.4
	Kernel-5_35-4_79_2_98_2_9:1.1.2.4
	Kernel-5_35-4_79_2_103:1.1.2.4
	Kernel-5_35-4_79_2_102:1.1.2.4
	Kernel-5_35-4_79_2_98_2_8:1.1.2.4
	Kernel-5_35-4_79_2_98_2_7:1.1.2.4
	Kernel-5_35-4_79_2_98_2_6:1.1.2.4
	Kernel-5_35-4_79_2_98_2_5:1.1.2.4
	Kernel-5_35-4_79_2_98_2_4:1.1.2.4
	Kernel-5_35-4_79_2_101:1.1.2.4
	Kernel-5_35-4_79_2_100:1.1.2.4
	Kernel-5_35-4_79_2_99:1.1.2.4
	Kernel-5_35-4_79_2_98_2_3:1.1.2.4
	Kernel-5_35-4_79_2_98_2_2:1.1.2.4
	Kernel-5_35-4_79_2_98_2_1:1.1.2.4
	Cortex:1.1.2.4.0.2
	Cortex_bp:1.1.2.4
	Kernel-5_35-4_79_2_98:1.1.2.4
	Kernel-5_35-4_79_2_97:1.1.2.4
	Kernel-5_35-4_79_2_96:1.1.2.4
	Kernel-5_35-4_79_2_95:1.1.2.4
	Kernel-5_35-4_79_2_94:1.1.2.4
	Kernel-5_35-4_79_2_93:1.1.2.4
	Kernel-5_35-4_79_2_92:1.1.2.4
	Kernel-5_35-4_79_2_91:1.1.2.4
	Kernel-5_35-4_79_2_90:1.1.2.4
	Kernel-5_35-4_79_2_89:1.1.2.4
	Kernel-5_35-4_79_2_88:1.1.2.4
	Kernel-5_35-4_79_2_87:1.1.2.4
	Kernel-5_35-4_79_2_86:1.1.2.4
	Kernel-5_35-4_79_2_85:1.1.2.4
	Kernel-5_35-4_79_2_84:1.1.2.4
	Kernel-5_35-4_79_2_83:1.1.2.4
	Kernel-5_35-4_79_2_82:1.1.2.4
	Kernel-5_35-4_79_2_81:1.1.2.4
	Kernel-5_35-4_79_2_80:1.1.2.4
	Kernel-5_35-4_79_2_79:1.1.2.4
	Kernel-5_35-4_79_2_78:1.1.2.4
	Kernel-5_35-4_79_2_77:1.1.2.4
	RO_5_07:1.1.2.4
	Kernel-5_35-4_79_2_76:1.1.2.4
	Kernel-5_35-4_79_2_75:1.1.2.4
	Kernel-5_35-4_79_2_74:1.1.2.4
	Kernel-5_35-4_79_2_73:1.1.2.4
	Kernel-5_35-4_79_2_72:1.1.2.4
	Kernel-5_35-4_79_2_71:1.1.2.4
	Kernel-5_35-4_79_2_70:1.1.2.4
	Kernel-5_35-4_79_2_69:1.1.2.4
	Kernel-5_35-4_79_2_68:1.1.2.4
	Kernel-5_35-4_79_2_67:1.1.2.4
	Kernel-5_35-4_79_2_66:1.1.2.4
	Kernel-5_35-4_79_2_65:1.1.2.4
	Kernel-5_35-4_79_2_64:1.1.2.4
	Kernel-5_35-4_79_2_63:1.1.2.4
	Kernel-5_35-4_79_2_62:1.1.2.4
	Kernel-5_35-4_79_2_61:1.1.2.4
	Kernel-5_35-4_79_2_59:1.1.2.4
	Kernel-5_35-4_79_2_58:1.1.2.4
	Kernel-5_35-4_79_2_57:1.1.2.4
	Kernel-5_35-4_79_2_56:1.1.2.4
	Kernel-5_35-4_79_2_55:1.1.2.4
	Kernel-5_35-4_79_2_54:1.1.2.3
	Kernel-5_35-4_79_2_53:1.1.2.3
	Kernel-5_35-4_79_2_52:1.1.2.3
	Kernel-5_35-4_79_2_51:1.1.2.3
	Kernel-5_35-4_79_2_50:1.1.2.3
	Kernel-5_35-4_79_2_49:1.1.2.3
	Kernel-5_35-4_79_2_48:1.1.2.3
	Kernel-5_35-4_79_2_47:1.1.2.2
	Kernel-5_35-4_79_2_46:1.1.2.2
	Kernel-5_35-4_79_2_45:1.1.2.2
	Kernel-5_35-4_79_2_44:1.1.2.2
	Kernel-5_35-4_79_2_25_2_2:1.1.2.2
	Kernel-5_35-4_79_2_43:1.1.2.2
	Kernel-5_35-4_79_2_42:1.1.2.2
	Kernel-5_35-4_79_2_41:1.1.2.2
	Kernel-5_35-4_79_2_40:1.1.2.2
	Kernel-5_35-4_79_2_39:1.1.2.2
	Kernel-5_35-4_79_2_38:1.1.2.2
	Kernel-5_35-4_79_2_37:1.1.2.2
	Kernel-5_35-4_79_2_36:1.1.2.2
	Kernel-5_35-4_79_2_35:1.1.2.2
	Kernel-5_35-4_79_2_34:1.1.2.2
	Kernel-5_35-4_79_2_33:1.1.2.2
	Kernel-5_35-4_79_2_32:1.1.2.2
	Kernel-5_35-4_79_2_25_2_1:1.1.2.2
	Kernel-5_35-4_79_2_31:1.1.2.2
	Kernel-5_35-4_79_2_30:1.1.2.2
	Kernel-5_35-4_79_2_29:1.1.2.2
	Kernel-5_35-4_79_2_28:1.1.2.2
	Kernel-5_35-4_79_2_27:1.1.2.2
	Kernel-5_35-4_79_2_26:1.1.2.2
	Kernel-5_35-4_79_2_25:1.1.2.2
	Kernel-5_35-4_79_2_24:1.1.2.2
	Kernel-5_35-4_79_2_23:1.1.2.2
	Kernel-5_35-4_79_2_22:1.1.2.2
	Kernel-5_35-4_79_2_21:1.1.2.2
	Kernel-5_35-4_79_2_20:1.1.2.2
	Kernel-5_35-4_79_2_19:1.1.2.2
	Kernel-5_35-4_79_2_18:1.1.2.2
	Kernel-5_35-4_79_2_17:1.1.2.2
	Kernel-5_35-4_79_2_16:1.1.2.2
	Kernel-5_35-4_79_2_15:1.1.2.2
	Kernel-5_35-4_79_2_14:1.1.2.2
	Kernel-5_35-4_79_2_13:1.1.2.2
	Kernel-5_35-4_79_2_12:1.1.2.2
	Kernel-5_35-4_79_2_11:1.1.2.2
	Kernel-5_35-4_79_2_10:1.1.2.2
	Kernel-5_35-4_79_2_9:1.1.2.2
	Kernel-5_35-4_79_2_8:1.1.2.2
	Kernel-5_35-4_79_2_7:1.1.2.2
	Kernel-5_35-4_79_2_6:1.1.2.2
	Kernel-5_35-4_79_2_5:1.1.2.2
	Kernel-5_35-4_79_2_4:1.1.2.2
	Kernel-5_35-4_79_2_3:1.1.2.2
	Kernel-5_35-4_79_2_2:1.1.2.2
	Kernel-5_35-4_79_2_1:1.1.2.1
	HAL:1.1.0.2;
locks; strict;
comment	@# @;


1.2
date	2016.06.30.20.07.36;	author jlee;	state Exp;
branches;
next	1.1;
commitid	IWoXxARWeuLDOwcz;

1.1
date	2000.09.15.12.38.00;	author kbracey;	state dead;
branches
	1.1.2.1;
next	;

1.1.2.1
date	2000.09.15.12.38.00;	author kbracey;	state Exp;
branches;
next	1.1.2.2;

1.1.2.2
date	2000.10.02.08.52.18;	author kbracey;	state Exp;
branches;
next	1.1.2.3;

1.1.2.3
date	2002.10.07.17.29.32;	author kbracey;	state Exp;
branches;
next	1.1.2.4;

1.1.2.4
date	2003.01.27.15.25.30;	author kbracey;	state Exp;
branches;
next	;


desc
@@


1.2
log
@Merge HAL branch to trunk
Detail:
  This change merges the past 15+ years of HAL branch development back to the trunk.
  This is effectively the end for non-HAL builds of the kernel, as no attempt has been made to maintain it during this merge, and all non-HAL & non-32bit code will soon be removed anyway.
  Rather than list everything that's been added to the HAL branch, it's easier to describe the change in terms of the things that the HAL branch was lacking:
  * Trunk version of Docs/32bit contained updated comments for the SVC stack structure during ErrorV
  * Trunk version of s/HeapMan contained a tweak to try and reduce the number of small free blocks that are created
  * Trunk version of s/Kernel contained a change to only copy 248 bytes of the error string to the error buffer (down from 252 bytes), to take into account the extra 4 bytes needed by the PSR. However this goes against the decision that's been made in the HAL branch that the error buffer should be enlarged to 260 bytes instead (ref: https://www.riscosopen.org/tracker/tickets/201), so the HAL build will retain its current behaviour.
  * Trunk version of s/MsgCode had RMNot32bit error in the list of error messages to count when countmsgusage {TRUE}
  * Trunk version of s/PMF/i2cutils contained support for OS_Memory 5, "read/write value of NVRamWriteSize". Currently the HAL branch doesn't have a use for this (in particular, the correct NVRamWriteSize should be specified by the HAL, so there should be no need for software to change it at runtime), and so this code will remain switched out in the HAL build.
Admin:
  Tested on Raspberry Pi


Version 5.48. Tagged as 'Kernel-5_48'
@
text
@RISC OS and the "HAL"
=====================

RISC OS currently is tied to the IOMD20 and VIDC20 peripheral set,
descendents of the original IOC, MEMC and VIDC devices designed in parallel
with the original ARM. These devices provide a close fit with RISC OS, and
their functionality is well suited to general purpose and embedded systems,
but the continuing drive to reduce cost requires us to support other
peripheral sets on off-the-shelf ARM system on chips.

First targets for support are L7205/L7210 for Customer L and CL92xx (the new
ARM920T based devices) for Customer A. Enclosed are a summary of their
advantages and disadvantages over the ARM7500FE for our Information
Appliance designs.

              L7205                       CL92xx
            + Faster (50% or so)        + Faster (400%+)
            + SDRAM support             + SDRAM support
            + USB                       + USB
                                        + EIDE interface
                                        + Lots of GPIO
            - No hardware cursor
            - No floating point         - Incompatible floating point
            - No video DACs             - No video DACs
            - No PS/2                   - No PS/2
                                        - Bizarre MS-Windows video system


To support these devices, and others in the future, a simple HAL is to be
inserted underneath RISC OS. This will provide two functions. Firstly, it
will be responsible for initial system bootstrap, much like a PC BIOS, and
secondly it will provide simple APIs to allow hardware access.

The HAL APIs are a thin veneer on top of the hardware. They are designed to
act as replacements for all the hardware knowledge and manipulation performed
by the RISC OS Kernel, together with some APIs that will allow RISC OS driver
modules to become more hardware independent. No attempt will be made (at this
stage) to perform such tasks as separating the video drivers from the Kernel,
for example.

One tricky design decision is the amount of abstraction to aim for. Too
little, and the system is not flexible enough; too much and HAL design is
needlessly complicated for simple hardware. The present design tries to
err on the side of too little abstraction. Extra, more abstract APIs can
always be added later. So, initially, for example, the serial device API
will just provide discovery, some capability flags and the base address
of the UART register set. This will be sufficient for the vast majority
of devices. If new hardware comes along later that isn't UART compatible,
a new API can be defined. Simple hardware can continue to just report
UART base addresses.

The bulk of device driver implementation remains in RISC OS modules - the
difference is that the HAL will allow many device drivers to no longer
directly access hardware. For example, PS2Driver can now use HAL calls to
send and receive bytes through the PS/2 ports, and thus is no longer tied to
IOMD's PS/2 hardware. Similarly, interrupt masking and unmasking, as
performed by any device vector claimant, is now a HAL call. Note that HAL
calls are normally performed via a Kernel SWI - alternatively the Kernel
can return the address of specific Kernel routines. There is nothing to stop
specific drivers talking to hardware directly, as long as they accept that
this will tie them to specific devices.

This dividing line between the HAL and RISC OS driver modules is crucial. If
the HAL does everything, then we have achieved nothing - we have just as much
hardware dependent code - it's just in a different place. It is important to
place the dividing line as close to the hardware as possible, to make it easy
to design a HAL and to prevent large amounts of code  duplication between
HALs for different platforms.

The Kernel remains responsible for the ARM's MMU and all other aspects of the
CPU core. The HAL requires no knowledge of details of ARM implementations,
and thus any HAL implementation should work on any processor from the ARM610
to the ARM940T or XScale.


OS independence
===============

Notionally, the HAL implementation is OS independent. It makes no assumptions
about the virtual memory map of the OS, and only uses the defined HAL->OS
entries. The HAL should not call RISC OS SWIs.

In practice, however, the HALs are unlikely to be used on anything other
than RISC OS, and many HALs are likely to be written. This makes it sensible
to place as much intelligence as possible within RISC OS itself, to prevent
duplicated effort.



Calling standards
=================

RISC OS and the HAL are two separate entities, potentially linked separately.
Thus some simple dynamic linking is required. This occurs via a hybrid of the
RISC OS module header and Shared C Library stubs. Each RISC OS/HAL entry is
given a unique (arbitrary) number, starting at 0. The offset to each entry is
given in an entry table. Calls can be made manually through this table, or
stubs could be created at run-time to allow high-level language calls.

Every entry (up to the declared maximum) must exist. If not implemented, a
failure response must be returned, or the call ignored, as appropriate.

To permit high-level language use in the future, the procedure call standard
in both directions is ATPCS, with no use of floating point, no stack limit
checking, no frame pointers, and no Thumb interworking. HAL code is expected
to be ROPI and RWPI (hence it is called with its static workspace base in
sb). The OS kernel is neither ROPI nor RWPI (except for the pre-MMU calls,
which are ROPI).

The HAL will always be called in a privileged mode - if called in an
interrupt mode, the corresponding interrupts will be disabled. The HAL should
not change mode. HAL code should work in both 26-bit and 32-bit modes (but
should assume 32-bit configuration).


Header formats
==============

The OS is linked to run at a particular base address. At present, the address
will be at <n>MB + 64KB. This allows a HAL of up to 64K to be placed at the
bottom of a ROM below the OS, and the whole thing to be section-mapped.
However, if a different arrangement is used, the system will still work
(albeit slightly less efficiently).

The OS starts with a magic word - this aids probing and location of images.
Following that is a defined header format:

Word 0: Magic word ("OSIm" - &6D49534F)
Word 1: Flags (0)
Word 2: Image size
Word 3: Offset from base to entry table
Word 4: Number of entries available

The HAL itself may have whatever header is required to start the system. For
example on ARM7500 16->32 bit switch code is required, and on the 9500 parts
a special ROM header and checksum must be present. Instead of a header,
a pointer to the HAL descriptor is passed to the OS in the OS_Start call:

Word 0: Flags
            bit 0 => uncachable workspace (32K) required
            bits 1-31 reserved
Word 1: Offset from descriptor to start of HAL (will be <= 0)
Word 2: HAL size
Word 3: Offset from descriptor to entry table
Word 4: Number of entries available
Word 5: Static workspace required

Each of the HAL and the OS must be contiguous within physical memory.






RISC OS entry points from HAL init
==================================


Entry 0:
void RISCOS_InitARM(unsigned int flags)

    flags: reserved - sbz

On entry:
  SVC mode
  MMU and caches off
  IRQs and FIQs disabled
  No RAM or stack used

On exit:
  Instruction cache may be on

Usage:
  This routine must be called once very early on in the HAL start-up, to accelerate the
  CPU for the rest of HAL initialisation. Typically, it will just enable the instruction
  cache (if possible on the ARM in use), and ensure that the processor is in 32-bit
  configuration and mode.

  Some architecture 4 (and later) ARMs have bits in the control register that affect
  the hardware layer - eg the iA and nF bits in the ARM920T. These are the HAL's
  responsibility - the OS will not touch them. Conversely, the HAL should not touch the
  cache, MMU and core configuration bits (currently bits 0-14).

  On architecture 3, the control register is write only - the OS will set bits 11-31 to
  zero.

  Likewise, such things as the StrongARM 110's register 15 (Test, Clock and Idle Control)
  are the HAL's responsibility. The OS does not know about the configuration of the
  system, so cannot program such registers.

  This entry may not be called after RISCOS_Start.



Entry 1:
void *RISCOS_AddRAM(unsigned int flags, void *start, void *end, uintptr_t sigbits, void *ref)
   flags
        bit 0: video memory (only first contiguous range will be used)
        bits 8-11: speed indicator (arbitrary, higher => faster)
        other bits reserved (SBZ)
   start
        start address of RAM (inclusive) (no alignment requirements)
   end
        end address of RAM (exclusive) (no alignment requirements, but must be >= start)
   sigbits
        significant address bit mask (1 => this bit of addr decoded, 0 => this bit ignored)
   ref
        reference handle (NULL for first call)

Returns ref for next call

On entry:
  SVC32 mode
  MMU and data cache off
  IRQs and FIQs disabled

Other notes:
  This entry point must be the first call from the HAL to RISC OS following a hardware
  reset. It may be called as many times as necessary to give all enumerate RAM that
  is available for general purpose use. It should only be called to declare video
  memory if the video memory may be used as normal RAM when in small video modes.

  To permit software resets:
    The HAL must be non-destructive of any declared RAM outside the first 4K of the first
    block.
    The stack pointer should be initialised 4K into the first block, or in some non-
    declared RAM.
    Must present memory in a fixed order on any given system.

  Current limitations:
    The first block must be at least 256K and 16K aligned. (Yuck)
    Block coalescing only works well if RAM banks are added in ascending address order.

  RISC OS will use RAM at the start of the first block as initial workspace. Max usage
  is 16 bytes per block + 32 (currently 8 per block + 4). This limits the number of
  discontiguous blocks (although RISC OS will concatanate contiguous blocks where
  possible).

  This call must not be made after RISCOS_Start.


Entry 2:
void RISCOS_Start(unsigned int flags, int *riscos_header, int *hal_entry_table, void *ref)

   flags
        bit 0: power on reset
        bit 1: CMOS reset inhibited (eg protection link on Risc PC)
        bit 2: perform a CMOS reset (if bit 1 clear and bit 0 set - eg front panel
                                     button held down on an NC)

On entry:
  SVC32 mode
  MMU and data cache off
  IRQs and FIQs disabled

Usage:
  This routine must be called after all calls to RISCOS_AddRAM have been completed.
  It does not return. Future calls back to the HAL are via the HAL entry table, after
  the MMU has been enabled.


Entry 3:
void *RISCOS_MapInIO(unsigned int flags, void *phys, unsigned int size)

   flags: bit 2 => make memory bufferable
    phys: physical address to map in
    size: number of bytes of memory to map in

Usage:
  This routine is used to map in IO memory for the HAL's usage. Normally it would
  only be called during HAL_Init(). Once mapped in the IO space cannot be released.

  It returns the resultant virtual address corresponding to phys, or 0 for failure.
  Failure can only occur if no RAM is available for page tables, or if the virtual
  address space is exhausted.



void *RISCOS_AccessPhysicalAddress(unsigned int flags, void *phys, void **oldp)

   flags: bit 2 => make memory bufferable
          other bits must be zero
    phys: physical address to access
    oldp: pointer to location to store old state (or NULL)

On entry:
  Privileged mode
  MMU on
  FIQs on
  Re-entrant

On exit:
  Returns logical address corresponding to phys

Usage:
  Arranges for the physical address phys to be mapped in to logical memory.
  In fact, the whole megabyte containing "phys" is mapped in (ie if phys =
  &12345678, then &12300000 to &123FFFFF become available). The memory is
  supervisor access only, non-cacheable, non-bufferable by default, and will
  remain available until the next call to RISCOS_Release/AccessPhysicalAddress
  (although interrupt routines or subroutines may temporarily map in something
  else).

  When finished, the user should call RISCOS_ReleasePhysicalAddress.




void RISCOS_ReleasePhysicalAddress(void *old)

  old: state returned from a previous call to RISCOS_AccessPhysicalAddress

On entry:
  MMU on
  FIQs on
  Re-entrant

Usage:
  Call with the a value output from a previous RISCOS_ReleasePhysicalAddress.

Example:

  void *old;
  unsigned int *addr = (unsigned int *) 0x80005000;
  unsigned int *addr2 = (unsigned int *) 0x90005000;

  addr = (unsigned int *) RISCOS_AccessPhysicalAddress(addr, &old);
  addr[0] = 3; addr[1] = 5;

  addr2 = (unsigned int *) RISCOS_AccessPhysicalAddress(addr2, NULL);
  *addr2 = 7;

  RISCOS_ReleasePhysicalAddress(old);





HAL entries
===========


void HAL_Start(int *riscos_header)
@


1.1
log
@file Entries was initially added on branch HAL.
@
text
@d1 343
@


1.1.2.1
log
@* Converted to building with ObjAsm (but still a single object file using ORG).
* Added ARM_IMB and ARM_IMBRange SWIs as recommended by ARMv5.
* Some early prototype HAL bits popped in - a lot of source restructuring still
  to come.
* New debug target creates an AIF image with debug information, and translates
  this into an ASCII object file for the 16702B logic analyser.

Version 5.35, 4.79.2.1. Tagged as 'Kernel-5_35-4_79_2_1'
@
text
@a0 338
RISC OS and the "HAL"
=====================

RISC OS currently is tied to the IOMD20 and VIDC20 peripheral set,
descendents of the original IOC, MEMC and VIDC devices designed in parallel
with the original ARM. These devices provide a close fit with RISC OS, and
their functionality is well suited to general purpose and embedded systems,
but the continuing drive to reduce cost requires us to support other
peripheral sets on off-the-shelf ARM system on chips.

First targets for support are L7205/L7210 for Customer L and CL92xx (the new
ARM920T based devices) for Customer A. Enclosed are a summary of their
advantages and disadvantages over the ARM7500FE for our Information
Appliance designs.

              L7205                       CL92xx
            + Faster (50% or so)        + Faster (400%+)
            + SDRAM support             + SDRAM support
            + USB                       + USB
                                        + EIDE interface
                                        + Lots of GPIO
            - No hardware cursor
            - No floating point         - Incompatible floating point
            - No video DACs             - No video DACs
            - No PS/2                   - No PS/2
                                        - Bizarre MS-Windows video system


To support these devices, and others in the future, a simple HAL is to be
inserted underneath RISC OS. This will provide two functions. Firstly, it
will be responsible for initial system bootstrap, much like a PC BIOS, and
secondly it will provide simple APIs to allow hardware access.

The HAL APIs are a thin veneer on top of the hardware. They are designed to
act as replacements for all the hardware knowledge and manipulation performed
by the RISC OS Kernel, together with some APIs that will allow RISC OS driver
modules to become more hardware independent. No attempt will be made (at this
stage) to perform such tasks as separating the video drivers from the Kernel,
for example.

One tricky design decision is the amount of abstraction to aim for. Too
little, and the system is not flexible enough; too much and HAL design is
needlessly complicated for simple hardware. The present design tries to
err on the side of too little abstraction. Extra, more abstract APIs can
always be added later. So, initially, for example, the serial device API
will just provide discovery, some capability flags and the base address
of the UART register set. This will be sufficient for the vast majority
of devices. If new hardware comes along later that isn't UART compatible,
a new API can be defined. Simple hardware can continue to just report
UART base addresses.

The bulk of device driver implementation remains in RISC OS modules - the
difference is that the HAL will allow many device drivers to no longer
directly access hardware. For example, PS2Driver can now use HAL calls to
send and receive bytes through the PS/2 ports, and thus is no longer tied to
IOMD's PS/2 hardware. Similarly, interrupt masking and unmasking, as
performed by any device vector claimant, is now a HAL call. Note that HAL
calls are normally performed via a Kernel SWI - alternatively the Kernel
can return the address of specific Kernel routines. There is nothing to stop
specific drivers talking to hardware directly, as long as they accept that
this will tie them to specific devices.

This dividing line between the HAL and RISC OS driver modules is crucial. If
the HAL does everything, then we have achieved nothing - we have just as much
hardware dependent code - it's just in a different place. It is important to
place the dividing line as close to the hardware as possible, to make it easy
to design a HAL and to prevent large amounts of code  duplication between
HALs for different platforms.

The Kernel remains responsible for the ARM's MMU and all other aspects of the
CPU core. The HAL requires no knowledge of details of ARM implementations,
and thus any HAL implementation should work on any processor from the ARM610
to the ARM940T or XScale.


OS independence
===============

Notionally, the HAL implementation is OS independent. It makes no assumptions
about the virtual memory map of the OS, and only uses the defined HAL->OS
entries. The HAL should not call RISC OS SWIs.

In practice, however, the HALs are unlikely to be used on anything other
than RISC OS, and many HALs are likely to be written. This makes it sensible
to place as much intelligence as possible within RISC OS itself, to prevent
duplicated effort.



Calling standards
=================

RISC OS and the HAL are two separate entities, potentially linked separately.
Thus some simple dynamic linking is required. This occurs via a hybrid of the
RISC OS module header and Shared C Library stubs. Each RISC OS/HAL entry is
given a unique (arbitrary) number, starting at 0. The offset to each entry is
given in an entry table. Calls can be made manually through this table, or
stubs could be created at run-time to allow high-level language calls.

Every entry (up to the declared maximum) must exist. If not implemented, a
failure response must be returned, or the call ignored, as appropriate.

To permit high-level language use in the future, the procedure call standard
in both directions is ATPCS, with no use of floating point, no stack limit
checking, no frame pointers, and no Thumb interworking. HAL code is expected
to be ROPI and RWPI (hence it is called with its static workspace base in
sb). The OS kernel is neither ROPI nor RWPI (except for the pre-MMU calls,
which are ROPI).

The HAL will always be called in a privileged mode - if called in an
interrupt mode, the corresponding interrupts will be disabled. The HAL should
not change mode. HAL code should work in both 26-bit and 32-bit modes (but
should assume 32-bit configuration).


Header formats
==============

The OS is linked to run at a particular base address. At present, the address
will be at <n>MB + 64KB. This allows a HAL of up to 64K to be placed at the
bottom of a ROM below the OS, and the whole thing to be section-mapped.
However, if a different arrangement is used, the system will still work
(albeit slightly less efficiently).

The OS starts with a magic word - this aids probing and location of images.
Following that is a defined header format:

Word 0: Magic word ("OSIm" - &6D49534F)
Word 1: Flags (0)
Word 2: Image size
Word 3: Offset from base to entry table
Word 4: Number of entries available

The HAL itself may have whatever header is required to start the system. For
example on ARM7500 16->32 bit switch code is required, and on the 9500 parts
a special ROM header and checksum must be present. Instead of a header,
a pointer to the HAL descriptor is passed to the OS in the OS_Start call:

Word 0: Flags (0)
Word 1: Offset from descriptor to start of HAL (will be <= 0)
Word 2: HAL size
Word 3: Offset from descriptor to entry table
Word 4: Number of entries available
Word 5: Static workspace required

Eoch of the HAL and the OS must be contiguous within physical memory.






RISC OS entry points from HAL init
==================================


Entry 0:
void RISCOS_InitARM(unsigned int flags)

    flags: reserved - sbz

On entry:
  SVC mode
  MMU and caches off
  IRQs and FIQs disabled
  No RAM or stack used

On exit:
  Instruction cache may be on

Usage:
  This routine must be called once very early on in the HAL start-up, to accelerate the
  CPU for the rest of HAL initialisation. Typically, it will just enable the instruction
  cache (if possible on the ARM in use), and ensure that the processor is in 32-bit
  configuration and mode.

  Some architecture 4 (and later) ARMs have bits in the control register that affect
  the hardware layer - eg the iA and nF bits in the ARM920T. These are the HAL's
  responsibility - the OS will not touch them. Conversely, the HAL should not touch the
  cache, MMU and core configuration bits (currently bits 0-14).

  On architecture 3, the control register is write only - the OS will set bits 11-31 to
  zero.

  Likewise, such things as the StrongARM 110's register 15 (Test, Clock and Idle Control)
  are the HAL's responsibility. The OS does not know about the configuration of the
  system, so cannot program such registers.

  This entry may not be called after RISCOS_Start.



Entry 1:
void *RISCOS_AddRAM(unsigned int flags, void *start, void *end, uintptr_t sigbits, void *ref)
   flags
        bit 0: video memory (only first contiguous range will be used)
        bits 8-11: speed indicator (arbitrary, higher => faster)
        other bits reserved (SBZ)
   start
        start address of RAM (inclusive) (no alignment requirements)
   end
        end address of RAM (exclusive) (no alignment requirements, but must be >= start)
   sigbits
        significant address bit mask (1 => this bit of addr decoded, 0 => this bit ignored)
   ref
        reference handle (NULL for first call)

Returns ref for next call

On entry:
  SVC32 mode
  MMU and data cache off
  IRQs and FIQs disabled

Other notes:
  This entry point must be the first call from the HAL to RISC OS following a hardware
  reset. It may be called as many times as necessary to give all enumerate RAM that
  is available for general purpose use. It should only be called to declare video
  memory if the video memory may be used as normal RAM when in small video modes.

  To permit software resets:
    The HAL must be non-destructive of any declared RAM outside the first 4K of the first
    block.
    The stack pointer should be initialised 4K into the first block, or in some non-
    declared RAM.
    Must present memory in a fixed order on any given system.

  Current limitations:
    The first block must be at least 256K and 16K aligned. (Yuck)
    Block coalescing only works well if RAM banks are added in ascending address order.

  RISC OS will use RAM at the start of the first block as initial workspace. Max usage
  is 16 bytes per block + 32 (currently 8 per block + 4). This limits the number of
  discontiguous blocks (although RISC OS will concatanate contiguous blocks where
  possible).

  This call must not be made after RISCOS_Start.


Entry 2:
void RISCOS_Start(unsigned int flags, int *riscos_header, int *hal_entry_table, void *ref)

   flags
        bit 0: power on reset

On entry:
  SVC32 mode
  MMU and data cache off
  IRQs and FIQs disabled

Usage:
  This routine must be called after all calls to RISCOS_AddRAM have been completed.
  It does not return. Future calls back to the HAL are via the HAL entry table, after
  the MMU has been enabled.


Entry 3:
void *RISCOS_MapInIO(unsigned int flags, void *phys, unsigned int size)

   flags: bit 2 => make memory bufferable
    phys: physical address to map in
    size: number of bytes of memory to map in

Usage:
  This routine is used to map in IO memory for the HAL's usage. Normally it would
  only be called during HAL_Init(). Once mapped in the IO space cannot be released.

  It returns the resultant virtual address corresponding to phys, or 0 for failure.
  Failure can only occur if no RAM is available for page tables, or if the virtual
  address space is exhausted.



void *RISCOS_AccessPhysicalAddress(unsigned int flags, void *phys, void **oldp)

   flags: bit 2 => make memory bufferable
          other bits must be zero
    phys: physical address to access
    oldp: pointer to location to store old state (or NULL)

On entry:
  Privileged mode
  MMU on
  FIQs on
  Re-entrant

On exit:
  Returns logical address corresponding to phys

Usage:
  Arranges for the physical address phys to be mapped in to logical memory.
  In fact, the whole megabyte containing "phys" is mapped in (ie if phys =
  &12345678, then &12300000 to &123FFFFF become available). The memory is
  supervisor access only, non-cacheable, non-bufferable by default, and will
  remain available until the next call to RISCOS_Release/AccessPhysicalAddress
  (although interrupt routines or subroutines may temporarily map in something
  else).

  When finished, the user should call RISCOS_ReleasePhysicalAddress.




void RISCOS_ReleasePhysicalAddress(void *old)

  old: state returned from a previous call to RISCOS_AccessPhysicalAddress

On entry:
  MMU on
  FIQs on
  Re-entrant

Usage:
  Call with the a value output from a previous RISCOS_ReleasePhysicalAddress.

Example:

  void *old;
  unsigned int *addr = (unsigned int *) 0x80005000;
  unsigned int *addr2 = (unsigned int *) 0x90005000;

  addr = (unsigned int *) RISCOS_AccessPhysicalAddress(addr, &old);
  addr[0] = 3; addr[1] = 5;

  addr2 = (unsigned int *) RISCOS_AccessPhysicalAddress(addr2, NULL);
  *addr2 = 7;

  RISCOS_ReleasePhysicalAddress(old);





HAL entries
===========


void HAL_Start(int *riscos_header)
@


1.1.2.2
log
@More HAL work. IOMD HAL work in progress. Lots of my own little build
scripts. Don't touch this.

Version 5.35, 4.79.2.2. Tagged as 'Kernel-5_35-4_79_2_2'
@
text
@a244 3
        bit 1: CMOS reset inhibited (eg protection link on Risc PC)
        bit 2: perform a CMOS reset (if bit 1 clear and bit 0 set - eg front panel
                                     button held down on an NC)
@


1.1.2.3
log
@Lots of Tungsten work.

Version 5.35, 4.79.2.48. Tagged as 'Kernel-5_35-4_79_2_48'
@
text
@d146 1
a146 1
Each of the HAL and the OS must be contiguous within physical memory.
@


1.1.2.4
log
@Support for keys held down in the HAL at power on.
*Configure ANYTHINGsize was broken due to not setting R0 to ReadUnsigned
IIC ack message uninternationalised
OS_Memory was saying we only had 4M of RAM
VDU4 scrolling when output was switched to sprite was causing corruption
on use of CTRL-J and CTRL-K
Default SystemSize CMOS set to 32k

Version 5.35, 4.79.2.55. Tagged as 'Kernel-5_35-4_79_2_55'
@
text
@d139 1
a139 3
Word 0: Flags
            bit 0 => uncachable workspace (32K) required
            bits 1-31 reserved
@


