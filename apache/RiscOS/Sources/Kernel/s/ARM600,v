head	4.26;
access;
symbols
	Kernel-6_14:4.26
	Kernel-6_01-3:4.26
	Kernel-6_13:4.26
	Kernel-6_12:4.26
	Kernel-6_11:4.26
	Kernel-6_10:4.26
	Kernel-6_09:4.26
	Kernel-6_08-4_129_2_10:4.26
	Kernel-6_08-4_129_2_9:4.26
	Kernel-6_08:4.26
	Kernel-6_07:4.26
	Kernel-6_06:4.26
	Kernel-6_05-4_129_2_8:4.26
	Kernel-6_05:4.26
	Kernel-6_04:4.26
	Kernel-6_03:4.26
	Kernel-6_01-2:4.26
	Kernel-6_01-4_146_2_1:4.26
	Kernel-6_02:4.26
	Kernel-6_01-1:4.26
	Kernel-6_01:4.26
	Kernel-6_00:4.26
	Kernel-5_99:4.26
	Kernel-5_98:4.26
	Kernel-5_97-4_129_2_7:4.26
	Kernel-5_97:4.26
	Kernel-5_96:4.26
	Kernel-5_95:4.26
	Kernel-5_94:4.26
	Kernel-5_93:4.26
	Kernel-5_92:4.26
	Kernel-5_91:4.26
	Kernel-5_90:4.26
	Kernel-5_89-4_129_2_6:4.26
	Kernel-5_89:4.26
	Kernel-5_88-4_129_2_5:4.26
	Kernel-5_88-4_129_2_4:4.26
	Kernel-5_88:4.26
	Kernel-5_87:4.26
	Kernel-5_86-4_129_2_3:4.26
	Kernel-5_86-4_129_2_2:4.26
	Kernel-5_86-4_129_2_1:4.26
	Kernel-5_86:4.26
	SMP:4.26.0.2
	SMP_bp:4.26
	Kernel-5_85:4.26
	Kernel-5_54-1:4.18
	Kernel-5_84:4.26
	Kernel-5_83:4.26
	Kernel-5_82:4.26
	Kernel-5_81:4.26
	Kernel-5_80:4.26
	Kernel-5_79:4.26
	Kernel-5_78:4.26
	Kernel-5_77:4.26
	Kernel-5_76:4.26
	Kernel-5_75:4.26
	Kernel-5_74:4.26
	Kernel-5_73:4.26
	Kernel-5_72:4.26
	Kernel-5_71:4.26
	Kernel-5_70:4.25
	Kernel-5_69:4.24
	Kernel-5_68:4.23
	Kernel-5_67:4.23
	Kernel-5_66:4.23
	Kernel-5_65:4.22
	Kernel-5_64:4.22
	Kernel-5_63:4.22
	Kernel-5_62:4.22
	Kernel-5_61:4.21
	Kernel-5_60:4.21
	Kernel-5_59:4.21
	Kernel-5_58:4.19
	Kernel-5_57:4.19
	Kernel-5_56:4.19
	Kernel-5_55:4.19
	Kernel-5_54:4.18
	Kernel-5_53:4.18
	Kernel-5_52:4.18
	Kernel-5_51:4.17
	Kernel-5_50:4.16
	Kernel-5_49:4.16
	HAL_merge:4.12.2.40
	Kernel-5_48:4.15
	Kernel-5_35-4_79_2_327:4.12.2.40
	Kernel-5_35-4_79_2_326:4.12.2.40
	Kernel-5_35-4_79_2_325:4.12.2.40
	Kernel-5_35-4_79_2_324:4.12.2.40
	Kernel-5_35-4_79_2_323:4.12.2.40
	Kernel-5_35-4_79_2_322:4.12.2.40
	Kernel-5_35-4_79_2_321:4.12.2.40
	Kernel-5_35-4_79_2_320:4.12.2.40
	Kernel-5_35-4_79_2_319:4.12.2.40
	Kernel-5_35-4_79_2_318:4.12.2.40
	Kernel-5_35-4_79_2_317:4.12.2.40
	Kernel-5_35-4_79_2_316:4.12.2.40
	Kernel-5_35-4_79_2_315:4.12.2.40
	Kernel-5_35-4_79_2_314:4.12.2.40
	Kernel-5_35-4_79_2_313:4.12.2.40
	Kernel-5_35-4_79_2_312:4.12.2.40
	Kernel-5_35-4_79_2_311:4.12.2.40
	Kernel-5_35-4_79_2_310:4.12.2.40
	Kernel-5_35-4_79_2_309:4.12.2.40
	Kernel-5_35-4_79_2_308:4.12.2.40
	Kernel-5_35-4_79_2_307:4.12.2.40
	Kernel-5_35-4_79_2_306:4.12.2.40
	Kernel-5_35-4_79_2_305:4.12.2.39
	Kernel-5_35-4_79_2_304:4.12.2.39
	Kernel-5_35-4_79_2_303:4.12.2.39
	Kernel-5_35-4_79_2_302:4.12.2.39
	Kernel-5_35-4_79_2_301:4.12.2.39
	Kernel-5_35-4_79_2_300:4.12.2.39
	Kernel-5_35-4_79_2_299:4.12.2.39
	Kernel-5_35-4_79_2_298:4.12.2.39
	Kernel-5_35-4_79_2_297:4.12.2.39
	Kernel-5_35-4_79_2_296:4.12.2.39
	Kernel-5_35-4_79_2_295:4.12.2.39
	Kernel-5_35-4_79_2_294:4.12.2.39
	Kernel-5_35-4_79_2_293:4.12.2.39
	Kernel-5_35-4_79_2_292:4.12.2.39
	Kernel-5_35-4_79_2_291:4.12.2.39
	Kernel-5_35-4_79_2_290:4.12.2.39
	Kernel-5_35-4_79_2_289:4.12.2.39
	Kernel-5_35-4_79_2_288:4.12.2.39
	Kernel-5_35-4_79_2_287:4.12.2.39
	Kernel-5_35-4_79_2_286:4.12.2.39
	Kernel-5_35-4_79_2_285:4.12.2.39
	Kernel-5_35-4_79_2_284:4.12.2.39
	Kernel-5_35-4_79_2_283:4.12.2.38
	Kernel-5_35-4_79_2_282:4.12.2.38
	Kernel-5_35-4_79_2_281:4.12.2.38
	Kernel-5_35-4_79_2_280:4.12.2.38
	Kernel-5_35-4_79_2_279:4.12.2.38
	Kernel-5_35-4_79_2_278:4.12.2.37
	Kernel-5_35-4_79_2_277:4.12.2.37
	Kernel-5_35-4_79_2_276:4.12.2.37
	Kernel-5_35-4_79_2_275:4.12.2.37
	Kernel-5_35-4_79_2_274:4.12.2.37
	Kernel-5_35-4_79_2_273:4.12.2.37
	Kernel-5_35-4_79_2_272:4.12.2.36
	Kernel-5_35-4_79_2_271:4.12.2.36
	Kernel-5_35-4_79_2_270:4.12.2.36
	Kernel-5_35-4_79_2_269:4.12.2.36
	Kernel-5_35-4_79_2_268:4.12.2.36
	Kernel-5_35-4_79_2_267:4.12.2.36
	Kernel-5_35-4_79_2_266:4.12.2.36
	Kernel-5_35-4_79_2_265:4.12.2.36
	Kernel-5_35-4_79_2_264:4.12.2.36
	Kernel-5_35-4_79_2_263:4.12.2.36
	Kernel-5_35-4_79_2_262:4.12.2.36
	Kernel-5_35-4_79_2_261:4.12.2.36
	Kernel-5_35-4_79_2_260:4.12.2.36
	Kernel-5_35-4_79_2_259:4.12.2.36
	Kernel-5_35-4_79_2_258:4.12.2.36
	Kernel-5_35-4_79_2_257:4.12.2.36
	Kernel-5_35-4_79_2_256:4.12.2.36
	Kernel-5_35-4_79_2_255:4.12.2.36
	Kernel-5_35-4_79_2_254:4.12.2.36
	Kernel-5_35-4_79_2_253:4.12.2.36
	Kernel-5_35-4_79_2_252:4.12.2.36
	Kernel-5_35-4_79_2_251:4.12.2.36
	Kernel-5_35-4_79_2_250:4.12.2.36
	Kernel-5_35-4_79_2_249:4.12.2.36
	Kernel-5_35-4_79_2_248:4.12.2.36
	Kernel-5_35-4_79_2_247:4.12.2.36
	Kernel-5_35-4_79_2_246:4.12.2.36
	Kernel-5_35-4_79_2_245:4.12.2.36
	Kernel-5_35-4_79_2_244:4.12.2.36
	Kernel-5_35-4_79_2_243:4.12.2.36
	Kernel-5_35-4_79_2_242:4.12.2.36
	Kernel-5_35-4_79_2_241:4.12.2.36
	Kernel-5_35-4_79_2_240:4.12.2.36
	Kernel-5_35-4_79_2_239:4.12.2.36
	Kernel-5_35-4_79_2_238:4.12.2.36
	Kernel-5_35-4_79_2_237:4.12.2.36
	Kernel-5_35-4_79_2_236:4.12.2.36
	Kernel-5_35-4_79_2_235:4.12.2.36
	Kernel-5_35-4_79_2_234:4.12.2.36
	Kernel-5_35-4_79_2_233:4.12.2.36
	Kernel-5_35-4_79_2_232:4.12.2.36
	Kernel-5_35-4_79_2_231:4.12.2.36
	Kernel-5_35-4_79_2_230:4.12.2.36
	Kernel-5_35-4_79_2_229:4.12.2.36
	Kernel-5_35-4_79_2_228:4.12.2.36
	Kernel-5_35-4_79_2_227:4.12.2.36
	Kernel-5_35-4_79_2_226:4.12.2.36
	Kernel-5_35-4_79_2_225:4.12.2.36
	Kernel-5_35-4_79_2_224:4.12.2.36
	Kernel-5_35-4_79_2_223:4.12.2.36
	Kernel-5_35-4_79_2_222:4.12.2.35
	Kernel-5_35-4_79_2_221:4.12.2.35
	Kernel-5_35-4_79_2_220:4.12.2.34
	Kernel-5_35-4_79_2_219:4.12.2.34
	Kernel-5_35-4_79_2_218:4.12.2.34
	Kernel-5_35-4_79_2_217:4.12.2.34
	Kernel-5_35-4_79_2_216:4.12.2.34
	Kernel-5_35-4_79_2_215:4.12.2.34
	Kernel-5_35-4_79_2_214:4.12.2.34
	Kernel-5_35-4_79_2_213:4.12.2.34
	Kernel-5_35-4_79_2_212:4.12.2.34
	Kernel-5_35-4_79_2_211:4.12.2.33
	Kernel-5_35-4_79_2_210:4.12.2.32
	Kernel-5_35-4_79_2_209:4.12.2.32
	Kernel-5_35-4_79_2_208:4.12.2.31
	Kernel-5_35-4_79_2_207:4.12.2.31
	Kernel-5_35-4_79_2_206:4.12.2.31
	Kernel-5_35-4_79_2_205:4.12.2.31
	Kernel-5_35-4_79_2_204:4.12.2.31
	Kernel-5_35-4_79_2_203:4.12.2.31
	Kernel-5_35-4_79_2_202:4.12.2.30
	Kernel-5_35-4_79_2_201:4.12.2.30
	Kernel-5_35-4_79_2_200:4.12.2.30
	Kernel-5_35-4_79_2_199:4.12.2.30
	Kernel-5_35-4_79_2_198:4.12.2.30
	Kernel-5_35-4_79_2_197:4.12.2.30
	Kernel-5_35-4_79_2_196:4.12.2.30
	Kernel-5_35-4_79_2_195:4.12.2.30
	Kernel-5_35-4_79_2_194:4.12.2.30
	Kernel-5_35-4_79_2_193:4.12.2.30
	Kernel-5_35-4_79_2_192:4.12.2.30
	Kernel-5_35-4_79_2_191:4.12.2.30
	Kernel-5_35-4_79_2_190:4.12.2.30
	Kernel-5_35-4_79_2_189:4.12.2.30
	Kernel-5_35-4_79_2_188:4.12.2.30
	Kernel-5_35-4_79_2_187:4.12.2.30
	Kernel-5_35-4_79_2_186:4.12.2.30
	Kernel-5_35-4_79_2_185:4.12.2.29
	Kernel-5_35-4_79_2_184:4.12.2.29
	Kernel-5_35-4_79_2_183:4.12.2.29
	Kernel-5_35-4_79_2_182:4.12.2.29
	Kernel-5_35-4_79_2_181:4.12.2.29
	Kernel-5_35-4_79_2_180:4.12.2.29
	Kernel-5_35-4_79_2_179:4.12.2.29
	Kernel-5_35-4_79_2_178:4.12.2.29
	Kernel-5_35-4_79_2_177:4.12.2.29
	Kernel-5_35-4_79_2_176:4.12.2.29
	Kernel-5_35-4_79_2_175:4.12.2.29
	Kernel-5_35-4_79_2_174:4.12.2.29
	Kernel-5_35-4_79_2_173:4.12.2.28
	Kernel-5_35-4_79_2_172:4.12.2.28
	Kernel-5_35-4_79_2_171:4.12.2.28
	Kernel-5_35-4_79_2_170:4.12.2.28
	Kernel-5_35-4_79_2_169:4.12.2.28
	Kernel-5_35-4_79_2_168:4.12.2.28
	Kernel-5_35-4_79_2_167:4.12.2.28
	Kernel-5_35-4_79_2_166:4.12.2.28
	Kernel-5_35-4_79_2_165:4.12.2.28
	RPi_merge:4.12.2.25.2.2
	Kernel-5_35-4_79_2_147_2_23:4.12.2.25.2.2
	Kernel-5_35-4_79_2_147_2_22:4.12.2.25.2.1
	Kernel-5_35-4_79_2_147_2_21:4.12.2.25.2.1
	Kernel-5_35-4_79_2_147_2_20:4.12.2.25.2.1
	Kernel-5_35-4_79_2_147_2_19:4.12.2.25.2.1
	Kernel-5_35-4_79_2_147_2_18:4.12.2.25.2.1
	Kernel-5_35-4_79_2_164:4.12.2.28
	Kernel-5_35-4_79_2_163:4.12.2.28
	Kernel-5_35-4_79_2_147_2_17:4.12.2.25.2.1
	Kernel-5_35-4_79_2_147_2_16:4.12.2.25.2.1
	Kernel-5_35-4_79_2_147_2_15:4.12.2.25.2.1
	Kernel-5_35-4_79_2_162:4.12.2.28
	Kernel-5_35-4_79_2_161:4.12.2.28
	Kernel-5_35-4_79_2_147_2_14:4.12.2.25
	Kernel-5_35-4_79_2_147_2_13:4.12.2.25
	Kernel-5_35-4_79_2_160:4.12.2.28
	Kernel-5_35-4_79_2_159:4.12.2.28
	Kernel-5_35-4_79_2_158:4.12.2.27
	Kernel-5_35-4_79_2_157:4.12.2.27
	Kernel-5_35-4_79_2_156:4.12.2.27
	Kernel-5_35-4_79_2_147_2_12:4.12.2.25
	Kernel-5_35-4_79_2_147_2_11:4.12.2.25
	Kernel-5_35-4_79_2_155:4.12.2.27
	Kernel-5_35-4_79_2_147_2_10:4.12.2.25
	Kernel-5_35-4_79_2_154:4.12.2.27
	Kernel-5_35-4_79_2_153:4.12.2.27
	Kernel-5_35-4_79_2_147_2_9:4.12.2.25
	Kernel-5_35-4_79_2_152:4.12.2.26
	Kernel-5_35-4_79_2_151:4.12.2.26
	Kernel-5_35-4_79_2_147_2_8:4.12.2.25
	Kernel-5_35-4_79_2_147_2_7:4.12.2.25
	Kernel-5_35-4_79_2_150:4.12.2.26
	Kernel-5_35-4_79_2_147_2_6:4.12.2.25
	Kernel-5_35-4_79_2_147_2_5:4.12.2.25
	Kernel-5_35-4_79_2_149:4.12.2.25
	Kernel-5_35-4_79_2_147_2_4:4.12.2.25
	Kernel-5_35-4_79_2_147_2_3:4.12.2.25
	Kernel-5_35-4_79_2_148:4.12.2.25
	Kernel-5_35-4_79_2_147_2_2:4.12.2.25
	Kernel-5_35-4_79_2_147_2_1:4.12.2.25
	RPi:4.12.2.25.0.2
	RPi_bp:4.12.2.25
	Kernel-5_35-4_79_2_98_2_52_2_1:4.12.2.22.2.3
	alees_Kernel_dev:4.12.2.22.2.3.0.2
	alees_Kernel_dev_bp:4.12.2.22.2.3
	Kernel-5_35-4_79_2_147:4.12.2.25
	Kernel-5_35-4_79_2_146:4.12.2.25
	Kernel-5_35-4_79_2_145:4.12.2.24
	Kernel-5_35-4_79_2_144:4.12.2.24
	Kernel-5_35-4_79_2_143:4.12.2.24
	Kernel-5_35-4_79_2_142:4.12.2.24
	Kernel-5_35-4_79_2_141:4.12.2.24
	Kernel-5_35-4_79_2_140:4.12.2.24
	Kernel-5_35-4_79_2_139:4.12.2.24
	Kernel-5_35-4_79_2_138:4.12.2.24
	Kernel-5_35-4_79_2_137:4.12.2.24
	Kernel-5_35-4_79_2_136:4.12.2.24
	Kernel-5_35-4_79_2_135:4.12.2.24
	Kernel-5_35-4_79_2_134:4.12.2.24
	Kernel-5_35-4_79_2_133:4.12.2.24
	Kernel-5_35-4_79_2_132:4.12.2.24
	Kernel-5_35-4_79_2_131:4.12.2.24
	Kernel-5_35-4_79_2_130:4.12.2.24
	Kernel-5_35-4_79_2_129:4.12.2.24
	Kernel-5_35-4_79_2_128:4.12.2.24
	Kernel-5_35-4_79_2_127:4.12.2.24
	Kernel-5_35-4_79_2_126:4.12.2.24
	Kernel-5_35-4_79_2_125:4.12.2.24
	Kernel-5_35-4_79_2_124:4.12.2.24
	Kernel-5_35-4_79_2_123:4.12.2.23
	Cortex_merge:4.12.2.22.2.3
	Kernel-5_35-4_79_2_122:4.12.2.22
	Kernel-5_35-4_79_2_98_2_54:4.12.2.22.2.3
	Kernel-5_35-4_79_2_98_2_53:4.12.2.22.2.3
	Kernel-5_35-4_79_2_98_2_52:4.12.2.22.2.3
	Kernel-5_35-4_79_2_98_2_51:4.12.2.22.2.3
	Kernel-5_35-4_79_2_98_2_50:4.12.2.22.2.3
	Kernel-5_35-4_79_2_98_2_49:4.12.2.22.2.3
	Kernel-5_35-4_79_2_98_2_48:4.12.2.22.2.3
	Kernel-5_35-4_79_2_121:4.12.2.22
	Kernel-5_35-4_79_2_98_2_47:4.12.2.22.2.2
	Kernel-5_35-4_79_2_120:4.12.2.22
	Kernel-5_35-4_79_2_98_2_46:4.12.2.22.2.2
	Kernel-5_35-4_79_2_119:4.12.2.22
	Kernel-5_35-4_79_2_98_2_45:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_44:4.12.2.22.2.2
	Kernel-5_35-4_79_2_118:4.12.2.22
	Kernel-5_35-4_79_2_98_2_43:4.12.2.22.2.2
	Kernel-5_35-4_79_2_117:4.12.2.22
	Kernel-5_35-4_79_2_116:4.12.2.22
	Kernel-5_35-4_79_2_98_2_42:4.12.2.22.2.2
	Kernel-5_35-4_79_2_115:4.12.2.22
	Kernel-5_35-4_79_2_98_2_41:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_40:4.12.2.22.2.2
	Kernel-5_35-4_79_2_114:4.12.2.22
	Kernel-5_35-4_79_2_98_2_39:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_38:4.12.2.22.2.2
	Kernel-5_35-4_79_2_113:4.12.2.22
	Kernel-5_35-4_79_2_112:4.12.2.22
	Kernel-5_35-4_79_2_98_2_37:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_36:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_35:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_34:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_33:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_32:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_31:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_30:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_29:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_28:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_27:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_26:4.12.2.22.2.2
	Kernel-5_35-4_79_2_111:4.12.2.22
	Kernel-5_35-4_79_2_98_2_25:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_24:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_23:4.12.2.22.2.2
	Kernel-5_35-4_79_2_110:4.12.2.22
	Kernel-5_35-4_79_2_98_2_22:4.12.2.22.2.2
	Kernel-5_35-4_79_2_109:4.12.2.22
	Kernel-5_35-4_79_2_98_2_21:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_20:4.12.2.22.2.2
	Kernel-5_35-4_79_2_108:4.12.2.22
	Kernel-5_35-4_79_2_107:4.12.2.22
	Kernel-5_35-4_79_2_98_2_19:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_18:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_17:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_16:4.12.2.22.2.2
	Kernel-5_35-4_79_2_98_2_15:4.12.2.22.2.2
	Kernel-5_35-4_79_2_106:4.12.2.22
	Kernel-5_35-4_79_2_105:4.12.2.22
	Kernel-5_35-4_79_2_104:4.12.2.22
	Kernel-5_35-4_79_2_98_2_14:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_13:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_12:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_11:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_10:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_9:4.12.2.22.2.1
	Kernel-5_35-4_79_2_103:4.12.2.22
	Kernel-5_35-4_79_2_102:4.12.2.22
	Kernel-5_35-4_79_2_98_2_8:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_7:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_6:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_5:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_4:4.12.2.22.2.1
	Kernel-5_35-4_79_2_101:4.12.2.22
	Kernel-5_35-4_79_2_100:4.12.2.22
	Kernel-5_35-4_79_2_99:4.12.2.22
	Kernel-5_35-4_79_2_98_2_3:4.12.2.22.2.1
	Kernel-5_35-4_79_2_98_2_2:4.12.2.22
	Kernel-5_35-4_79_2_98_2_1:4.12.2.22
	Cortex:4.12.2.22.0.2
	Cortex_bp:4.12.2.22
	Kernel-5_35-4_79_2_98:4.12.2.22
	Kernel-5_35-4_79_2_97:4.12.2.22
	Kernel-5_35-4_79_2_96:4.12.2.22
	Kernel-5_35-4_79_2_95:4.12.2.22
	Kernel-5_35-4_79_2_94:4.12.2.22
	Kernel-5_35-4_79_2_93:4.12.2.22
	Kernel-5_35-4_79_2_92:4.12.2.22
	Kernel-5_35-4_79_2_91:4.12.2.22
	Kernel-5_35-4_79_2_90:4.12.2.22
	Kernel-5_35-4_79_2_89:4.12.2.22
	Kernel-5_35-4_79_2_88:4.12.2.22
	Kernel-5_35-4_79_2_87:4.12.2.22
	Kernel-5_35-4_79_2_86:4.12.2.22
	Kernel-5_35-4_79_2_85:4.12.2.22
	Kernel-5_35-4_79_2_84:4.12.2.22
	Kernel-5_35-4_79_2_83:4.12.2.22
	Kernel-5_35-4_79_2_82:4.12.2.22
	Kernel-5_35-4_79_2_81:4.12.2.22
	Kernel-5_35-4_79_2_80:4.12.2.22
	Kernel-5_35-4_79_2_79:4.12.2.22
	Kernel-5_35-4_79_2_78:4.12.2.22
	Kernel-5_35-4_79_2_77:4.12.2.22
	RO_5_07:4.12.2.22
	Kernel-5_35-4_79_2_76:4.12.2.22
	Kernel-5_35-4_79_2_75:4.12.2.22
	Kernel-5_35-4_79_2_74:4.12.2.22
	Kernel-5_35-4_79_2_73:4.12.2.22
	Kernel-5_35-4_79_2_72:4.12.2.22
	Kernel-5_35-4_79_2_71:4.12.2.22
	Kernel-5_35-4_79_2_70:4.12.2.22
	Kernel-5_35-4_79_2_69:4.12.2.22
	Kernel-5_35-4_79_2_68:4.12.2.22
	Kernel-5_35-4_79_2_67:4.12.2.22
	Kernel-5_35-4_79_2_66:4.12.2.22
	Kernel-5_35-4_79_2_65:4.12.2.21
	Kernel-5_35-4_79_2_64:4.12.2.21
	Kernel-5_35-4_79_2_63:4.12.2.21
	Kernel-5_35-4_79_2_62:4.12.2.21
	Kernel-5_35-4_79_2_61:4.12.2.21
	Kernel-5_35-4_79_2_59:4.12.2.21
	Kernel-5_35-4_79_2_58:4.12.2.21
	Kernel-5_35-4_79_2_57:4.12.2.21
	Kernel-5_35-4_79_2_56:4.12.2.21
	Kernel-5_35-4_79_2_55:4.12.2.21
	Kernel-5_35-4_79_2_54:4.12.2.21
	Kernel-5_35-4_79_2_53:4.12.2.21
	Kernel-5_35-4_79_2_52:4.12.2.21
	Kernel-5_35-4_79_2_51:4.12.2.21
	Kernel-5_35-4_79_2_50:4.12.2.20
	Kernel-5_35-4_79_2_49:4.12.2.19
	Kernel-5_35-4_79_2_48:4.12.2.19
	Kernel-5_47:4.14
	Kernel-5_46-4_90_2_1:4.14
	nbingham_Kernel_FastNC_dev_bp:4.14
	nbingham_Kernel_FastNC_dev:4.14.0.2
	Kernel-5_46:4.14
	Kernel-5_45:4.14
	Kernel-5_35-4_79_2_47:4.12.2.18
	Kernel-5_35-4_79_2_46:4.12.2.18
	Kernel-5_35-4_79_2_45:4.12.2.18
	Kernel-5_35-4_79_2_44:4.12.2.18
	Kernel-5_35-4_79_2_25_2_2:4.12.2.16
	Kernel-5_35-4_79_2_43:4.12.2.18
	Kernel-5_35-4_79_2_42:4.12.2.18
	Kernel-5_35-4_79_2_41:4.12.2.18
	Kernel-5_35-4_79_2_40:4.12.2.18
	Kernel-5_35-4_79_2_39:4.12.2.18
	Kernel-5_35-4_79_2_38:4.12.2.18
	Kernel-5_35-4_79_2_37:4.12.2.18
	Kernel-5_35-4_79_2_36:4.12.2.18
	Kernel-5_35-4_79_2_35:4.12.2.18
	Kernel-5_35-4_79_2_34:4.12.2.18
	Kernel-5_35-4_79_2_33:4.12.2.18
	Kernel-5_35-4_79_2_32:4.12.2.17
	Kernel-5_44:4.14
	Kernel-5_35-4_79_2_25_2_1:4.12.2.16
	Kernel-5_43:4.14
	Kernel-5_35-4_79_2_31:4.12.2.17
	Kernel-5_35-4_79_2_30:4.12.2.16
	Kernel-5_35-4_79_2_29:4.12.2.16
	Kernel-5_35-4_79_2_28:4.12.2.16
	Kernel-5_35-4_79_2_27:4.12.2.16
	Kernel-5_35-4_79_2_26:4.12.2.16
	Kernel-5_42:4.14
	Kernel-5_41:4.14
	Kernel-5_40:4.14
	Kernel-5_35-4_79_2_25:4.12.2.16
	Kernel-5_35-4_79_2_24:4.12.2.16
	Kernel-5_35-4_79_2_23:4.12.2.16
	Kernel-5_35-4_79_2_22:4.12.2.16
	Kernel-5_35-4_79_2_21:4.12.2.16
	Kernel-5_35-4_79_2_20:4.12.2.16
	Kernel-5_35-4_79_2_19:4.12.2.16
	Kernel-5_35-4_79_2_18:4.12.2.16
	Kernel-5_35-4_79_2_17:4.12.2.16
	Kernel-5_35-4_79_2_16:4.12.2.15
	Kernel-5_35-4_79_2_15:4.12.2.14
	Kernel-5_35-4_79_2_14:4.12.2.13
	Kernel-5_39:4.13
	Kernel-5_13-4_52_2_1:4.9
	Bethany:4.9.0.2
	Kernel-5_38:4.12
	Kernel-5_35-4_79_2_13:4.12.2.12
	Kernel-5_35-4_79_2_12:4.12.2.11
	Kernel-5_35-4_79_2_11:4.12.2.10
	Kernel-5_37:4.12
	Kernel-5_35-4_79_2_10:4.12.2.9
	Kernel-5_35-4_79_2_9:4.12.2.8
	Kernel-5_36:4.12
	Kernel-5_35-4_79_2_8:4.12.2.6
	Kernel-5_35-4_79_2_7:4.12.2.6
	Kernel-5_35-4_79_2_6:4.12.2.6
	Kernel-5_35-4_79_2_5:4.12.2.5
	Kernel-5_35-4_79_2_4:4.12.2.4
	Kernel-5_35-4_79_2_3:4.12.2.3
	Kernel-5_35-4_79_2_2:4.12.2.2
	dellis_autobuild_BaseSW:4.12
	Kernel-5_35-4_79_2_1:4.12.2.1
	HAL:4.12.0.2
	Kernel-5_35:4.12
	Kernel-5_34:4.12
	Kernel-5_33:4.12
	Kernel-5_32:4.12
	Kernel-5_31:4.12
	Kernel-5_30:4.12
	Kernel-5_29:4.12
	Kernel-5_28:4.12
	Kernel-5_27:4.12
	Kernel-5_26:4.12
	Kernel-5_25:4.12
	Kernel-5_24:4.12
	Kernel-5_23:4.11
	Kernel-5_22:4.10
	sbrodie_sedwards_16Mar2000:4.10
	Kernel-5_21:4.10
	Kernel-5_20:4.10
	Kernel-5_19:4.10
	Kernel-5_18:4.10
	Kernel-5_17:4.10
	Kernel-5_16:4.10
	Kernel-5_15:4.10
	Kernel-5_14:4.9
	Kernel-5_13:4.9
	Kernel-5_12:4.9
	Kernel-5_11:4.9
	Kernel-5_10:4.9
	Kernel-5_09:4.9
	Kernel-5_08:4.9
	Kernel-5_07:4.9
	Kernel-5_06:4.9
	Kernel-5_05:4.9
	Kernel-5_04:4.9
	Kernel-5_03:4.9
	Kernel-5_02:4.9
	Kernel-5_01:4.9
	Kernel-5_00:4.9
	Kernel-4_99:4.9
	Kernel-4_98:4.9
	Kernel-4_97:4.9
	Kernel-4_96:4.9
	Kernel-4_95:4.9
	Kernel-4_94:4.9
	Kernel-4_93:4.9
	Kernel-4_92:4.9
	Kernel-4_91:4.9
	Kernel-4_90:4.9
	dcotton_autobuild_BaseSW:4.14
	Kernel-4_89:4.8
	Kernel-4_88:4.7
	Kernel-4_87:4.7
	Kernel-4_86:4.7
	Kernel-4_85:4.7
	sbrodie_UrsulaRiscPC_Kernel_19Aug99:4.3.2.5.2.1
	Kernel-4_84:4.7
	sbrodie_UrsulaRiscPC_Kernel_18Aug99:4.3.2.5.2.1
	Ursula_RiscPC_bp:4.3.2.5
	Kernel-4_83:4.7
	Kernel-4_82:4.7
	Kernel-4_81:4.7
	Kernel-4_80:4.6
	Kernel-4_79:4.6
	Kernel-4_78:4.6
	Kernel-4_77:4.6
	Kernel-4_76:4.6
	Kernel-4_75:4.5
	Kernel-4_74:4.5
	Kernel-4_73:4.5
	Kernel-4_72:4.5
	Kernel-4_71:4.5
	Kernel-4_70:4.5
	Kernel-4_69:4.5
	Kernel-4_68:4.4
	mstphens_UrsulaRiscPCBuild_20Nov98:4.3.2.5.2.1
	Ursula_RiscPC:4.3.2.5.0.2
	Kernel-4_63-1_1_2_5:4.1.7.3
	Kernel-4_63-1_1_2_4:4.1.7.3
	Kernel-4_67:4.4
	Kernel-4_66:4.4
	Kernel-4_63-1_1_2_3:4.1.7.3
	Kernel-4_65:4.4
	Ursula_merge:4.3
	Kernel-4_64:4.4
	mstphens_Kernel-3_81:4.3.2.6
	Kernel-4_63-1_1_2_2:4.1.7.3
	nicke_Kernel_4_62:4.1.7.3
	rthornb_UrsulaBuild-19Aug1998:4.3.2.5
	UrsulaBuild_FinalSoftload:4.3.2.5
	rthornb_UrsulaBuild-12Aug1998:4.3.2.5
	aglover_UrsulaBuild-05Aug1998:4.3.2.5
	rthornb_UrsulaBuild-29Jul1998:4.3.2.5
	rthornb_UrsulaBuild-22Jul1998:4.3.2.5
	nturton_v459:4.1.7.3
	nturton_v460:4.1.7.3
	rthornb_UrsulaBuild-15Jul1998:4.3.2.5
	rthornb_UrsulaBuild-07Jul1998:4.3.2.5
	rthornb_UrsulaBuild-17Jun1998:4.3.2.5
	rthornb_UrsulaBuild-03Jun1998:4.3.2.5
	rthornb_UrsulaBuild-27May1998:4.3.2.5
	mstphens_Kernel-3_80:4.3.2.5
	rthornb_UrsulaBuild-21May1998:4.3.2.5
	afrost_Boca-1_2-Beta:4.1.7.3
	rthornb_UrsulaBuild_01May1998:4.3.2.5
	afrost_NC2_Generic:4.1.7.3
	Spinner_B20_2:4.1.7.3
	Spinner_19_3:4.1.7.3
	Spinner_B18:4.1.7.3
	Spinner_B17:4.1.7.3
	Spinner_B15:4.1.7.3
	Spinner_B14:4.1.7.3
	Spinner_B13:4.1.7.3
	Spinner_B12:4.1.7.3
	Spinner_B10:4.1.7.3
	Daytona:4.3.0.4
	Daytona_bp:4.3
	Ursula_bp:4.3
	Ursula:4.3.0.2
	Spinner_B7:4.1.7.3
	RO_3_71:4.1.3.2
	ARTtmp_merge:4.1.7.1
	Spin_3Apr97:4.1.7.1
	ARTtmp:4.1.7.1.0.2
	Spin_merge:4.1.7.3
	MergeFiles:4.1.3.1
	RO_3_70:4.1.3.1
	NC_1_06:4.1.7.1
	Spinner:4.1.7
	Spin_xx:4.1.5
	NC_xx:4.1.5.1
	RO_3_60:4.1.1.1
	StrongARM:4.1.3
	Black:4.1.1;
locks; strict;
comment	@# @;


4.26
date	2016.12.13.19.41.12;	author jlee;	state Exp;
branches;
next	4.25;
commitid	XeVhUEC50BLVkRxz;

4.25
date	2016.12.13.19.03.34;	author jlee;	state Exp;
branches;
next	4.24;
commitid	dvbJa4TQHit18Rxz;

4.24
date	2016.12.13.18.39.09;	author jlee;	state Exp;
branches;
next	4.23;
commitid	O0s9EhrhFbuFZQxz;

4.23
date	2016.12.13.16.42.50;	author jlee;	state Exp;
branches;
next	4.22;
commitid	aGog9bB8f4QKlQxz;

4.22
date	2016.10.17.20.52.47;	author jlee;	state Exp;
branches;
next	4.21;
commitid	duwVFka8P3V5zxqz;

4.21
date	2016.09.08.00.42.41;	author jlee;	state Exp;
branches;
next	4.20;
commitid	XDWFHFSHuLLI7qlz;

4.20
date	2016.09.07.21.45.13;	author jlee;	state Exp;
branches;
next	4.19;
commitid	GPzWDxzZgYTN8plz;

4.19
date	2016.08.02.22.10.43;	author jlee;	state Exp;
branches;
next	4.18;
commitid	CnQYuUGzojQfrMgz;

4.18
date	2016.06.30.21.14.27;	author jlee;	state Exp;
branches;
next	4.17;
commitid	juXQJ5NfO6DKbxcz;

4.17
date	2016.06.30.20.59.45;	author jlee;	state Exp;
branches;
next	4.16;
commitid	skOEjp3ipLHx6xcz;

4.16
date	2016.06.30.20.28.55;	author jlee;	state Exp;
branches;
next	4.15;
commitid	lMnWzoE9eJz3Wwcz;

4.15
date	2016.06.30.20.08.07;	author jlee;	state Exp;
branches;
next	4.14;
commitid	IWoXxARWeuLDOwcz;

4.14
date	2001.04.02.11.28.17;	author dcotton;	state Exp;
branches;
next	4.13;

4.13
date	2001.01.05.13.50.38;	author sbrodie;	state Exp;
branches;
next	4.12;

4.12
date	2000.04.13.10.37.25;	author kbracey;	state Exp;
branches
	4.12.2.1;
next	4.11;

4.11
date	2000.04.04.14.27.26;	author kbracey;	state Exp;
branches;
next	4.10;

4.10
date	2000.02.02.11.59.06;	author sbrodie;	state Exp;
branches;
next	4.9;

4.9
date	99.09.29.17.09.23;	author kbracey;	state Exp;
branches;
next	4.8;

4.8
date	99.09.23.16.47.42;	author kbracey;	state Exp;
branches;
next	4.7;

4.7
date	99.08.03.09.58.55;	author kbracey;	state Exp;
branches;
next	4.6;

4.6
date	99.04.30.15.18.47;	author kbracey;	state Exp;
branches;
next	4.5;

4.5
date	99.02.09.10.57.36;	author nturton;	state Exp;
branches;
next	4.4;

4.4
date	98.09.30.08.42.24;	author kbracey;	state Exp;
branches;
next	4.3;

4.3
date	97.05.07.05.51.44;	author kbracey;	state Exp;
branches
	4.3.2.1;
next	4.2;

4.2
date	97.01.21.14.06.53;	author nturton;	state Exp;
branches;
next	4.1;

4.1
date	96.11.05.09.41.09;	author nturton;	state Exp;
branches
	4.1.1.1
	4.1.3.1
	4.1.5.1
	4.1.7.1;
next	;

4.12.2.1
date	2000.09.15.12.38.00;	author kbracey;	state Exp;
branches;
next	4.12.2.2;

4.12.2.2
date	2000.10.02.08.52.19;	author kbracey;	state Exp;
branches;
next	4.12.2.3;

4.12.2.3
date	2000.10.03.12.05.59;	author mstephen;	state Exp;
branches;
next	4.12.2.4;

4.12.2.4
date	2000.10.05.11.55.12;	author mstephen;	state Exp;
branches;
next	4.12.2.5;

4.12.2.5
date	2000.10.05.13.54.49;	author kbracey;	state Exp;
branches;
next	4.12.2.6;

4.12.2.6
date	2000.10.05.14.33.00;	author mstephen;	state Exp;
branches;
next	4.12.2.7;

4.12.2.7
date	2000.10.06.09.08.11;	author kbracey;	state Exp;
branches;
next	4.12.2.8;

4.12.2.8
date	2000.10.09.15.59.15;	author kbracey;	state Exp;
branches;
next	4.12.2.9;

4.12.2.9
date	2000.10.16.11.55.38;	author kbracey;	state Exp;
branches;
next	4.12.2.10;

4.12.2.10
date	2000.10.20.15.48.04;	author mstephen;	state Exp;
branches;
next	4.12.2.11;

4.12.2.11
date	2000.10.23.10.22.11;	author kbracey;	state Exp;
branches;
next	4.12.2.12;

4.12.2.12
date	2000.11.10.15.51.34;	author kbracey;	state Exp;
branches;
next	4.12.2.13;

4.12.2.13
date	2001.01.09.17.17.32;	author mstephen;	state Exp;
branches;
next	4.12.2.14;

4.12.2.14
date	2001.01.12.13.52.13;	author mstephen;	state Exp;
branches;
next	4.12.2.15;

4.12.2.15
date	2001.01.23.15.43.53;	author mstephen;	state Exp;
branches;
next	4.12.2.16;

4.12.2.16
date	2001.02.13.09.36.04;	author kbracey;	state Exp;
branches;
next	4.12.2.17;

4.12.2.17
date	2001.05.22.15.27.53;	author mstephen;	state Exp;
branches;
next	4.12.2.18;

4.12.2.18
date	2001.06.11.11.33.31;	author kbracey;	state Exp;
branches;
next	4.12.2.19;

4.12.2.19
date	2002.10.07.17.29.38;	author kbracey;	state Exp;
branches;
next	4.12.2.20;

4.12.2.20
date	2002.10.28.16.13.46;	author bavison;	state Exp;
branches;
next	4.12.2.21;

4.12.2.21
date	2002.11.30.00.31.05;	author bavison;	state Exp;
branches;
next	4.12.2.22;

4.12.2.22
date	2004.05.06.16.02.00;	author kbracey;	state Exp;
branches
	4.12.2.22.2.1;
next	4.12.2.23;

4.12.2.23
date	2011.11.26.21.11.14;	author jlee;	state Exp;
branches;
next	4.12.2.24;
commitid	cI3W0zbtALQG6TIv;

4.12.2.24
date	2011.11.27.11.48.06;	author rsprowson;	state Exp;
branches;
next	4.12.2.25;
commitid	OFgqaKhOb6swXXIv;

4.12.2.25
date	2012.04.15.19.48.05;	author jlee;	state Exp;
branches
	4.12.2.25.2.1;
next	4.12.2.26;
commitid	95iLwHSxemPb701w;

4.12.2.26
date	2012.05.21.19.31.38;	author rsprowson;	state Exp;
branches;
next	4.12.2.27;
commitid	oEtPURiKNEPMRC5w;

4.12.2.27
date	2012.06.18.20.17.55;	author rsprowson;	state Exp;
branches;
next	4.12.2.28;
commitid	KeuVX14bDnORde9w;

4.12.2.28
date	2012.07.04.17.50.50;	author rsprowson;	state Exp;
branches;
next	4.12.2.29;
commitid	BwjRc3GMlaDwTgbw;

4.12.2.29
date	2012.10.28.16.51.45;	author rsprowson;	state Exp;
branches;
next	4.12.2.30;
commitid	ruXZqdTJKJ85Qaqw;

4.12.2.30
date	2013.03.28.21.36.23;	author jlee;	state Exp;
branches;
next	4.12.2.31;
commitid	UN0GP6eB0LlNyBJw;

4.12.2.31
date	2013.12.15.21.34.03;	author jlee;	state Exp;
branches;
next	4.12.2.32;
commitid	KwuK29hKRyXO7hhx;

4.12.2.32
date	2014.01.26.18.34.20;	author rsprowson;	state Exp;
branches;
next	4.12.2.33;
commitid	cMl8ftJxfN0xMEmx;

4.12.2.33
date	2014.03.23.14.36.09;	author jlee;	state Exp;
branches;
next	4.12.2.34;
commitid	RkutfyF7UjUdFPtx;

4.12.2.34
date	2014.03.23.20.31.01;	author rsprowson;	state Exp;
branches;
next	4.12.2.35;
commitid	PmN1xYlDslRNCRtx;

4.12.2.35
date	2014.04.19.14.45.41;	author jlee;	state Exp;
branches;
next	4.12.2.36;
commitid	41mDnYJhlOjHQixx;

4.12.2.36
date	2014.04.20.18.56.36;	author jlee;	state Exp;
branches;
next	4.12.2.37;
commitid	gm3fCQRphk0Ncsxx;

4.12.2.37
date	2015.08.05.21.51.29;	author jlee;	state Exp;
branches;
next	4.12.2.38;
commitid	SpZpzVH47zb408wy;

4.12.2.38
date	2015.08.14.22.02.31;	author jlee;	state Exp;
branches;
next	4.12.2.39;
commitid	6gyfvmM0cNZULhxy;

4.12.2.39
date	2015.08.31.19.28.37;	author jlee;	state Exp;
branches;
next	4.12.2.40;
commitid	Ni3KL17bG70fnszy;

4.12.2.40
date	2016.03.10.22.57.40;	author jlee;	state Exp;
branches;
next	;
commitid	DAXUqMY2ucjim9Yy;

4.12.2.22.2.1
date	2009.03.06.23.23.41;	author jlee;	state Exp;
branches;
next	4.12.2.22.2.2;

4.12.2.22.2.2
date	2009.11.06.23.17.45;	author jlee;	state Exp;
branches;
next	4.12.2.22.2.3;

4.12.2.22.2.3
date	2011.08.08.23.28.26;	author jlee;	state Exp;
branches;
next	;
commitid	D7rzILnwRRSXoLuv;

4.12.2.25.2.1
date	2012.07.20.00.51.55;	author bavison;	state Exp;
branches;
next	4.12.2.25.2.2;
commitid	ELcSZZYPVgQ6Kedw;

4.12.2.25.2.2
date	2012.09.18.15.50.00;	author jlee;	state Exp;
branches;
next	;
commitid	jeuxYpI6CQUxM1lw;

4.3.2.1
date	97.05.21.09.30.02;	author mstphens;	state Exp;
branches;
next	4.3.2.2;

4.3.2.2
date	97.09.09.13.32.54;	author mstphens;	state Exp;
branches;
next	4.3.2.3;

4.3.2.3
date	97.10.21.15.31.02;	author mstphens;	state Exp;
branches;
next	4.3.2.4;

4.3.2.4
date	97.12.08.14.34.10;	author mstphens;	state Exp;
branches;
next	4.3.2.5;

4.3.2.5
date	98.03.26.11.25.15;	author mstphens;	state Exp;
branches
	4.3.2.5.2.1;
next	4.3.2.6;

4.3.2.6
date	98.09.24.13.16.56;	author mstphens;	state Exp;
branches;
next	;

4.3.2.5.2.1
date	98.11.23.14.58.59;	author mstphens;	state Exp;
branches;
next	;

4.1.1.1
date	96.11.05.09.41.09;	author nturton;	state Exp;
branches;
next	;

4.1.3.1
date	96.11.06.01.59.34;	author nturton;	state Exp;
branches
	4.1.3.1.2.1;
next	4.1.3.2;

4.1.3.2
date	97.05.01.08.09.17;	author kbracey;	state Exp;
branches;
next	;

4.1.3.1.2.1
date	97.04.30.16.45.54;	author kbracey;	state Exp;
branches;
next	;

4.1.5.1
date	96.11.21.12.10.37;	author nturton;	state Exp;
branches;
next	;

4.1.7.1
date	96.11.29.21.03.17;	author nturton;	state Exp;
branches;
next	4.1.7.2;

4.1.7.2
date	97.04.21.15.41.54;	author scormie;	state Exp;
branches;
next	4.1.7.3;

4.1.7.3
date	97.04.23.13.22.38;	author nturton;	state Exp;
branches;
next	;


desc
@@


4.26
log
@Implement support for cacheable pagetables
Detail:
  Modern ARMs (ARMv6+) introduce the possibility for the page table walk hardware to make use of the data cache(s) when performing memory accesses. This can significantly reduce the cost of a TLB miss on the system, and since the accesses are cache-coherent with the CPU it allows us to make the page tables cacheable for CPU (program) accesses also, improving the performance of page table manipulation by the OS.
  Even on ARMs where the page table walk can't use the data cache, it's been measured that page table manipulation operations can still benefit from placing the page tables in write-through or bufferable memory.
  So with that in mind, this set of changes updates the OS to allow cacheable/bufferable page tables to be used by the OS + MMU, using a system-appropriate cache policy.
  File changes:
  - hdr/KernelWS - Allocate workspace for storing the page flags that are to be used by the page tables
  - hdr/OSMem - Re-specify CP_CB_AlternativeDCache as having a different behaviour on ARMv6+ (inner write-through, outer write-back)
  - hdr/Options - Add CacheablePageTables option to allow switching back to non-cacheable page tables if necessary. Add SyncPageTables var which will be set {TRUE} if either the OS or the architecture requires a DSB after writing to a faulting page table entry.
  - s/ARM600, s/VMSAv6 - Add new SetTTBR & GetPageFlagsForCacheablePageTables functions. Update VMSAv6 for wider XCBTable (now 2 bytes per element)
  - s/ARMops - Update pre-ARMv7 MMU_Changing ARMops to drain the write buffer on entry if cacheable pagetables are in use (ARMv7+ already has this behaviour due to architectural requirements). For VMSAv6 Normal memory, change the way that the OS encodes the cache policy in the page table entries so that it's more compatible with the encoding used in the TTBR.
  - s/ChangeDyn - Update page table page flag handling to use PageTable_PageFlags. Make use of new PageTableSync macro.
  - s/Exceptions, s/AMBControl/memmap - Make use of new PageTableSync macro.
  - s/HAL - Update MMU initialisation sequence to make use of PageTable_PageFlags + SetTTBR
  - s/Kernel - Add PageTableSync macro, to be used after any write to a faulting page table entry
  - s/MemInfo - Update OS_Memory 0 page flag conversion. Update OS_Memory 24 to use new symbol for page table access permissions.
  - s/MemMap2 - Use PageTableSync. Add routines to enable/disable cacheable pagetables
  - s/NewReset - Enable cacheable pagetables once we're fully clear of the MMU initialision sequence (doing earlier would be trickier due to potential double-mapping)
Admin:
  Tested on pretty much everything currently supported
  Delivers moderate performance benefits to page table ops on old systems (e.g. 10% faster), astronomical benefits on some new systems (up to 8x faster)
  Stats: https://www.riscosopen.org/forum/forums/3/topics/2728?page=2#posts-58015


Version 5.71. Tagged as 'Kernel-5_71'
@
text
@; Copyright 1996 Acorn Computers Ltd
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;
; > ARM600

        ; Convert given page flags to the equivalent temp uncacheable L2PT flags
        ; n.b. temp not used here but included for VMSAv6 compatibility
        MACRO
        GetTempUncache $out, $pageflags, $pcbtrans, $temp
        ASSERT  $out <> $pageflags ; For consistency with VMSAv6 version
        ASSERT  $out <> $pcbtrans
      [ "$temp" <> ""
        ASSERT  $out <> $temp      ; For consistency with VMSAv6 version
        ASSERT  $temp <> $pcbtrans ; For consistency with VMSAv6 version
      ]
        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4
        AND     $out, $pageflags, #DynAreaFlags_NotCacheable + DynAreaFlags_NotBufferable
        ORR     $out, $out, #DynAreaFlags_NotCacheable      ; treat as temp uncache
        LDRB    $out, [$pcbtrans, $out, LSR #4]             ; convert to X, C and B bits for this CPU
        MEND

TempUncache_L2PTMask * L2_X+L2_C+L2_B

; MMU interface file - ARM600 version

        KEEP

; **************** CAM manipulation utility routines ***********************************

; **************************************************************************************
;
;       BangCamUpdate - Update CAM, MMU for page move, coping with page currently mapped in
;
; mjs Oct 2000
; reworked to use generic ARM ops (vectored to appropriate routines during boot)
;
; First look in the CamEntries table to find the logical address L this physical page is
; currently allocated to. Then check in the Level 2 page tables to see if page L is currently
; at page R2. If it is, then map page L to be inaccessible, otherwise leave page L alone.
; Then map logical page R3 to physical page R2.
;
; in:   r2 = physical page number
;       r3 = logical address (2nd copy if doubly mapped area)
;       r9 = offset from 1st to 2nd copy of doubly mapped area (either source or dest, but not both)
;       r11 = PPL + CB bits
;
; out:  r0, r1, r4, r6 corrupted
;       r2, r3, r5, r7-r12 preserved
;

BangCamUpdate ROUT
        TST     r11, #DynAreaFlags_DoublyMapped ; if moving page to doubly mapped area
        SUBNE   r3, r3, r9                      ; then CAM soft copy holds ptr to 1st copy

        LDR     r1, =ZeroPage
        LDR     r1, [r1, #CamEntriesPointer]
        ADD     r1, r1, r2, LSL #CAM_EntrySizeLog2 ; point at cam entry (logaddr, PPL)
        ASSERT  CAM_LogAddr=0
        ASSERT  CAM_PageFlags=4
        LDMIA   r1, {r0, r6}                    ; r0 = current logaddress, r6 = current PPL
        BIC     r4, r11, #PageFlags_Unsafe
        STMIA   r1, {r3, r4}                    ; store new address, PPL
        Push    "r0, r6"                        ; save old logical address, PPL
        LDR     r1, =ZeroPage+PhysRamTable      ; go through phys RAM table
        MOV     r6, r2                          ; make copy of r2 (since that must be preserved)
10
        LDMIA   r1!, {r0, r4}                   ; load next address, size
        SUBS    r6, r6, r4, LSR #12             ; subtract off that many pages
        BCS     %BT10                           ; if more than that, go onto next bank

        ADD     r6, r6, r4, LSR #12             ; put back the ones which were too many
        ADD     r0, r0, r6, LSL #12             ; move on address by the number of pages left
        LDR     r6, [sp]                        ; reload old logical address

; now we have r6 = old logical address, r2 = physical page number, r0 = physical address

        TEQ     r6, r3                          ; TMD 19-Jan-94: if old logaddr = new logaddr, then
        BEQ     %FT20                           ; don't remove page from where it is, to avoid window
                                                ; where page is nowhere.
        LDR     r1, =L2PT
        ADD     r6, r1, r6, LSR #10             ; r6 -> L2PT entry for old log.addr
        MOV     r4, r6, LSR #12                 ; r4 = word offset into L2 for address r6
        LDR     r4, [r1, r4, LSL #2]            ; r4 = L2PT entry for L2PT entry for old log.addr
        TST     r4, #3                          ; if page not there
        BEQ     %FT20                           ; then no point in trying to remove it

        LDR     r4, [r6]                        ; r4 = L2PT entry for old log.addr
        MOV     r4, r4, LSR #12                 ; r4 = physical address for old log.addr
        TEQ     r4, r0, LSR #12                 ; if equal to physical address of page being moved
        BNE     %FT20                           ; if not there, then just put in new page

        AND     r4, r11, #PageFlags_Unsafe
        Push    "r0, r3, r11, r14"              ; save phys.addr, new log.addr, new PPL, lr
        ADD     r3, sp, #4*4
        LDMIA   r3, {r3, r11}                   ; reload old logical address, old PPL
        LDR     r0, =DuffEntry                  ; Nothing to do if wasn't mapped in
        ORR     r11, r11, r4
        TEQ     r3, r0
        MOV     r0, #0                          ; cause translation fault
        BLNE    BangL2PT                        ; map page out
        Pull    "r0, r3, r11, r14"
20
        ADD     sp, sp, #8                      ; junk old logical address, PPL
        B       BangCamAltEntry                 ; and branch into BangCam code

; **************************************************************************************
;
;       BangCam - Update CAM, MMU for page move, assuming page currently mapped out
;
; This routine maps a physical page to a given logical address
; It is assumed that the physical page is currently not mapped anywhere else
;
; in:   r2 = physical page number
;       r3 = logical address (2nd copy if doubly mapped)
;       r9 = offset from 1st to 2nd copy of doubly mapped area (either source or dest, but not both)
;       r11 = PPL
;
; out:  r0, r1, r4, r6 corrupted
;       r2, r3, r5, r7-r12 preserved
;
; NB The physical page number MUST be in range.

BangCam ROUT
        TST     r11, #DynAreaFlags_DoublyMapped ; if area doubly mapped
        SUBNE   r3, r3, r9              ; then move ptr to 1st copy

        LDR     r1, =ZeroPage+PhysRamTable ; go through phys RAM table
        MOV     r6, r2                  ; make copy of r2 (since that must be preserved)
10
        LDMIA   r1!, {r0, r4}           ; load next address, size
        SUBS    r6, r6, r4, LSR #12     ; subtract off that many pages
        BCS     %BT10                   ; if more than that, go onto next bank

        ADD     r6, r6, r4, LSR #12     ; put back the ones which were too many
        ADD     r0, r0, r6, LSL #12     ; move on address by the number of pages left
BangCamAltEntry
        LDR     r4, =DuffEntry          ; check for requests to map a page to nowhere
        TEQ     r4, r3                  ; don't actually map anything to nowhere
        MOVEQ   pc, lr
        GetPTE  r0, 4K, r0, r11
 
        LDR     r1, =L2PT               ; point to level 2 page tables

        ;fall through to BangL2PT

;internal entry point for updating L2PT entry
;
; entry: r0 = new L2PT value, r1 -> L2PT, r3 = logical address (4k aligned), r11 = PPL
;
; exit: r0,r1,r4,r6 corrupted
;
BangL2PT                                        ; internal entry point used only by BangCamUpdate
        Push    "lr"
        MOV     r6, r0

        TST     r11, #PageFlags_Unsafe
        BNE     BangL2PT_unsafe

        ;In order to safely map out a cacheable page and remove it from the
        ;cache, we need to perform the following process:
        ;* Make the page uncacheable
        ;* Flush TLB
        ;* Clean+invalidate cache
        ;* Write new mapping (r6)
        ;* Flush TLB
        ;For uncacheable pages we can just do the last two steps
        ;
        TEQ     r6, #0                          ;EQ if mapping out
        TSTEQ   r11, #DynAreaFlags_NotCacheable ;EQ if also cacheable (overcautious for temp uncache+illegal PCB combos)
        LDR     r4, =ZeroPage
        BNE     %FT20
        LDR     lr, [r4, #MMU_PCBTrans]
        GetTempUncache r0, r11, lr
        LDR     lr, [r1, r3, LSR #10]           ;get current L2PT entry
        BIC     lr, lr, #TempUncache_L2PTMask   ;remove current attributes
        ORR     lr, lr, r0
        STR     lr, [r1, r3, LSR #10]!          ;Make uncacheable
        TST     r11, #DynAreaFlags_DoublyMapped
        BEQ     %FT19
        STR     lr, [r1, r9, LSR #10]           ;Update 2nd mapping too if required
        ADD     r0, r3, r9
        ARMop   MMU_ChangingEntry,,, r4
19
        MOV     r0, r3
        ARMop   MMU_ChangingEntry,,, r4
        LDR     r1, =L2PT

20      STR     r6, [r1, r3, LSR #10]!          ;update L2PT entry
        TST     r11, #DynAreaFlags_DoublyMapped
        BEQ     %FT21
        STR     r6, [r1, r9, LSR #10]           ;Update 2nd mapping
        MOV     r0, r3
        ARMop   MMU_ChangingUncachedEntry,,, r4 ; TLB flush for 1st mapping
        ADD     r3, r3, r9                      ;restore r3 back to 2nd copy
21
        Pull    "lr"
        MOV     r0, r3
        ARMop   MMU_ChangingUncachedEntry,,tailcall,r4

BangL2PT_unsafe
        STR     r6, [r1, r3, LSR #10]!          ; update level 2 page table (and update pointer so we can use bank-to-bank offset
        TST     r11, #DynAreaFlags_DoublyMapped ; if area doubly mapped
        STRNE   r6, [r1, r9, LSR #10]           ; then store entry for 2nd copy as well
        ADDNE   r3, r3, r9                      ; and point logical address back at 2nd copy
        Pull    "pc"

 [ ARM6support
PPLTransARM6
        &       (AP_Full * L2_APMult) + L2_SmallPage      ; R any W any
        &       (AP_Read * L2_APMult) + L2_SmallPage      ; R any W sup
        &       (AP_None * L2_APMult) + L2_SmallPage      ; R sup W sup
        &       (AP_Read * L2_APMult) + L2_SmallPage      ; R any W sup

PPLAccessARM6        ; EL1EL0
                     ; RWXRWX
        GenPPLAccess 2_111111
        GenPPLAccess 2_111101
        GenPPLAccess 2_111000
        GenPPLAccess 2_111101
        DCD     -1
 ]

PPLTrans
        &       (AP_Full * L2_APMult) + L2_SmallPage      ; R any W any
        &       (AP_Read * L2_APMult) + L2_SmallPage      ; R any W sup
        &       (AP_None * L2_APMult) + L2_SmallPage      ; R sup W sup
        &       (AP_ROM  * L2_APMult) + L2_SmallPage      ; R any W none

PPLTransX
        &       (AP_Full * L2X_APMult) + L2_ExtPage       ; R any W any
        &       (AP_Read * L2X_APMult) + L2_ExtPage       ; R any W sup
        &       (AP_None * L2X_APMult) + L2_ExtPage       ; R sup W sup
        &       (AP_ROM  * L2X_APMult) + L2_ExtPage       ; R any W none

PPLAccess            ; EL1EL0
                     ; RWXRWX
        GenPPLAccess 2_111111
        GenPPLAccess 2_111101
        GenPPLAccess 2_111000
        GenPPLAccess 2_101101
        DCD     -1

PageShifts
        =       12, 13, 0, 14           ; 1 2 3 4
        =       0,  0,  0, 15           ; 5 6 7 8

        LTORG

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; "ARM600"-specific OS_MMUControl code
;

; in:   r0 = 0 (reason code 0, for modify control register)
;       r1 = EOR mask
;       r2 = AND mask
;
;       new control = ((old control AND r2) EOR r1)
;
; out:  r1 = old value
;       r2 = new value
MMUControl_ModifyControl ROUT
        Push    "r0,r3,r4,r5"
        CMP     r1,#0
        CMPEQ   r2,#&FFFFFFFF
        BEQ     MMUC_modcon_readonly
        LDR     r3,=ZeroPage
        LDRB    r5,[r3, #ProcessorArch]
        PHPSEI  r4                      ; disable IRQs while we modify soft copy (and possibly switch caches off/on)

        CMP     r5,#ARMv4
        LDRLO   lr, [r3, #MMUControlSoftCopy]
        ARM_read_control lr,HS          ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
        AND     r2, r2, lr
        EOR     r2, r2, r1
        MOV     r1, lr
        STR     r2, [r3, #MMUControlSoftCopy]
        BIC     lr, r2, r1              ; lr = bits going from 0->1
        TST     lr, #MMUC_C             ; if cache turning on then flush cache before we do it
        BEQ     %FT05

        ARMop   Cache_InvalidateAll,,,r3 ; D-cache turning on, I-cache invalidate is either necessary (both turning on) or a safe side-effect
        B       %FT10

05
        TST     lr, #MMUC_I
        ARMop   IMB_Full,NE,,r3         ; I-cache turning on, Cache_InvalidateAll could be unsafe

10
        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off then clean data cache first
        BEQ     %FT15
        ARMop   Cache_CleanAll,,,r3
15
        ARM_write_control r2
        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off then flush cache afterwards
        BEQ     %FT17
        LDR     r3,=ZeroPage
        ARMop   Cache_InvalidateAll,,,r3 ; D-cache turned off, can safely invalidate I+D
        B       %FT20
17
        TST     lr, #MMUC_I
        BEQ     %FT20
        LDR     r3,=ZeroPage
        ARMop   IMB_Full,,,r3           ; Only I-cache which turned off, clean D-cache & invalidate I-cache
20
        PLP     r4                      ; restore IRQ state
        Pull    "r0,r3,r4,r5,pc"

MMUC_modcon_readonly
        LDR     r3, =ZeroPage
        LDRB    r5, [r3, #ProcessorArch]
        CMP     r5, #ARMv4
        LDRLO   lr, [r3, #MMUControlSoftCopy]
        ARM_read_control lr,HS          ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
        STRHS   lr, [r3, #MMUControlSoftCopy]
        MOV     r1, lr
        MOV     r2, lr
        Pull    "r0,r3,r4,r5,pc"

; If extended pages are supported:
; PPLTrans should contain L2X_AP + L2_ExtPage
; PCBTrans should contain L2_C+L2_B+L2_TEX (for an extended page)
; If extended pages aren't supported:
; PPLTrans should contain L2_AP + L2_SmallPage
; PCBTrans should contain L2_C+L2_B

; In:
; r0 = phys addr (aligned)
; r1 = page flags:
;      DynAreaFlags_APBits
;      DynAreaFlags_NotBufferable
;      DynAreaFlags_NotCacheable
;      DynAreaFlags_CPBits
;      PageFlags_TempUncacheableBits
; r2 -> PPLTrans
; r3 -> PCBTrans
; Out:
; r0 = PTE for 4K page ("small page" or "extended page" depending on PPLTrans)
Get4KPTE ROUT
        Entry   "r4"
        AND     lr, r1, #DynAreaFlags_APBits
        LDR     lr, [r2, lr, LSL #2]
        ; Insert AP bits, page type/size
        ORR     r0, r0, lr
        ; Insert CB+TEX bits
        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4
        TST     r1, #PageFlags_TempUncacheableBits
        AND     r4, r1, #DynAreaFlags_NotCacheable + DynAreaFlags_NotBufferable
        AND     lr, r1, #DynAreaFlags_CPBits
        ORRNE   r4, r4, #DynAreaFlags_NotCacheable      ; if temp uncache, set NC bit, ignore P
        ORREQ   r4, r4, lr, LSR #10-4                   ; else use NC, NB and P bits
        LDRB    r4, [r3, r4, LSR #4]                    ; convert to X, C and B bits for this CPU
        ORR     r0, r0, r4
        EXIT

; In:
; As per Get4KPTE
; Out:
; r0 = PTE for 64K page ("large page")
Get64KPTE ROUT
        Entry   "r4"
        AND     lr, r1, #DynAreaFlags_APBits
        LDR     lr, [r2, lr, LSL #2]
        ; Force to large page
        ORR     r0, r0, #L2_LargePage
        ; Insert AP bits
        AND     lr, lr, #L2X_AP ; If extended pages are supported, we need to expand L2X_AP to L2_AP
        MOV     r4, #L2_APMult/L2X_APMult
        MLA     r0, r4, lr, r0
50
        ; Insert CB+TEX bits
        ; Shared with Get1MPTE
        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4
        TST     r1, #PageFlags_TempUncacheableBits
        AND     r4, r1, #DynAreaFlags_NotCacheable + DynAreaFlags_NotBufferable
        AND     lr, r1, #DynAreaFlags_CPBits
        ORRNE   r4, r4, #DynAreaFlags_NotCacheable      ; if temp uncache, set NC bit, ignore P
        ORREQ   r4, r4, lr, LSR #10-4                   ; else use NC, NB and P bits
        LDRB    r4, [r3, r4, LSR #4]                    ; convert to X, C and B bits for this CPU
        ; Move TEX field up
        ORR     r4, r4, r4, LSL #L2L_TEXShift-L2_TEXShift
        BIC     r4, r4, #L2_TEX :OR: ((L2_C+L2_B) :SHL: (L2L_TEXShift-L2_TEXShift))
        ORR     r0, r0, r4
        EXIT

; In:
; As per Get4KPTE
; Out:
; r0 = PTE for 1M page ("section")
Get1MPTE
        ALTENTRY
        AND     lr, r1, #DynAreaFlags_APBits
      [ ARM6support
        ; Set U bit if cacheable and not ROM access
        ; (Because ROM access isn't supported, it'll get mapped to AP_Read.
        ;  Writes to ROM will presumably be ignored by the bus, but if we have
        ;  U set it will update the cache, effectively giving people the power
        ;  to temporarily overwrite ROM)
        CMP     lr, #2
        TSTLS   r1, #DynAreaFlags_NotCacheable        
        ORREQ   r0, r0, #L1_U
      ]
        LDR     lr, [r2, lr, LSL #2]
        ; Force to section map
        ORR     r0, r0, #L1_Section
        ; Insert AP bits
        ASSERT  L1_AP = L2X_AP :SHL: 6
        AND     lr, lr, #L2X_AP
        ORR     r0, r0, lr, LSL #6
        ; Insert CB+TEX bits
        ASSERT  L1_C = L2_C
        ASSERT  L1_B = L2_B
        ASSERT  L1_TEXShift = L2L_TEXShift
        B       %BT50

; In:
; r0 = L2PT entry
; Out:
; r0 = phys addr
; r1 = page flags
;      or -1 if fault
; r2 = page size (bytes)
DecodeL2Entry   ROUT
        ANDS    r2, r0, #3
        MOVEQ   r1, #-1
        MOVEQ   pc, lr
        Entry   "r3-r5"
        ; Get AP bits in low bits
        ASSERT  L2X_APMult = 1:SHL:4
        MOV     r1, r0, LSR #4
        ; Remap TEX+CB so that they're in the same position as an extended page entry
        ASSERT  L2_LargePage < L2_SmallPage
        ASSERT  L2_SmallPage < L2_ExtPage
        CMP     r2, #L2_SmallPage
        AND     r4, r0, #L2_C+L2_B
        ANDLT   lr, r0, #L2L_TEX
        ORRLT   r4, r4, lr, LSR #L2L_TEXShift-L2_TEXShift
        ANDGT   lr, r0, #L2_TEX
        ORRGT   r4, r4, lr
        ; Align phys addr to page size and set up R2
        MOV     r0, r0, LSR #12
        BICLT   r0, r0, #15
        MOV     r0, r0, LSL #12
        MOVLT   r2, #65536
        MOVGE   r2, #4096
20
        ; Common code shared with DecodeL1Entry
        ; Only four PPL possibilities, so just directly decode it
        ; ARM access goes 0 => all R/O, 1 => user none, 2 => user R/O, 3  => user R/W
        ; PPL access goes 0 => user R/W, 1 => user R/O, 2 => user none, 3 => all R/0
        ; i.e. just invert the bits
        AND     r1, r1, #3
        LDR     r3, =ZeroPage
        EOR     r1, r1, #3
        ; Search through PCBTrans for a match on TEX+CB
        ; Funny order is used so that NCNB is preferred over other variants (since NCNB is common fallback)
        LDR     r3, [r3, #MMU_PCBTrans]
        MOV     lr, #3
30
        LDRB    r5, [r3, lr]
        CMP     r5, r4
        BEQ     %FT40
        TST     lr, #2_11
        SUBNE   lr, lr, #1                      ; loop goes 3,2,1,0,7,6,5,4,...,31,30,29,28
        ADDEQ   lr, lr, #7
        TEQ     lr, #35  
        BNE     %BT30                           ; Give up if end of table reached
40
        ; Decode index back into page flags
        ; n.b. temp uncache is ignored (no way we can differentiate between real uncached)
        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4
        AND     r4, lr, #XCB_NC+XCB_NB
        AND     lr, lr, #7*XCB_P
        ORR     r1, r1, r4, LSL #4
        ORR     r1, r1, lr, LSL #10
        EXIT

; In:
; r0 = L1PT entry
; Out:
; r0 = phys addr
; r1 = page flags if 1MB page
;      or -1 if fault
;      or -2 if page table ptr
DecodeL1Entry
        ALTENTRY
        AND     r1, r0, #3
        ASSERT  L1_Fault < L1_Page
        ASSERT  L1_Page < L1_Section
        CMP     r1, #L1_Page
        BGT     %FT50
        MOVLT   r1, #-1
        MOVEQ   r1, #-2
        MOVEQ   r0, r0, LSR #10
        MOVEQ   r0, r0, LSL #10
        EXIT
50
        ; Get AP bits in low bits
        ASSERT  L1_APMult = 1:SHL:10
        MOV     r1, r0, LSR #10
        ; Remap TEX+CB so that they're in the same position as an extended page entry
        ASSERT  L1_C = L2_C
        ASSERT  L1_B = L2_B
        AND     r4, r0, #L1_C+L1_B
        AND     lr, r0, #L1_TEX
        ORR     r4, r4, lr, LSR #L1_TEXShift-L2_TEXShift
        ; Align phys addr to page size
        MOV     r0, r0, LSR #20
        MOV     r0, r0, LSL #20
        ; Jump to common code to do AP decode + PCBTrans search
        B       %BT20

; In:
; r0 = phys addr (aligned)
; r1 -> ZeroPage
; Out:
; TTBR and any other related registers updated
; If MMU is currently on, it's assumed the mapping of ROM+stack will not be
; affected by this change
SetTTBR ROUT
        ARM_MMU_transbase r0
        MOV     pc, lr

 [ CacheablePageTables
; Out: R0 = desired page flags for the page tables
GetPageFlagsForCacheablePageTables ROUT
        ; For ARMv5 and below the MMU can't read from the L1 cache, so the
        ; best we can do is a write-through cache policy
        LDR     r0, =AreaFlags_PageTablesAccess :OR: (CP_CB_Writethrough :SHL: DynAreaFlags_CPShift)
        MOV     pc, lr
 ]

        END
@


4.25
log
@Make MMU_Changing ARMops perform the sub-operations in a sensible order
Detail:
  For a while we've known that the correct way of doing cache maintenance on ARMv6+ (e.g. when converting a page from cacheable to non-cacheable) is as follows:
  1. Write new page table entry
  2. Flush old entry from TLB
  3. Clean cache + drain write buffer
  The MMU_Changing ARMops (e.g. MMU_ChangingEntry) implement the last two items, but in the wrong order. This has caused the operations to fall out of favour and cease to be used, even in pre-ARMv6 code paths where the effects of improper cache/TLB management perhaps weren't as readily visible.
  This change re-specifies the relevant ARMops so that they perform their sub-operations in the correct order to make them useful on modern ARMs, updates the implementations, and updates the kernel to make use of the ops whereever relevant.
  File changes:
  - Docs/HAL/ARMop_API - Re-specify all the MMU_Changing ARMops to state that they are for use just after a page table entry has been changed (as opposed to before - e.g. 5.00 kernel behaviour). Re-specify the cacheable ones to state that the TLB invalidatation comes first.
  - s/ARM600, s/ChangeDyn, s/HAL, s/MemInfo, s/VMSAv6, s/AMBControl/memmap - Replace MMU_ChangingUncached + Cache_CleanInvalidate pairs with equivalent MMU_Changing op
  - s/ARMops - Update ARMop implementations to do everything in the correct order
  - s/MemMap2 - Update ARMop usage, and get rid of some lingering sledgehammer logic from ShuffleDoublyMappedRegionForGrow
Admin:
  Tested on pretty much everything currently supported


Version 5.70. Tagged as 'Kernel-5_70'
@
text
@d534 20
@


4.24
log
@Place restrictions on the use of cacheable doubly-mapped DAs
Detail:
  The kernel has always allowed software to create cacheable doubly-mapped DAs, despite the fact that the VIVT caches used on ARMv5 and below would have no way of keeping both of the mappings coherent
  This change places restrictions the following restrictions on doubly-mapped areas, to ensure that cache settings which can't be supported by the cache architecture of the CPU can't be selected:
  * On ARMv6 and below, cacheable doubly-mapped areas aren't supported.
    * Although ARMv6 has VIPT data caches, it's also subject to page colouring constraints which would require us to force the DA size to be a multiple of 16k. So for now keep things simple and disallow cacheable doubly-mapped areas on ARMv6.
  * On ARMv7 and above, cacheable doubly-mapped areas are allowed, but only if they are marked non-executable
    * The blocker to allowing executable cacheable doubly-mapped areas are the VIPT instruction caches; OS_SynchroniseCodeAreas (or callers of it) would need to know that a doubly-mapped area is in use so that they can flush both mappings from the I-cache. Although some chips do have PIPT instruction caches, again it isn't really worth supporting executable cacheable doubly-mapped areas at the moment.
  These changes also allow us to get rid of the expensive 'sledgehammer' logic when dealing with doubly-mapped areas
  File changes:
  - s/ARM600, s/VMSAv6 - Remove the sledgehammer logic, only perform cache/TLB maintenance for the required areas
  - s/ChangeDyn - Implement the required checks
  - s/MemMap2 - Move some cache maintenance logic into RemoveCacheabilityR0ByMinusR2, which previously would have had to be performed by the caller due to the sledgehammer paranoia
Admin:
  Cacheable doubly-mapped DAs tested on iMx6 (tried making screen memory write-through cacheable; decent performance gain seen)
  Note OS_Memory 0 "make temporarily uncacheable" doesn't work on doubly-mapped areas, so cacheable doubly-mapped areas are not yet safe for general DMA


Version 5.69. Tagged as 'Kernel-5_69'
@
text
@d195 1
a195 4
        ARMop   MMU_ChangingUncachedEntry,,, r4 ; TLB flush
        ADD     r0, r3, r9
        ADD     r1, r0, #4096
        ARMop   Cache_CleanInvalidateRange,,, r4 ; Cache flush
d198 1
a198 4
        ARMop   MMU_ChangingUncachedEntry,,, r4 ; TLB flush
        MOV     r0, r3
        ADD     r1, r3, #4096
        ARMop   Cache_CleanInvalidateRange,,, r4 ; Cache flush
@


4.23
log
@Reimplement AMBControl ontop of the PMP system
Detail:
  With this set of changes, each AMB node is now the owner of a fake DANode which is linked to a PMP.
  From a user's perspective the behaviour of AMBControl is the same as before, but rewriting it to use PMPs internally offers the following (potential) benefits:
  * Reduction in the amount of code which messes with the CAM & page tables, simplifying future work/maintenance. Some of the AMB ops (grow, shrink) now just call through to OS_ChangeDynamicArea. However all of the old AMB routines were well-optimised, so to avoid a big performance hit for common operations not all of them have been removed (e.g. mapslot / mapsome). Maybe one day these optimal routines will be made available for use by regular PMP DAs.
  * Removal of the slow Service_MemoryMoved / Service_PagesSafe handlers that had to do page list fixup after the core kernel had reclaimed/moved pages. Since everything is a PMP, the kernel will now deal with this on behalf of AMB.
  * Removal of a couple of other slow code paths (e.g. Do_AMB_MakeUnsparse calls from OS_ChangeDynamicArea)
  * Potential for more flexible mapping of application space in future, e.g. sparse allocation of memory to the wimp slot
  * Simpler transition to an ASID-based task swapping scheme on ARMv6+?
  Other changes of note:
  * AMB_LazyMapIn switch has been fixed up to work correctly (i.e. turning it off now disables lazy task swapping and all associated code instead of producing a build error)
  * The DANode for the current app should be accessed via the GetAppSpaceDANode macro. This will either return the current AMB DANode, or AppSpaceDANode (if e.g. pre-Wimp). However be aware that AppSpaceDANode retains the legacy behaviour of having a base + size relative to &0, while the AMB DANodes (identifiable via the PMP flag) are sane and have their base + size relative to &8000.
  * Mostly-useless DebugAborts switch removed
  * AMBPhysBin (page number -> phys addr lookup table) removed. Didn't seem to give any tangible performance benefit, and was imposing hidden restrictions on memory usage (all phys RAM fragments in PhysRamTable must be multiple of 512k). And if it really was a good optimisation, surely it should have been applied to all areas of the kernel, not just AMB!
  Other potential future improvements:
  * Turn the fake DANodes into real dynamic areas, reducing the amount of special code needed in some places, but allow the DAs to be hidden from OS_DynamicArea 3 so that apps/users won't get too confused
  * Add a generic abort trapping system to PMPs/DAs (lazy task swapping abort handler is still a special case)
  File changes:
  - s/ARM600, s/VMSAv6, s/ExtraSWIs - Remove DebugAborts
  - s/ArthurSWIs - Remove AMB service call handler dispatch
  - s/ChangeDyn - AMB_LazyMapIn switch fixes. Add alternate internal entry points for some PMP ops to allow the DANode to be specified (used by AMB)
  - s/Exceptions - Remove DebugAborts, AMB_LazyMapIn switch fixes
  - s/Kernel - Define GetAppSpaceDANode macro, AMB_LazyMapIn switch fix
  - s/MemInfo - AMB_LazyMapIn switch fixes
  - s/AMBControl/AMB - Update GETs
  - s/AMBControl/Memory - Remove block size quantisation, AMB_BlockResize (page list blocks are now allocated by PMP code)
  - s/AMBControl/Options - Remove PhysBin definitions, AMBMIRegWords (moved to Workspace file), AMB_LimpidFreePool switch. Add AMB_Debug switch.
  - s/AMBControl/Workspace - Update AMBNode to contain an embedded DANode. Move AMBMIRegWords here from Options file.
  - s/AMBControl/allocate - Fake DA node initialisation
  - s/AMBControl/deallocate - Add debug output
  - s/AMBControl/growp, growshrink, mapslot, mapsome, shrinkp - Rewrite to use PMP ops where possible, add debug output
  - s/AMBControl/main - Remove PhysBin initialisation. Update the enumerate/mjs_info call.
  - s/AMBControl/memmap - Low-level memory mapping routines updated or rewritten as appropriate.
  - s/AMBControl/readinfo - Update to cope with DANode
  - s/AMBControl/service - Remove old service call handlers
  - s/AMBControl/handler - DA handler for responding to PMP calls from OS_ChangeDynamicArea; just calls through to growpages/shrinkpages as appropriate.
Admin:
  Tested on pretty much everything currently supported


Version 5.66. Tagged as 'Kernel-5_66'
@
text
@d170 1
a170 4
        BNE     %FT30

        TST     r11, #DynAreaFlags_DoublyMapped
        BNE     BangL2PT_sledgehammer           ;if doubly mapped, don't try to be clever
d190 10
a199 1
        STR     lr, [r1, r3, LSR #10]           ;Make uncacheable
d207 8
a214 1
20      STR     r6, [r1, r3, LSR #10]           ;update L2PT entry
d219 2
a220 13
BangL2PT_sledgehammer

        ;sledgehammer is super cautious and does cache/TLB coherency on a global basis
        ;should only be used for awkward cases
        ;
        TEQ     r6, #0                          ;EQ if mapping out
        TSTEQ   r11, #DynAreaFlags_NotCacheable ;EQ if also cacheable (overcautious for temp uncache+illegal PCB combos)
        ADR     lr, %FT30
        LDR     r4, =ZeroPage
        ARMop   MMU_Changing, EQ, tailcall, r4
        ARMop   MMU_ChangingUncached, NE, tailcall, r4

30      STR     r6, [r1, r3, LSR #10]!          ; update level 2 page table (and update pointer so we can use bank-to-bank offset
a223 1

@


4.22
log
@Prevent disabling of the D-cache on Cortex-A53. Other OS_MMUControl 0 fixes.
Detail:
  On Cortex-A53, a load/store exclusive instruction will abort if it targets non-cacheable memory or if the D-cache is disabled. Since the correct operation of these instructions is important to the OS and apps, it makes sense to prevent *Cache Off / OS_MMUControl 0 from being able to disable the D-cache on such systems.
  hdr/OSMisc, s/ARMops - Add new OS_PlatformFeatures 0 flag to indicate when disabling of the D-cache isn't allowed
  s/VMSAv6 - Update MMUControl_ModifyControl to force the D-cache to always be on when the "unsafe to disable D-cache" PlatformFeatures flag is set. Also, disallow mismatched I+D cache settings if we have an L2 cache (causes issues due to IMB ops only flushing to PoU), and fix dangerous D-cache invalidation when it's only the I-cache which is being disabled
  s/ARM600 - Clean up MMUControl_ModifyControl a bit so that it's a closer match to the VMSAv6 version, and fix the dangerous D-cache invalidation.
Admin:
  Tested on ARM11, Cortex-A7, Cortex-A53


Version 5.62. Tagged as 'Kernel-5_62'
@
text
@a16 3
        GBLL    DebugAborts
DebugAborts SETL {FALSE}

@


4.21
log
@Build fix
Detail:
  s/ARM600 - Update ARM600 version of GetTempUncache to not check $temp constraints if $temp not supplied
Admin:
  Tungsten/IOMD kernel now builds OK


Version 5.59. Retagged as 'Kernel-5_59'
@
text
@d284 1
a284 1
        Push    "r3,r4,r5"
d294 1
a294 3
        ARM_read_control lr,HS
;        MOVHS   lr,lr,LSL #19
;        MOVHS   lr,lr,LSR #19           ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
a297 9
        LDR     r5, [r3, #ProcessorFlags]
        TST     r5, #CPUFlag_SplitCache
        BEQ     %FT05
 [ {FALSE}
        TST     r2,#MMUC_C              ; if split caches, then I bit mirrors C bit
        ORRNE   r2,r2,#MMUC_I
        BICEQ   r2,r2,#MMUC_I
 ]
05
d301 8
a308 2
        TSTEQ   lr, #MMUC_I
        BEQ     %FT10
a309 3
        Push    "r0"
        ARMop   Cache_InvalidateAll,,,r3
        Pull    "r0"
a313 1
        Push    "r0"
a314 1
        Pull    "r0"
d319 6
a324 1
        TSTNE   lr, #MMUC_I
d326 2
a327 3
        Push    "r0"
        ARMop   Cache_InvalidateAll,,,r3
        Pull    "r0"
d330 1
a330 1
        Pull    "r3,r4,r5,pc"
d337 1
a337 3
        ARM_read_control lr,HS
;        MOVHS   lr,lr,LSL #19
;        MOVHS   lr,lr,LSR #19           ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
d341 1
a341 1
        Pull    "r3,r4,r5,pc"
@


4.20
log
@Misc memory management fixes
Detail:
  s/ChangeDyn - Fix register corruption in PMP_LogOp when mapping a page into a location that already contains a page. Fix excessive TLB flush in AreaShrink.
  s/ARM600, s/VMSAv6 - Add asserts to GetTempUncache to detect invalid register combinations
Admin:
  Tested on BB-xM


Version 5.59. Tagged as 'Kernel-5_59'
@
text
@d26 1
d29 1
@


4.19
log
@Add support for shareable pages and additional access privileges
Detail:
  This set of changes:
  * Refactors page table entry encoding/decoding so that it's (mostly) performed via functions in the MMU files (s.ARM600, s.VMSAv6) rather than on an ad-hoc basis as was the case previously
  * Page table entry encoding/decoding performed during ROM init is also handled via the MMU functions, which resolves some cases where the wrong cache policy was in use on ARMv6+
  * Adds basic support for shareable pages - on non-uniprocessor systems all pages will be marked as shareable (however, we are currently lacking ARMops which broadcast cache maintenance operations to other cores, so safe sharing of cacheable regions isn't possible yet)
  * Adds support for the VMSA XN flag and the "privileged ROM" access permission. These are exposed via RISC OS access privileges 4 and above, taking advantage of the fact that 4 bits have always been reserved for AP values but only 4 values were defined
  * Adds OS_Memory 17 and 18 to convert RWX-style access flags to and from RISC OS access privelege numbers; this allows us to make arbitrary changes to the mappings of AP values 4+ between different OS/hardware versions, and allows software to more easily cope with cases where the most precise AP isn't available (e.g. no XN on <=ARMv5)
  * Extends OS_Memory 24 (CheckMemoryAccess) to return executability information
  * Adds exported OSMem header containing definitions for OS_Memory and OS_DynamicArea
  File changes:
  - Makefile - export C and assembler versions of hdr/OSMem
  - Resources/UK/Messages - Add more text for OS_Memory errors
  - hdr/KernelWS - Correct comment regarding DCacheCleanAddress. Allocate workspace for MMU_PPLTrans and MMU_PPLAccess.
  - hdr/OSMem - New file containing exported OS_Memory and OS_DynamicArea constants, and public page flags
  - hdr/Options - Reduce scope of ARM6support to only cover builds which require ARMv3 support
  - s/AMBControl/Workspace - Clarify AMBNode_PPL usage
  - s/AMBControl/growp, mapslot, mapsome, memmap - Use AreaFlags_ instead of AP_
  - s/AMBControl/main, memmap - Use GetPTE instead of generating page table entry manually
  - s/ARM600 - Remove old coments relating to lack of stack. Update BangCam to use GetPTE. Update PPL tables, removing PPLTransL1 (L1 entries are now derived from L2 table on demand) and adding a separate table for ARM6. Implement the ARM600 versions of the Get*PTE ('get page table entry') and Decode*Entry functions
  - s/ARMops - Add Init_PCBTrans function to allow relevant MMU_PPLTrans/MMU_PCBTrans pointers to be set up during the pre-MMU stage of ROM init. Update ARM_Analyse to set up the pointers that are used post MMU init.
  - s/ChangeDyn - Move a bunch of flags to hdr/OSMem. Rename the AP_ dynamic area flags to AreaFlags_ to avoid name clashes and confusion with the page table AP_ values exported by Hdr:MEMM.ARM600/Hdr:MEMM.VMSAv6. Also generate the relevant flags for OS_Memory 24 so that it can refer to the fixed areas by their name instead of hardcoding the permissions.
  - s/GetAll - GET Hdr:OSMem
  - s/HAL - Change initial page table setup to use DA/page flags and GetPTE instead of building page table entries manually. Simplify AllocateL2PT by removing the requirement for the user to supply the access perimssions that will be used for the area; instead for ARM6 we just assume that cacheable memory is the norm and set L1_U for any L1 entry we create here.
  - s/Kernel - Add GetPTE macro (for easier integration of Get*PTE functions) and GenPPLAccess macro (for easy generation of OS_Memory 24 flags)
  - s/MemInfo - Fixup OS_Memory 0 to not fail on seeing non-executable pages. Implement OS_Memory 17 & 18. Tidy up some error generation. Make OS_Memory 13 use GetPTE. Extend OS_Memory 24 to return (non-) executability information, to use the named CMA_ constants generated by s/ChangeDyn, and to use the Decode*Entry functions when it's necessary to decode page table entries.
  - s/NewReset - Use AreaFlags_ instead of AP_
  - s/VMSAv6 - Remove old comments relating to lack of stack. Update BangCam to use GetPTE. Update PPL tables, removing PPLTransL1 (L1 entries are now derived from L2 table on demand) and adding a separate table for shareable pages. Implement the VMSAv6 versions of the Get*PTE and Decode*Entry functions.
Admin:
  Tested on Raspberry Pi 1, Raspberry Pi 3, Iyonix, RPCEmu (ARM6 & ARM7), comparing before and after CAM and page table dumps to check for any unexpected differences


Version 5.55. Tagged as 'Kernel-5_55'
@
text
@d24 4
@


4.18
log
@Tidy things up a bit
Detail:
  hdr/Options - Reduce the scope of SASTMhatbroken and InterruptDelay switches so that they're only enabled when we're building for ARMv4 targets
  s/ARM600, s/VMSAv6, s/ExtraSWIs, s/Exceptions - Move duplicate code out of s/ARM600 & s/VMSAv6 and into shared locations. OS_UpdateMEMC, the bulk of OS_MMUControl, and OS_SynchroniseCodeAreas are now located in s/ExtraSWIs. Meanwhile the data & prefetch abort veneers have been moved to the new file s/Exceptions. s/ARM600 and s/VMSAv6 are now almost purely to do with the different page table formats.
  s/GetAll - GET s/Exceptions
Admin:
  Tested on Raspberry Pi


Version 5.52. Tagged as 'Kernel-5_52'
@
text
@a59 1
; NB Use of stack is allowed in this routine
d131 1
a131 5
; NB Can't use stack - there might not be one!
;
; NB Also - the physical page number MUST be in range.

; This routine must work in 32-bit mode
a147 1
        LDR     r6, =ZeroPage
a148 1
        LDR     r1, [r6, #ProcessorFlags]
d150 2
a151 21
        TST     r1, #CPUFlag_ExtendedPages
        AND     r4, r11, #3             ; first use PPL bits
        ADREQ   r1, PPLTrans
        ADRNE   r1, PPLTransX           ; always use extended pages if supported
        LDR     r1, [r1, r4, LSL #2]    ; get PPL bits and SmallPage indicator

        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4

        ORR     r0, r0, r1

        LDR     r6, [r6, #MMU_PCBTrans]
        AND     r4, r11, #DynAreaFlags_CPBits
        AND     r1, r11, #DynAreaFlags_NotCacheable + DynAreaFlags_NotBufferable
        TST     r11, #PageFlags_TempUncacheableBits
        ORRNE   r1, r1, #DynAreaFlags_NotCacheable      ; if temp uncache, set NC bit, ignore P
        ORREQ   r1, r1, r4, LSR #10-4                   ; else use NC, NB and P bits
        LDRB    r1, [r6, r1, LSR #4]                    ; convert to X, C and B bits for this CPU
        ORR     r0, r0, r1

d222 6
d229 8
a236 5
PPLTransL1
        &       (AP_Full * L1_APMult) + L1_Section        ; R any W any
        &       (AP_Read * L1_APMult) + L1_Section        ; R any W sup
        &       (AP_None * L1_APMult) + L1_Section        ; R sup W sup
        &       (AP_ROM  * L1_APMult) + L1_Section        ; R any W none
d250 7
a256 5
PageSizes
        &       4*1024                  ; 0 is 4K
        &       8*1024                  ; 4 is 8K
        &       16*1024                 ; 8 is 16
        &       32*1024                 ; C is 32
d345 199
@


4.17
log
@Delete lots of old switches
Detail:
  This change gets rid of the following switches from the source (picking appropriate code paths for a 32bit HAL build):
  * FixCallBacks
  * UseProcessTransfer
  * CanLiveOnROMCard
  * BleedinDaveBell
  * NewStyleEcfs
  * DoVdu23_0_12
  * LCDPowerCtrl
  * HostVdu
  * Print
  * EmulatorSupport
  * TubeInfo
  * AddTubeBashers
  * TubeChar, TubeString, TubeDumpNoStack, TubeNewlNoStack macros
  * FIQDebug
  * VCOstartfix
  * AssemblingArthur (n.b. still defined for safety with anything in Hdr: which uses it, but not used explicitly by the kernel)
  * MouseBufferFix
  * LCDInvert
  * LCDSupport
  * DoInitialiseMode
  * Interruptible32bitModes
  * MouseBufferManager
  * StrongARM (new CacheCleanerHack and InterruptDelay switches added to hdr/Options to cover some functionality that StrongARM previously covered)
  * SAcleanflushbroken
  * StrongARM_POST
  * IrqsInClaimRelease
  * CheckProtectionLink
  * GSWorkspaceInKernelBuffers
  * EarlierReentrancyInDAShrink
  * LongCommandLines
  * ECC
  * NoSPSRcorruption
  * RMTidyDoesNowt
  * RogerEXEY
  * StorkPowerSave
  * DebugForcedReset
  * AssembleKEYV
  * AssemblePointerV
  * ProcessorVectors
  * Keyboard_Type
  Assorted old files have also been deleted.
Admin:
  Identical binary to previous revision for IOMD & Raspberry Pi builds


Version 5.51. Tagged as 'Kernel-5_51'
@
text
@d277 2
a279 16
; SWI OS_UpdateMEMC: Read/write MEMC1 control register

SSETMEMC ROUT

        AND     r10, r0, r1
        LDR     r12, =ZeroPage
        WritePSRc SVC_mode+I_bit+F_bit, r0
        LDR     r0, [r12, #MEMC_CR_SoftCopy] ; return old value
        BIC     r11, r0, r1
        ORR     r11, r11, R10
        BIC     r11, r11, #&FF000000
        BIC     r11, r11, #&00F00000
        ORR     r11, r11, #MEMCADR
        STR     r11, [r12, #MEMC_CR_SoftCopy]

; mjs Oct 2000 kernel/HAL split
d281 1
a281 2
; The kernel itself should now never call this SWI, but grudgingly has
; to maintain at least bit 10 of soft copy
a282 3
; Here, we only mimic action of bit 10 to control video/cursor DMA (eg. for ADFS)
; The whole OS_UpdateMEMC thing would ideally be withdrawn as archaic, but
; unfortunately has not even been deprecated up to now
a283 30
; for reference, the bits of the MEMC1 control register are:
;
; bits 0,1 => unused
; bits 2,3 => page size, irrelevant since always 4K
; bits 4,5 => low ROM access time (mostly irrelevant but set it up anyway)
; bits 6,7 => hi  ROM access time (definitely irrelevant but set it up anyway)
; bits 8,9 => DRAM refresh control
; bit 10   => Video/cursor DMA enable
; bit 11   => Sound DMA enable
; bit 12   => OS mode

        Push  "r0,r1,r4, r14"
        TST   r11, #(1 :SHL: 10)
        MOVEQ r0, #1             ; blank (video DMA disable)
        MOVNE r0, #0             ; unblank (video DMA enable)
        MOV   r1, #0             ; no funny business with DPMS
        ADD   r4, r12, #VduDriverWorkSpace
        LDR   r4, [r4, #CurrentGraphicsVDriver]
        MOV   r4, r4, LSL #24
        ORR   r4, r4, #GraphicsV_SetBlank
        BL    CallGraphicsV
        Pull  "r0,r1,r4, r14"

        WritePSRc SVC_mode+I_bit, r11
        ExitSWIHandler

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
;       SWI OS_MMUControl
;
a291 41
;
; in:   r0 bits 1 to 28 = 0, bit 0 = 1  (reason code 1, for flush request)
;          r0 bit 31 set if cache(s) to be flushed
;          r0 bit 30 set if TLB(s) to be flushed
;          r0 bit 29 set if flush of entry only (else whole flush)
;          r0 bit 28 set if write buffer to be flushed (implied by bit 31)
;       r1 = entry specifier, if r0 bit 29 set
;       (currently, flushing by entry is ignored, and just does full flush)
;
; in:   r0 bits 0-7 = 2: reason code 2, read ARMop
;          r0 bits 15-8 = ARMop index
;
; out:  r0 = ARMop function ptr
;

MMUControlSWI   Entry
        BL      MMUControlSub
        PullEnv
        ORRVS   lr, lr, #V_bit
        ExitSWIHandler

MMUControlSub
        Push    lr
        AND     lr,r0,#&FF
        CMP     lr, #MMUCReason_Unknown
        ADDCC   pc, pc, lr, LSL #2
        B       MMUControl_Unknown
        B       MMUControl_ModifyControl
        B       MMUControl_Flush
        B       MMUControl_GetARMop

MMUControl_Unknown
        ADRL    r0, ErrorBlock_HeapBadReason
 [ International
        BL      TranslateError
 |
        SETV
 ]
        Pull    "pc"


a359 230
MMUControl_Flush
       MOVS     r10, r0
       LDR      r12, =ZeroPage
       ARMop    Cache_CleanInvalidateAll,MI,,r12
       TST      r10,#&40000000
       ARMop    TLB_InvalidateAll,NE,,r12
       TST      r10,#&10000000
       ARMop    DSB_ReadWrite,NE,,r12
       ADDS     r0,r10,#0
       Pull     "pc"

MMUControl_GetARMop
       AND      r0, r0, #&FF00
       CMP      r0, #(ARMopPtrTable_End-ARMopPtrTable):SHL:6
       BHS      MMUControl_Unknown
       ADRL     lr, ARMopPtrTable
       LDR      r0, [lr, r0, LSR #6]
       LDR      r0, [r0]
       Pull     "pc"

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
;       Exception veneers

 [ ChocolateAMB
;  Instruction fetch abort pre-veneer, just to field possible lazy AMB aborts
;
PAbPreVeneer    ROUT
        Push    "r0-r7, lr"               ; wahey, we have an abort stack
        SUB     r0, lr_abort, #4          ; aborting address
        MOV     r2, #1
        BL      AMB_LazyFixUp             ; can trash r0-r7, returns NE status if claimed and fixed up
        Pull    "r0-r7, lr", NE           ; restore regs and
        SUBNES  pc, lr_abort, #4          ; restart aborting instruction if fixed up
        LDR     lr, [sp, #8*4]            ; (not a lazy abort) restore lr
        LDR     r0, =ZeroPage+PAbHan      ; we want to jump to PAb handler, in abort mode
        LDR     r0, [r0]
        STR     r0, [sp, #8*4]
        Pull    "r0-r7, pc"
 ]

; Preliminary layout of abort indirection nodes

        ^       0
AI_Link #       4
AI_Low  #       4
AI_High #       4
AI_WS   #       4
AI_Addr #       4

        EXPORT DAbPreVeneer

DAbPreVeneer    ROUT

        SUB     r13_abort, r13_abort, #17*4     ; we use stacks, dontcherknow
        STMIA   r13_abort, {r0-r7}              ; save unbanked registers anyway
        STR     lr_abort, [r13_abort, #15*4]    ; save old PC, ie instruction address

  [ ChocolateAMB
        ARM_read_FAR r0                         ; aborting address
        MOV     r2, #0
        BL      AMB_LazyFixUp                   ; can trash r0-r7, returns NE status if claimed and fixed up
        LDR     lr_abort, [r13_abort, #15*4]    ; restore lr_abort
        LDMIA   r13_abort, {r0-r7}              ; restore regs
        ADDNE   r13_abort, r13_abort, #17*4     ; if fixed up, restore r13_abort
        SUBNES  pc, lr_abort, #8                ; and restart aborting instruction
  ]

        MRS     r0, SPSR                        ; r0 = PSR when we aborted
        MRS     r1, CPSR                        ; r1 = CPSR
        ADD     r2, r13_abort, #8*4             ; r2 -> saved register bank for r8 onwards

        LDR     r4, =ZeroPage+Abort32_dumparea+3*4 ;use temp area (avoid overwriting main area for expected aborts)
        ARM_read_FAR r3
        STMIA   r4, {r0,r3,lr_abort}            ; dump 32-bit PSR, fault address, 32-bit PC

        MOV     r4, lr_abort                    ; move address of aborting instruction into an unbanked register
        BIC     r1, r1, #&1F                    ; knock out current mode bits
        ANDS    r3, r0, #&1F                    ; extract old mode bits (and test for USR26_mode (=0))
        TEQNE   r3, #USR32_mode                 ; if usr26 or usr32 then use ^ to store registers
  [ SASTMhatbroken
        STMEQIA r2!,{r8-r12}
        STMEQIA r2 ,{r13,r14}^
        SUBEQ   r2, r2, #5*4
  |
        STMEQIA r2, {r8-r14}^
  ]
        BEQ     %FT05

        ORR     r3, r3, r1                      ; and put in user's
        MSR     CPSR_c, r3                      ; switch to user's mode

        STMIA   r2, {r8-r14}                    ; save the banked registers

        MRS     r5, SPSR                        ; get the SPSR for the aborter's mode
        STR     r5, [r2, #8*4]                  ; and store away in the spare slot on the end
                                                ; (this is needed for LDM with PC and ^)
        ORR     r1, r1, #ABT32_mode
        MSR     CPSR_c, r1                      ; back to abort mode for the rest of this
05
        Push    "r0"                            ; save SPSR_abort

  [ SASTMhatbroken
        SUB     sp, sp, #3*4
        STMIA   sp, {r13,r14}^                  ; save USR bank in case STM ^, and also so we can corrupt them
        NOP
        STMDB   sp!, {r8-r12}
  |
        SUB     sp, sp, #8*4                    ; make room for r8_usr to r14_usr and PC
        STMIA   sp, {r8-r15}^                   ; save USR bank in case STM ^, and also so we can corrupt them
  ]

        SUB     r11, r2, #8*4                   ; r11 -> register bank
        STR     r4, [sp, #7*4]                  ; store aborter's PC in user register bank

; Call normal exception handler

90

; copy temp area to real area (we believe this is an unexpected data abort now)

        LDR     r0, =ZeroPage+Abort32_dumparea
        LDR     r1, [r0,#3*4]
        STR     r1, [r0]
        LDR     r1, [r0,#4*4]
        STR     r1, [r0,#4]
        LDR     r1, [r0,#5*4]
        STR     r1, [r0,#2*4]

        LDR     r0, =ZeroPage                           ; we're going to call abort handler
      [ ZeroPage = 0
        STR     r0, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      |
        MOV     r2, #0
        STR     r2, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      ]

        LDR     r0, [r0, #DAbHan]                       ; get address of data abort handler
 [ DebugAborts
        DREG    r0, "Handler address = "
 ]

        ADD     r2, r11, #8*4                   ; point r2 at 2nd half of main register bank
        LDMIA   sp, {r8-r14}^                   ; reload user bank registers
        NOP                                     ; don't access banked registers after LDM^
        ADD     sp, sp, #9*4                    ; junk user bank stack frame + saved SPSR

        MRS     r1, CPSR

        MRS     r6, SPSR                        ; get original SPSR, with aborter's original mode
        AND     r7, r6, #&0F
        TEQ     r7, #USR26_mode                 ; also matches USR32
        LDMEQIA r2, {r8-r14}^                   ; if user mode then just use ^ to reload registers
        NOP
        BEQ     %FT80

        ORR     r6, r6, #I32_bit                ; use aborter's flags and mode but set I
        BIC     r6, r6, #T32_bit                ; and don't set Thumb
        MSR     CPSR_c, r6                      ; switch to aborter's mode
        LDMIA   r2, {r8-r14}                    ; reload banked registers
        MSR     CPSR_c, r1                      ; switch back to ABT32

80
        STR     r0, [r13_abort, #16*4]          ; save handler address at top of stack
        LDR     lr_abort, [r13_abort, #15*4]    ; get abort address back in R14

        LDMIA   r13_abort, {r0-r7}              ; reload r0-r7
        ADD     r13_abort, r13_abort, #16*4     ; we use stacks, dontcherknow

        Pull    pc


;
; ---------------- XOS_SynchroniseCodeAreas implementation ---------------
;

;this SWI effectively implements IMB and IMBrange (Instruction Memory Barrier)
;for newer ARMs

;entry:
;   R0 = flags
;        bit 0 set ->  R1,R2 specify virtual address range to synchronise
;                      R1 = start address (word aligned, inclusive)
;                      R2 = end address (word aligned, inclusive)
;        bit 0 clear   synchronise entire virtual space
;        bits 1..31    reserved
;
;exit:
;   R0-R2 preserved
;
SyncCodeAreasSWI ROUT
        Push    "lr"
        BL      SyncCodeAreas
        Pull    "lr"                    ; no error return possible
        B       SLVK

SyncCodeAreas
        TST     R0,#1                   ; range variant of SWI?
        BEQ     SyncCodeAreasFull

SyncCodeAreasRange
        Push    "r0-r2, lr"
        MOV     r0, r1
        ADD     r1, r2, #4                 ;exclusive end address
        LDR     r2, =ZeroPage
        LDRB    lr, [r2, #Cache_Type]
        CMP     lr, #CT_ctype_WB_CR7_Lx ; DCache_LineLen lin or log?
        LDRB    lr, [r2, #DCache_LineLen]
        MOVEQ   r2, #4
        MOVEQ   lr, r2, LSL lr
        LDREQ   r2, =ZeroPage
        SUB     lr, lr, #1
        ADD     r1, r1, lr                 ;rounding up end address
        MVN     lr, lr
        AND     r0, r0, lr                 ;cache line aligned
        AND     r1, r1, lr                 ;cache line aligned
        ARMop   IMB_Range,,,r2
        Pull    "r0-r2, pc"

SyncCodeAreasFull
        Push    "r0, lr"
        LDR     r0, =ZeroPage
        ARMop   IMB_Full,,,r0
        Pull    "r0, pc"

        LTORG

 [ DebugAborts
        InsertDebugRoutines
 ]
@


4.16
log
@Delete pre-HAL and 26bit code
Detail:
  This change gets rid of the following switches from the source (picking appropriate code paths for a 32bit HAL build):
  * HAL
  * HAL26
  * HAL32
  * No26bitCode
  * No32bitCode
  * IncludeTestSrc
  * FixR9CorruptionInExtensionSWI
  Various old files have also been removed (POST code, Arc/STB keyboard drivers, etc.)
Admin:
  Identical binary to previous revision for IOMD & Raspberry Pi builds


Version 5.49. Tagged as 'Kernel-5_49'
@
text
@a19 9
; Disable ProcessTransfer code pending execution.
; If we want to reuse the code at some point in the future, be aware that it
; needs the following work performing:
; * Updating to cope with HiProcVecs (or special zero page handling removed)
; * (preferablly) add support for all the 'new' load/store instructions.
;   LDRH/STRH, LDRD/STRD, coprocessor transfers, etc.
        GBLL    UseProcessTransfer
UseProcessTransfer SETL {FALSE}

a35 53
; Created by TMD 15-Jul-92
; Comments updated by TMD 04-Aug-93

;24-01-96 MJS  now effectively codes for ARM 6 onwards (6,7,8,A, where A = StrongARM)
;              but ARM8 not properly supported (not needed for RO 3.70)
;07-10-96 MJS  proper support for ARM810 added


; Workspace needed for ARM600 work is as follows:
;
; * Level 2 page tables for a contiguous logical area starting at zero
;     This consists of:
;       a) a fixed size bit covering 0 to 192M (currently)
;       b) a variable size bit covering the free pool - 192M to 192M + (memsize rounded up to 4M)
;     Note that the 192M value is sufficient to cover all the fixed size areas at present.
;     As more areas switch to new world, this limit will come down and down, but free pool must always
;      start at the end of the fixed areas.
;     (Level 2 for areas outside this region are allocated dynamically afterwards)
;
; * Level 1 page table (16K, stored in the middle of L2PT, where the I/O + ROM would be if it wasn't section mapped)
;
; * Undefined32 mode stack (8K)
;
; * Abort32 mode stack (8K)
;
; * Soft CAM map (variable size = memsize/4K*8, rounded up to 4K)
;
; In order to make the memory models for MEMC1 and IOMD harmonious, the MEMC1 system is considered as a section of
; video RAM starting at &02000000 size 480K, and an area of "non-video RAM" starting at &02078000, size (totalRAM-480K)
; IOMD has 1 area of video RAM and up to 4 areas of non-video RAM.
;
; (Note: when OS is soft-loaded, a 2 Mbyte chunk of DRAM is removed from the RAM map, therefore the model allows for
;  1 area of video RAM and up to 5 areas of non-video RAM)
;
; The fixed system pages (which include those described above) start at the base of the first bank of non-video RAM
; (on IOMD we allow this to be in any of the 4 RAM sites, ie you don't have to have RAM in any particular SIMM site)
; Consequently the base of the fixed system pages is not known at assembly time, so has to be passed in a register
; to the generic code.
;
; amg 7/12/96 Renaissance, import changes below from Spinner tree, but this is fundamentally the
; 3.70 file.

; 17-Jun-96     BAR     Change speed settings for the second bank of ROM space.
; 09-Jul-96     BAR     Improve IOMD ID vsn code - two places.
;                       Change ROM Speed settings for 7500FE and non-7500FE parts.
; 25-Jul-96     BAR     Correct bug in video bandwidth code, wrong label used.
; 16-Aug-96     JRH     Programming of 2nd ROM bank (IOMD ROMCR1 register):
;                               reinstated ExtROMSupport code, added CanLiveOnROMCard code
;                       MemInitTable:
;                               If ExtROMSupport: added assertion that ImageSize <= 4096
;                               and maps 4MB of each ROM bank.
;                               Otherwise: always maps 8MB of ROM space independant of ImageSize

a563 381
 [ UseProcessTransfer
        TST     r0, #T32_bit                    ; were they in Thumb mode? if so, give up now
        BNE     %FT90

;ARMv4+ allow half-word load/stores - not supported at present
;ARMv5TE+ allow double-word load/stores - not supported at present
;ARMv6 allow load/store exclusive - not supported at present
        LDR     r10, [r4, #-8]!                 ; r10 = actual instruction that aborted, and r4 points to it
        AND     r9, r10, #2_1110 :SHL: 24
        TEQ     r9, #2_1000 :SHL: 24            ; test for LDM/STM
        BNE     %FT50                           ; if not LDM/STM, then it's an "easy" LDR/STR

 [ DebugAborts
        DLINE   "It's an LDM/STM"
 ]

; First count the number of transferred registers, and undo any writeback

        MOV     r9, #0                          ; r9 = no. of registers in list
        MOVS    r8, r10, LSL #16
        BEQ     %FT20
10
        MOVS    r8, r8, LSL #1
        ADDCS   r9, r9, #1
        BNE     %BT10
20
        MOV     r8, r10, LSR #16
        AND     r8, r8, #&0F                    ; base register number
        LDR     r7, [r11, r8, LSL #2]           ; ------""----- value

        TST     r10, #1 :SHL: 23                ; test up/down
        MOVNE   r1, r9                          ; if up, r1 = +ve no. of regs
        RSBEQ   r1, r9, #0                      ; if down, r1 = -ve no. of regs

;initially assume writeback
;we want r6 = base reg value before assumed writeback (r7 is base reg value after abort)
;writeback will have been performed for ARMs with CPUFlag_BaseRestored clear
;
        LDR     r6, =ZeroPage
        LDR     r6, [r6, #ProcessorFlags]
        TST     r6, #CPUFlag_BaseRestored
        MOVNE   r6, r7
        SUBEQ   r6, r7, r1, ASL #2

;now we want r6 to be the base register value before the abort, so we will discard
;our adjusted value and take r7, if the instruction in fact had no writeback
;
        TST     r10, #1 :SHL: 21                ; test if write-back bit set
        TEQNE   r8, #15                         ; (if base is PC then write-back not allowed)
        MOVEQ   r6, r7                          ; if not wb, reg after abort is correct

        MOV     r1, sp                          ; r1 -> end of stack frame, and start of user-mode register bank
        SUB     sp, sp, r9, LSL #2              ; make stack frame for registers
        TST     r10, #1 :SHL: 20                ; if its an STM, we have to load up the stack frame
        BNE     %FT30                           ; but if it's an LDM, we call trap routine first

        STR     r6, [r11, r8, LSL #2]           ; store original base in register list, to be overwritten after 1st transfer

; now go through registers, storing them into frame

        MOV     r5, sp                          ; pointer to position in stack frame
        MOV     lr, r10, LSL #16                ; extract bottom 16 bits
        MOVS    lr, lr, LSR #16                 ; ie bitmask of which registers r0-r15 stored
        BEQ     %FT30                           ; this shouldn't happen (it's illegal)

        MOV     r3, r11                         ; current pointer into register bank
21
        TST     r10, #1 :SHL: 22                ; is it STM with ^
        ANDNE   lr, lr, #&FF                    ; if so then extract bottom 8 bits (r0-r7 on 1st pass, r8-r15 on 2nd)
22
        MOVS    lr, lr, LSR #1                  ; shift bit into carry
        LDRCS   r2, [r3], #4                    ; if set bit then transfer word from register bank
        STRCS   r2, [r5], #4                    ; into stack frame
        STRCS   r7, [r11, r8, LSL #2]           ; and after 1st transfer, store updated base into register bank
        ADDCC   r3, r3, #4                      ; else just increment register bank pointer
        BNE     %BT22                           ; if more bits to do, then loop

        TEQ     r5, r1                          ; have we done all registers?
        MOVNE   lr, r10, LSR #8                 ; no, then must have been doing STM with ^, and have some user-bank regs to store
        MOVNE   r3, r1                          ; so point r3 at user-mode register bank
        BNE     %BT21                           ; and go back into loop

30

; now work out address of 1st transfer

        ANDS    r5, r10, #(3 :SHL: 23)          ; bit 24 set => pre, bit 23 set => inc
        SUBEQ   r2, r6, r9, LSL #2              ; if post-dec, then 1st address = initial-nregs*4+4
        ADDEQ   r2, r2, #4
        BEQ     %FT32

        CMP     r5, #2 :SHL: 23
        MOVCC   r2, r6                          ; CC => post-inc, so 1st address = initial
        SUBEQ   r2, r6, r9, LSL #2              ; EQ => pre-dec,  so 1st address = initial-nregs*4
        ADDHI   r2, r6, #4                      ; HI => pre-inc,  so 1st address = initial+4
32
        ANDS    r0, r10, #1 :SHL: 20            ; r0 = 0 => STM
        MOVNE   r0, #1                          ;    = 1 => LDM
        LDR     r1, [r1, #8*4]                  ; get SPSR_abort
        TST     r1, #&F                         ; test if transfer took place in USR mode
        ORRNE   r0, r0, #2                      ; if not then set bit 1 of flags word in r0
        MOV     r1, sp                          ; block to transfer from/into
        BIC     r2, r2, #3                      ; LDM/STM always present word-aligned address
        MOV     r3, r9, LSL #2                  ; length of transfer in bytes, and r4 still points to aborting instruction
        BL      ProcessTransfer
        ADDVS   sp, sp, r9, LSL #2              ; if invalid transfer then junk stack frame
        BVS     %FT90                           ; and generate an exception

; we transferred successfully, so now check if LDM and load up register bank from block

        TST     r10, #1 :SHL: 20
        ADDEQ   sp, sp, r9, LSL #2              ; it's an STM, so junk stack frame and tidy up
        BEQ     %FT70

; now go through registers, loading them from frame

        ADD     r1, sp, r9, LSL #2              ; r1 -> end of stack frame, and start of user-mode bank registers
        MOV     r5, sp                          ; pointer to position in stack frame
        MOV     r4, r10, LSL #16                ; extract bottom 16 bits
        MOVS    r4, r4, LSR #16                 ; ie bitmask of which registers r0-r15 stored
        BEQ     %FT40                           ; this shouldn't happen (it's illegal)

        SUB     r3, r1, #8*4                    ; r3 -> notional start of user bank, if it began at r0 (it actually starts at r8)
        MOV     r0, #0                          ; assume no user registers by default
        TST     r10, #1 :SHL: 15                ; is PC in list
        BNE     %FT34                           ; then can't be LDM of user bank
        TST     r10, #1 :SHL: 22                ; is it LDM with ^
        BEQ     %FT34                           ; no, then use main bank for all registers
        LDR     r2, [r1, #8*4]                  ; get SPSR
        ANDS    r2, r2, #15                     ; get bottom 4 bits of mode (EQ => USR26 or USR32)
        BEQ     %FT34                           ; if USR mode then use main bank for all
        TEQ     r2, #FIQ26_mode                 ; if FIQ mode then put r8-r14 in user bank
        LDREQ   lr, =&7F00                      ; then put r8-r14 in user bank
        LDRNE   lr, =&6000                      ; else put r13,r14 in user bank
        AND     r0, r4, lr                      ; r0 = mask of registers to put into user bank
        BIC     r4, r4, lr                      ; r4 = mask of registers to put into main bank
34
        MOV     lr, #0
35
        MOVS    r4, r4, LSR #1                  ; shift bit into carry
        LDRCS   r2, [r5], #4                    ; if set bit then transfer word from stack frame
        STRCS   r2, [r11, lr, LSL #2]           ; into main register bank
        MOVS    r0, r0, LSR #1                  ; shift bit into carry
        LDRCS   r2, [r5], #4                    ; if set bit then transfer word from stack frame
        STRCS   r2, [r3, lr, LSL #2]            ; into user register bank
        ADD     lr, lr, #1
        ORRS    r6, r0, r4                      ; have we finished both banks?
        BNE     %BT35                           ; no, then loop

; If LDM with PC in list, then add 4 to it, so the exit procedure is the same as if PC not loaded
; Also, if it was an LDM with PC and ^, then we have to update the stacked SPSR

40
        MOV     sp, r1                          ; junk frame

        TST     r10, #1 :SHL: 15                ; check PC in list
        ADDNE   r2, r2, #4                      ; since PC is last, r2 will still hold the value loaded
        STRNE   r2, [r11, #15*4]                ; store back into main register bank
        TSTNE   r10, #1 :SHL: 22                ; now check LDM ^
        BEQ     %FT70                           ; [not LDM with PC in list]

        LDR     r9, [sp, #8*4]                  ; get SPSR_abort
        AND     r8, r9, #&1F                    ; r8 = aborter's mode
        TEQ     r8, #USR32_mode                 ; if in USR32
        BEQ     %FT70                           ; then the ^ has no effect (actually uses CPSR)
        TST     r8, #&1C                        ; if 32-bit mode
        LDRNE   r7, [r11, #16*4]                ; then use SPSR for the aborter's mode else use updated r15 in r2 (26-bit format)
        ANDEQ   r7, r2, #&F0000003              ; flag and mode bits in same place
        ANDEQ   r2, r2, #&0C000000              ; but I and F have to move to bits 7 and 6
        ORREQ   r7, r7, r2, LSR #(26-6)

; r7 is now desired PSR (in 32-bit format) to update to
; now check which bits can actually be updated

        TEQ     r8, #USR26_mode
        BICEQ   r9, r9, #&F0000000              ; if USR26 then we can only update NZCV
        ANDEQ   r7, r7, #&F0000000
        ORREQ   r9, r9, r7
        MOVNE   r9, r7                          ; else can update all bits
        STR     r9, [sp, #8*4]                  ; store back updated SPSR_abort (to become CPSR)
        B       %FT70                           ; now tidy up

50

; it's an LDR/STR

        TEQ     r9, #2_0000 :SHL: 24            ; is it the extra load/store family?
        BNE     %FT55                           ; no, plain LDR[B]
 [ DebugAborts
        DLINE   "It's LDR[EX|SB|H|SH|D]/STR[EX|H|D]"
 ]
        AND     r9, r10, #2_1111 :SHL: 4
        TEQ     r9, #2_1101 :SHL: 4
        BNE     %FT90                           ; Abort if LDR[EX|H|SH]/STR[EX|H|D]
        TST     r10, #1 :SHL: 20
        BEQ     %FT90                           ; Abort if LDRD (encoded where STRSB would be)

        TST     r10, #1 :SHL: 22                ; if immediate
        BICNE   r9, r10, #2_1111 :SHL: 4
        ORRNE   r9, r9, r9, LSR #4
        ANDNE   r9, r9, #&FF                    ; then extract imm8 bits
        ANDEQ   r8, r10, #&0F                   ; register offset
        LDREQ   r9, [r11, r8, LSL #2]           ; get actual value of register
        ORR     r10, r10, #1 :SHL: 22           ; ensure it looks like a byte access
        B       %FT60
        ; We've effectively reencoded the weird load/stores to look like
        ; cccc 0zxp ubwl nnnn tttt xxxx xxxx xxxx
        ; z = zero/sign extend     b = byte/word
        ; p = pre/post             l = load/store
        ; u = up/down              x = don't care from here on
55
 [ DebugAborts
        DLINE   "It's an LDR[B]/STR[B]"
 ]
        TST     r10, #1 :SHL: 25                ; if immediate
        MOVEQ   r9, r10, LSL #(31-11)           ; then extract bottom 12 bits
        MOVEQ   r9, r9, LSR #(31-11)
        BEQ     %FT60

        AND     r8, r10, #&0F                   ; register to shift
        LDR     r9, [r11, r8, LSL #2]           ; get actual value of register

        MOV     r8, r10, LSR #7                 ; extract shift amount
        ANDS    r8, r8, #&1F                    ; (bits 7..11)
        MOVEQ   r8, #32                         ; if zero then make 32

        ANDS    r7, r10, #&60
        ANDEQ   r8, r8, #&1F                    ; LSL 0 is really zero
        MOVEQ   r9, r9, LSL r8
        TEQ     r7, #&20
        MOVEQ   r9, r9, LSR r8
        TEQ     r7, #&40
        MOVEQ   r9, r9, ASR r8
        TEQ     r7, #&60
        MOVEQ   r9, r9, ROR r8                  ; if 32 then we haven't spoilt it!
        TEQEQ   r8, #32                         ; if ROR #32 then really RRX
        BNE     %FT60
        LDR     r7, [sp, #8*4]                  ; get SPSR
        AND     r7, r7, #C_bit
        CMP     r7, #1                          ; set carry from original user
        MOV     r9, r9, RRX
60
        TST     r10, #1 :SHL: 23                ; test for up/down
        RSBEQ   r9, r9, #0                      ; if down then negate

        LDR     r8, =ZeroPage
        LDR     r8, [r8, #ProcessorFlags]
        TST     r8, #CPUFlag_BaseRestored
        BNE     %FT62
;not base restored
        TST     r10, #1 :SHL: 21                ; if write-back
        MOVNE   r8, #0                          ; then no post-inc
        RSBEQ   r8, r9, #0                      ; else post-inc = - pre-inc
        ADD     r0, r8, r9                      ; amount to subtract off base register for correction

        TST     r10, #1 :SHL: 24                ; however, if we're doing post-increment
        MOVEQ   r8, r9                          ; then post-inc = what was pre-inc
        MOVEQ   r0, r9                          ; and adjustment is what was added on
        RSB     r9, r8, #0                      ; and pre-inc = -post-inc
        B       %FT63
62
;base restored
        TST     r10, #1 :SHL: 21                ; if write-back
        MOVNE   r8, #0                          ; then no post-inc
        RSBEQ   r8, r9, #0                      ; else post-inc = - pre-inc

        TST     r10, #1 :SHL: 24                ; however, if we're doing post-increment
        MOVEQ   r8, r9                          ; then post-inc = what was pre-inc
        MOVEQ   r9, #0                          ; and pre-inc = 0

63
        MOV     r7, r10, LSL #31-19
        MOV     r7, r7, LSR #28                 ; r7 = base register number
        LDR     r6, [r11, r7, LSL #2]           ; r6 = base register value

        LDR     r1, =ZeroPage
        LDR     r1, [r1, #ProcessorFlags]
        TST     r1, #CPUFlag_BaseRestored
        SUBEQ   r0, r6, r0                      ; compute adjusted base register (if not base restored)
        STREQ   r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all

; no need to clear PSR bits out of R15, because PSR is separate

        ADD     r9, r9, r6                      ; r2 = offset+base = illegal address

 [ DebugAborts
        DREG    r9, "Aborting address = "
        DREG    r8, "Post-increment = "
        DREG    r4, "Instruction where abort happened = "
 ]

        ANDS    r0, r10, #1 :SHL: 20            ; if an LDR then bit 20 set
        MOVNE   r0, #1                          ; so make 1
        SUBNE   sp, sp, #4                      ; then just create 1 word stack frame
        BNE     %FT65

        MOV     r5, r10, LSR #12                ; else it's an STR (r0 = 0)
        AND     r5, r5, #&0F                    ; r5 = source register number
        LDR     r5, [r11, r5, LSL #2]           ; r5 = value of source register
 [ DebugAborts
        DREG    r5, "Data value to store = "
 ]
        Push    "r5"                            ; create stack frame with this value in it
65
        LDR     r1, [sp, #(1+8)*4]              ; get SPSR_abort
        TST     r1, #&F                         ; test if transfer took place in USR mode
        ORRNE   r0, r0, #2                      ; if not then set bit 1 of flags word in r0

        MOV     r1, sp                          ; r1 -> data block
        TST     r10, #1 :SHL: 22                ; if byte transfer
        MOVNE   r3, #1                          ; then length of transfer = 1
        MOVNE   r2, r9                          ; and use unmolested address
        MOVEQ   r3, #4                          ; else length = 4
        BICEQ   r2, r9, #3                      ; and mask out bottom 2 bits of address

        BL      ProcessTransfer
        ADDVS   sp, sp, #4                      ; if illegal transfer, junk stack frame
        BVS     %FT90                           ; and cause exception

        ADD     r6, r9, r8                      ; update base register with offset
        STR     r6, [r11, r7, LSL #2]           ; and store back (NB if LDR and dest=base, the load overwrites the updated base)

        TST     r10, #1 :SHL: 20                ; if it's STR (not LDR)
        ADDEQ   sp, sp, #4                      ; then junk stack frame
        BEQ     %FT70                           ; and tidy up

        Pull    "r6"                            ; LDR/LDRB/LDRSB: get value to load into register
        TST     r10, #1 :SHL: 22
        BEQ     %FT67
        TST     r10, #1 :SHL: 26                ; LDRB: see if zero fill or sign extend is needed
        MOVEQ   r6, r6, LSL #24
        MOVEQ   r6, r6, ASR #24                 ; fill with b7
        ANDNE   r6, r6, #&FF                    ; fill with zero
        B       %FT69
67
        AND     r9, r9, #3                      ; LDR: rotate word to correct position - r9 = bottom 2 bits of address
        MOV     r9, r9, LSL #3                  ; multiply by 8 to get rotation factor
        MOV     r6, r6, ROR r9                  ; rotate to correct position in register
69
        MOV     r5, r10, LSR #12                ; test for LDR PC
        AND     r5, r5, #&0F                    ; r5 = dest register number
        TEQ     r5, #15                         ; if PC
        ADDEQ   r6, r6, #4                      ; then adjust for abort exit
        STR     r6, [r11, r5, LSL #2]           ; store into register bank

70

; Tidy up routine, common to LDR/STR and LDM/STM

        ADD     r2, r11, #8*4                   ; point r2 at 2nd half of main register bank
        LDMIA   sp, {r8-r14}^                   ; reload user bank registers
        NOP                                     ; don't access banked registers after LDM^
        ADD     sp, sp, #8*4                    ; junk user bank stack frame

        Pull    "r0"                            ; r0 = (possibly updated) SPSR_abort
        MRS     r1, CPSR

        MRS     r6, SPSR                        ; get original SPSR, with aborter's original mode
        AND     r7, r6, #&0F
        TEQ     r7, #USR26_mode                 ; also matches USR32
        LDMEQIA r2, {r8-r14}^                   ; if user mode then just use ^ to reload registers
        NOP
        BEQ     %FT80

        ORR     r6, r6, #I32_bit                ; use aborter's flags and mode but set I
        BIC     r6, r6, #T32_bit                ; and don't set Thumb bit
        MSR     CPSR_c, r6                      ; switch to aborter's mode
        LDMIA   r2, {r8-r14}                    ; reload banked registers
        MSR     CPSR_c, r1                      ; switch back to ABT32

80
        LDR     lr_abort, [r13_abort, #15*4]    ; get PC to return to
        MSR     SPSR_cxsf, r0                   ; set up new SPSR (may have changed for LDM {PC}^)

        LDMIA   r13_abort, {r0-r7}              ; reload r0-r7
        ADD     r13_abort, r13_abort, #17*4     ; we use stacks, dontcherknow
        SUBS    pc, lr_abort, #4                ; go back 8 to adjust for PC being 2 words out,
                                                ; then forward 4 to skip instruction we've just executed

 ] ; UseProcessTransfer

a620 285
 [ UseProcessTransfer

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
;       ProcessTransfer - Process an abort transfer
;
; in:   r0 = flags
;               bit 0 = 0 => Store to memory
;                       1 => Load from memory
;               bit 1 = 0 => Transfer executed in user mode
;                       1 => Transfer executed in non-user mode
;       r1 = block of data to transfer from/into
;       r2 = illegal address
;       r3 = length of transfer in bytes
;       r4 -> instruction which aborted
;       SVC26/32 mode
;
; out:  V=0 => transfer accomplished
;       V=1 => transfer not accomplished
;       All registers preserved
;

SectionSizeShift *      20
SectionSize     *       1 :SHL: SectionSizeShift

LargePageSizeShift *    16
LargePageSize   *       1 :SHL: LargePageSizeShift

SmallPageSizeShift *    12
SmallPageSize   *       1 :SHL: SmallPageSizeShift

ProcessTransfer Entry "r1-r7,r12"

 [ DebugAborts
        DLINE   "ProcessTransfer entered"
        DREG    r2, "Illegal address = "
        DREG    r3, "Length of transfer = "
        DREG    r4, "Abort happened at address "
        DREG    r0, "Flags = "
        DLINE   "Data = ",cc

        MOV     r5, r3
        MOV     r6, r1
01
        LDR     r7, [r6], #4
        DREG    r7," ",cc
        SUBS    r5, r5, #4
        BHI     %BT01
        DLINE   ""
 ]


; First identify if start address should have aborted

10
        LDR     r7, =L1PT
        MOV     lr, r2, LSR #SectionSizeShift           ; r2 as a multiple of 1Mb
        EOR     r5, r2, lr, LSL #SectionSizeShift       ; r5 = offset within section
        SUB     r5, r2, r5                              ; r5 -> start of section containing r2
        ADD     r5, r5, #SectionSize                    ; r5 -> start of section after r2

        LDR     lr, [r7, lr, LSL #2]                    ; get L1PT entry
        ANDS    r7, lr, #3                              ; 00 => trans.fault, 01 => page, 10 => section, 11 => reserved (fault)
        TEQNE   r7, #3
        BEQ     Fault
        TEQ     r7, #1
        BEQ     CheckPage

; it's section mapped - check section access privileges

15
        ANDS    r7, lr, #3 :SHL: 10                     ; extract ap
        BEQ     Fault                                   ; 00 => no access for anyone (at the moment)
        TST     r0, #2                                  ; test for non-usr access
        BNE     %FT20                                   ; if non-usr then OK to access here
        CMP     r7, #2 :SHL: 10
        BCC     Fault                                   ; 01 => no usr access
        BHI     %FT20                                   ; 11 => full user access, so OK
        TST     r0, #1
        BEQ     Fault                                   ; 10 => usr read-only, so stores not allowed

; access OK, so copy up to end of section/sub-page

20
;ARM 8 and StrongARM will abort for vector reads (as well as writes) in 26bit mode, so we must
;handle vector reads properly as well now
;In fact, StrongARM does not abort (optional in architecture 4), but ARM 8 does - MJS 08-10-96
  [ {FALSE}
        TST     r0, #1                                  ; if load from memory
        BNE     %FT60                                   ; then skip
  ]

; it's a store to memory (may be a vector write), or a read from memory (may be a vector read)
; do it in words if >= 4 bytes, so word writes to VIDC work for example

25
        ASSERT  (:LNOT: HiProcVecs) ; Needs updating for high vectors!
        CMP     r2, #&1C                                ; if in abort area (but allow any access to &1C)
  [ OnlyKernelCanAccessHardwareVectors
        BHS     %FT22
        CMP     r4, #ROM                                ; and executing outside the kernel
        BLO     %FT23
        ADRL    lr, EndOfKernel
        CMP     r4, lr
        BLO     %FT22
23
        MOV     r5, #&20                                ; then set end-of-section = 32
        B       Fault                                   ; and check user list
22
  |
        CMPCC   r4, #ROM                                ; and executing out of RAM
        MOVCC   r5, #&20                                ; then set end-of-section = 32
        BCC     Fault                                   ; and check user list
  ]

        TST     r0, #1                                  ; test for peek/poke
        BEQ     %FT30
26
;peeking
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BEQ     %FT50                                   ; if so then exit if finished else go back to outer loop
        SUBS    r3, r3, #4                              ; have we got at least a word to do?
        LDRCS   lr, [r2], #4                            ; if so then copy word
        STRCS   lr, [r1], #4
        BHI     %BT26                                   ; and if not all done then loop
        BEQ     %FT50                                   ; if all done then switch back to SVC26 and exit

        ADDS    r3, r3, #4
27
        LDRB    lr, [r2], #1                            ; read byte from register bank
        STRB    lr, [r1], #1                            ; and store to memory
        SUBS    r3, r3, #1                              ; decrement byte count
        BEQ     %FT50                                   ; if finished then switch back to SVC26 and exit
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BNE     %BT27                                   ; no, then loop
        B       %FT50

30
;poking
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BEQ     %FT50                                   ; if so then exit if finished else go back to outer loop
        SUBS    r3, r3, #4                              ; have we got at least a word to do?
        LDRCS   lr, [r1], #4                            ; if so then copy word
        STRCS   lr, [r2], #4
        BHI     %BT30                                   ; and if not all done then loop
        BEQ     %FT50                                   ; if all done then switch back to SVC26 and exit

        ADDS    r3, r3, #4
40
        LDRB    lr, [r1], #1                            ; read byte from register bank
        STRB    lr, [r2], #1                            ; and store to memory
        SUBS    r3, r3, #1                              ; decrement byte count
        BEQ     %FT50                                   ; if finished then switch back to SVC26 and exit
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BNE     %BT40                                   ; no, then loop

50
        CMP     r3, #0
        BNE     %BT10
        EXIT                                            ; exit (VC from CMP)

  [ {FALSE}
; it's a load from memory
60
        LDRB    lr, [r2], #1                            ; read byte from memory
        STRB    lr, [r1], #1                            ; and store to memory bank
        SUBS    r3, r3, #1                              ; decrement byte count
        EXIT    EQ                                      ; if finished then exit (VC from SUBS)
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BNE     %BT60                                   ; no, then loop
        B       %BT10                                   ; yes, then go back to start
  ]

; it's page mapped, so check L2PT
; lr = L1 table entry
; We use the logical copy of physical space here, in order to access the entry pointed to by the L1 entry

CheckPage
        MOV     r5, r2, LSR #SmallPageSizeShift         ; r2 as a multiple of 4K
        MOV     r5, r5, LSL #SmallPageSizeShift
        ADD     r5, r5, #SmallPageSize                  ; if translation fault, then it applies to small page

        MOV     lr, lr, LSR #10                         ; remove domain and U bits
        MOV     lr, lr, LSL #10

        SUB     sp, sp, #4
        Push    "r0-r3,r12"
        MOV     r0, #0
        MOV     r1, lr
        ADD     r2, sp, #5*4
        BL      RISCOS_AccessPhysicalAddress
        MOV     lr, r0
        Pull    "r0-r3,r12"

        AND     r7, r2, #&000FF000                      ; extract bits which are to form L2 offset

        LDR     lr, [lr, r7, LSR #10]                   ; lr = L2PT entry

        Push    "r0-r3,r12,lr"
        LDR     r0, [sp, #6*4]
        BL      RISCOS_ReleasePhysicalAddress
        Pull    "r0-r3,r12,lr"
        ADD     sp, sp, #4

        ANDS    r7, lr, #3                              ; 00 => trans.fault, 01 => large page
                                                        ; 10 => small page, 11 => reserved (fault)
        TEQNE   r7, #3
        BEQ     Fault
        TEQ     r7, #2                          ; if small page
        MOVEQ   r7, #SmallPageSizeShift-2       ; then sub-page size = 1<<10
        MOVNE   r7, #LargePageSizeShift-2       ; else sub-page size = 1<<14

        MOV     r5, r2, LSR r7                  ; round down to start of sub-page
        MOV     r5, r5, LSL r7
        MOV     r6, #1
        ADD     r5, r5, r6, LSL r7              ; then move on to start of next sub-page

        MOV     r7, r2, LSR r7                  ; put sub-page number in bits 1,2
        AND     r7, r7, #3                      ; and junk other bits
        RSB     r7, r7, #3                      ; invert sub-page ordering
        MOV     r7, r7, LSL #1                  ; and double it
        MOV     lr, lr, LSL r7                  ; then shift up access privileges so that correct ones appear in bits 10,11
        B       %BT15                           ; re-use code to check access privileges

Fault
        SUB     r5, r5, r2                      ; r5 = number of bytes we can do in this section/page/sub-page
        Push    "r3"                            ; save number of bytes to do
        CMP     r3, r5                          ; if more bytes than there are in this block
        MOVHI   r3, r5

; Now scan list of user abort addresses

        LDR     r6, =ZeroPage
        LDR     r6, [r6, #AbortIndirection]
        TEQ     r6, #0
        BEQ     %FT85                           ; address not in any abort node
75
        LDR     r5, [r6, #AI_Low]
        CMP     r2, r5
        BCC     %FT80
        LDR     r5, [r6, #AI_High]
        CMP     r2, r5
        BCS     %FT80

        Push    "r3"                            ; save number of bytes we can do in this section/page/sub-page
        SUB     r5, r5, r2                      ; number of bytes we can do for this node
        CMP     r3, r5                          ; if bigger than the size of this node
        MOVHI   r3, r5                          ; then restrict number of bytes

        ADD     r5, r6, #AI_WS
        MOV     lr, pc
        LDMIA   r5, {r12, pc}

; returns to here

        ADDVS   sp, sp, #8                      ; if user abort failed, then junk both pushed r3's
        EXIT    VS                              ; and exit

        ADD     r1, r1, r3                      ; advance register block
        ADD     r2, r2, r3                      ; and illegal address pointer

        LDR     r5, [sp, #4]                    ; subtract amount done from stacked total amount to do
        SUBS    r5, r5, r3
        STR     r5, [sp, #4]                    ; and store back

        Pull    "r5"
        SUBS    r3, r5, r3                      ; is there more to do in this section/page/sub-page?
        BEQ     %FT90                           ; no then skip
80
        LDR     r6, [r6, #AI_Link]              ; else try next node
        TEQ     r6, #0
        BNE     %BT75
85
        ADD     sp, sp, #4                      ; junk pushed r3
        SETV                                    ; indicate access invalid
        EXIT                                    ; and exit

90
        Pull    "r3"                            ; restore total amount left to do
        TEQ     r3, #0
        BNE     %BT10                           ; yes, then loop
        EXIT                                    ; no, then exit (V=0 from SUBS)

 ] ; UseProcessTransfer

@


4.15
log
@Merge HAL branch to trunk
Detail:
  This change merges the past 15+ years of HAL branch development back to the trunk.
  This is effectively the end for non-HAL builds of the kernel, as no attempt has been made to maintain it during this merge, and all non-HAL & non-32bit code will soon be removed anyway.
  Rather than list everything that's been added to the HAL branch, it's easier to describe the change in terms of the things that the HAL branch was lacking:
  * Trunk version of Docs/32bit contained updated comments for the SVC stack structure during ErrorV
  * Trunk version of s/HeapMan contained a tweak to try and reduce the number of small free blocks that are created
  * Trunk version of s/Kernel contained a change to only copy 248 bytes of the error string to the error buffer (down from 252 bytes), to take into account the extra 4 bytes needed by the PSR. However this goes against the decision that's been made in the HAL branch that the error buffer should be enlarged to 260 bytes instead (ref: https://www.riscosopen.org/tracker/tickets/201), so the HAL build will retain its current behaviour.
  * Trunk version of s/MsgCode had RMNot32bit error in the list of error messages to count when countmsgusage {TRUE}
  * Trunk version of s/PMF/i2cutils contained support for OS_Memory 5, "read/write value of NVRamWriteSize". Currently the HAL branch doesn't have a use for this (in particular, the correct NVRamWriteSize should be specified by the HAL, so there should be no need for software to change it at runtime), and so this code will remain switched out in the HAL build.
Admin:
  Tested on Raspberry Pi


Version 5.48. Tagged as 'Kernel-5_48'
@
text
@a97 38

 [ :LNOT: HAL
; Fixed page allocation is as follows

        ^       0
DRAMOffset_CursorChunk  #       32*1024         ; ie on MEMC1 this is the last 32K of DAG-addressable memory
DRAMOffset_PageZero     #       32*1024         ; 32K at location zero
DRAMOffset_SystemHeap   #       32*1024         ; system heap/svc stack
 [ No26bitCode
DRAMOffset_AbortStack   #        8*1024
 ]
        AlignSpace      16*1024                 ; L1PT (and hence L2PT) must be 16K-aligned
DRAMOffset_L2PT         #       0               ; static L2PT (variable size, with embedded L1PT)
DRAMOffset_L1PT         *       DRAMOffset_L2PT + 48*1024

; Undefined stack memory (size 8K) starts immediately after end of L2PT (which is variable size)
; Soft CAM map (variable size) starts immediately after end of UndStack

StaticPagesSize         *       @@

; Logical addresses are as follows


FixedAreasL2Size        *       96*1024        ; amount of L2 to cover fixed areas, excluding free pool

UndStackSoftCamChunk    *       &01E00000
UndStackSize            *       8*1024
CamEntriesForVicky      *       UndStackSoftCamChunk + UndStackSize


; - address for virtual area for StrongARM data cache cleaning (32k, for two 16k areas)
; - the two areas are used in strict rotation for each full clean, so that we can do a full
;   clean (and not flush) with interrupts on
; - the address must be aligned such that EOR with 16*1024 flipflops between the two addresses
ARMA_Cleaners_address  * &01F10000
 ] ; :LNOT: HAL


d535 1
a535 36
 [ :LNOT:No26bitCode
; Undefined instruction trap pre-veneer
; in:   r13_undef -> a FD stack
;       r14_undef -> undefined instruction +4
;       psr_undef = PSR at time of undef'd instruction

UndPreVeneer    ROUT

        Push    "r0-r7,r14"             ; push r0-r7 on undef stack, and make room for return address
        MOV     r0, r13_undef

; for the time being just merge lr and psr

        MRS     r1, SPSR                                ; r1 = saved PSR
        AND     r2, r1, #&F0000003                      ; get saved NZCV and 26 bit modes
        ORR     lr_undef, lr_undef, r2
        AND     r2, r1, #I32_bit + F32_bit              ; extract I and F from new place
        ORR     r1, lr_undef, r2, LSL #IF32_26Shift     ; r1 = combined lr and psr

        MRS     r2, CPSR                ; now switch into SVC26
        BIC     r3, r2, #&1F
        ORR     r3, r3, #SVC26_mode
        MSR     SPSR_cxsf, r3           ; set SPSR_undef to be CPSR but with SVC26
        MSR     CPSR_c, r3              ; and select this mode now

        MOV     lr_svc, r1              ; lr_svc = PC + PSR from exception

        MSR     CPSR_c, r2              ; go back into undef mode

        LDR     r1, =UndHan             ; work out address of undefined instruction handler
        LDR     r1, [r1]
        STR     r1, [r0, #8*4]          ; and store it as return address
        Pull    "r0-r7, pc",,^          ; exit to handler, restoring sp_undef and entering SVC26 mode
 ]

 [ No26bitCode :LAND: ChocolateAMB
a551 34
 [ :LNOT:No26bitCode
; Instruction fetch abort pre-veneer

PAbPreVeneer    ROUT

        LDR     r13_abort, =PreVeneerRegDump
        STMIA   r13_abort, {r0-r7}
        MOV     r0, r13_abort

; for the time being just merge lr and psr

        MRS     r1, SPSR                                ; r1 = saved PSR

        LDR     r2, =Abort32_dumparea
        STMIA   r2, {r1,lr_abort}                       ;dump 32-bit PSR, fault address (PC)
        STR     lr_abort,[r2,#2*4]                      ;dump 32-bit PC

        AND     r2, r1, #&F0000003                      ; get saved NZCV and 26 bit modes
        ORR     lr_abort, lr_abort, r2
        AND     r2, r1, #I32_bit + F32_bit              ; extract I and F from new place
        ORR     r1, lr_abort, r2, LSL #IF32_26Shift     ; r1 = combined lr and psr

        MRS     r2, CPSR                ; now switch into SVC26
        BIC     r2, r2, #&1F
        ORR     r2, r2, #SVC26_mode
        MSR     CPSR_c, r2

        MOV     lr_svc, r1              ; lr_svc = PC + PSR from exception
        LDR     r1, =PAbHan
        LDR     r1, [r1]
        STR     r1, [r0, #8*4]
        LDMIA   r0, {r0-r7, pc}         ; jump to prefetch abort handler
 ]

a564 1
 [ No26bitCode
a565 3
 |
        LDR     r13_abort, =PreVeneerRegDump
 ]
a607 1
  [ No26bitCode
a611 6
  |
05
        ORR     r1, r1, #SVC26_mode             ; then switch to SVC for the rest of this
        MSR     CPSR_c, r1
        Push    "r0, lr_svc"                    ; save SPSR_abort and lr_svc
  ]
a979 1
 [ No26bitCode
a981 5
 |
        Pull    "r0, lr"                        ; r0 = (possibly updated) SPSR_abort, restore lr_svc

        SetMode ABT32_mode, r1                  ; leaves r1 = current PSR
 ]
a1000 1
 [ No26bitCode
a1001 1
 ]
a1020 1
 [ No26bitCode
a1062 42
 |
; for the time being just merge lr and psr

        LDR     r0, [sp, #8*4]                          ; r0 = original SPSR (can't have been modified)

        LDR     lr, [r11, #15*4]                        ; get PC of aborter
        AND     r1, r0, #&F0000000                      ; get saved NZCV
        ORR     lr, lr, r1
        AND     r1, r0, #I32_bit + F32_bit              ; extract I and F from new place
        ORR     lr, lr, r1, LSL #IF32_26Shift           ; and merge
        AND     r1, r0, #3                              ; get old mode bits (have to assume a 26-bit mode!)
        ORR     lr, lr, r1                              ; lr = combined lr and psr
        STR     lr, [sp, #9*4]                          ; overwrite stacked lr_svc
        TEQ     r1, #SVC26_mode                         ; if aborter was in SVC mode
        STREQ   lr, [r11, #14*4]                        ; then also overwrite r14 in aborter's register bank

        BIC     r0, r0, #&1F                            ; clear mode bits in SPSR
        ORR     r0, r0, #SVC26_mode :OR: I32_bit        ; and force SVC26 with I set
 [ DebugAborts
        DLINE   "Going to call data abort handler"
        DREG    lr, "lr_svc will be "
        DREG    r0, "PSR going to exit with = "
 ]
        STR     r0, [sp, #8*4]                          ; overwrite stacked SPSR

        LDR     r0, =ZeroPage                           ; we're going to call abort handler
      [ ZeroPage = 0
        STR     r0, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      |
        MOV     r2, #0
        STR     r2, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      ]

        LDR     r0, =ZeroPage+DAbHan
        LDR     r0, [r0, #DAbHan]                       ; get address of data abort handler
 [ DebugAborts
        DREG    r0, "Handler address = "
 ]
        ADD     r0, r0, #4                              ; add on 4 to adjust for abort exit
        STR     r0, [r11, #15*4]                        ; and store in pc in register bank
        B       %BT70                                   ; then junk to normal tidy-up routine
 ]
a1178 4
  [ :LNOT:No26bitCode
        SetMode SVC32_mode, lr                          ; go into SVC32 so we can poke or peek vector area
  ]

a1220 3
  [ :LNOT:No26bitCode
        SetMode SVC26_mode, lr
  ]
d1248 1
a1248 1
 [ HAL
d1257 1
a1257 3
 |
        ORR     lr, lr, #PhysSpace                      ; now physical address is converted to a logical one (in physspace)
 ]
d1261 1
a1261 1
 [ HAL
d1267 1
a1267 1
 ]
a1346 158

; L1L2PTenhancements not currently used for HAL, but let's keep it as reference in case we want to implement it later
 [ :LNOT: HAL

;some tricks to improve performance, looking at MMU level 1 and level 2 page tables
L1L2PTenhancements ROUT
        Push    "r0-r5,lr"

        ;mjs change for Ursula:
        ;improved kernel workspace protection
        ; - user access to bottom 3k restricted to read only (things like Clib tmpnam counter prevent
        ;   going further)
        ; - Java VM will probably require bottom 1k restricted to no user access (so that VM can avoid
        ;   all run-time checks for null pointers), but this currently makes various things like ShareFS
        ;   go pop-bang, so not done yet (see TRUE/FALSE choice below)
        ;
        MOV     r0,#L2PT                ;L2PT address for page at 0
        LDR     r1,[r0]
        BIC     r1,r1,#&FF0             ;clear current AP bits for all four 1k sub-pages (S0 to S3)
     [ {FALSE}                          ;this would be good for Java VM:
        ORR     r1,r1,#&E90             ;S0=user none, S1=user read, S2=user read, S3=user read/write
     |                                  ;this makes less current things go pop-bang:
        ORR     r1,r1,#&EA0             ;S0=user read, S1=user read, S2=user read, S3=user read/write
     ]
        STR     r1,[r0]

;if the MMU control reg (soft copy) has R bit set (bit 9), then adjust the L1 entries for ROM
;space to give full write protection (user and supervisor)
        LDR     r0,=ZeroPage
        LDR     r1,[r0,#MMUControlSoftCopy]
        TST     r1,#MMUC_R
        BEQ     L1L2PTe_WPROMdone              ;ARM 610 has no R bit, for example
        LDR     r0,=L1PT
        ADD     r0,r0,#ROM :SHR: (20-2)        ;address of first L1PT entry for ROM space
  [ OSROM_ImageSize > 8192
        MOV     r1,#OSROM_ImageSize / 1024
  |
        MOV     r1,#8                          ;8 entries (8 Mbytes)
  ]
L1L2PTe_WPROMloop
        LDR     r2,[r0]
        BIC     r2,r2,#&C00                    ;set AP (access permission) bits to 00
        STR     r2,[r0],#4
        SUBS    r1,r1,#1
        BNE     L1L2PTe_WPROMloop
L1L2PTe_WPROMdone

   [ :LNOT: (CanLiveOnROMCard :LOR: ROMCardSupport :LOR: ExtROMSupport)

;go for best available memory speed for data cache cleaner area (StrongARM)
        LDR     r0,=L2PT :OR: (ARMA_Cleaners_address :SHR: 10)  ;address of 1st L2PT word for cleaner area
        LDR     r1,[r0]
        MOV     r1,r1,LSL #20
        MOV     r1,r1,LSR #20                   ;zap physical address field
        ORR     r1,r1,#&01000000                ; = physical address of start of ROM bank 1
        MOV     r2,#8                           ;8 L2PT entries to fiddle
00
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT00
        MOV     r0,#IOC
        MOV     r1,#5
        STRB    r1,[r0, #IOMD_ROMCR1]           ;ROM bank 1 speed = fastest (62.5 ns)
    ]

;make first 5 pages of cursor chunk cacheable and bufferable - this is rather handy, 'coz things
;like the SWI dispatcher, IRQ dispatcher are here. May be a slight worry over cursor data
;being write-back cached (StrongARM) - should strictly clean,drain write buffer or whatever for shape change.
        LDR     r0,=L2PT :OR: (CursorChunkAddress :SHR: 10)  ;address of 1st L2PT word for CursorChunk
        MOV     R2,#5                           ;5 entries to adjust
01
        LDR     r1,[r0]
        ORR     r1,r1,#&C                       ;make page cacheable and bufferable
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT01

;make other 3 pages of chunk bufferable
        MOV     R2,#3
02
        LDR     r1,[r0]
        ORR     r1,r1,#&4                       ;make page bufferable
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT02

;try to rescue some pages from the L2PT itself, in the AppSpace region - ie. AppSpace max size can really
;be total RAM size, if that is less than 28 Mb, and for every 4Mb less that is we can rescue a 4k page
;and return it to the free pool - handy on a 2Mb Kryten for instance!

        LDR     r0,=ZeroPage+MaxCamEntry
        LDR     r0,[r0]
        ADD     r0,r0,#1+255+768                ; = no. of 4k RAM pages in machine + 255 + 3*256
        MOV     r0,r0,LSR #8                    ; = no. of Mbytes in machine rounded up + 3
        BIC     r0,r0,#3                        ; round up to next 4 Mb
        CMP     r0,#28                          ; if 28Mb or more, no pages to be rescued from L2PT AppSpace
        BHS     %FT09
        LDR     r1,=ZeroPage+AppSpaceDANode
        MOV     r2,r0,LSL #20
        STR     r2,[r1,#DANode_MaxSize]         ; update AppSpace max size
        MOV     r0,r0,LSR #2                    ; no. of L2PT AppSpace pages which cannot be rescued
        MOV     r1,#L2PT
        ADD     r4, r1, #L1PT-L2PT
        ADD     r4, r4, r0, LSL #4              ;the L1PT entry to blank out (4 L1 entries per L2 entry)
        ADD     r1,r1,#(L2PT :SHR: (12-2))      ;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r1,r0,LSL #2                 ;first entry for rescue
        LDR     r3,=ZeroPage+FreePoolDANode
        LDR     r2,[r3,#DANode_Base]
        LDR     r5,[r3,#DANode_Size]            ; FreePool size so far
        ADD     r2,r2,r5                        ; r2 -> next logical address for a rescued page

        SUB     sp,sp,#16                       ; room for 1 page block entry + terminator
        MOV     r3,sp
05
        Push    "r0"
        LDR     r0,[r1],#4                      ; pick up the L2PT entry
        BIC     r0,r0,#&0FF
        BIC     r0,r0,#&F00                     ; mask to leave physical address only
        STR     r0,[r3,#8]                      ; store physical address in word 2 of page block entry

        Push    "r1-r2"
        MOV     r0,#&0C00
        MOV     r1,r3
        MOV     r2,#1
        SWI     XOS_Memory                      ; fill in page number, given physical address

        MOV     r0,#2                           ; means inaccessible in user mode (destined for FreePool)
        STR     r0,[r3,#8]
        MOV     r0,#-1
        STR     r0,[r3,#12]                     ; terminator
        Pull    "r1-r2"

        STR     r2,[r3,#4]                      ; new logical address for page
        MOV     r0,r3
        SWI     XOS_SetMemMapEntries

        MOV     r0, #0                          ; Blank out the L1PT entries for the page table we just removed
        STR     r0, [r4], #4
        STR     r0, [r4], #4
        STR     r0, [r4], #4
        STR     r0, [r4], #4

        Pull    "r0"
        ADD     r2,r2,#4096
        ADD     r5,r5,#4096                     ; next page
        ADD     r0,r0,#1
        CMP     r0,#7                           ;7 entries in total for full 28Mb AppSpace
        BNE     %BT05
        ADD     sp,sp,#16                       ;drop the workspace

        LDR     r0,=ZeroPage+FreePoolDANode
        STR     r5,[r0,#DANode_Size]            ;update FreePoolSize

09
        Pull    "r0-r5,pc"

 ] ; :LNOT: HAL

@


4.14
log
@    Fix to bugzilla bug 4065

Detail:
    1MB VRAM was not being correctly identified. This was due to register
corruption in r12 in the VRAM detection routines in s.ARM600. This bug has been a longstanding one introduced in Kernel 4.69 two years ago.

Admin:
    Been put through the Kev&Mike change control process (tm).

Version 5.40. Tagged as 'Kernel-5_40'
@
text
@d20 22
a41 3
 [ Simulator
        ! 0, "**** Warning - IOMD Simulator debugging included - will crash on real thing! ****"
 ]
d87 1
a87 1
; 17-Jun-96	BAR	Change speed settings for the second bank of ROM space.
d90 7
a96 8
; 25-Jul-96	BAR	Correct bug in video bandwidth code, wrong label used.
; 16-Aug-96	JRH	Programming of 2nd ROM bank (IOMD ROMCR1 register):
;				reinstated ExtROMSupport code, added CanLiveOnROMCard code
;			MemInitTable:
;				If ExtROMSupport: added assertion that ImageSize <= 4096
;				and maps 4MB of each ROM bank.
;				Otherwise: always maps 8MB of ROM space independant of ImageSize

d99 1
a119 2
L2PT                    *       &02C00000       ; size 256K
L1PT                    *       &02C0C000       ; in the middle of L2PT, where the mapping for 03000000 to 03FFFFFF would be
a125 7
UNDSTK                  *       CamEntriesForVicky ; points to end of stack
 [ No26bitCode
AbtStack                *       &02000000
AbtStackSize            *       8*1024
ABTSTK                  *       AbtStack + AbtStackSize
 ]
PhysSpace               *       &80000000       ; Map of MEMC/IOMD physical space (64M/512M in size)
d133 1
d136 1
a136 156
 [ {FALSE}
arm600stuff_before_align
         ALIGN   4096     ;align to page boundary to allow for easy ROMpatch

arm600stuff_startofstuff
  ! 0, "-- start of (4k aligned) ARM600+ stuff at ":CC::STR:(arm600stuff_startofstuff)
 ]

;note that we use the R bit if supported (not 610), so that we can write protect ROM space
;fully (user and supervisor)
;
ARM_default_MMU_CR_table
;
;ARM 6              SBLDPWCAM
         DCD  2_0000001111101
;
;ARM 7            FRSB1DPWCAM
         DCD  2_0011001111101
;
  [ ARM810bpbroken  ;branch prediction broken!
;ARM 8           Z0RSB111WCAM
         DCD  2_0001001111101
  |
;ARM 8           Z0RSB111WCAM
         DCD  2_0101001111101
  ]
;
;ARM 9 ??
         DCD  0
;
  [ SAWBbroken  ;write buffer broken! - turn off write buffer (safe-ish - safer would turn off DC as well)
;StrongARM      I00RSB111WCAM
         DCD  2_1001001110101
  |
;StrongARM      I00RSB111WCAM
         DCD  2_1001001111101
  ]
;


ARM_cacheoff_MMU_CR_table
;
;ARM 6              SBLDPWCAM
         DCD  2_0000001110001
;
;ARM 7            FRSB1DPWCAM
         DCD  2_0011001110001
;
;ARM 8           Z0RSB111WCAM
         DCD  2_0001001110001
;
;ARM 9 ??
         DCD  0
;
;StrongARM      I00RSB111WCAM
         DCD  2_0001001110001
;


OneMByte                EQU     (1024*1024)
SixteenMByte            EQU     (1024*1024 * 16)

; *****************************************************************************
;
;       SetDAG - Program DMA address generator R1 with physical address R0
;       NB on IOMD this is the true physical address, not just offset into VRAM or DRAM
;
; in:   r0 = physical address
;       r1 = index of DMA address generator to program, as defined in vdudecl
;
; out:  All registers preserved, operation ignored if illegal
;

SetDAG  ENTRY   "r0-r1,r12"
        MOV     r12, #IOMD_Base
        CMP     r1, #1
        BEQ     %FT10
        BHI     %FT20

; Program VInit

00
        ASSERT  MEMCDAG_VInit = 0
        MOV     r14, #0
        STR     r0, [r14, #VInitSoftCopy]       ; save VInit so that writes to VEnd can check
        LDR     r14, [r14, #VEndSoftCopy]
        CMP     r0, r14                         ; if VInit >= VEnd then set L bit
        ORRCS   r0, r0, #IOMD_DMA_L_Bit
        STR     r0, [r12, #IOMD_VIDINIT]

        [ :LNOT: STB
        MOV     r1, #0
        LDRB    r1, [r1, #LCD_Active]
        TST     r1, #&80
        EXIT    EQ                              ;Exit if not a dual-panel LC display
        ]

        ;Otherwise, we are going to have to update VIDINITB too...
        MOV     r1, #VduDriverWorkSpace
        LDR     r1, [r1, #ScreenSize]
        BIC     r0, r0, #IOMD_DMA_L_Bit
        ADD     r0, r0, r1, LSR #1              ;R0 = VIDINIT+(screensize/2)
        CMP     r0, r14                         ;If VIDINITB>=VEnd...
        ORREQ   r0, r0, #IOMD_DMA_L_Bit         ;Set the L bit if =
        SUBGT   r0, r0, r14                     ;VIDINITB=VIDINITB-VEnd
        MOVGT   r14, #0
        LDRGT   r1, [r14, #VStartSoftCopy]
        ADDGT   r0, r0, r1                      ;VIDINITB=VIDINITB+VStart
        SUBGT   r0, r0, #16                     ;Quad word correction. /** You are not expected to understand this **/ :-)
        STR     r0, [r12, #IOMD_VIDINITB]
        EXIT

; Program VStart

10
        ASSERT  MEMCDAG_VStart = 1
        MOV     r14, #0
        STR     r0, [r14, #VStartSoftCopy]
        STR     r0, [r12, #IOMD_VIDSTART]
        EXIT

20
        CMP     r1, #3
        EXIT    HI
        BEQ     %FT30

; Program VEnd

        ASSERT  MEMCDAG_VEnd = 2
        MOV     r14, #0
        STR     r0, [r14, #VEndSoftCopy]        ; remember old VEnd value
        LDR     r14, [r14, #VInitSoftCopy]      ; load old VInit
        CMP     r14, r0                         ; if VInit >= VEnd
        ORRCS   r14, r14, #IOMD_DMA_L_Bit       ; then set L bit
        STR     r14, [r12, #IOMD_VIDINIT]       ; store VInit
        STR     r0, [r12, #IOMD_VIDEND]         ; and VEnd

        [ :LNOT: STB
        MOV     r14, #0
        LDRB    r14, [r14, #LCD_Active]
        TST     r14, #&80
        EXIT    EQ                              ; Not a dual-panel LCD so no need to hang around....
        ]

        ;Check whether we need to update VIDINITB or not...

        EXIT

; Program CInit

30
        ASSERT  MEMCDAG_CInit = 3
        STR     r0, [r12, #IOMD_CURSINIT]
        EXIT


d142 1
a142 1
;       BangCamUpdate - Update CAM entry and soft copy
d144 2
a145 1
; This part of the routine has to do more work on ARM600
d166 1
a166 1
        MOV     r1, #0
d168 3
a170 1
        ADD     r1, r1, r2, LSL #3              ; point at cam entry (logaddr, PPL)
d172 2
a173 1
        STMIA   r1, {r3, r11}                   ; store new address, PPL
d175 1
a175 1
        MOV     r1, #PhysRamTable               ; go through phys RAM table
d184 1
a184 1
        LDMFD   r13, {r6}                       ; reload old logical address
d203 1
d207 3
d211 1
a211 1
        BL      BangL2PT                        ; map page out
d219 1
a219 1
;       BangCam - Update CAM entry, but not soft copy
d222 1
a222 3
; For ARM600, I assume that the physical page was previously not mapped
; anywhere else - on MEMC1 it would automatically unmap any logical
; address that the physical page was previously at, but on ARM600 it won't
a237 11
        GBLL    UsePPLCBBits
UsePPLCBBits    SETL    {TRUE}

;if we can assume no code above 64Mb (ie. 26bit code space), big optimise for StrongARM
        GBLL    AssumeNoCodeAbove64Mb
AssumeNoCodeAbove64Mb  SETL    No32bitCode

;if we just use sledgehammer approach anyway
        GBLL    AlwaysSledgehammer
AlwaysSledgehammer SETL {FALSE}

d242 1
a242 1
        MOV     r1, #PhysRamTable       ; go through phys RAM table
d252 6
a257 1
        ADR     r1, PPLTrans
d259 2
d262 14
a275 7
 [ UsePPLCBBits
        TST     r11, #DynAreaFlags_NotCacheable
        TSTEQ   r11, #PageFlags_TempUncacheableBits
        ORREQ   r1, r1, #L2_C           ; if cacheable (area bit CLEAR + temp count zero), then OR in C bit
        TST     r11, #DynAreaFlags_NotBufferable
        ORREQ   r1, r1, #L2_B           ; if bufferable (area bit CLEAR), then OR in B bit
 ]
d280 2
d289 6
a294 3
  [ AlwaysSledgehammer
        B       BangL2PT_sledgehammer
  |
a296 38
  ]
  [ ARM810support
    ;if we are mapping out a cacheable page on an ARM810, must clean+flush cache _before_
    ;remapping, since ARM810 relies on virtual addresses for writebacks
        ARM_read_ID r4
        AND     r4,r4,#&F000                    ;ARM ID nibble now in r4
        CMP     r0,#0                           ;EQ if map out
        TSTEQ   r11,#DynAreaFlags_NotCacheable  ;EQ if also cacheable
        CMPEQ   r4,#&8000                       ;EQ if also ARM 8
        BNE     BangL2PT_noARM810flush
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r6,r4
        MOV     r4,#&8000
    |
        ARM8_cleanflush_IDC r6
    ]
BangL2PT_noARM810flush
  ]
        STR     r0, [r1, r3, LSR #10]           ;update L2PT
  [ :LNOT: ARM810support
        ARM_read_ID r4
        AND     r4,r4,#&F000                    ;ARM ID nibble in r4
  ]
        CMP     r0,#0
        BEQ     BangL2PT_mapout                 ;the update is a map out => cache(s) may need clean/flush
;else update is a map in (and nothing should be there at the moment) => no cache worries
        CMP     r4,#&A000
        BEQ     BangL2PT_mapin_StrongARM
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLBentry r3,EQ               ;flush TLB entry for this page, ARM 8
        ARM67_flush_TLBentry r3,NE              ;flush TLB entry for this page, ARM 6,7
        MOV     pc,lr
  |
;else assume ARM 6,7
        ARM67_flush_TLBentry r3                 ;flush TLB entry for this page
        MOV     pc,lr
  ]
d298 25
a322 9
BangL2PT_mapin_StrongARM
        ARMA_drain_WB                           ;in case L2PT entry itself is in a bufferable area
        ARMA_flush_DTLBentry r3                 ;flush data TLB entry for this page
  [ AssumeNoCodeAbove64Mb
        CMP     r3,#64*1024*1024                ;if logical address above 64Mb, assume no code (26 bit)
        MOVHS   pc,lr
  ]
        ARMA_flush_ITLB                         ;but if there is code, we must flush instruction TLB
        MOV     pc,lr
d324 4
a327 20
BangL2PT_mapout
        CMP     r4,#&A000
        BEQ     BangL2PT_mapout_StrongARM
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLBentry r3,EQ                 ;flush TLB entry for this page, ARM 8
        MOVEQ   pc,lr                             ;ARM8 cache already flushed, if necessary
  ]
;else assume ARM 6,7
        TST     r11,#DynAreaFlags_NotCacheable
        ARM67_flush_cache EQ                    ;flush instruction/data cache if necessary
        ARM67_flush_TLBentry r3                 ;flush TLB entry for this page
        MOV     pc,lr

BangL2PT_mapout_StrongARM
        TST     r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_mapin_StrongARM        ;if NotCacheable, no flush needed (ie. same as mapin)
;note that we are cleaning *after* remapping, so relying on StrongARM writebacks using physical address
        MOV     r4,r3
        ADD     r6,r3,#4*1024                   ;clean/flush data cache over 4k range of page
d329 1
a329 29
  [ SAcleanflushbroken        ; ARMA_cleanflush_DCentry instruction seems to be ineffective
01
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        CMP     r4,r6
        BLO     %BT01
  |
01
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        CMP     r4,r6
        BLO     %BT01
  ]
d331 9
a339 11
        ARMA_drain_WB
        ARMA_flush_DTLBentry r3                 ;flush data TLB entry for this page
  [ AssumeNoCodeAbove64Mb
        CMP     r3,#64*1024*1024                ;if logical address above 64Mb, assume no code (26 bit)
        MOVHS   pc,lr
  ]
        ARMA_flush_IC WithoutNOPs
        MOV     r0,r0                           ;NOPs to ensure 4 instructions before return, after IC flush
        MOV     r0,r0
        ARMA_flush_ITLB
        MOV     pc,lr
d341 1
a341 26
BangL2PT_sledgehammer
  [ ARM810support
        ;if necessary, clean+flush _before_ reamapping, since ARM810 writebacks use virtual addresses
        ARM_read_ID r4
        AND     r4,r4,#&F000
        CMP     r4,#&8000
        TSTEQ   r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_sledge_noARM810flush
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r4,r6
    |
        ARM8_cleanflush_IDC r4
    ]
BangL2PT_sledge_noARM810flush
  ]
        BICS    r4, r3, #(3 :SHL: 10)   ; ensure going to be on word boundary
 [ {FALSE}      ; this breaks too many things at the moment
        BICEQ   r0, r0, #&30            ; if logical page zero, then make 1st 1K no user access
        ORREQ   r0, r0, #&10
 ]
 [ :LNOT: UsePPLCBBits
        LDR     r6, [r1, r4, LSR #10]   ; read current contents
        AND     r6, r6, #L2_C :OR: L2_B ; preserve old CB bits (set up by soft loader)
        ORR     r0, r0, r6              ; but OR in new address and PPL bits
 ]
        STR     r0, [r1, r4, LSR #10]!  ; update level 2 page table (and update pointer so we can use bank-to-bank offset
d343 4
a346 2
        STRNE   r0, [r1, r9, LSR #10]   ; then store entry for 2nd copy as well
        ADDNE   r3, r3, r9              ; and point logical address back at 2nd copy
a347 35
        ARM_read_ID r4
        AND     r4,r4,#&F000
        CMP     r4,#&A000
        BEQ     BangL2PT_sledgehammer_StrongARM
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLB EQ
        MOVEQ   pc, lr      ;ARM8 cache already flushed if necessary
  ]
;else assume ARM 6,7
        TST     r11,#DynAreaFlags_NotCacheable
        ARM67_flush_cache EQ
        ARM67_flush_TLB
        MOV     pc, lr
BangL2PT_sledgehammer_StrongARM
        TST     r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_sledgehammer_StrongARM_NotC

        MOV     r4,#ARMA_Cleaner_flipflop
        LDR     r0,[r4]                   ;last cleaner address
        EOR     r0,r0,#16*1024            ;flip it (r0 -> cleaner address to use)
        STR     r0,[r4]

        ARMA_clean_DC r0,r4,r6            ;effectively, clean/flush DC fully with respect to non-interrupt stuff
        ARMA_drain_WB
        ARMA_flush_IC WithoutNOPs         ;do *not* flush DC - there may be some stuff from interrupt routines
        MOV     r0,r0                     ;NOPs to ensure 4 instructions before return, after IC flush
        MOV     r0,r0
        ARMA_flush_TLBs
        MOV     pc,lr

BangL2PT_sledgehammer_StrongARM_NotC    ;no flush necessary if NotCacheable
        ARMA_drain_WB
        ARMA_flush_TLBs
        MOV     pc,lr
d349 5
d359 7
a365 1
        &       (AP_None * L2_APMult) + L2_SmallPage      ; R sup W sup
d383 1
a383 1
        MOV     r12, #0
d393 10
a402 1
; We now have to mimic the relevant bits of the MEMC1 control register
d413 11
a423 14
        Push    "r10"
        MOV     r12, #IOMD_Base
        TST     r11, #1 :SHL: 10   ; see if video DMA wants to be enabled
        LDRB    r11, [r12, #IOMD_VIDCR]
        AND     r11, r11, #(&7F :AND: :NOT: IOMD_VIDCR_Enable)  ; knock out bit 7 and video DMA enable bit
        ORRNE   r11, r11, #IOMD_VIDCR_Enable
  [ :LNOT: STB
        MOV     r10, #0
        LDRB    r10, [r10, #LCD_Active]
        TST     r10, #&80
        ORRNE   r11, r11, #IOMD_VIDCR_Dup                       ;Set bit 7 if we're on an LCD dual-panel display
  ]
        Pull    "r10"
        STRB    r11, [r12, #IOMD_VIDCR]
a429 1875
;       ClearPhysRAM - Routine to clear "all" memory
;
; While this routine is running, keyboard IRQs may happen. For this reason
; it avoids LogRAM 0..31 (where hardware IRQ vector is) and PhysRAM
; 0..31 where the IRQ workspace is.
;
; We also have to avoid the L2PT (inc L1PT) and the PhysRamTable.
; The latter is also used to tell us which areas of memory we should clear.

; We don't have to worry about trampling on the ROM image as it's
; already been excluded from PhysRamTable.

; This routine must work in 32-bit mode.

; in:   r7 = memory speed
;       r8 = page size
;       r9 = MEMC control register
;       r13 = total RAM size
;
; None of the above are actually used by this routine
;
; out:  r7-r9, r13 preserved
;

     GBLL ClearPhysRAMspeedup
ClearPhysRAMspeedup SETL {TRUE}

ClearPhysRAM ROUT

      [ EmulatorSupport
        ARM_on_emulator r0
        BEQ     CPR_skipped
      ]

;StrongARM - We will make the logical representation of physical space for RAM temporarily bufferable
;            (on any ARM). This is small boost for ARM 6,7,8 but a big speed benefit for StrongARM (which
;            won't burst write in non bufferable areas).

        LDR     r0,  =L1PT
        LDR     r12, =PhysRamTable
        ADD     r4, r12, #PhysRamTableEnd-PhysRamTable  ; r4 -> end of table
02
        LDMIA   r12!, {r10, r11}                        ; load next address, size
        SUB     r11,r11,#&100000                        ; 1 Mb will be done on first L1PT update
        ORR     r10, r10, #PhysSpace                    ; point to logical representation of physical space
        ADD     r1,r0,r10,LSR #(20-2)                   ; L1PT address for same
;MJS bug fix (since 3.70) for memory fragments not necessarily 1Mb aligned (eg 2 Mb Kryten)
        BIC     r1,r1,#3
;
04
        LDR     r2,[r1]
        ORR     r2,r2,#4                                ; bufferable bit
        STR     r2,[r1],#4
        SUBS    r11,r11,#&100000                        ; another 1 Mb done
        BPL     %BT04
        TEQ     r12, r4                                 ; have we done all areas?
        BNE     %BT02

;now let us do the clear
  [ ClearPhysRAMspeedup
        MOV     r0,#48                                  ;we can preserve r7-r9,r13 at logical address 48..63
        STMIA   r0,{r7-r9,r13}
        MOV     r7,  #0
        MOV     r8,  #0
        MOV     r9,  #0
        MOV     r13, #0
  ]
        MOV     r0, #0
        MOV     r1, #0
        MOV     r2, #0
        MOV     r3, #0
        LDR     r12, =PhysRamTable                      ; point to 5 lots of (physaddr,size)
        ADR     r6, RamSkipTable
        ADD     r4, r12, #PhysRamTableEnd-PhysRamTable  ; r4 -> end of table
10
        LDR     r5, [r6], #4                            ; load first skip offset

        LDMIA   r12!, {r10, r11}                        ; load next address, size

        ORR     r10, r10, #PhysSpace                    ; point to logical representation of physical space
        ADD     r11, r11, r10                           ; r11 -> end address of this area
15
        ADD     r5, r5, r10                             ; r5 -> skip address if any
20
        TEQ     r10, r11                                ; test for end of this area?
        BEQ     %FT30
        TEQ     r10, r5                                 ; test for the start of a skipped region
  [ ClearPhysRAMspeedup
        STMNEIA r10!, {r0-r3,r7-r9,r13}
  |
        STMNEIA r10!, {r0-r3}
  ]
        BNE     %BT20

        LDR     r5, [r6], #4                            ; load skip amount
        CMP     r5, #0                                  ; if negative, then it's an offset from start of skipped bit
        LDRLT   r5, [r10, r5]                           ; to address of word holding skip amount
        ADD     r10, r10, r5                            ; and skip it
        LDR     r5, [r6], #4                            ; load next skip offset (NB relative to end of last skip)
        B       %BT15

30
        TEQ     r12, r4                                 ; have we done all areas?
        BNE     %BT10

  [ ClearPhysRAMspeedup
        MOV     r12,#48
        LDMIA   r12,{r7-r9,r13}                         ;restore
        MOV     r12,#32                                 ;clear our speed up workspace
        STMIA   r12!,{r0-r3}
        STMIA   r12!,{r0-r3}
  ]

;StrongARM - now let us remove bufferable status of logical representation of physical space (perhaps we could
;            leave it? not sure at the mo.)

        LDR     r0,  =L1PT
        LDR     r12, =PhysRamTable
        ADD     r4, r12, #PhysRamTableEnd-PhysRamTable  ; r4 -> end of table
32
        LDMIA   r12!, {r10, r11}                        ; load next address, size
        SUB     r11,r11,#&100000                        ; 1 Mb will be done on first L1PT update
        ORR     r10, r10, #PhysSpace                    ; point to logical representation of physical space
        ADD     r1,r0,r10,LSR #(20-2)                   ; L1PT address for same
;MJS bug fix (since 3.70) for memory fragments not necessarily 1Mb aligned (eg 2 Mb Kryten)
        BIC     r1,r1,#3
;
34
        LDR     r2,[r1]
        BIC     r2,r2,#4                                ; bufferable bit
        STR     r2,[r1],#4
        SUBS    r11,r11,#&100000                        ; another 1 Mb done
        BPL     %BT34
        TEQ     r12, r4                                 ; have we done all areas?
        BNE     %BT32

CPR_skipped

        LDR     r0, =OsbyteVars + :INDEX: LastBREAK

        MOV     r1, #&80
        STRB    r1, [r0]                                ; flag the fact that RAM cleared

        ARM_number r0
        SUB     r0,r0,#6
        ADRL    r1,ARM_default_MMU_CR_table
        LDR     r1,[r1,r0,LSL #2]
        MOV     r0, #0
        STR     r1, [r0, #MMUControlSoftCopy]           ; set up MMU soft copy

        MOV     pc, lr

        LTORG

        GBLA    lastaddr
lastaddr SETA   0
        GBLA    lastregion
lastregion SETA 0

        MACRO
        MakeSkipTable $region, $addr, $size
 [ ($region)<>lastregion
        &       -1
lastaddr SETA   0
 ]
        &       ($addr)-lastaddr, $size
lastaddr SETA   ($addr)+($size)
lastregion SETA $region
        MEND

        MACRO
        EndSkipTables
        WHILE   lastregion < (PhysRamTableEnd-PhysRamTable)/8
        &       -1
lastregion SETA   lastregion +1
        WEND
        MEND

; Note (TMD 04-Aug-93): Special bodge put in here to allow variable size skip for L2PT.
; If skip size field is negative, then it's an offset from the start of this skipped bit to a word holding
; the size of the skip. This relies on the L2PTSize being in page zero, which is at a lower physical address than
; the L2 itself. Also assumes that there are no more skips in the 1st DRAM chunk after the L2PT, since the offset
; to the next skip is relative to the end of the previous one, which isn't known at assembly time!

; Tim says "Yuk, yuk, yuk!!"

RamSkipTable
 [ ClearPhysRAMspeedup ; allow some workspace to speed up ClearPhysRAM  Mike says whoosh
        MakeSkipTable   1, DRAMOffset_PageZero + 0, 64  ; skip 1st 32 bytes of LogRAM, so IRQs work!
                                                        ; additional 32 bytes for workspace
 |
        MakeSkipTable   1, DRAMOffset_PageZero + 0, 32  ; skip 1st 32 bytes of LogRAM, so IRQs work!
 ]
        MakeSkipTable   1, DRAMOffset_PageZero + SkippedTables, SkippedTablesEnd-SkippedTables
        MakeSkipTable   1, DRAMOffset_L2PT, DRAMOffset_PageZero + L2PTSize - DRAMOffset_L2PT
        EndSkipTables

        ASSERT  DRAMOffset_PageZero + L2PTSize < DRAMOffset_L2PT


; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
;       InitMEMC - Initialise memory controller
;
; in:   If ResetIndirection assembly flag set, then
;         r1 = 0 if reset, 1 if break
;       else
;         r1 undefined
;       endif

InitMEMC ROUT

; Note: On IOMD, all accesses go to ROM until the first write cycle.

        MOV     r12, #IOMD_Base

; amg: drop in FE-aware routine, leave old one here for reference

  [ MorrisSupport
; Perform a dummy write to IOMD (some harmless register) to get it out of ROM force mode.
; Reads from IOMD will return garbage before this has happened. If we're actually running out
; of 32-bit wide ROMs on MORRIS, a write will already have happened, to get ROMCR0 from
; 16 to 32-bit wide mode, but we can't yet determine for sure (by reading it back), so do it
; anyway.

        STRB    r12, [r12, #IOMD_DMAREQ]              ; writes to DMAREQ are ignored

        LDRB    r2,[r12,#IOMD_ID1]	; load r2 with IOMD ID high byte
        LDRB    r0,[r12,#IOMD_ID0]	; load r0 with IOMD ID low byte
        ORR     r0,r0,r2, LSL #8	; Or r0 and r2 - shifted left 8, put in r0
        LDR     r2,=IOMD_7500		; get Ref IOMD ID code for IOMD in a 7500
        CMPS    r0,r2                   ; check for IOMD ID Code for IOMD in a 7500
	BEQ	init7500cpu		; If equal, got to init7500cpu

        LDRNE   r2,=IOMD_7500FE		; If not, get ID code for IOMD in a 7500FE
        CMPNES  r0,r2			; If not, check for IOMD ID Code for IOMD in a 7500FE
        BNE     MedusaInit              ; NOT MORRIS assume Medusa hardware


init7500FEcpu
; Here bceause its an ARM7500 'FE' variant
; Program the CPU, Memory and IO clock prescalers
; Set the prescalers to :-

  [ RO371Timings
;	CPUCLK divide by 1
;	MEMCLK divide by 2
;	IOCLK  divide by 2
;
	MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkHalf + IOMD_CLKCTL_IOclkHalf
  |
;	CPUCLK divide by 2 unless FECPUSpeedNormal set
;	MEMCLK divide by 1
;	IOCLK  divide by 1
;
   [ FECPUSpeedNormal
     [ FEIOSpeedHalf
	MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkHalf
     |
	MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
     ]
   |
     [ FEIOSpeedHalf
	MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkHalf
     |
	MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
     ]
   ]
  ]
        STRB    r0, [r12, #IOMD_CLKCTL] ; initialise all the prescalers.
;
; Set ROM speed, take care to preserve 16-bit mode bit...
;
; According to BSiddle on the 15-May-96, Omega will use burst mode roms: use 93nS burst, 156nS initial.
; According to TDobson on the 09-Jul-96, Omega will handle ROMS up to 120nS and 70nS.
; Thus the ROM speed should be initilised to :-
; Half Speed or H bit, clear, which is ON ! : Half the delays, thus DOUBLE all clock ticks.
; Non-Sequental delay : 10 Ticks : Half speed on, so select 5 ticks (5*2)
; Burst delay         :  8 Ticks : Half speed on, so select 4 ticks (4*2)
; Remember the Memory clock on Omega is faster than on previous products.
; The fast flash devices used for Omega testing should be able to cope even
; though they aren't burst devices.
        LDRB    r0, [r12, #IOMD_ROMCR0]         ; Get contents of ROMCR0 in to r0
        AND     r0, r0, #&40                    ; clear all but the 16-bit mode flag
  [ RO371Timings
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_3
  |
    [ ROMSpeedNormal
        ORR     r0, r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_NSTicks_$ROMSpeedNSTicks :OR: IOMD_ROMCR_BTicks_$ROMSpeedBurstTicks
    |
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_NSTicks_$ROMSpeedNSTicks :OR: IOMD_ROMCR_BTicks_$ROMSpeedBurstTicks
    ]
  ]
        STRB    r0, [r12, #IOMD_ROMCR0]         ; Prog. the reg.s

; Program the 2nd ROM bank
  [ ExtROMSupport

;   Unless we're actually running from the 2nd ROM bank (CanLiveOnROMCard), we don't know how fast
;   the extension ROM in the 2nd bank goes, so program it for a slow default speed
    [ CanLiveOnROMCard
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank? Program the 2nd bank the same as the 1st if so
	STRNE   r0, [r12, #IOMD_ROMCR1]
    ]
    [ ExtROMis16bit
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    |
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    ]
    [ CanLiveOnROMCard
        STREQB	r0, [r12, #IOMD_ROMCR1]
    |
        STRB	r0, [r12, #IOMD_ROMCR1]
    ]

  |;ExtROMSupport

    [ CanLiveOnROMCard
        STRB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
    |
        STRB	r0, [r12, #IOMD_ROMCR1]		; 2nd bank unused: program it the same anyway
    ]

  ];ExtROMSupport

; Now program ASTCR to add wait states, since MEMCLK is fast relative to IOCLK

	MOV	r0, #IOMD_ASTCR_WaitStates
	STRB	r0, [r12, #IOMD_ASTCR]

	B	init7500cpu_common		; branch to common init code.
;

init7500cpu
; Here because its an ARM7500 variant - NON 'FE' device.
; Program the CPU, Memory and IO clock prescalers
; Set the prescalers to :-
;	CPUCLK divide by 1
;	MEMCLK divide by 1
;	IOCLK  divide by 1
;
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
        STRB    r0, [r12, #IOMD_CLKCTL] ; initialise all prescalers to div1
;
; Set ROM speed, take care to preserve 16-bit mode bit...
;
; According to RJKing on 6/5/94, Kryten will use burst mode roms: use 93nS burst, 156nS initial.
; According to BSiddle on 09-Jul-96 - Omenga will need to set the burst speed to 4 ticks from 3 ticks.
; Thus the ROM speed should be initilised to :-
; Half Speed or H bit, Set, which is OFF ! : Don't half the delays.
; Non-Sequental delay :  5 Ticks : Half speed off, so select 5 ticks
; Burst delay         :  4 Ticks : Half speed off, so select 4 ticks
; The fast EPROMS used for Kryten testing should be able to cope even though
; they aren't burst devices

        LDRB    r0, [r12, #IOMD_ROMCR0]          ; Get contents of ROMCR0 in to r0
        AND     r0, r0, #&40                    ; clear all but the 16-bit mode flag
  [ RO371Timings
        ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_3
  |
    [ ROMSpeedNormal
        ORR     r0, r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_NSTicks_$ROMSpeedNSTicks :OR: IOMD_ROMCR_BTicks_$ROMSpeedBurstTicks
    |
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_NSTicks_$ROMSpeedNSTicks :OR: IOMD_ROMCR_BTicks_$ROMSpeedBurstTicks
    ]
  ]
        STRB    r0, [r12, #IOMD_ROMCR0]          ; Prog. the reg.s

; Program the 2nd ROM bank
  [ ExtROMSupport

;   Unless we're actually running from the 2nd ROM bank (CanLiveOnROMCard), we don't know how fast
;   the extension ROM in the 2nd bank goes, so program it for a slow default speed
    [ CanLiveOnROMCard
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank? Program the 2nd bank the same as the 1st if so
	STRNE   r0, [r12, #IOMD_ROMCR1]
    ]
    [ ExtROMis16bit
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    |
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    ]
    [ CanLiveOnROMCard
        STREQB	r0, [r12, #IOMD_ROMCR1]
    |
        STRB	r0, [r12, #IOMD_ROMCR1]
    ]

  |;ExtROMSupport

    [ CanLiveOnROMCard
        STRB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
    |
        STRB	r0, [r12, #IOMD_ROMCR1]		; 2nd bank unused: program it the same anyway
    ]

  ];ExtROMSupport

; Now program ASTCR to *NOT* add wait states, since MEMCLK is slow relative to IOCLK

	MOV	r0, #IOMD_ASTCR_Minimal
	STRB	r0, [r12, #IOMD_ASTCR]

;
;
init7500cpu_common
; Common setup requirments for BOTH 7500 and 7500FE.
;
; MORRIS doesn't support VRAM. Kryten has same DRAM speed as Medusa
;
        MOV     r0, #IOMD_VREFCR_REF_16                         ; select 16s refresh
        STRB    r0, [r12, #IOMD_VREFCR]

        MOV     r0, #IOMD_IOTCR_Network_TypeA :OR: IOMD_IOTCR_Combo_TypeB :OR: IOMD_IOTCR_Sound_TypeB :OR: IOMD_IOTCR_Sound_Word
        STRB    r0, [r12, #IOMD_IOTCR]

        MOV     r0, #0                          ; Podule manager wants TypeA setting by default for all podules
        STRB    r0, [r12, #IOMD_ECTCR]

   [ Japanese16BitSound :LAND: STB
        MOV     r0, #2_10
        STRB    r0, [r12, #IOMD_VIDMUX]
   ]
        B       CommonInit

MedusaInit
  ] ; MorrisSupport

; amg renaissance ->  [ MorrisSupport
; amg renaissance -> ; Perform a dummy write to IOMD (some harmless register) to get it out of ROM force mode.
; amg renaissance -> ; Reads from IOMD will return garbage before this has happened. If we're actually running out
; amg renaissance -> ; of 32-bit wide ROMs on MORRIS, a write will already have happened, to get ROMCR0 from
; amg renaissance -> ; 16 to 32-bit wide mode, but we can't yet determine for sure (by reading it back), so do it
; amg renaissance -> ; anyway.
; amg renaissance ->
; amg renaissance ->         STRB    r12, [r12, #IOMD_DMAREQ]              ; writes to DMAREQ are ignored
; amg renaissance ->
; amg renaissance ->         LDRB    r0, [r12, #IOMD_ID0]
; amg renaissance ->         CMP     r0, #&98
; amg renaissance ->         LDRB    r0, [r12, #IOMD_ID1]
; amg renaissance ->         CMPEQ   r0, #&5B
; amg renaissance ->        ;MOVEQ   r3, #xxxx
; amg renaissance ->         BNE     MedusaInit                            ; NOT MORRIS assume Medusa hardware
; amg renaissance -> ;
; amg renaissance -> ; MORRIS contains IOMD equivalant circuitry. Due to lack of VRAM, presence of 16/32 bit support
; amg renaissance -> ; and a different ROM speed register, we program it slightly differently.
; amg renaissance -> ;
; amg renaissance ->
; amg renaissance -> ;
; amg renaissance -> ; PSwindell wants all prescalers set to divide by 1
; amg renaissance -> ;
; amg renaissance ->         MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
; amg renaissance ->         STRB    r0, [r12, #IOMD_CLKCTL] ; initialise all prescalers to div1
; amg renaissance ->
; amg renaissance -> ;
; amg renaissance -> ; Set ROM speed, take care to preserve 16-bit mode bit...
; amg renaissance -> ;
; amg renaissance -> ; According to RJKing on 6/5/94, Kryten will use burst mode roms: use 93nS burst, 156nS initial.
; amg renaissance -> ;
; amg renaissance -> ; We assume that the extension ROMs are the same access time and width as the main OS ROMS.
; amg renaissance -> ;
; amg renaissance ->         LDRB    r0, [r12, #IOMD_ROMCR0]
; amg renaissance ->         AND     r0, r0, #&40            ; clear all but 16-bit mode bit, giving us the slowest ROMs possible
; amg renaissance ->  [ :LNOT: AutoSpeedROMS
; amg renaissance ->   [ NormalSpeedROMS
; amg renaissance ->    ;Normal code
; amg renaissance ->         ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_Burst93
; amg renaissance ->                                                                 ; initialise ROM speed to 156.25nS, 93.75nS burst
; amg renaissance ->         ; the fast EPROMS used for Kryten testing should be able to cope even though they aren't
; amg renaissance ->         ; burst devices
; amg renaissance ->   |
; amg renaissance ->    ;Slow ROM access for PSwindells test EPROMS. Paul requested 156nS (or slower), burst off.
; amg renaissance ->         ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_187 + IOMD_ROMCR_BurstOff
; amg renaissance ->
; amg renaissance ->         ! 0, "*** WARNING *** Slow ROM version ment for PSwindell"
; amg renaissance ->   ]
; amg renaissance ->  ]
; amg renaissance ->         STRB    r0, [r12, #IOMD_ROMCR0]
; amg renaissance ->         STRB    r0, [r12, #IOMD_ROMCR1]         ; and do the same for extension ROMs (just in case)
; amg renaissance -> ;
; amg renaissance -> ; MORRIS doesn't support VRAM. Kryten has same DRAM speed as Medusa
; amg renaissance -> ;
; amg renaissance ->         MOV     r0, #IOMD_VREFCR_REF_16                         ; select 16s refresh
; amg renaissance ->         STRB    r0, [r12, #IOMD_VREFCR]
; amg renaissance ->
; amg renaissance ->         MOV     r0, #IOMD_IOTCR_Network_TypeA :OR: IOMD_IOTCR_Combo_TypeB :OR: IOMD_IOTCR_Sound_TypeB :OR: IOMD_IOTCR_Sound_Word
; amg renaissance ->         STRB    r0, [r12, #IOMD_IOTCR]
; amg renaissance ->
; amg renaissance ->         MOV     r0, #0                          ; Podule manager wants TypeA setting by default for all podules
; amg renaissance ->         STRB    r0, [r12, #IOMD_ECTCR]
; amg renaissance ->
; amg renaissance ->  [ Select16BitSound
; amg renaissance -> ; All MORRIS based machines have 16bit 'Japanese' format sound DAC's
; amg renaissance ->         MOV     r0, #2_10
; amg renaissance ->         STRB    r0, [r12, #IOMD_VIDMUX]
; amg renaissance ->  ]
; amg renaissance ->         B       CommonInit
; amg renaissance ->
; amg renaissance -> MedusaInit
; amg renaissance ->  ]


  [ RO371Timings
        MOV     r0, #&12    ; 5-3 cycle ROM access
  |

 [ Simulator
        MOV     r0, #IOMD_ROMCR_62 + IOMD_ROMCR_BurstOff        ; make faster for simulation (no point in burst mode, it's
                                                                ; no faster than the fastest initial speed)
 |
  [ RISCPCBurstMode
   [ 1 = 1
        ReadCop r0, CR_ID
        BIC     r0, r0, #&F     ;ignore 4 bit revision field
        LDR     r2, =&41007100                                  ;Test for early 710's
        CMP     r0, r2                                          ;
        MOVEQ   r0, #IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff       ;cos they can't work in burst mode!
        MOVNE   r0, #IOMD_ROMCR_156 + IOMD_ROMCR_Burst93        ;610's 710A's and beyond can
        ! 0, "*** WARNING *** Burst mode enabled on RISC PC iff processor can cope"
   |
        MOV     r0, #IOMD_ROMCR_156 + IOMD_ROMCR_Burst93
        ! 0, "*** WARNING *** Burst mode enabled on RISC PC"
   ]
  |
        MOV     r0, #IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff       ; initialise ROM speed to 156.25ns (changed from 187ns 21-Jan-94)
  ]
 ]

  ] ;RO371Timings conditional

        STRB    r0, [r12, #IOMD_ROMCR0]
 [ STB
  [ :LNOT: ExtROMis16bit
        STRB    r0, [r12, #IOMD_ROMCR1]         ; and do the same for extension ROMs (just in case)
  |
        MOV	r0, #IOMD_ROMCR_16bit + IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff
	STRB    r0, [r12, #IOMD_ROMCR1]		; 16bit 156.25nS noburst (Lowest common denominator)
  ]
 |
        STRB    r0, [r12, #IOMD_ROMCR1]         ; and do the same for extension ROMs (just in case)
 ]
        MOV     r0, #IOMD_VREFCR_VRAM_256Kx64 :OR: IOMD_VREFCR_REF_16   ; select 16s refresh, assume 2 banks of VRAM
        STRB    r0, [r12, #IOMD_VREFCR]

        MOV     r0, #IOMD_IOTCR_Network_TypeA :OR: IOMD_IOTCR_Combo_TypeB :OR: IOMD_IOTCR_Sound_TypeB :OR: IOMD_IOTCR_Sound_Word
        STRB    r0, [r12, #IOMD_IOTCR]

        MOV     r0, #0                          ; Podule manager wants TypeA setting by default for all podules
        STRB    r0, [r12, #IOMD_ECTCR]

CommonInit
; On breaks (ie software resets) we have to turn the MMU off.
; This is slightly tricky if we've been soft-loaded!

;mjs - must now (if not before) be true, since 26 bit configuration does not exist in Architecture 4 (ARM 810/StrongARM)
        ASSERT ResetIndirected

 [ ResetIndirected
        TEQ     r1, #0                  ; r1 = 0 if reset, 1 if break
        BEQ     %FT03                   ; [it's a reset]

        SetMode SVC32_mode, r0          ; select 32-bit mode (we know we're in 32-bit config)
        B       %FT05
03
 |

; We check for breaks by testing if we're in 32-bit configuration:
;  - on reset we'll be put into 26-bit config, MMU off, 26-bit mode
;  - on breaks we'll be left in 32-bit config, MMU on,  26-bit mode

; In both cases we want to end up in 32-bit config with MMU off, in 32-bit mode

        SetMode SVC32_mode, r1, r0      ; try to select SVC32 mode
        mrs     AL, r2, CPSR            ; read back PSR
        AND     r2, r2, #&1F            ; extract mode bits from PSR we tried to modify
        TEQ     r2, #SVC32_mode         ; and see if we made it into SVC32
        BEQ     %FT05                   ; [we made it so must be a Break]
 ]

; It's a reset, so select 32-bit config, MMU off

 [ LateAborts
        MOV     r2, #MMUC_P :OR: MMUC_D :OR: MMUC_L ; select 32-bit config, MMU off, late aborts
 |
        MOV     r2, #MMUC_P :OR: MMUC_D ; select 32-bit config, MMU off
 ]
        SetCop  r2, CR_Control
        SetMode SVC32_mode, r1, r0      ; and re-select 32-bit mode (this time it'll work)
        AND     r0, r0, #&1F            ; check original mode
        TEQ     r0, #SVC26_mode         ; if we were in a 26-bit mode,
        BICEQ   lr, lr, #&FC000003      ; then knock off 26-bit style PSR bits from link register
                                        ; don't knock them off otherwise, since we may be soft-loaded above 64M
        MOV     pc, lr                  ; and exit

; It's a Break

; The MMU is on and we want it off: whether we're executing out of ROM or RAM, we
; have to jump to the physical location of our image, which means paging it in at its
; own physical address.

; On MEMC1 systems it's possible that the L1/L2 logical address is the same as the image's physical
; address, which causes a headache, so we'd best use the physical mapping of the page tables (this
; can't clash as IOMD only goes up to 2000 0000 and our physical mapping is above that).

05
        MOV     r0, #0
        LDR     r0, [r0, #DRAMPhysAddrA]        ; get address of 1st DRAM bank
        LDR     r1, =PhysSpace + DRAMOffset_L1PT ; offset to start of L1
        ADD     r0, r0, r1                      ; r0 -> L1 in physical mapped logical space

        LDR     r1, [r0, #ROM :SHR: (20-2)]     ; load L1 entry for 1st Mbyte of ROM
        MOV     r1, r1, LSR #20                 ; knock off other bits
        LDR     r2, =(AP_None * L1_APMult) + L1_Section
                                                ; (svc-only access) + ~ucb + section mapped
        ORR     r2, r2, r1, LSL #20             ; merge in address
        STR     r2, [r0, r1, LSL #2]!           ; store in L1PT for 1st Mbyte
        ADD     r2, r2, #1 :SHL: 20             ; move on to 2nd Mbyte
        STR     r2, [r0, #4]                    ; and store in next entry

        ARM_flush_cacheandTLB r0

        MOV     r0, r1, LSL #20
        SUB     r0, r0, #ROM                    ; form RAM-ROM offset
        ADD     pc, pc, r0                      ; jump to RAM code (when we get onto IOMD, we'll have to be in 32-bit mode)
        NOP                                     ; this instruction will be skipped

; we're now in RAM, so it's safe to turn the MMU off, but leave us in 32-bit config (and 32-bit mode)

 [ :LNOT:No26bitCode
        BIC     lr, lr, #&FC000003              ; knock out PSR bits from return address
                                                ; (we know we were in 32-bit config, 26-bit mode on entry)
 ]
        ADD     lr, lr, r0                      ; and add on offset - NB this may now be above 64MB (on IOMD)

;mjs - the MMU off values are ok for all ARMs; some will ignore P,D,L bits
 [ LateAborts
        MOV     r0, #MMUC_P :OR: MMUC_D :OR: MMUC_L ; turn MMU off, but leave us in 32-bit config, late aborts
 |
        MOV     r0, #MMUC_P :OR: MMUC_D         ; turn MMU off, but leave us in 32-bit config
 ]
        ARM_write_control r0

        MOV     pc, lr                          ; return to caller, but in physical address space

        LTORG
; -> MemSize

; (non-destructive) algorithm to determine MEMC RAM configuration
;
; Dave Flynn and Alasdair Thomas
; 17-March-87
;
; Spooling checkered by NRaine and SSwales !
; 8MByte check bodged in by APT
;
; NOTE: Routines MemSize and TimeCPU are called by the power-on test software,
; so their specifications MUST not change.
;
; Set MEMC for 32-k page then analyse signature of possible
; external RAM configurations...
; The configurations are:
;
; Ram Size    Page Size    Configuration    (Phys RAM) Signature
;--------------------------------------------------------------------
;  16MByte      32k        4*32*1Mx1         A13,A20,A21,A22,A23,A23.5 distinct
;  16MByte      32k        16*8*256kx4       A13,A20,A21,A22,A23,A23.5 distinct
;
;  12MByte      32k        3*32*1Mx1         A13,A20,A21,A22,A23 OK, A23.5 fail
;  12MByte      32k        12*8*256kx4       A13,A20,A21,A22,A23 OK, A23.5 fail
;
;   8MByte      32k        2*32*1Mx1         A13,A20,A21,A22 distinct, A23 fail
;   8MByte      32k         8*8*256kx4       A13,A20,A21,A22 distinct, A23 fail
;
;   4Mbyte      32k          32*1Mx1         A13,A21,A20 distinct, A22,A23 fail
;   4Mbyte      32k         4*8*256kx4       A13,A21,A20 distinct, A22,A23 fail
;
;   2Mbyte      32k    expandable 2*8*256kx4 A13,A20 distinct, A21 fails
;   2Mbyte ???  16k      fixed 2*8*256kx4    A13,A21 distinct, A20 fails
;
;   1Mbyte       8k          32*256kx1       A13,A20 fail, A19,A18,A12 distinct
;   1Mbyte       8k           8*256kx1       A13,A20 fail, A19,A18,A12 distinct
;   1Mbyte       8k          4*8*64kx4       A13,A20 fail, A19,A18,A12 distinct
;
; 512Kbyte       8k    expandable 2*8*64kx4  A13,A20,A19 fail, A12,A18 distinct
; 512Kbyte       4k      fixed 2*8*64kx4     A13,A20,A12 fail, A19,A18 distinct
;
; 256Kbyte       4K           8*64kx4        A13,A20,A12,A18 fail, A21,A19 ok
; 256Kbyte       4K          32*64kx1        A13,A20,A12,A18 fail, A21,A19 ok
;

; MemSize routine... enter with 32K pagesize set
; R0 returns page size
; R1 returns memory size
; R2 returns value set in MEMC
; Can corrupt R3-R14

; Note that on a soft-loaded system, the 1st word of the image may be
; temporarily overwritten, but this is just the reset branch so it's OK.

; MMU is always off at this point, so we must use the physical address of PhysRAM
; Also we are entered in 32-bit config, 32-bit mode,
; but we exit in 32-bit config, 26-bit mode

 [ MorrisSupport
funnypatterns
        &       &66CC9933   ; 0110 1100 1001 0011
        &       &CC993366   ; 1100 1001 0011 0110
 ]

MemSize ROUT
        MOV     r13, lr                                 ;save in a register, cos we've got no stack

        MOV     r12, #IOMD_Base

 [ MorrisSupport
;
        LDRB    r0, [r12, #IOMD_ID0]	; load r1 with IOMD ID high byte
        LDRB    r1, [r12, #IOMD_ID1]	; load r0 with IOMD ID low byte
        ORR     r0,r0,r1,LSL#8		; Or r0 and r1, shifted left 8, put in r0
        LDR     r1,=IOMD_Original       ; get Ref IOMD ID code - original
        CMP     r0,r1                   ; check for IOMD ID Code - original
        BEQ     MemSizeIOMD             ; Not ID Code - original,
                                        ;    therefore jump to Medusa hardware code
                                        ;    else fall through to Morris code.
;
; MemSize for Morris
;
  [ RO371Timings
        MOV     r11, #&70     ;all 4 banks assumed 32 bit - EDO and timing bits set in case 7500FE (don't care bits otherwise)
  |
        MOV     r11, #IOMD_DRAMWID_DRAM_32bit * &0F     ;set all 4 banks to be 32bit initially
 	LDR	r1, =IOMD_7500FE
	TEQ	r0, r1					; are we on FE part?
	ORREQ	r11, r11, #IOMD_DRAMWID_EDO_Enable :OR: IOMD_DRAMWID_RASCAS_3 :OR: IOMD_DRAMWID_RASPre_3
							; if so, then enable EDO and slower RASCAS and RASPre times
        ! 0,"7500FE support expects EDO memory in s.ARM600"
  ]
        MOV     r14, #IOMD_Base
        STRB    r11, [r14, #IOMD_DRAMWID]
        MOV     r10, #0                                 ;indicate no RAM found yet
        MOV     r9, #IOMD_DRAMWID_DRAM_16bit            ;bit to OR into DRAMWID to set 16bit
        MOV     r0, #DRAM0PhysRam
;
; r0    DRAM address
; r9    IOMD_DRAMWID_DRAM_16bit for current DRAM bank
; r11   current IOMD_DRAMWID register contents
;
ExamineDRAMBank                                         ;examine first/next DRAM bank
;
        LDMIA   r0, {r1, r2}                            ;Preserve the two locations that we widdle on

        ADR     r3, funnypatterns                       ;We write different values to two locations
        LDMIA   r3, {r3, r4}                            ; incase bus capacitance holds our value
        STMIA   r0, {r3, r4}
        LDMIA   r0, {r5, r6}                            ;Reread test locations
        EORS    r5, r5, r3                              ;Both locations should read correctly
        EOR     r6, r6, r4                              ; if memory is 32bits wide
       ;TEQ     r5, #0
        TEQEQ   r6, #0
        BEQ     %FT05                                   ;32bit wide memory

        TST     r5, #&00FF                              ;If the bottom 16bits of each location
        TSTEQ   r5, #&FF00                              ; are correct, the memory is 16bits wide
        TSTEQ   r6, #&00FF
        TSTEQ   r6, #&FF00
        ADDNE   r0, r0, #DRAM1PhysRam-DRAM0PhysRam      ; move onto next bank
        BNE     NoRamInBank                             ;No memory in this bank

        ORR     r11, r11, r9                            ;Bank is 16bits wide
05
        STMIA   r0, {r1, r2}                            ;Restore the two locations we widdled on
                                                        ;Must do BEFORE poking the DRAMWID register
        MOV     r14, #IOMD_Base                         ;
        STRB    r11, [r14, #IOMD_DRAMWID]               ;

        BL	Add_DRAM_bank

NoRamInBank
        MOV     r9, r9, LSL #1                          ; shunt up position in DRAMWID
        CMP     r9, #&0010                              ; if more banks to do
        BLT     ExamineDRAMBank                         ; then loop

	MOV	r6, #0					; No VRAM
	MOV	r0, #0
        MOV     r14, #IOMD_Base

	LDRB	r4, [r14, #IOMD_ID0]
	LDRB	r7, [r14, #IOMD_ID1]
	ORR	r4, r4, r7, LSL #8
	LDR	r7, =IOMD_7500FE			; if FE part, then assume EDO DRAM
	TEQ	r4, r7
	LDREQ	r2, =80000000				; so allow 80E6 bytes/s
 [ STB
	LDRNE	r2, =44000000				; else only allow 44E6 bytes/s
 |
        LDRNE   r2, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
 ]
	MOV	r1, #IOMD_VIDCR_DRAMMode :OR: &10       ; if no VRAM, then turn on DRAM mode, and set increment to &10

        B       Allocate_DRAM

MemSizeIOMD
 ]

; Right, let's find out where our memory is

; StrongARM - aha! but we still have no nice MMU, nor even fast core clock, and this memory sizing type
; stuff is going to be very slow for large memory. So turn on I cache (allowed with MMU off), and fast
; core clock now - this is then ok until MMU etc comes on (near CritStart)

        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&A000
        BNE     MemSizeIOMD_notSA
        ARM_read_control r2
        ORR     r2,r2,#&1000     ;I cache bit is bit 12
        ARM_write_control r2
        ARMA_fastcoreclock
  [ ARM810fastclock
        B       MemSizeIOMD_not810
  ]
MemSizeIOMD_notSA
  [ ARM810fastclock
    ;fast clock for ARM 810 now
        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&8000
        BNE     MemSizeIOMD_not810
    [ ARM810usePLL
        ARM8_pll_fclk r2
    |
        ARM8_refclk_fclk r2
    ]
MemSizeIOMD_not810
  ]

        MOV     r11, #IOMD_DRAMCR_DRAM_Large * &55      ; set all banks to be large initially
        MOV     r14, #IOMD_Base
        STRB    r11, [r14, #IOMD_DRAMCR]

        MOV     r10, #0                                 ; indicate no RAM found yet
        MOV     r9, #IOMD_DRAMCR_DRAM_Small             ; bit to OR into DRAMCR
        MOV     r0, #DRAM0PhysRam
10
        ADD     r1, r0, #A10                            ; this should be OK for both configurations
        BL      DistinctAddresses
        ADDNE   r0, r0, #DRAM1PhysRam-DRAM0PhysRam      ; move onto next bank
        BNE     %FT15                                   ; [no RAM in this bank at all]

        ADD     r1, r0, #A11                            ; test for 256K DRAM
        BL      DistinctAddresses
        ORRNE   r11, r11, r9                            ; it is, so select small multiplexing
        MOVNE   r14, #IOMD_Base
        STRNEB  r11, [r14, #IOMD_DRAMCR]                ; store new value of DRAMCR, so we can use memory immediately

	BL	Add_DRAM_bank

; Now, we have to find a bank of DRAM, so we've got somewhere to store our results!
15
        MOV     r9, r9, LSL #2                          ; shunt up position in DRAMCR
        CMP     r9, #&100                               ; if more banks to do
        BCC     %BT10                                   ; then loop

; Now, we check out the VRAM.
; Don't bother checking for more than 2M of VRAM, because we don't know what the 1/2 SAM length is for larger sizes

        MOV     r12, #IOMD_Base
        MOV     r2, #IOMD_VREFCR_VRAM_256Kx64 :OR: IOMD_VREFCR_REF_16 ; assume 2 banks of VRAM by default
        STRB    r2, [r12, #IOMD_VREFCR]

        MOV     r0, #VideoPhysRam                       ; point at VRAM
        ADD     r1, r0, #A2                             ; test A2
        BL      DistinctAddresses
        MOVEQ   r6, #2                                  ; we've got 2M of VRAM
        BEQ     %FT20

        MOV     r2, #IOMD_VREFCR_VRAM_256Kx32 :OR: IOMD_VREFCR_REF_16
        STRB    r2, [r12, #IOMD_VREFCR]
        ADD     r1, r0, #A2                             ; check for any VRAM at all
        BL      DistinctAddresses
        MOVEQ   r6, #1                                  ; we've got 1M of VRAM
        MOVNE   r6, #0                                  ; no VRAM
20
 [ IgnoreVRAM
        MOV     r6, #0                                  ; pretend there's no VRAM
 ]
        CMP     r6, #1
        MOVCC   r1, #IOMD_VIDCR_DRAMMode :OR: &10       ; if no VRAM, then turn on DRAM mode, and set increment to &10
        MOVEQ   r1, #SAMLength/2/256                    ; if 1M VRAM, then use VRAM mode, and set increment for 1/2 SAM
        MOVHI   r1, #SAMLength/2/256*2                  ; if 2M VRAM, then use VRAM mode, and set increment for 2*1/2 SAM
        LDRCC   r2, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
        LDREQ   r2, =80000000                           ; if 1M VRAM, then 80E6   ---------""--------
        LDRHI   r2, =160000000                          ; if 2M VRAM, then 160E6  ---------""--------
	MOVCC	r0, #0					; Clear VRAM base if there is no VRAM

; Allocate_DRAM
;   r0  = Video base if r6!=0
;   r1  = Value for IOMD VIDCR
;   r2  = Bandwidth limit
;   r6  = VRAM size in Mb
;   r10 = End of DRAM list
Allocate_DRAM

NoDRAMPanic
	TST	r10, r10
	BEQ	NoDRAMPanic				; Stop here if there is no DRAM (we could use VRAM I suppose...)

	MOV	r7, r6, LSL #20				; r7 = size of video memory
	LDR	r8, [r10]				; r8 = the number of DRAM blocks.
	SUB	r11, r10, r8, LSL #3			; Jump back to the start of the list

	LDMIA	r11!, {r4, r5}				; Get a block from the list. (r4,r5) = (base,size)
	CMP	r6, #0					; Did we find any VRAM?
	BNE	%FT30					; Skip this bit if we did.
	MOV	r0, r4					; Allocate this block as video memory
	MOV	r7, r5
	CMP	r10, r11				; Was this the only block?  If so, leave 1M
	SUBEQS	r7, r7, #1024*1024
	MOVCC	r7, r5, ASR #1				; If that overflowed, take half the bank.
	CMP	r7, #8*1024*1024
	MOVCS	r7, #8*1024*1024			; Limit allocation to 8M - the size of the logical space

	ADD	r4, r4, r7				; Adjust the DRAM block base...
	SUBS	r5, r5, r7				; ... and the size.
	LDMEQIA	r11!, {r4, r5}				; Fetch the next block if we claimed it all.

30	ADD	r12, r4, #DRAMOffset_PageZero		; Use the first block for kernel workspace.
	ADD	r3, r12, #DRAMPhysAddrA			; Set the table address as well

	CMP	r8, #5
	ADDCS	r10, r11, #3:SHL:3			; Limit to 4 blocks of DRAM (3 + this one)

35	STMIA	r3!, {r4, r5}				; Put the DRAM block into the table
	TEQ	r10, r11
	LDMNEIA	r11!, {r4, r5}				; Get the next block if there is one.
	BNE	%BT35

; Now go back and put the VRAM information in, and also program VIDCR and VIDCUR

        STR     r6, [r12, #VRAMWidth]                   ; store width of VRAM (0,1 or 2)
        MOV     r14, #IOMD_Base
        STRB    r1, [r14, #IOMD_VIDCR]
        STR     r0, [r14, #IOMD_VIDCUR]                 ; set up VIDCUR to start of video RAM
        STR     r0, [r14, #IOMD_VIDSTART]               ; do same for VIDSTART
        STR     r0, [r14, #IOMD_VIDINIT]                ; and for VIDINIT
                                                        ; so we don't get a mess when we turn video DMA on later
        STR     r2, [r12, #VideoBandwidth]              ; store video bandwidth

        ADD     r4, r0, #1024*1024-4096                 ; add on a bit to form VIDEND (will be on mult. of SAM)
        STR     r4, [r14, #IOMD_VIDEND]                 ; yes I know it's a bit of a bodge

        MOV     r4, r6, LSL #20                         ; convert amount of VRAM to bytes
        STR     r4, [r12, #VRAMSize]                    ; and store

	ADD	r2, r12, #VideoPhysAddr			; r2 -> Start of PhysRamTable
        STMIA   r2, {r0, r7}                            ; store video memory block
MemSizeTotalRAM
; Now we have to work out the total RAM size

  [ Simulator
        TubeString r4, r5, r6, "Address  Size"
  ]
        MOV     r1, #0
        MOV     r7, r2
40
        LDMIA   r7!, {r4, r5}                           ; get address, size
        ADD     r1, r1, r5                              ; add on size
  [ Simulator
        TubeDumpNoStack r4, r6, r8, r9
        TubeDumpNoStack r5, r6, r8, r9
        TubeNewlNoStack r6, r8
  ]
        TEQ     r7, r3
        BNE     %BT40

        MOV     r0, #Page4K                             ; something to put in MEMC CR soft copy
                                                        ; (it's probably irrelevant)
	ADRL	r4, ROM

; r0 = Page size
; r1 = Total memory size (bytes)
; r2 = PhysRamTable
; r3 = After last used entry in PhysRamTable
; r4 = Address of ROM

; now store zeros to fill out table

55
        ADD     r5, r2, #PhysRamTableEnd-PhysRamTable
        MOV     r6, #0
        MOV     r7, #0
57
        CMP     r3, r5
        STMCCIA r3!, {r6, r7}
        BCC     %BT57

; Now set up L1 + L2
; - first work out how big static L2 needs to be
; - then zero L1 + L2 (L1 is actually inside L2)

        MOV     r3, r1, LSR #22                 ; r3 = memsize / 4M
        TEQ     r1, r3, LSL #22                 ; if any remainder
        ADDNE   r3, r3, #1                      ; then round up (r3 is now how many pages of L2 needed for free pool)
        MOV     r3, r3, LSL #12                 ; convert to bytes
        ADD     r3, r3, #FixedAreasL2Size       ; add on size of L2 for other fixed areas
        STR     r3, [r2, #L2PTSize-PhysRamTable] ; save away for future reference

        LDR     r2, [r2, #DRAMPhysAddrA-PhysRamTable]   ; get address of 1st DRAM bank
        LDR     r5, =DRAMOffset_L2PT
        ADD     r2, r2, r5                              ; make r2 -> L2PT
        MOV     r5, #0                          ; value to initialise L1 and L2 to (translation faults)
        MOV     r6, r5
        MOV     r7, r5
        MOV     r8, r5
        MOV     r9, r5
        MOV     r10, r5
        MOV     r11, r5
        MOV     r12, r5
 [ :LNOT: Simulator                             ; don't bother zeroing L1/2 for Mark
        ADD     r2, r2, r3                      ; start at end and work back
60
        STMDB   r2!, {r5-r12}
        SUBS    r3, r3, #8*4
        BNE     %BT60
 ]

; r2 ends up pointing at L2

        ADD     r3, r2, #DRAMOffset_L1PT-DRAMOffset_L2PT        ; r3 -> L1Phys

; now initialise all the L1 for the area covered by the static L2, as if it were all page mapped
; - the section mapped stuff will be overwritten when we go thru MemInitTable shortly

        ORR     r5, r2, #L1_Page + L1_U         ; take phys base of L2, and or in other bits to form an L1 entry
        LDR     r6, =L2PTSize+DRAMOffset_PageZero-DRAMOffset_L2PT
        LDR     r10, [r2, r6]                   ; r10 = size of L2 (used after this loop, too)
        ADD     r6, r5, r10                     ; r6 = value in r5 when we've finished
        MOV     r7, r3                          ; r7 -> where we're storing L1 entries
61
        STR     r5, [r7], #4                    ; store L1 entry
        ADD     r5, r5, #1024                   ; advance L2 pointer
        TEQ     r5, r6
        BNE     %BT61

; now go through memory initialisation table, setting up entries

        ADR     r5, MemInitTable
65
        LDMIA   r5!, {r6-r8}                    ; load size, logaddr, indicator
        TEQ     r6, #0                          ; if size field is zero
        BEQ     %FT90                           ; then we've finished going through table

        TST     r8, #1                          ; if bit 0 of indicator is set, then it's page mapped
        BNE     %FT75

        TST     r8, #2                          ; is it abort?
        BNE     %FT68                           ; [no]

; it's a section abort (r8=0)

66
        STR     r8, [r3, r7, LSR #20-2]         ; store zero in L1 table
        ADD     r7, r7, #&00100000              ; increment logical address by 1M
        SUBS    r6, r6, #&00100000              ; and decrement size by 1M
        BNE     %BT66                           ; loop until done
        B       %BT65


68
; it's section mapped

        TST     r8, #ROMbit                     ; is it a ROM image offset
        ADDNE   r8, r8, r4                      ; if so, then add in image offset
        BICNE   r8, r8, #ROMbit                 ; and knock out the dodgy bit

        TST     r8, #Vidbit                     ; is it a video memory offset
        LDRNE   r9, =VideoPhysAddr+DRAMOffset_PageZero-DRAMOffset_L2PT
        LDRNE   r9, [r2, r9]                    ; get physical address of video RAM
        ADDNE   r8, r8, r9                      ; add on offset
        BICNE   r8, r8, #Vidbit                 ; and knock out the dodgy bit
70
        STR     r8, [r3, r7, LSR #20-2]         ; store entry in L1 table (assumes bits 18, 19 are clear!)
        ADD     r7, r7, #&00100000              ; increment logical address by 1M
        ADD     r8, r8, #&00100000              ; and physical address by 1M
        SUBS    r6, r6, #&00100000              ; and decrement size by 1M
        BNE     %BT70                           ; if we've not finished then loop
        B       %BT65                           ; else go back to main loop

; explicit L2 setup

75
        CMP     r6, #-1                         ; if size <> -1
        BNE     %FT80                           ; then normal

; size = -1 => this is the chunk with the soft CAM map in it,
; so we must work out a suitable size (and store it in SoftCamMapSize)
; we also have to work out the correct offset in the DRAM bank, since this is
; after variable size L2PT

        MOV     r6, r1, LSR #24-3               ; number of pages for cam map
        CMP     r1, r6, LSL #24-3               ; if bits dropped off
        ADDNE   r6, r6, #1                      ; then need one more page
        MOV     r6, r6, LSL #12
        LDR     r9, =DRAMOffset_PageZero-DRAMOffset_L2PT+SoftCamMapSize
        STR     r6, [r2, r9]                    ; store size used
        ADD     r6, r6, #UndStackSize           ; chunk also includes undstack
        ADD     r9, r10, #DRAMOffset_L2PT       ; undstack/cammap starts at offset L2PT + L2PTSize
        ORR     r8, r8, r9                      ; OR in other misc bits from table
80
        LDR     r9, =DRAMOffset_PageZero-DRAMOffset_L2PT+DRAMPhysAddrA
                                                ; offset from L2 to word containing physical address of 1st DRAM bank
        LDR     r9, [r2, r9]                    ; r9 = address of 1st DRAM bank
        ADD     r8, r8, r9                      ; convert offset to address
        EOR     r8, r8, #L2_SmallPage :EOR: 1   ; make bottom 2 bits correct for L2
        ADD     r9, r2, r7, LSR #10             ; r9 -> L2 for this page
85
        STR     r8, [r9], #4                    ; store entry in L2
        ADD     r8, r8, #4*1024                 ; advance physical page address
        SUBS    r6, r6, #4*1024                 ; one less page to do
        BNE     %BT85
        B       %BT65

; L1 is now set up correctly, and L2 has the correct CB bits, but no accessible pages
; Put in the L2 entries for the logical area we are going to access the L2 (and L1) at
; r10 still holds L2PT size

90
        ADD     r5, r2, #(L2PT :SHR: 10)        ; r5 -> start of L2PT for L2 logical address
        LDR     r6, =(AP_None * L2_APMult) + L2_SmallPage ; r6 = other gubbins to put in L2 entries (not C or B)
        ORR     r6, r6, r2                      ; OR in physical address of L2
        MOV     r7, r10                         ; amount to put in (L2PTSize)
95
        STR     r6, [r5], #4                    ; store entry
        ADD     r6, r6, #4096                   ; move onto next page
        SUBS    r7, r7, #4096                   ; one less page to do
        BNE     %BT95                           ; loop until done

; But before we turn on, we have to temporarily make the addresses we are currently executing out of
; into a section mapped area straight through, so we don't crash before we can jump up into ROM area

        ASSERT ((CritStart :EOR: CritEnd) :AND: &FFF00000)=0    ; make sure start and end are in the same MB chunk

        ADR     r5, CritStart                   ; point at critical region start
        MOV     r5, r5, LSR #20                 ; divide by 1MB
        LDR     r6, [r3, r5, LSL #2]            ; get current L1 entry to put back later
        MOV     r7, r5, LSL #20                 ; r7 = physical address of base of section
        ORR     r7, r7, #(AP_None * L1_APMult)
        ORR     r7, r7, #L1_Section
        STR     r7, [r3, r5, LSL #2]            ; store replacement entry in L1 (not U,C or B)

        ARM_MMU_transbase r3                    ; set up MMU pointer to L1
        ADD     r3, r3, #PhysSpace              ; when we put L1 entry back later, we need to use the copy in PhysSpace area

        MOV     r7, #1
        ARM_MMU_domain r7                       ; only use domain 0

        ARM_flush_cacheandTLB r7                ; flush cache + TLB just in case

        ARM_number r2                           ;should be 6,7,8 or &A
 [ ARM810support
   ;ARM810 has already had fast clock selected (MemSizeIOMD) - so has StrongARM, therefore code below removed
 |
        CMP     r2,#&A
        ARMA_fastcoreclock EQ                   ;otherwise StrongARM is going to have a limp wrist
 ]
        SUB     r2,r2,#6                        ; r2 := 0..4 for ARM 6,7,8,(9),&A
        ADRL    r7,ARM_default_MMU_CR_table
        LDR     r7,[r7,r2,LSL #2]               ;get appropriate default value for MMU control reg

CritStart
        ARM_write_control r7

; now we can jump into the ROM space (if we're not already there)

        RSB     r4, r4, #ROM                    ; make offset from current address to ROM
        ADD     pc, pc, r4                      ; jump up into ROM area
        NOP                                     ; this instruction will be skipped

; now put back the L1 entry we messed up

        STR     r6, [r3, r5, LSL #2]
CritEnd                                         ; 2 words after we go up into ROM
        ARM_flush_TLB r2                        ; flush TLB (no need to flush cache, as there's nothing in it)

        SetMode UND32_mode, r7
        LDR     r13_undef, =UNDSTK              ; set up undefined mode stack pointer

 [ No26bitCode
        SetMode ABT32_mode, r7
        LDR     r13_abort, =ABTSTK              ; set up abort mode stack pointer

        SetMode SVC32_mode, r7                  ; RISC OS is 32 bit now. yay!
 |
        SetMode SVC26_mode, r7                  ; switch into 26-bit mode
 ]
        ADD     r13, r13, r4                    ; adjust return address

        LDR     r2, ResetMemC_Value
        BIC     r2, r2, #&C
        ORR     r2, r2, r0
        MOV     r0, #4*1024                     ; r0 = true page size (now split off
                                                ; from MEMC control register)
  [ Simulator
        TubeString r4, r5, r6, "Got through all of MemSize, and we're still here!"
        TubeChar r4, r5, "MOV r5, #4", NoStack
  ]
        MOV     pc, r13

; add_dram_bank
;   Entry: r10 -> workspace (initially 0)
;          r0  =  bank address
;   Exit:  r10 -> workspace (allocated if 0 on entry)
;          r0  =  next bank address
;          r9, r11, r13 preserved
;   Probe a DRAM bank, and add any DRAM found to the workspace
Add_DRAM_bank
	ROUT
	MOV	r12, lr			; r12 = return address
	EOR	r1, r0, #A16		; Check there is some RAM in the bank
	BL	DistinctAddresses
	ADDNE	r0, r0, #DRAM1PhysRam-DRAM0PhysRam
	MOVNE	pc, r12			; Return if no RAM in the bank

	; Only some address lines are decoded by the SIMM.  For example, a 4M SIMM may be split
	; into 2 banks, with A2-A20 decoded on each, or A2-A19,A21 decoded.  First we need to
	; find out which address lines are decoded, and which are ignored.
	MOV	r6, #DRAM1PhysRam-DRAM0PhysRam
	MOV	r7, #A17
	SUB	r6, r6, #1		; Get address lines which select address within bank.

	; Loop through the address lines, finding out which are decoded.  We clear the bits in r6
	; which correspond to non-decoded address lines.
	; r6 = address line mask
	; r7 = current address line
10	EOR	r1, r0, r7		; Toggle the address line
	BL	DistinctAddresses	; Check if address line has any effect.
	BICNE	r6, r6, r7		; Clear the bit if the address line fails.
	MOV	r7, r7, LSL #1		; Move onto the next address line.
	TST	r6, r7			; Have we reached the limit?
	BNE	%BT10			; Repeat if not.

	; r6 = decoded address lines in bank. (ie in A0-A25)
	; r7 = The size of the DRAM bank
	; Since the DRAM bank may not be contiguous, we now split the bank up into contiguous
	; blocks.  We make these as large as possible to save work.  Here we set r8 to the
	; size of the smallest contiguous block(s) of RAM.  (There will also be some contiguous
	; blocks which are twice this size in some cases.)
	ADD	r8, r6, #A17
	BIC	r8, r8, r6		; r8 = First clear bit in r6 from A17 up.

	RSB	r4, r8, #0		; r4 = All bits at or above r8 set since r8 is a power of 2.

	RSB	r7, r7, #0		; r7 = address bits which select the bank since r7 was a
					;      power of 2.
	ORR	r3, r7, r6		; r3 = All decoded address lines.
	AND	r7, r4, r3		; r7 = All decoded bits at or above r8.

; Make sure that the dram bank may not be contained within the image.  The code below fails
; to work correctly if a dram bank is contained within an OS image.  Currently this would
; require an image larger than 64M.
		ASSERT	OSROM_ImageSize*1024 <= DRAM1PhysRam-DRAM0PhysRam

15	MOV	r1, r0			; r1 = Address of start of block (inclusive).
	ADD	r2, r1, r8		; r2 = End of the block (exclusive).

	; Move the end of the block if the OS image begins in this block.
	ADRL	r4, ROM			; r4 = Start of the OS image (which may be in RAM).
	EOR	r5, r4, r1		; r5 = Difference between image and memory block.
	TST	r5, r7			; Check if the image begins in this block of RAM.
	ANDEQ	r2, r4, r3		; Set end of block to start of image.

	; Move the start of the block if the OS image ends in this block.
	ADD	r4, r4, #OSROM_ImageSize*1024
	SUB	r4, r4, #1		; r4 = Last byte of the OS image.
	EOR	r5, r4, r1		; r5 = Difference between end of image and block.
	TST	r5, r7			; Check if the image ends in this block of RAM.
	ANDEQ	r5, r4, r3		; r5 = Address of last byte of the image within this block.
	ADDEQ	r1, r5, #1		; Set start of block to the byte after the image.

	; If the image is contained in the block, we will have swapped the start and end
	; addresses.  This means that the block is split into two parts.  The bit below
	; the image and the bit above the image.
	CMP	r1, r2
	BLS	%FT20			; If start <= end, then block is not fragmented.
	CMP	r2, r0			; Check the size of the fragment before the image.
	MOV	r0, r1			; Store old start address
        SUB     r1, r1, #1              ; last byte of image (definitely in block)
	AND	r1, r1, r7		; Get the start of the block
	BLNE	Allocate_DRAM_fragment	; Allocate it if it's non-zero.
	MOV	r1, r0			; Restore the old start of fragment
        SUB     r0, r0, #1              ; last byte of image (definitely in block)
	AND	r0, r0, r7		; Get the start of the block again.
	ADD	r2, r0, r8		; End of next fragment is the end of the block.

	CMP	r1, r2			; Compare start and (modified) end.
20	BLNE	Allocate_DRAM_fragment

	; Now move onto the next block.  We add the non-decoded address lines to cause the
	; carry to be propagated across them.  Then we mask them out.
	MVN	r4, r7			; Add the non-connected address lines to ...
	ADD	r4, r4, r0		; ... the block address ...
	ADD	r4, r4, r8		; ... and the block size.
;	EOR	r5, r0, r4		; Compare with old address
	AND	r0, r4, r7		; Leave only the decoded lines set.
;	BIC	r5, r5, r6		; Clear decoded lines within the bank.
;	TST	r5, r7			; Check only the bank lines.
;	BEQ	%BT15			; Repeat for next block.

	TST	r0, r6
	BNE	%BT15

	MOV	pc, r12			; Done for this bank.

; Allocate_DRAM_block
;   Entry:
;     r1 = block start (inclusive)
;     r2 = block end (exclusive)
;     r3 = All decoded address lines
;     r7 = All decoded bits at or above r8
;     r8 = Size of largest contiguous block
;     block length is assumed to be at least the size of the static data - ie. 160k
;     The maximum block list size is then 4k, which fits easily into the cursor chunk
;   Exit:
;     r10 updated
;     r0, r3, r6-r9, r11-r13 preserved
;     r10 points to a word containing the number of blocks stored.
;     The pairs of words before
Allocate_DRAM_fragment
	ROUT
	CMP	r10, #0
	BEQ	%FT20

	; We are not dealing with the first block since r10 != 0.  Make an attempt to merge this block
	; with the previous block.
	LDMDB	r10, {r4, r5}		; Get details of the previous block
	ADD	r5, r4, r5		; Get the end address
	EOR	r5, r5, r1		; Compare with the current block start address...
	TST	r5, r3			; ... but only check the decoded bits.
	EOR	r5, r5, r1		; Restore the previous block end address.
	BNE	%FT10			; We can't merge it after the previous block

	; r4 = previous start
	; r5 = previous end
	; The block is just after the previous block.  That means the start address is unchanged, but
	; the length is increased.
	SUB	r5, r5, r4		; Calculate the previous block length.
	SUB	r2, r2, r1		; Find the length of the new block.
	; r2 = length of block
	ADD	r5, r5, r2		; Add it to the previous length.
	STR	r5, [r10, #-4]		; Update the block size in memory.
	MOV	pc, lr

	; The block is not just after the previous block, but it may be just before.  This may be the
	; case if we are softloaded.
10	SUB	r4, r4, #1		; Compare the address before the previous block start ...
	SUB	r2, r2, #1		; ... with the address of the last byte in this block ...
	EOR	r4, r4, r2
	TST	r4, r3			; ... but check only the decoded bits.
	ADD	r2, r2, #1		; Restore the end address.
	BNE	%FT20			; Skip if we cannot merge the block.

	; The block is just before the previous block.  The start address and length both change.
	LDR	r4, [r10, #-8]		; Get the previous block start again.

	SUB	r2, r2, r1		; Calculate the current block size.
	SUB	r4, r4, r2		; Subtract from the previous block start address.
	SUB	r5, r5, r4		; Calculate the new length=end-start
	STMDB	r10, {r4, r5}		; Update the block info in memory.
	MOV	pc, lr

	; We now have a region which does not merge with a previous region.  We move it up to the
	; highest address we can in the hope that this block will merge with the next block.
20	SUB	r2, r2, r1		; Calculate the block size
	MVN	r4, r3			; Get the non-decoded address lines.
	ORR	r1, r4, r1		; Set the non-decoded address bit in the start address.

30	CMP	r10, #0			; If the workspace has not been allocated...
	MOVEQ	r10, r1			; ... use this block.
	MOVEQ	r4, #0			; Initialise the counter.

	; The block/fragment to be added is between r1 and r1+r2.
	LDRNE	r4, [r10]		; Get the old counter if there was one.
	STMIA	r10!, {r1, r2}		; Store address and size.
	ADD	r4, r4, #1		; Increment the counter.
	STR	r4, [r10]		; Store the counter.

	MOV	pc, lr			; We've done with this block now.



; Memory map initialisation table
; Consists of word triplets (size,logaddr,type)
; where size    is size in bytes of area (size=0 terminates list)
;       logaddr is the base logical address of area
;       type is one of 5 formats:
;       a) a standard section-mapped L1 entry (physical address gets incremented for each MB in size)
;       b) like a section-mapped L1 entry, but with bit 12 set (address field holds base offset from "ROM" image)
;       c) like a section-mapped L1 entry, but with bit 13 set (address field holds base offset from start of video RAM)
;       d) like a page-mapped L1 entry, which indicates a page-mapped area to fill in
;          the L2 for. In this case the other bits are as follows:-
;               Bits 3,2   - CB respectively
;               Bits (11,10),(9,8),(7,6),(5,4) - access privileges
;               Bits 31-12 - offset in 1st DRAM bank to start of these pages (in units of pages)
;          If the size field contains -1, then it is the SoftCAMMap, and the appropriate size should be worked out,
;           and stored in SoftCamMapSize. Also, since the size of the L2 is variable the offset into the DRAM bank
;           of the SoftCamMap is unknown at assembly time, so the offset bits in table are zero.
;       e) zero - indicating that this area should abort (only necessary for section mapped bits in 48M-64M, cause they
;           have no level 2, therefore section must abort) - used for VIDC1 emulation area.
;       Note in case d), the L1 is not actually touched (it should have already been set up to point to the right L2)
;

ROMbit  *       1 :SHL: 12
Vidbit  *       1 :SHL: 13
PSS     *       PhysSpaceSize           :SHR: 20  ; Number of megabytes in physical space (used in table generation)

        MACRO
        MemInitSection  $size, $U, $C, $B, $logaddr, $ap, $physaddr
        &       ($size)*&00100000
        &       $logaddr
        &       (($U)*L1_U):OR:(($C)*L1_C):OR:(($B)*L1_B):OR:(($ap)*L1_APMult):OR:$physaddr:OR:L1_Section
        MEND

        MACRO
        MemInitROMs     $size, $U, $C, $B, $logaddr, $ap
        &       ($size)*&00100000
        &       $logaddr
        &       (($U)*L1_U):OR:(($C)*L1_C):OR:(($B)*L1_B):OR:(($ap)*L1_APMult):OR:ROMbit:OR:L1_Section
        MEND

        MACRO
        MemInitVideo    $size, $U, $C, $B, $logaddr, $ap
        &       ($size)*&00100000
        &       $logaddr
        &       (($U)*L1_U):OR:(($C)*L1_C):OR:(($B)*L1_B):OR:(($ap)*L1_APMult):OR:Vidbit:OR:L1_Section
        MEND

        MACRO
        MemInitAbort    $size, $logaddr
        &       ($size)*&00100000
        &       $logaddr
        &       0
        MEND

        MACRO
        MemInitPagesL2  $size, $C, $B, $logaddr, $ap, $dramoffset
        &       ($size)
        &       $logaddr
        &       (($C)*L1_C):OR:(($B)*L1_B):OR:(($ap)*L2_APMult):OR:$dramoffset:OR:L1_Page
        MEND

MemInitTable    ;       sz, U, C, B, logaddr,   (ap,     (physaddr))
        MemInitSection   4, 1, 0, 0, &03000000, AP_None, &03000000      ; I/O

        MemInitAbort     1,          &03400000                          ; VIDC1 emulation zone
        MemInitSection   1, 1, 0, 0, &03500000, AP_None, &03400000      ; VIDC20 space
        MemInitSection   2, 1, 0, 0, &03600000, AP_None, &03600000      ; LAGs

 [ OSROM_ImageSize >= 8192
        ; We will map in the whole ROM, but only the first 8M will fall in the 26-bit
        ; address space, and be available for modules.
        MemInitROMs      (OSROM_ImageSize / 1024), 1, 1, 1, &03800000, AP_Read
 |
  [ STB
   [ ExtROMSupport                                                      ; System build option
        ASSERT (OSROM_ImageSize <= 4096)                                ; No room for extension ROMs with an 8MB OS image
        MemInitROMs      4, 1, 1, 1, &03800000, AP_Read                 ; ROM
        MemInitSection   4, 1, 1, 1, &03C00000, AP_Read, &01000000      ; Extension ROM
   |
        MemInitROMs      8, 1, 1, 1, &03800000, AP_Read                 ; ROM (1st or 2nd bank)
   ]
  |
        [ OSROM_ImageSize = 4096
        MemInitROMs      4, 1, 1, 1, &03800000, AP_Read                 ; ROM
        MemInitROMs      4, 1, 1, 1, &03C00000, AP_Read                 ; ROM
        |
        MemInitROMs      2, 1, 1, 1, &03800000, AP_Read                 ; ROM
        MemInitROMs      2, 1, 1, 1, &03A00000, AP_Read                 ; ROM
        MemInitROMs      2, 1, 1, 1, &03C00000, AP_Read                 ; ROM
        MemInitROMs      2, 1, 1, 1, &03E00000, AP_Read                 ; ROM
        ]
  ]
 ]

        MemInitSection PSS, 1, 0, 0, PhysSpace, AP_None, &00000000      ; map of physical space

 [ ShadowROM
        MemInitROMs      2, 1, 1, 1, &FF800000, AP_Read                 ; ROM
        MemInitROMs      2, 1, 1, 1, &FFA00000, AP_Read                 ; ROM
        MemInitROMs      2, 1, 1, 1, &FFC00000, AP_Read                 ; ROM
        MemInitROMs      2, 1, 1, 1, &FFE00000, AP_Read                 ; ROM
 ]

; Now explicit initialisation of L2 for static pages

        MemInitPagesL2  &8000, 0, 0, CursorChunkAddress, AP_Read, DRAMOffset_CursorChunk  ;but see L1L2PTenhancements
        MemInitPagesL2  &8000, 1, 1, &00000000, AP_Full, DRAMOffset_PageZero
        MemInitPagesL2  &8000, 1, 1, SysHeapChunkAddress, AP_Full, DRAMOffset_SystemHeap

  [ StrongARM
;StrongARM requires 2*16k of private logical space (used for absolutely nothing else), which is
;readable and cacheable, for data cache cleaning purposes. We want to map the space to
;start of ROM bank 1 (physical target), so that IOMD timings can be poked for maximum read speed
;(only requirement of physical space is that it is readable without h/w abort). Here, though,
;we have to conform to format for MemInitPagesL2, so we just point to some convenient RAM,
;and fix things up later (see L1L2PTenhancements)
;
        MemInitPagesL2  &8000, 1, 1, ARMA_Cleaners_address, AP_Read, DRAMOffset_PageZero
  ]
  [ No26bitCode
        MemInitPagesL2  AbtStackSize, 1, 1, AbtStack, AP_Read, DRAMOffset_AbortStack
  ]

        MemInitPagesL2     -1, 1, 1, UndStackSoftCamChunk, AP_Full, 0   ; variable offset and size

        &       0, 0, 0                                                 ; terminate table

        LTORG

; DistinctAddresses routine...
; r0,r1 are the addresses to check
; uses r2-5
; writes interleaved patterns (to prevent dynamic storage...)
; checks writing every bit low and high...
; return Z-flag set if distinct

; This routine must work in 32-bit mode

DistinctAddresses ROUT
        LDR     r2, [r0] ; preserve
        LDR     r3, [r1]
        LDR     r4, Pattern
        STR     r4, [r0] ; mark first
        MOV     r5, r4, ROR #16
        STR     r5, [r1] ; mark second
        LDR     r5, [r0]
        CMP     r5, r4 ; check first
        BNE     %10    ; exit with Z clear
        LDR     r5, [r1] ; check second
        CMP     r5, r4, ROR #16 ; clear Z if not same
        BNE     %10
; now check inverse bit writes
        STR     r4, [r1] ; mark second
        MOV     r5, r4, ROR #16
        STR     r5, [r0] ; mark first
        LDR     r5, [r1]
        CMP     r5, r4 ; check second
        BNE     %10   ; exit with Z clear
        LDR     r5, [r0] ; check first
        CMP     r5, r4, ROR #16 ; clear Z if not same
10      STR     r3, [r1] ; restore
        STR     r2, [r0]
        MOV     pc, lr                  ; Z flag is already set up, and other flags don't matter

Pattern
        &       &AAFF5500 ; shiftable bit check pattern

; init state with masked out page size

ResetMemC_Value
        & &E010C :OR: MEMCADR       ; slugged ROMs + flyback refresh only + 32K page

; Constants
;
A0      *       1 :SHL: 00
A1      *       1 :SHL: 01
A2      *       1 :SHL: 02
A3      *       1 :SHL: 03
A4      *       1 :SHL: 04
A5      *       1 :SHL: 05
A6      *       1 :SHL: 06
A7      *       1 :SHL: 07
A8      *       1 :SHL: 08
A9      *       1 :SHL: 09
A10     *       1 :SHL: 10
A11     *       1 :SHL: 11
A12     *       1 :SHL: 12
A13     *       1 :SHL: 13
A14     *       1 :SHL: 14
A15     *       1 :SHL: 15
A16     *       1 :SHL: 16
A17     *       1 :SHL: 17
A18     *       1 :SHL: 18
A19     *       1 :SHL: 19
A20     *       1 :SHL: 20
A21     *       1 :SHL: 21
A22     *       1 :SHL: 22
A23     *       1 :SHL: 23
A24     *       1 :SHL: 24
A25     *       1 :SHL: 25
A26     *       1 :SHL: 26
A27     *       1 :SHL: 27
A28     *       1 :SHL: 28
A29     *       1 :SHL: 29
A30     *       1 :SHL: 30
A31     *       1 :SHL: 31

Page32K * &C ; in MEMC control reg patterns...
Page16K * &8
Page8K  * &4
Page4K  * &0

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; In    r0=0 -> Coming from the Test routine - no fancy business!
;       r1-r6 trashable
;       [[[ r9 = Current MEMC CR (true MEMC value, not fudged to look like 4K page size) ]]]

; Out   [[[ r9 MEMC value with slowest ROM speed, correct pagesize ]]]
;       r7 processor speed in kHz, bit 16 => can do STM to I/O (ie MEMC1a, MEMC2), bit 17 => MEMC2

; This routine must work in 32-bit mode, and should not use any memory!!!!

  [ RO371Timings

TimeCPU ROUT         ;does not actually measure anything - assumes timings (and EDO for 7500FE) according to IOMD id

        MOV     r2, #IOC                ; Address of the IO controller  (IOMD)

        LDRB    r7, [r2, #IOMD_ID0]     ; Is
        CMP     r7, #&E7                ; It
        LDRB    r7, [r2, #IOMD_ID1]     ; A
        CMPEQ   r7, #&D4                ; Risc PC ?
        BEQ     timecpuriscpc
        CMP     r7, #&AA                ; assume 7500 or 7500FE
        BEQ     timecpu7500FE
;7500 then
        MOV     r7, #&32                      ; 5-3 cycle ROM access
        STRB    r7, [r2, #IOMD_ROMCR0]
        STRB    r7, [r2, #IOMD_ROMCR1]
        MOV     r7, #&07                      ; clock dividers: /1 for I/O, /1 for CPU, /1 for memory
        STRB    r7, [r2, #IOMD_CLKCTL]
        LDR     r7, =(1 :SHL: 16) :OR: 16000  ; assumed 16MHz RAM (32 MHz bus)
        MOV     pc, lr

timecpu7500FE
;set memory to 32MHz for early boot (avoid probs with POST and with power-on key detection)
        MOV     r7, #&12                      ; 5-3 cycle ROM access, half speed (ie. 10-6)
        STRB    r7, [r2, #IOMD_ROMCR0]
        STRB    r7, [r2, #IOMD_ROMCR1]
        MOV     r7, #&70                      ; EDO RAM, 32 bit wide, conservative RAS and CAS timing
        STRB    r7, [r2, #IOMD_DRAMWID]       ; DRAM control reg. (more than just width on FE)
        MOV     r7, #&04                      ; clock dividers: /1 for CPU, /2 for memory, /2 for I/O
        STRB    r7, [r2, #IOMD_CLKCTL]
        LDR     r7, =(1 :SHL: 16) :OR: 32000  ; assumed 32MHz RAM (64 MHz bus), even though /2 at the moment
        MOV     pc, lr

timecpuriscpc
        MOV     r7, #&12                      ; 5-3 cycle ROM access
        STR     r7, [r2, #IOMD_ROMCR0]
        STR     r7, [r2, #IOMD_ROMCR1]
        LDR     r7, =(1 :SHL: 16) :OR: 16000  ; assumed 16MHz RAM (32 MHz bus)
        MOV     pc, lr

;used by NewReset, after main kernel boot
;sets full 64MHz memory if on 7500FE
;preserves registers _and_ flags
;
finalmemoryspeed ROUT
        EntryS  r0
        MOV     lr, #IOC
        LDRB    r0, [lr, #IOMD_ID0]     ; Is
        CMP     r0, #&E7                ; It
        LDRB    r0, [lr, #IOMD_ID1]     ; A
        CMPEQ   r0, #&D4                ; Risc PC ?
        BEQ     fmspeed_done
        CMP     r0, #&AA                ; EQ if 7500FE
        MOVEQ   r0, #&80
        STREQB  r0, [lr, #&CC]          ; ASTCR register: set i/o asynchronous timing for fast memory clock
        MOVEQ   r0, #&06                ; clock dividers: /1 for CPU, /1 for memory, /2 for I/O
        STREQB  r0, [lr, #IOMD_CLKCTL]
fmspeed_done
        EXITS                           ; ***KJB - flag preservation necessary?

  | ; else if not RO371Timings

ncpuloops * 1024 ; don't go longer than 4ms without refresh !
nmulloops * 128

TimeCPU ROUT            ;ONLY WORKS FOR IOMD(L) machines - this shouldn't be a problem though
 [ :LNOT: AutoSpeedROMS
        LDR     r7, =(1 :SHL: 16) :OR: 16000    ; indicate 16MHz RAM
 |

   [ {TRUE}
;don't do timing for Risc PC
;
;MJS bug fix (since 3.70) - setup r3 properly, and don't corrupt r0 you fool
;
        MOV     r3, #IOC                ; Address of the IO controller
        LDRB    r7, [r3, #IOMD_ID0]     ; Is
        CMP     r7, #&E7                ; It
        LDRB    r7, [r3, #IOMD_ID1]     ; A
        CMPEQ   r7, #&D4                ; Medusa?
        MOVEQ   r7,#&3e00               ;for non-Morris force 16MHz timing, assumed Risc PC
        ORREQ   r7,r7,#&80
        ORREQ   r7,r7,#&10000           ;and note we're on IOMD
        MOVEQ   pc,lr
  ]

; Time CPU/Memory speed
        LDR     r1, =&7FFE              ; 32K @@ 2MHz = ~16ms limit
        MOV     r3, #IOC                ; Address of the IO controller

        CMP     r0, #0
        LDREQ   r7, =(1 :SHL: 16) :OR: 16000    ; indicate 16MHz RAM - a little lie :-)
        MOVEQ   pc, lr                          ; Quick, leg it while they're not looking!

        ;Turn off the CPU cache
        ARM_number r4
        SUB     r4,r4,#6
        ADRL    r2,ARM_cacheoff_MMU_CR_table
        LDR     r2,[r2,r4,LSL #2]                 ;get appropriate cache-off value for MMU control reg
        ARM_write_control r2

        ;And don't forget to flush afterwards :-)
        ;SetCop r0, CR_IDCFlush
        ;SetCop  r0, CR_TLBFlush

        ;Turn off DMA/refreshes, but keep the reg contents for future restoration
        LDRB    r4, [r3, #IOMD_VREFCR]  ;Refresh
        LDRB    r5, [r3, #IOMD_SD0CR]   ;Sound
        LDRB    r6, [r3, #IOMD_VIDCR]   ;Video
        MOV     r2, #0
        STRB    r2, [r3, #IOMD_VREFCR]  ;Refresh off
        STRB    r2, [r3, #IOMD_SD0CR]   ;Sound off
        STRB    r2, [r3, #IOMD_VIDCR]   ;Video off

        MOV     r2, r1, LSR #8
        STRB    r1, [r3, #Timer1LL]
        STRB    r2, [r3, #Timer1LH]
        LDR     r2, =ncpuloops
        STRB    r2, [r3, #Timer1GO]     ; start the timer NOW
        B       %FT10                   ; Looks superfluous, but is required
                                        ; to get ncpuloops pipeline breaks
10
        SUBS    r2, r2, #1              ; 1S
        BNE     %BT10                   ; 1N + 2S

        STRB    r2, [r3, #Timer1LR]     ; latch count NOW
        LDRB    r2, [r3, #Timer1CL]
        LDRB    r7, [r3, #Timer1CH]
        ADD     r2, r2, r7, LSL #8      ; count after looping is ...

        SUB     r2, r1, r2              ; decrements !
        MOV     r7, r2, LSR #1          ; IOC clock decrements at 2MHz, so we now have ticks in 1MHz

        ;Put DMA/refreshes back to what they were
        STRB    r4, [r3, #IOMD_VREFCR]  ;Refresh back
        STRB    r5, [r3, #IOMD_SD0CR]   ;Sound back
        STRB    r6, [r3, #IOMD_VIDCR]   ;Video back

        ;And don't forget to flush first
        ;SetCop r0, CR_IDCFlush
        ;SetCop r0, CR_TLBFlush

        ;Turn on the CPU cache
        ARM_number r4
        SUB     r4,r4,#6
        ADRL    r2,ARM_default_MMU_CR_table
        LDR     r2,[r2,r4,LSL #2]                 ;get appropriate default value for MMU control reg
        ARM_write_control r2

        MOV     r2, r7
; In ROM - each cpu loop took 4R cycles @@ [MEMCLK cycles+1]/f*500ns/cycle

 [ MorrisSupport
        LDRB    r0, [r3, #IOMD_ID0]     ; Is
        CMP     r0, #&E7                ; It
        LDRB    r0, [r3, #IOMD_ID1]     ; A
        CMPEQ   r0, #&D4                ; Medusa?
        LDRNE   r0, =(4*15*500*ncpuloops)               ;Morris timing values [reordered to prevent miscalculation
                                                        ;due to Aasm integering mid-calculation] (30720000)
        LDREQ   r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
        DivRem  r7, r0, r2, r1          ; r2 preserved,   R7=memory speed in kHz (MEMCLK/2)
 |
        LDR     r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
        DivRem  r7, r0, r2, r1          ; r2 preserved,   R7=memory speed in kHz (MEMCLK/2)
 ]

        ;Set the ROM speeds appropriately here, including Burst/NoBurst
        MOV     r4, #SystemROMspeed     ;
        MUL     r0, r7, r4              ; r0 = number of cycles/ROM access *500000
        LDR     r1, =500000
        DivRem  r2, r0, r1, r4          ; r2 = divisor, r0 = remainder, r4 is trashed
        CMP     r0, #0
        ADDGT   r2, r2, #1              ; Always round _UPWARDS_
        CMP     r2, #14
        MOVGT   r2, #14                 ; Top out at 14 cycles

        MOV     r5, #BurstROMspeed      ;
        MUL     r0, r7, r5              ; r0 = number of cycles/ROM burst access *500000
        DivRem  r3, r0, r1, r4          ; r3 = divisor, r0 = remainder, r4 is trashed
        CMP     r0, #0
        ADDGT   r3, r3, #1              ; Always round _upwards_
        CMP     r3, #4
        MOVGT   r3, #4                  ; Top out at 4 cycles

  [ :LNOT: NormalSpeedROMS
    ;limit speeds to 4 cycles minimum (125 ns) - eg. for StrongARM with EPROM
    CMP   r2,#4
    MOVLT r2,#4
    CMP   r3,#4
    MOVLT r3,#4
    ! 0, "*** WARNING Autospeed ROM speed limited to 4 cycles (125 ns) minimum ***"
  ]
        ;So we have R2=cycles for normal access, R3=cycles for burst access
        ;Load the iomd reg into R1, clear the bits we're messing with
        MOV     r4, #IOC
        LDRB    r1, [r4, #IOMD_ROMCR0]  ; Read ROMCR0
        AND     r1, r1, #2_11000000     ; Only preserve bits 6 & 7

        ADR     r0, MemClkTable
        LDRB    r5, [r0, r2]            ; Grab the relevant byte
        ORR     r1, r1, r5

        ADR     r0, BurstTable
        LDRB    r5, [r0, r3]            ; Grab the relevant info
        ORR     r1, r1, r5

        STRB    r1, [r4, #IOMD_ROMCR0]  ; Write ROMCR0
        STRB    r1, [r4, #IOMD_ROMCR1]  ; Write ROMCR1

        ORR     r7, r7, #1 :SHL: 16     ; Note MEMC1a presence (we're on IOMD)
  ]
timecpu_sodthefancytimingstuff
        MOV     pc, lr

  ] ;RO371Timings conditional

        LTORG

MemClkTable
        DCB     2_100101                ; 0 cycles (set to min which is 2)
        DCB     2_100101                ; 1 cycle (set to min. which is 2)
        DCB     2_100101                ; 2 cycles
        DCB     2_100100                ; 3 cycles
        DCB     2_100011                ; 4 cycles
        DCB     2_100010                ; 5 cycles
        DCB     2_100001                ; 6 cycles
        DCB     2_100000                ; 7 cycles
        DCB     2_000011                ; 8 cycles (2x4)
        DCB     2_000010                ; 9 cycles (same as 10)
        DCB     2_000010                ; 10 cycles (2x5)
        DCB     2_000001                ; 11 cycles (same as 12)
        DCB     2_000001                ; 12 cycles (2x6)
        DCB     2_000000                ; 13 cycles (same as 14)
        DCB     2_000000                ; 14 cycles (2x7)

        ALIGN
BurstTable
        DCB     2_000000                ; 0 cycles (no burst)
        DCB     2_011000                ; 1 cycle
        DCB     2_011000                ; 2 cycles
        DCB     2_010000                ; 3 cycles
        DCB     2_001000                ; 4 cycles

        ALIGN

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
d445 1
d449 5
d455 1
a455 6
        ^       0
MMUCReason_ModifyControl        # 1    ; reason code 0
MMUCReason_Flush                # 1    ; reason code 1
MMUCReason_Unknown              # 0

MMUControlSWI   ENTRY
d469 1
d475 2
d478 2
a479 3
        Pull    lr
        SETV
        MOV     pc, lr
d486 9
a494 11
        PHPSEI  r4                      ; disable IRQs while we modify soft copy
        ARM_number r5
        MOV     r3, #0
        LDR     lr, [r3, #MMUControlSoftCopy]
        CMP     r5,#&A
  [ ARM810support
        CMPNE   r5,#8                   ; can read control reg on ARM 810 too
  ]
        ARM_read_control lr,EQ
        MOVEQ   lr,lr,LSL #19
        MOVEQ   lr,lr,LSR #19           ; if StrongARM then we can read control reg. - trust this more than soft copy
d498 8
a505 13
  [ ARM810support
        CMP     r5,#8
        BNE     %FT03
        TST     r2,#4
        ORRNE   r2,r2,#&800            ; if ARM810 then Z bit (branch prediction) mirrors C bit
        BICEQ   r2,r2,#&800
03
  ]
        CMP     r5,#&A
        BNE     %FT05
        TST     r2,#&4                  ; if StrongARM, then I bit mirrors C bit
        ORRNE   r2,r2,#&1000
        BICEQ   r2,r2,#&1000
a506 12
   [ SAWBbroken :LOR: ARM810bpbroken
        MOV     lr,r2
   [ SAWBbroken
        CMP     r5,#&A
        BICEQ   lr,lr,#&0008                   ;sorry guys, we can't use write buffer (safe-ish - safer would zap data cache bit as well)
     ]
     [ ARM810bpbroken
        CMP     r5, #8
        BICEQ   lr,lr,#&0800                   ;sorry guys (or sorry Guy!), we can't use branch predictor
     ]
        STR     lr, [r3, #MMUControlSoftCopy]
   |
a507 1
   ]
d510 1
d512 4
a515 1
        ARM_flush_cache r3
a516 3
  [ ARM810support
        CMP     r5,#8
        BNE     %FT12
d518 2
a519 8
        TST     lr, #MMUC_C             ; if cache turning off then clean/flush cache first
        BEQ     %FT12
    [ ARM810cleanflushbroken
        Push    "r0,r1"
        ARM8_cleanflush_IDC r0,r1
        ARM8_branchpredict_off r0       ; and turn off branch predict cleanly (must go off with cache)
        Pull    "r0,r1"
    |
d521 1
a521 2
        ARM8_cleanflush_IDC r0
        ARM8_branchpredict_off r0       ; and turn off branch predict cleanly (must go off with cache)
a522 15
    ]
12
  ]
        CMP     r5,#&A
        BNE     %FT15
        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off then clean StrongARM data cache first
        BEQ     %FT15
        Push    "r0-r2"
        MOV     r1,#ARMA_Cleaner_flipflop
        LDR     r0,[r1]
        EOR     r0,r0,#16*1024
        STR     r0,[r1]
        ARMA_clean_DC r0,r1,r2
        Pull    "r0-r2"
a523 12
   [ SAWBbroken :LOR: ARM810bpbroken
        MOV     lr,r2
   [ SAWBbroken
        CMP     r5,#&A
        BICEQ   lr,lr,#&0008            ;sorry guys, we can't use write buffer
     ]
     [ ARM810bpbroken
        CMP     r5,#8
        BICEQ   lr,lr,#&0800            ;sorry guys, we can't use branch predictor
     ]
        ARM_write_control lr
   |
a524 1
   ]
d527 1
d529 3
a531 1
        ARM_flush_cache r3
d537 8
a544 11
        ARM_number r5
        MOV     r3, #0
        LDR     lr, [r3, #MMUControlSoftCopy]
        CMP     r5,#&A
  [ ARM810support
        CMPNE   r5,#8                   ; can read control reg on ARM 810 too
  ]
        ARM_read_control lr,EQ
        MOVEQ   lr,lr,LSL #19
        MOVEQ   lr,lr,LSR #19           ; if StrongARM then we can read control reg. - trust this more than soft copy
        STREQ   lr, [r3, #MMUControlSoftCopy]
d550 18
a567 46
       Push     "r0-r4"
       ARM_read_ID r4
       AND      r4,r4,#&F000
       TST      r0,#&80000000
       BEQ      MMUC_flush_flushT
;flush cache
       CMP      r4,#&A000
  [ ARM810support
       CMPNE    r4,#&8000
  ]
       ARM67_flush_cache NE       ;if not StrongARM or ARM810, assume 6,7
       BNE      MMUC_flush_flushT
  [ ARM810support
       CMP      r4,#&A000
       BEQ      MMUC_flush_SA
;ARM810 then
    [ ARM810cleanflushbroken
       ARM8_cleanflush_IDC r1,r4
       MOV      r4,#&8000
    |
       ARM8_cleanflush_IDC r1
    ]
       B        MMUC_flush_flushT
MMUC_flush_SA
  ]
;StrongARM then
       MOV     r2,#ARMA_Cleaner_flipflop
       LDR     r1,[r2]
       EOR     r1,r1,#16*1024
       STR     r1,[r2]
       ARMA_clean_DC r1,r2,r3     ;effectively, fully clean/flush wrt non-interrupt stuff
       ARMA_drain_WB
       ARMA_flush_IC              ;do *not* flush DC - may be interrupt stuff in it
MMUC_flush_flushT
       TST     r0,#&40000000
       BEQ     MMUC_flush_done
  [ ARM810support
    ;there is a general macro, should have used this before anyway
       ARM_flush_TLB r1
  |
       CMP     r4,#&A000
       ARMA_flush_TLBs EQ
       ARM67_flush_TLB NE         ;if not StrongARM, assume 6,7
  ]
MMUC_flush_done
       Pull     "r0-r4,pc"
d586 1
a586 1
        mrs     AL, r1, SPSR                            ; r1 = saved PSR
d592 1
a592 1
        mrs     AL, r2, CPSR            ; now switch into SVC26
d595 2
a596 2
        msr     AL, SPSR_cxsf, r3       ; set SPSR_undef to be CPSR but with SVC26
        msr     AL, CPSR_c, r3          ; and select this mode now
d600 1
a600 1
        msr     AL, CPSR_c, r2          ; go back into undef mode
d608 17
d636 1
a636 1
        mrs     AL, r1, SPSR                            ; r1 = saved PSR
d647 1
a647 1
        mrs     AL, r2, CPSR            ; now switch into SVC26
d650 1
a650 1
        msr     AL, CPSR_c, r2
d668 2
d680 12
a691 2
        mrs     AL, r0, SPSR                    ; r0 = PSR when we aborted
        mrs     AL, r1, CPSR                    ; r1 = CPSR
d694 1
a694 1
        LDR     r4, =Abort32_dumparea+3*4       ;use temp area (avoid overwriting main area for expected aborts)
d712 1
a712 1
        msr     AL, CPSR_c, r3                  ; switch to user's mode
d716 1
a716 1
        mrs     AL, r5, SPSR                    ; get the SPSR for the aborter's mode
d721 1
a721 1
        msr     AL, CPSR_c, r1                  ; back to abort mode for the rest of this
d727 1
a727 1
        msr     AL, CPSR_c, r1
d744 7
a750 2
;ARM 810 or StrongARM allow signed byte load or half-word load/stores - not supported at present
;***KJB - need to think about LDRH family
d752 2
a753 2
        AND     r9, r10, #&0E000000
        TEQ     r9, #&08000000                  ; test for LDM/STM
a755 2
;        Write   "It's an LDM/STM"

d780 7
a786 8
;ARM 6/7 will have performed any writeback, ARM 8,StrongARM will not

        ARM_read_ID r6
        AND     r6, r6, #&F000
        CMP     r6, #&8000                      ;ARM 8 or
        CMPNE   r6, #&A000                      ;StrongARM
        MOVEQ   r6, r7
        SUBNE   r6, r7, r1, ASL #2
d790 1
a790 1

d843 1
a843 1
        TST     r1, #3                          ; test if transfer took place in USR mode
d880 1
d882 1
a882 1
34
d891 1
a891 1
        BNE     %BT34                           ; no, then loop
d928 1
a928 1
; it's an LDR/STR - first work out offset
d930 2
d933 1
a933 1
        DLINE   "It's an LDR/STR"
d935 5
d941 17
d989 5
a993 29
;;;assume ARM 6 configured for LateAbort - others cannot be configured
;;;so, at run time, ARM 6 or 7 means late, ARM 8 or StrongARM means early
;;;
;;; [ LateAborts
;;;        TST     r10, #1 :SHL: 21                ; if write-back
;;;        MOVNE   r8, #0                          ; then no post-inc
;;;        RSBEQ   r8, r9, #0                      ; else post-inc = - pre-inc
;;;        ADD     r0, r8, r9                      ; amount to subtract off base register for correction

;;;        TST     r10, #1 :SHL: 24                ; however, if we're doing post-increment
;;;        MOVEQ   r8, r9                          ; then post-inc = what was pre-inc
;;;        MOVEQ   r0, r9                          ; and adjustment is what was added on
;;;        RSB     r9, r8, #0                      ; and pre-inc = -post-inc
;;; |
;;;        TST     r10, #1 :SHL: 21                ; if write-back
;;;        MOVNE   r8, #0                          ; then no post-inc
;;;        RSBEQ   r8, r9, #0                      ; else post-inc = - pre-inc

;;;        TST     r10, #1 :SHL: 24                ; however, if we're doing post-increment
;;;        MOVEQ   r8, r9                          ; then post-inc = what was pre-inc
;;;        MOVEQ   r9, #0                          ; and pre-inc = 0
;;; ]

        ARM_read_ID r8
        AND     r8, r8, #&F000
        CMP     r8, #&8000
        CMPNE   r8, #&A000
        BEQ     %FT62
;ARM 6 or 7 (late)
d1005 1
a1005 1
;ARM 8 or StrongARM (early)
d1019 5
a1023 11
;;; [ LateAborts
;;;        SUB     r0, r6, r0                      ; compute adjusted base register
;;;        STR     r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all
;;; ]

        ARM_read_ID r1
        AND     r1, r1, #&F000
        CMP     r1, #&8000
        CMPNE   r1, #&A000
        SUBNE   r0, r6, r0                      ; compute adjusted base register (if late)
        STRNE   r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all
d1049 1
a1049 1
        TST     r1, #3                          ; test if transfer took place in USR mode
d1070 13
a1082 7
        Pull    "r6"                            ; LDR/LDRB, so get value to load into register
        TST     r10, #1 :SHL: 22                ; if LDRB
        ANDNE   r6, r6, #&FF                    ; then put zero in top 3 bytes of word
        ANDEQ   r9, r9, #3                      ; else rotate word to correct position - r9 = bottom 2 bits of address
        MOVEQ   r9, r9, LSL #3                  ; multiply by 8 to get rotation factor
        MOVEQ   r6, r6, ROR r9                  ; rotate to correct position in register

d1100 1
a1100 1
        mrs     AL, r1, CPSR
d1107 1
a1107 1
        mrs     AL, r6, SPSR                    ; get original SPSR, with aborter's original mode
d1116 1
a1116 1
        msr     AL, CPSR_c, r6                  ; switch to aborter's mode
d1118 1
a1118 1
        msr     AL, CPSR_c, r1                  ; switch back to ABT32
d1122 1
a1122 1
        msr     AL, SPSR_cxsf, r0               ; set up new SPSR (may have changed for LDM {PC}^)
d1131 2
d1139 1
a1139 1
        LDR     r0, =Abort32_dumparea
d1148 2
a1149 1
        MOV     r0, #0                                  ; we're going to call abort handler
d1151 4
d1156 1
a1156 2
        LDR     r0, =DAbHan
        LDR     r0, [r0]                                ; get address of data abort handler
d1166 1
a1166 1
        mrs     AL, r1, CPSR
d1168 1
a1168 1
        mrs     AL, r6, SPSR                    ; get original SPSR, with aborter's original mode
d1177 1
a1177 1
        msr     AL, CPSR_c, r6                  ; switch to aborter's mode
d1179 1
a1179 1
        msr     AL, CPSR_c, r1                  ; switch back to ABT32
a1213 1
 ]
d1215 2
a1216 1
        MOV     r0, #0                                  ; we're going to call abort handler
d1218 4
d1223 2
a1224 2
        LDR     r0, =DAbHan
        LDR     r0, [r0]                                ; get address of data abort handler
d1231 3
d1264 1
a1264 1
ProcessTransfer ENTRY "r1-r7,r12"
d1329 1
d1424 10
d1435 1
d1439 7
d1474 1
a1474 1
        MOV     r6, #0
d1526 3
d1533 18
d1553 1
a1553 1
        MOV     r0,#0
d1555 1
a1555 1
        TST     r1,#&200
a1610 18
;if we are on StrongARM, make the pages of the L2PT itself (for AppSpace only), bufferable (improves task swap speed)
;AppSpace is 0-28M
        ARM_read_ID r0
        AND     r0,r0,#&F000
        CMP     r0,#&A000
        BNE     %FT04
        MOV     r0,#L2PT
        ADD     r0,r0,#(L2PT :SHR: 10) ;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r0,#7*4             ;7 L2PT-of-L2PT entries for 28M of space
03
        LDR     r2,[r0]
        ORR     r2,r2,#4               ;bufferable bit
        STR     r2,[r0],#4
        CMP     r0,r1
        BNE     %BT03
        ARMA_drain_WB                  ;let us be paranoid
04

d1615 1
a1615 1
        LDR     r0,=MaxCamEntry
d1617 4
a1620 4
        ADD     r0,r0,#1+255+768		; = no. of 4k RAM pages in machine + 255 + 3*256
        MOV     r0,r0,LSR #8			; = no. of Mbytes in machine rounded up + 3
        BIC     r0,r0,#3			; round up to next 4 Mb
        CMP     r0,#28				; if 28Mb or more, no pages to be rescued from L2PT AppSpace
d1622 1
a1622 1
        LDR     r1,=AppSpaceDANode
d1624 2
a1625 2
        STR     r2,[r1,#DANode_MaxSize]		; update AppSpace max size
        MOV     r0,r0,LSR #2			; no. of L2PT AppSpace pages which cannot be rescued
d1627 5
a1631 5
        ADD	r4, r1, #L1PT-L2PT
        ADD	r4, r4, r0, LSL #4		;the L1PT entry to blank out (4 L1 entries per L2 entry)
        ADD     r1,r1,#(L2PT :SHR: (12-2))	;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r1,r0,LSL #2			;first entry for rescue
        LDR     r3,=FreePoolDANode
d1633 2
a1634 2
        LDR     r5,[r3,#DANode_Size]		; FreePool size so far
        ADD     r2,r2,r5			; r2 -> next logical address for a rescued page
d1636 1
a1636 1
        SUB     sp,sp,#16			; room for 1 page block entry + terminator
d1640 1
a1640 1
        LDR     r0,[r1],#4			; pick up the L2PT entry
d1642 2
a1643 2
        BIC     r0,r0,#&F00			; mask to leave physical address only
        STR     r0,[r3,#8]			; store physical address in word 2 of page block entry
d1649 1
a1649 1
        SWI     XOS_Memory			; fill in page number, given physical address
d1651 1
a1651 1
        MOV     r0,#2				; means inaccessible in user mode (destined for FreePool)
d1654 1
a1654 1
        STR     r0,[r3,#12]			; terminator
d1657 1
a1657 1
        STR     r2,[r3,#4]			; new logical address for page
d1661 5
a1665 5
	MOV	r0, #0				; Blank out the L1PT entries for the page table we just removed
	STR	r0, [r4], #4
	STR	r0, [r4], #4
	STR	r0, [r4], #4
	STR	r0, [r4], #4
d1669 1
a1669 1
        ADD     r5,r5,#4096			; next page
d1671 1
a1671 1
        CMP     r0,#7				;7 entries in total for full 28Mb AppSpace
d1673 1
a1673 1
        ADD     sp,sp,#16			;drop the workspace
d1675 2
a1676 2
        LDR     r0,=FreePoolDANode
        STR     r5,[r0,#DANode_Size]		;update FreePoolSize
d1680 5
a1684 1
  [ StrongARM
a1691 4
;max address range before IMBrange is treated as IMB (performance issue,
;since range clean can only specify entries by virtual address)
ARMA_IMBrange_threshold * 128*1024

a1702 7
;method:
;  ARMs 6,7 need do nothing (no IMB consideration)
;  ARM 8 need do nothing (SWI call itself flushes prefetch unit)
;  StrongARM must:
;    (1) clean data cache, (2) drain write buffer, (3) flush instruction cache
;    - the clean is either whole cache or range as appropriate
;
d1704 3
a1706 35
        ARM_read_ID R10
        AND     R10,R10,#&F000
        CMP     R10,#&A000
        BNE     SLVK                         ;not StrongARM
        TST     R0,#1                        ;range variant of SWI?
        BEQ     %FT01
        MOV     R11,R1                       ;R11 := low address (inclusive)
        ADD     R12,R2,#4                    ;R12 := high address (exclusive)
        SUB     R12,R12,R11
        CMP     R12,#ARMA_IMBrange_threshold
        BHS     %FT01                        ;do full IMB
        ADD     R12,R12,R11
        ARMA_clean_DCrange R11,R12
        ARMA_drain_WB
        ARMA_flush_IC WithoutNOPs
        MOV     R0,R0                  ;NOPs to ensure 4 instructions after IC flush before return
        MOV     R0,R0
        MOV     R0,R0
        B       SLVK
01      ;full IMB required
        LDR     R12,=SyncCodeA_sema
        MOV     R10,#1                  ;set semaphore
        SWPB    R11,R10,[R12]
        CMP     R11,#0                  ;was it already set?
        BNE     SLVK                    ;semaphore set, avoid reentrancy, let first call do it
        MOV     R12,#ARMA_Cleaner_flipflop
        LDR     R11,[R12]
        EOR     R11,R11,#16*1024
        STR     R11,[R12]
        ARMA_clean_DC R11,R12,R10  ;fully clean/flush DC wrt non-interrupt stuff
        ARMA_drain_WB
        ARMA_flush_IC WithoutNOPs  ;do *not* flush DC - may be stuff from interrupt routines
        MOV     R12,#0
        STRB    R12,[R12,#SyncCodeA_sema]  ;reset semaphore
        MOV     R0,R0              ;NOP to ensure 4 instructions after IC flush before return
d1708 29
a1739 88
;
;some service routines here for easy patchability
        ALIGN

dtgps_SAcleanflush  ; used during pages_unsafe/safe in ChangeDyn
    ADR     r0,PageBlock1
    ADD     r0,r0,#4        ; r0 -> page block (logical addresses)
    LDR     r1,NumEntries
dtgps_SAloop0
    LDR     r2,[r0],#12
    ADD     r3,r2,#4096     ; 4k page
dtgps_SAloop1
 [ SAcleanflushbroken         ; 2 separate instructions 'coz SA110 cleanflush (1 instruction) seems ineffective
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
 |
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
  ]
    CMP     r2,r3
    BLO     dtgps_SAloop1
    SUBS    r1,r1,#1
    BNE     dtgps_SAloop0
    ARMA_drain_WB           ; squeeze out those last drops
    MOV     pc,lr

 ]

;ARM810 equiv of dtgps_SAcleanflush must clean/flush whole cache (cannot clean/flush by virtual address)
;and is shared with code in meminfo_flushplease, below

meminfo_flushplease         ; used by MemInfo
        ARM_read_ID r0
        AND     r0,r0,#&F000
        CMP     r0,#&A000
        BEQ     mifp_SA
  [ ARM810support
        CMP     r0,#&8000
        BEQ     mifp_810
  ]
;assume ARM 6 or 7 - simple!
        ARM67_flush_cache
        MOV     pc,lr
mifp_SA
;StrongARM - this could take a while...
        MOV     r1,#ARMA_Cleaner_flipflop
        LDR     r0,[r1]
        EOR     r0,r0,#16*1024
        STR     r0,[r1]
        ARMA_clean_DC r0,r1,r2          ;clean/flush data cache wrt non-interrupt stuff (trashes r0,r1,r2)
        ARMA_flush_IC                   ;do *not* flush DC - may be interrupt stuff
        MOV     pc,lr
  [ ARM810support
mifp_810
dtgps_810cleanflush                     ;entry point also used during pages_unsafe/safe in ChangeDyn
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r0,r1
    |
        ARM8_cleanflush_IDC r0
    ]
        MOV     pc,lr
  ]
;

 [ {FALSE}
        DCB     "GROT"                  ;spare words marker
        ALIGN   4096                    ;align to page boundary for easy ROMpatch
arm600stuff_endofstuff
  ! 0,"-- size of ARM600+ stuff (4k aligned) is ":CC::STR:(arm600stuff_endofstuff - arm600stuff_startofstuff)
 ]


@


4.13
log
@  BBE changes.
Detail:
  Also a fix to the DRAM allocation in s/ARM600 to fix address masking.
Admin:
  Required by BBE.

Version 5.39. Tagged as 'Kernel-5_39'
@
text
@d1551 1
@


4.12
log
@* Run-time emulator detection added (no need for separate images). Needs an
  RPCEm update.
* Register allocation in default ErrorV handler fixed - problems occured when
  callbacks were triggered on way out.
* OS_Byte 19 didn't manipulate interrupt disable flag correctly in 26-bit
  builds.
* Stray bit of debugging left in sprite code many years ago removed.

Version 5.23. Not tagged
@
text
@d1970 1
d1974 1
@


4.12.2.1
log
@* Converted to building with ObjAsm (but still a single object file using ORG).
* Added ARM_IMB and ARM_IMBRange SWIs as recommended by ARMv5.
* Some early prototype HAL bits popped in - a lot of source restructuring still
  to come.
* New debug target creates an AIF image with debug information, and translates
  this into an ASCII object file for the 16702B logic analyser.

Version 5.35, 4.79.2.1. Tagged as 'Kernel-5_35-4_79_2_1'
@
text
@d20 3
a83 1
 [ :LNOT: HAL
a92 1
 ]
a100 1
 [ :LNOT: HAL
a102 1
 ]
d198 1
a198 1
SetDAG  Entry   "r0-r1,r12"
a666 1
  [ :LNOT: HAL
d856 6
a861 1
        MakeSkipTable   1, DRAMOffset_PageZero + 0, InitWsEnd - ZeroPage  ; skip 1st n bytes of LogRAM, so IRQs work!
a866 1
 ]
d1191 4
d1211 1
d1258 1
a1258 1
        MRS     r2, CPSR                ; read back PSR
a1289 3
 [ HAL
        ! 0, "Sort out Break"
 |
a1309 1
 ]
d1623 1
a1623 2
 [ :LNOT:HAL
        STRB    r6, [r12, #VRAMWidth]                   ; store width of VRAM (0,1 or 2)
a1636 1
  ]
d1643 3
d1651 5
a1679 1
 [ :LNOT: HAL
d1702 1
d1708 1
d1886 4
a1891 2
 ] ; :LNOT: HAL

a2175 1
 [ :LNOT: HAL
a2194 1
 ]
d2565 1
a2565 1
MMUControlSWI   Entry
d2776 1
a2776 1
        MRS     r1, SPSR                                ; r1 = saved PSR
d2782 1
a2782 1
        MRS     r2, CPSR                ; now switch into SVC26
d2785 2
a2786 2
        MSR     SPSR_cxsf, r3           ; set SPSR_undef to be CPSR but with SVC26
        MSR     CPSR_c, r3              ; and select this mode now
d2790 1
a2790 1
        MSR     CPSR_c, r2              ; go back into undef mode
d2809 1
a2809 1
        MRS     r1, SPSR                                ; r1 = saved PSR
d2820 1
a2820 1
        MRS     r2, CPSR                ; now switch into SVC26
d2823 1
a2823 1
        MSR     CPSR_c, r2
d2851 2
a2852 2
        MRS     r0, SPSR                        ; r0 = PSR when we aborted
        MRS     r1, CPSR                        ; r1 = CPSR
d2873 1
a2873 1
        MSR     CPSR_c, r3                      ; switch to user's mode
d2877 1
a2877 1
        MRS     r5, SPSR                        ; get the SPSR for the aborter's mode
d2882 1
a2882 1
        MSR     CPSR_c, r1                      ; back to abort mode for the rest of this
d2888 1
a2888 1
        MSR     CPSR_c, r1
d3258 1
a3258 1
        MRS     r1, CPSR
d3265 1
a3265 1
        MRS     r6, SPSR                        ; get original SPSR, with aborter's original mode
d3274 1
a3274 1
        MSR     CPSR_c, r6                      ; switch to aborter's mode
d3276 1
a3276 1
        MSR     CPSR_c, r1                      ; switch back to ABT32
d3280 1
a3280 1
        MSR     SPSR_cxsf, r0                   ; set up new SPSR (may have changed for LDM {PC}^)
d3318 1
a3318 1
        MRS     r1, CPSR
d3320 1
a3320 1
        MRS     r6, SPSR                        ; get original SPSR, with aborter's original mode
d3329 1
a3329 1
        MSR     CPSR_c, r6                      ; switch to aborter's mode
d3331 1
a3331 1
        MSR     CPSR_c, r1                      ; switch back to ABT32
d3409 1
a3409 1
ProcessTransfer Entry "r1-r7,r12"
a3833 10
        Push    "lr"
        BL      SyncCodeAreas
        Pull    "lr"                    ; no error return possible
        B       SLVK

SyncCodeAreas
        TST     R0,#1                   ; range variant of SWI?
        BEQ     SyncCodeAreasFull

SyncCodeAreasRange
d3837 3
a3839 2
        MOVNE   PC,LR                        ;not StrongARM

d3852 3
a3854 9
        MOV     PC,LR

SyncCodeAreasFull
        ARM_read_ID R10
        AND     R10,R10,#&F000
        CMP     R10,#&A000
        MOVNE   PC,LR                        ;not StrongARM

01      LDR     R12,=SyncCodeA_sema
d3858 1
a3858 1
        MOVNE   PC,LR                   ;semaphore set, avoid reentrancy, let first call do it
d3869 1
a3869 1
        MOV     PC,LR
@


4.12.2.2
log
@More HAL work. IOMD HAL work in progress. Lots of my own little build
scripts. Don't touch this.

Version 5.35, 4.79.2.2. Tagged as 'Kernel-5_35-4_79_2_2'
@
text
@a109 1
 [ :LNOT: HAL
a115 1
 ]
a137 1
 [ :LNOT: CacheOff
a163 1
 ]
d731 1
a731 1
        MOV     r0,#ZeroPage+InitClearRamWs             ;we can preserve r7-r9,r13 at logical address 52..67
d777 5
a781 12
        MOV     r0, #ZeroPage+InitClearRamWs
        LDMIA   r0, {r7-r9,r13}                         ;restore

        MOV     r0, #ZeroPage+InitUsedStart             ;clear our speed up workspace
        ASSERT  InitUsedStart < InitUsedEnd
        ASSERT  InitUsedEnd < InitClearRamWs
        GBLA    finalclear
finalclear      SETA InitUsedStart
        WHILE   finalclear < InitWsEnd
        STMIA   r0!,{r1-r3}
finalclear      SETA finalclear + 12
        WEND
@


4.12.2.3
log
@partial video changes for kernel/HAL split
near-HAL code for VIDC/IOMD in vdu.vduhint
briefly tested in Ursula desktop build
still some kernel workspace dependency in near-HAL code

Version 5.35, 4.79.2.3. Tagged as 'Kernel-5_35-4_79_2_3'
@
text
@d65 1
a65 1
; 17-Jun-96     BAR     Change speed settings for the second bank of ROM space.
d68 7
a74 7
; 25-Jul-96     BAR     Correct bug in video bandwidth code, wrong label used.
; 16-Aug-96     JRH     Programming of 2nd ROM bank (IOMD ROMCR1 register):
;                               reinstated ExtROMSupport code, added CanLiveOnROMCard code
;                       MemInitTable:
;                               If ExtROMSupport: added assertion that ImageSize <= 4096
;                               and maps 4MB of each ROM bank.
;                               Otherwise: always maps 8MB of ROM space independant of ImageSize
a138 1
  [ :LNOT: CacheOff
d140 1
d148 4
d154 1
d159 4
a164 3
;
  |
ARM_default_MMU_CR_table      ; if CacheOff true, same as cacheoff table
d167 3
d905 4
a908 4
        LDRB    r2,[r12,#IOMD_ID1]      ; load r2 with IOMD ID high byte
        LDRB    r0,[r12,#IOMD_ID0]      ; load r0 with IOMD ID low byte
        ORR     r0,r0,r2, LSL #8        ; Or r0 and r2 - shifted left 8, put in r0
        LDR     r2,=IOMD_7500           ; get Ref IOMD ID code for IOMD in a 7500
d910 1
a910 1
        BEQ     init7500cpu             ; If equal, got to init7500cpu
d912 2
a913 2
        LDRNE   r2,=IOMD_7500FE         ; If not, get ID code for IOMD in a 7500FE
        CMPNES  r0,r2                   ; If not, check for IOMD ID Code for IOMD in a 7500FE
d923 3
a925 3
;       CPUCLK divide by 1
;       MEMCLK divide by 2
;       IOCLK  divide by 2
d927 1
a927 1
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkHalf + IOMD_CLKCTL_IOclkHalf
d929 3
a931 3
;       CPUCLK divide by 2 unless FECPUSpeedNormal set
;       MEMCLK divide by 1
;       IOCLK  divide by 1
d935 1
a935 1
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkHalf
d937 1
a937 1
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
d941 1
a941 1
        MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkHalf
d943 1
a943 1
        MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
d979 2
a980 2
        TST     pc, #PhysExtROM                 ; are we running out of the 2nd ROM bank? Program the 2nd bank the same as the 1st if so
        STRNE   r0, [r12, #IOMD_ROMCR1]
d996 1
a996 1
        STREQB  r0, [r12, #IOMD_ROMCR1]
d998 1
a998 1
        STRB    r0, [r12, #IOMD_ROMCR1]
d1004 1
a1004 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; Program the 2nd bank the same as the 1st
d1006 1
a1006 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; 2nd bank unused: program it the same anyway
d1013 2
a1014 2
        MOV     r0, #IOMD_ASTCR_WaitStates
        STRB    r0, [r12, #IOMD_ASTCR]
d1016 1
a1016 1
        B       init7500cpu_common              ; branch to common init code.
d1023 3
a1025 3
;       CPUCLK divide by 1
;       MEMCLK divide by 1
;       IOCLK  divide by 1
d1060 2
a1061 2
        TST     pc, #PhysExtROM                 ; are we running out of the 2nd ROM bank? Program the 2nd bank the same as the 1st if so
        STRNE   r0, [r12, #IOMD_ROMCR1]
d1077 1
a1077 1
        STREQB  r0, [r12, #IOMD_ROMCR1]
d1079 1
a1079 1
        STRB    r0, [r12, #IOMD_ROMCR1]
d1085 1
a1085 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; Program the 2nd bank the same as the 1st
d1087 1
a1087 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; 2nd bank unused: program it the same anyway
d1094 2
a1095 2
        MOV     r0, #IOMD_ASTCR_Minimal
        STRB    r0, [r12, #IOMD_ASTCR]
d1224 2
a1225 2
        MOV     r0, #IOMD_ROMCR_16bit + IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff
        STRB    r0, [r12, #IOMD_ROMCR1]         ; 16bit 156.25nS noburst (Lowest common denominator)
d1409 3
a1411 3
        LDRB    r0, [r12, #IOMD_ID0]    ; load r1 with IOMD ID high byte
        LDRB    r1, [r12, #IOMD_ID1]    ; load r0 with IOMD ID low byte
        ORR     r0,r0,r1,LSL#8          ; Or r0 and r1, shifted left 8, put in r0
d1424 4
a1427 4
        LDR     r1, =IOMD_7500FE
        TEQ     r0, r1                                  ; are we on FE part?
        ORREQ   r11, r11, #IOMD_DRAMWID_EDO_Enable :OR: IOMD_DRAMWID_RASCAS_3 :OR: IOMD_DRAMWID_RASPre_3
                                                        ; if so, then enable EDO and slower RASCAS and RASPre times
d1468 1
a1468 1
        BL      Add_DRAM_bank
d1475 2
a1476 2
        MOV     r6, #0                                  ; No VRAM
        MOV     r0, #0
d1479 6
a1484 6
        LDRB    r4, [r14, #IOMD_ID0]
        LDRB    r7, [r14, #IOMD_ID1]
        ORR     r4, r4, r7, LSL #8
        LDR     r7, =IOMD_7500FE                        ; if FE part, then assume EDO DRAM
        TEQ     r4, r7
        LDREQ   r2, =80000000                           ; so allow 80E6 bytes/s
d1486 1
a1486 1
        LDRNE   r2, =44000000                           ; else only allow 44E6 bytes/s
d1490 1
a1490 1
        MOV     r1, #IOMD_VIDCR_DRAMMode :OR: &10       ; if no VRAM, then turn on DRAM mode, and set increment to &10
a1506 1
    [ :LNOT: CacheOff
a1509 1
    ]
d1548 1
a1548 1
        BL      Add_DRAM_bank
d1585 1
a1585 1
        MOVCC   r0, #0                                  ; Clear VRAM base if there is no VRAM
d1596 2
a1597 2
        TST     r10, r10
        BEQ     NoDRAMPanic                             ; Stop here if there is no DRAM (we could use VRAM I suppose...)
d1599 29
a1627 29
        MOV     r7, r6, LSL #20                         ; r7 = size of video memory
        LDR     r8, [r10]                               ; r8 = the number of DRAM blocks.
        SUB     r11, r10, r8, LSL #3                    ; Jump back to the start of the list

        LDMIA   r11!, {r4, r5}                          ; Get a block from the list. (r4,r5) = (base,size)
        CMP     r6, #0                                  ; Did we find any VRAM?
        BNE     %FT30                                   ; Skip this bit if we did.
        MOV     r0, r4                                  ; Allocate this block as video memory
        MOV     r7, r5
        CMP     r10, r11                                ; Was this the only block?  If so, leave 1M
        SUBEQS  r7, r7, #1024*1024
        MOVCC   r7, r5, ASR #1                          ; If that overflowed, take half the bank.
        CMP     r7, #8*1024*1024
        MOVCS   r7, #8*1024*1024                        ; Limit allocation to 8M - the size of the logical space

        ADD     r4, r4, r7                              ; Adjust the DRAM block base...
        SUBS    r5, r5, r7                              ; ... and the size.
        LDMEQIA r11!, {r4, r5}                          ; Fetch the next block if we claimed it all.

30      ADD     r12, r4, #DRAMOffset_PageZero           ; Use the first block for kernel workspace.
        ADD     r3, r12, #DRAMPhysAddrA                 ; Set the table address as well

        CMP     r8, #5
        ADDCS   r10, r11, #3:SHL:3                      ; Limit to 4 blocks of DRAM (3 + this one)

35      STMIA   r3!, {r4, r5}                           ; Put the DRAM block into the table
        TEQ     r10, r11
        LDMNEIA r11!, {r4, r5}                          ; Get the next block if there is one.
        BNE     %BT35
d1648 1
a1648 1
        ADD     r2, r12, #VideoPhysAddr                 ; r2 -> Start of PhysRamTable
d1663 1
a1663 1
        ADRL    r4, ROM
d1899 40
a1938 40
        ROUT
        MOV     r12, lr                 ; r12 = return address
        EOR     r1, r0, #A16            ; Check there is some RAM in the bank
        BL      DistinctAddresses
        ADDNE   r0, r0, #DRAM1PhysRam-DRAM0PhysRam
        MOVNE   pc, r12                 ; Return if no RAM in the bank

        ; Only some address lines are decoded by the SIMM.  For example, a 4M SIMM may be split
        ; into 2 banks, with A2-A20 decoded on each, or A2-A19,A21 decoded.  First we need to
        ; find out which address lines are decoded, and which are ignored.
        MOV     r6, #DRAM1PhysRam-DRAM0PhysRam
        MOV     r7, #A17
        SUB     r6, r6, #1              ; Get address lines which select address within bank.

        ; Loop through the address lines, finding out which are decoded.  We clear the bits in r6
        ; which correspond to non-decoded address lines.
        ; r6 = address line mask
        ; r7 = current address line
10      EOR     r1, r0, r7              ; Toggle the address line
        BL      DistinctAddresses       ; Check if address line has any effect.
        BICNE   r6, r6, r7              ; Clear the bit if the address line fails.
        MOV     r7, r7, LSL #1          ; Move onto the next address line.
        TST     r6, r7                  ; Have we reached the limit?
        BNE     %BT10                   ; Repeat if not.

        ; r6 = decoded address lines in bank. (ie in A0-A25)
        ; r7 = The size of the DRAM bank
        ; Since the DRAM bank may not be contiguous, we now split the bank up into contiguous
        ; blocks.  We make these as large as possible to save work.  Here we set r8 to the
        ; size of the smallest contiguous block(s) of RAM.  (There will also be some contiguous
        ; blocks which are twice this size in some cases.)
        ADD     r8, r6, #A17
        BIC     r8, r8, r6              ; r8 = First clear bit in r6 from A17 up.

        RSB     r4, r8, #0              ; r4 = All bits at or above r8 set since r8 is a power of 2.

        RSB     r7, r7, #0              ; r7 = address bits which select the bank since r7 was a
                                        ;      power of 2.
        ORR     r3, r7, r6              ; r3 = All decoded address lines.
        AND     r7, r4, r3              ; r7 = All decoded bits at or above r8.
d1943 1
a1943 1
                ASSERT  OSROM_ImageSize*1024 <= DRAM1PhysRam-DRAM0PhysRam
d1945 2
a1946 2
15      MOV     r1, r0                  ; r1 = Address of start of block (inclusive).
        ADD     r2, r1, r8              ; r2 = End of the block (exclusive).
d1948 40
a1987 40
        ; Move the end of the block if the OS image begins in this block.
        ADRL    r4, ROM                 ; r4 = Start of the OS image (which may be in RAM).
        EOR     r5, r4, r1              ; r5 = Difference between image and memory block.
        TST     r5, r7                  ; Check if the image begins in this block of RAM.
        ANDEQ   r2, r4, r3              ; Set end of block to start of image.

        ; Move the start of the block if the OS image ends in this block.
        ADD     r4, r4, #OSROM_ImageSize*1024
        SUB     r4, r4, #1              ; r4 = Last byte of the OS image.
        EOR     r5, r4, r1              ; r5 = Difference between end of image and block.
        TST     r5, r7                  ; Check if the image ends in this block of RAM.
        ANDEQ   r5, r4, r3              ; r5 = Address of last byte of the image within this block.
        ADDEQ   r1, r5, #1              ; Set start of block to the byte after the image.

        ; If the image is contained in the block, we will have swapped the start and end
        ; addresses.  This means that the block is split into two parts.  The bit below
        ; the image and the bit above the image.
        CMP     r1, r2
        BLS     %FT20                   ; If start <= end, then block is not fragmented.
        CMP     r2, r0                  ; Check the size of the fragment before the image.
        MOV     r0, r1                  ; Store old start address
        AND     r1, r1, r7              ; Get the start of the block
        BLNE    Allocate_DRAM_fragment  ; Allocate it if it's non-zero.
        MOV     r1, r0                  ; Restore the old start of fragment
        AND     r0, r0, r7              ; Get the start of the block again.
        ADD     r2, r0, r8              ; End of next fragment is the end of the block.

        CMP     r1, r2                  ; Compare start and (modified) end.
20      BLNE    Allocate_DRAM_fragment

        ; Now move onto the next block.  We add the non-decoded address lines to cause the
        ; carry to be propagated across them.  Then we mask them out.
        MVN     r4, r7                  ; Add the non-connected address lines to ...
        ADD     r4, r4, r0              ; ... the block address ...
        ADD     r4, r4, r8              ; ... and the block size.
;       EOR     r5, r0, r4              ; Compare with old address
        AND     r0, r4, r7              ; Leave only the decoded lines set.
;       BIC     r5, r5, r6              ; Clear decoded lines within the bank.
;       TST     r5, r7                  ; Check only the bank lines.
;       BEQ     %BT15                   ; Repeat for next block.
d1989 2
a1990 2
        TST     r0, r6
        BNE     %BT15
d1992 1
a1992 1
        MOV     pc, r12                 ; Done for this bank.
d2009 57
a2065 3
        ROUT
        CMP     r10, #0
        BEQ     %FT20
d2067 1
a2067 55
        ; We are not dealing with the first block since r10 != 0.  Make an attempt to merge this block
        ; with the previous block.
        LDMDB   r10, {r4, r5}           ; Get details of the previous block
        ADD     r5, r4, r5              ; Get the end address
        EOR     r5, r5, r1              ; Compare with the current block start address...
        TST     r5, r3                  ; ... but only check the decoded bits.
        EOR     r5, r5, r1              ; Restore the previous block end address.
        BNE     %FT10                   ; We can't merge it after the previous block

        ; r4 = previous start
        ; r5 = previous end
        ; The block is just after the previous block.  That means the start address is unchanged, but
        ; the length is increased.
        SUB     r5, r5, r4              ; Calculate the previous block length.
        SUB     r2, r2, r1              ; Find the length of the new block.
        ; r2 = length of block
        ADD     r5, r5, r2              ; Add it to the previous length.
        STR     r5, [r10, #-4]          ; Update the block size in memory.
        MOV     pc, lr

        ; The block is not just after the previous block, but it may be just before.  This may be the
        ; case if we are softloaded.
10      SUB     r4, r4, #1              ; Compare the address before the previous block start ...
        SUB     r2, r2, #1              ; ... with the address of the last byte in this block ...
        EOR     r4, r4, r2
        TST     r4, r3                  ; ... but check only the decoded bits.
        ADD     r2, r2, #1              ; Restore the end address.
        BNE     %FT20                   ; Skip if we cannot merge the block.

        ; The block is just before the previous block.  The start address and length both change.
        LDR     r4, [r10, #-8]          ; Get the previous block start again.

        SUB     r2, r2, r1              ; Calculate the current block size.
        SUB     r4, r4, r2              ; Subtract from the previous block start address.
        SUB     r5, r5, r4              ; Calculate the new length=end-start
        STMDB   r10, {r4, r5}           ; Update the block info in memory.
        MOV     pc, lr

        ; We now have a region which does not merge with a previous region.  We move it up to the
        ; highest address we can in the hope that this block will merge with the next block.
20      SUB     r2, r2, r1              ; Calculate the block size
        MVN     r4, r3                  ; Get the non-decoded address lines.
        ORR     r1, r4, r1              ; Set the non-decoded address bit in the start address.

30      CMP     r10, #0                 ; If the workspace has not been allocated...
        MOVEQ   r10, r1                 ; ... use this block.
        MOVEQ   r4, #0                  ; Initialise the counter.

        ; The block/fragment to be added is between r1 and r1+r2.
        LDRNE   r4, [r10]               ; Get the old counter if there was one.
        STMIA   r10!, {r1, r2}          ; Store address and size.
        ADD     r4, r4, #1              ; Increment the counter.
        STR     r4, [r10]               ; Store the counter.

        MOV     pc, lr                  ; We've done with this block now.
d2623 12
d2636 1
d2674 12
d2687 1
d3741 4
a3744 4
        ADD     r0,r0,#1+255+768                ; = no. of 4k RAM pages in machine + 255 + 3*256
        MOV     r0,r0,LSR #8                    ; = no. of Mbytes in machine rounded up + 3
        BIC     r0,r0,#3                        ; round up to next 4 Mb
        CMP     r0,#28                          ; if 28Mb or more, no pages to be rescued from L2PT AppSpace
d3748 2
a3749 2
        STR     r2,[r1,#DANode_MaxSize]         ; update AppSpace max size
        MOV     r0,r0,LSR #2                    ; no. of L2PT AppSpace pages which cannot be rescued
d3751 4
a3754 4
        ADD     r4, r1, #L1PT-L2PT
        ADD     r4, r4, r0, LSL #4              ;the L1PT entry to blank out (4 L1 entries per L2 entry)
        ADD     r1,r1,#(L2PT :SHR: (12-2))      ;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r1,r0,LSL #2                 ;first entry for rescue
d3757 2
a3758 2
        LDR     r5,[r3,#DANode_Size]            ; FreePool size so far
        ADD     r2,r2,r5                        ; r2 -> next logical address for a rescued page
d3760 1
a3760 1
        SUB     sp,sp,#16                       ; room for 1 page block entry + terminator
d3764 1
a3764 1
        LDR     r0,[r1],#4                      ; pick up the L2PT entry
d3766 2
a3767 2
        BIC     r0,r0,#&F00                     ; mask to leave physical address only
        STR     r0,[r3,#8]                      ; store physical address in word 2 of page block entry
d3773 1
a3773 1
        SWI     XOS_Memory                      ; fill in page number, given physical address
d3775 1
a3775 1
        MOV     r0,#2                           ; means inaccessible in user mode (destined for FreePool)
d3778 1
a3778 1
        STR     r0,[r3,#12]                     ; terminator
d3781 1
a3781 1
        STR     r2,[r3,#4]                      ; new logical address for page
d3785 5
a3789 5
        MOV     r0, #0                          ; Blank out the L1PT entries for the page table we just removed
        STR     r0, [r4], #4
        STR     r0, [r4], #4
        STR     r0, [r4], #4
        STR     r0, [r4], #4
d3793 1
a3793 1
        ADD     r5,r5,#4096                     ; next page
d3795 1
a3795 1
        CMP     r0,#7                           ;7 entries in total for full 28Mb AppSpace
d3797 1
a3797 1
        ADD     sp,sp,#16                       ;drop the workspace
d3800 1
a3800 1
        STR     r5,[r0,#DANode_Size]            ;update FreePoolSize
@


4.12.2.4
log
@further kernel/HAL split work in video area
almost-HAL code for VIDC20/IOMD in vdu.vduhint, now almost divorced
from kernel workspace
tested briefly in Ursula desktop environment

Version 5.35, 4.79.2.4. Tagged as 'Kernel-5_35-4_79_2_4'
@
text
@d184 92
a276 3
; mjs Oct 2000 kernel/HAL split
; SetDAG stuff is no more, routines like SetVinit now call equivalent HAL
; routine
d634 1
a634 10
; mjs Oct 2000 kernel/HAL split
;
; The kernel itself should now never call this SWI, but grudgingly has
; to maintain at least bit 10 of soft copy
;
; Here, we only mimic action of bit 10 to control video/cursor DMA (eg. for ADFS)
; The whole OS_UpdateMEMC thing would ideally be withdrawn as archaic, but
; unfortunately has not even been deprecated up to now

; for reference, the bits of the MEMC1 control register are:
d645 14
a658 14
        Push  "r0-r3, r9, r14"   ; can corrupt r12
        TST   r11, #(1 :SHL: 10)
        MOVEQ r0, #1             ; blank (video DMA disable)
        MOVNE r0, #0             ; unblank (video DMA enable)
        MOV   r1, #0             ; no funny business with DPMS
;;;
;;;mjsHAL my temporary macros aren't defined early enough! 
;;;        mjsAddressHAL
;;;        mjsCallHAL    HAL_Video_SetBlank
   LDR     r9, =mjs_tempHALworkspace
   LDR     r9, [r9] 
   BL      HAL_Video_SetBlank
;;;
        Pull  "r0-r3, r9, r14"
@


4.12.2.5
log
@More HAL work. IOMD HAL fleshed out somewhat - system gets most of the way
through initialisation.

Version 5.35, 4.79.2.5. Tagged as 'Kernel-5_35-4_79_2_5'
@
text
@a135 1
 [ :LNOT: HAL
a178 1
 ]
a182 2
        KEEP

d571 1
a571 1
;;;mjsHAL my temporary macros aren't defined early enough!
d575 1
a575 1
   LDR     r9, [r9]
a2727 2

        EXPORT DAbPreVeneer
@


4.12.2.6
log
@mjs macros switch on HAL for calling video code in HAL/pseudo HAL cases
vduhint code even more almost ready to move to HAL

Version 5.35, 4.79.2.6. Tagged as 'Kernel-5_35-4_79_2_6'
@
text
@d574 8
a581 2
        mjsAddressHAL
        mjsCallHAL    HAL_Video_SetBlank
@


4.12.2.7
log
@Wahey! This version gives you a display.

It says "Abort on data transfer".
@
text
@d117 1
a118 1
 ]
a2074 1
 [ :LNOT: HAL
a2075 1
 ]
a3455 10
 [ HAL
        SUB     sp, sp, #4
        Push    "r0-r3,r12"
        MOV     r0, #0
        MOV     r1, lr
        ADD     r2, sp, #5*4
        BL      RISCOS_AccessPhysicalAddress
        MOV     lr, r0
        Pull    "r0-r3,r12"
 |
a3456 1
 ]
a3461 7
 [ HAL
        Push    "r0-r3,r12,lr"
        LDR     r0, [sp, #6*4]
        BL      RISCOS_ReleasePhysicalAddress
        Pull    "r0-r3,r12,lr"
        ADD     sp, sp, #4
 ]
@


4.12.2.8
log
@More L7200 HAL work
@
text
@a2247 1
 [ :LNOT: HAL
a2266 1
 ]
@


4.12.2.9
log
@More stuff. Up to the desktop now; cache on, working keyboard. Some source
restructuring to start to make splitting it up into several object files more
feasible.
@
text
@d366 10
a375 5

        MOV     r0, r3
        Push    "r2,r3,lr"
        ARMop   TLB_InvalidateEntry             ;invalidate TLB entry for this page
        Pull    "r2,r3,pc"
a395 2
        MOV     r0, r3
        Push    "r2,r3,lr"
d397 3
a399 4
        ARMop   MMU_ChangingEntry, EQ             ;flush instruction/data cache if necessary
        TST     r11,#DynAreaFlags_NotCacheable
        ARMop   TLB_InvalidateEntry, NE           ;flush TLB entry for this page
        Pull    "r2,r3,pc"
a489 1
        Push    "r2,r3,lr"
d491 3
a493 4
        ARMop   MMU_Changing, EQ             ;flush instruction/data cache+TLB if necessary
        TST     r11,#DynAreaFlags_NotCacheable
        ARMop   TLB_InvalidateAll, NE        ;flush TLB
        Pull    "r2,r3,pc"
d2542 1
a2542 4

        Push    "r0-r3"
        ARMop   Cache_InvalidateAll
        Pull    "r0-r3"
@


4.12.2.10
log
@more use of ARMops in page manipulation, change register usage of ARmops
tested by kernel boot to star prompt only

Version 5.35, 4.79.2.11. Tagged as 'Kernel-5_35-4_79_2_11'
@
text
@d197 1
a197 1
;       BangCamUpdate - Update CAM, MMU for page move, coping with page currently mapped in
d199 1
a199 2
; mjs Oct 2000
; reworked to use generic ARM ops (vectored to appropriate routines during boot)
d266 1
a266 1
;       BangCam - Update CAM, MMU for page move, assuming page currently mapped out
d269 3
a271 1
; It is assumed that the physical page is currently not mapped anywhere else
d287 11
d315 1
a315 1

d321 1
a321 1

a325 2
        ;fall through to BangL2PT

d333 3
a335 3
        Push    "lr"
        MOV     r6, r0

d338 43
d382 53
a434 11
        ;we sort out cache coherency _before_ remapping, because some ARMs might insist on
        ;that order (write back cache doing write backs to logical addresses)
        ;we need to worry about cache only if mapping out a cacheable page
        ;
        TEQ     r6, #0                          ;EQ if mapping out
        TSTEQ   r11, #DynAreaFlags_NotCacheable ;EQ if also cacheable
        MOV     r0, r3                          ;MMU page entry address
        ADR     lr, %FT20
        MOV     r4, #0
        ARMop   MMU_ChangingEntry, EQ, tailcall, r4
        ARMop   MMU_ChangingUncachedEntry, NE, tailcall, r4
d436 11
a446 3
20      STR     r6, [r1, r3, LSR #10]           ;update L2PT entry

        Pull    "pc"
d449 25
a473 12

        ;sledgehammer is super cautious and does cache/TLB coherency on a global basis
        ;should only be used for awkward cases                                       
        ;
        TEQ     r6, #0                          ;EQ if mapping out
        TSTEQ   r11, #DynAreaFlags_NotCacheable ;EQ if also cacheable
        ADR     lr, %FT30
        MOV     r4, #0
        ARMop   MMU_Changing, EQ, tailcall, r4
        ARMop   MMU_ChangingUncached, NE, tailcall, r4

30      STR     r6, [r1, r3, LSR #10]!          ; update level 2 page table (and update pointer so we can use bank-to-bank offset     
d475 2
a476 2
        STRNE   r6, [r1, r9, LSR #10]           ; then store entry for 2nd copy as well
        ADDNE   r3, r3, r9                      ; and point logical address back at 2nd copy
d478 37
a514 1
        Pull    "pc"
d2543 3
a2545 4
        Push    "r0"
        MOV     r0, #0
        ARMop   Cache_InvalidateAll,,,r0
        Pull    "r0"
@


4.12.2.11
log
@More touchscreen tuning. Screen memory increase crash fixed.
@
text
@a299 1
        LDR     r4, =DuffEntry          ; check for requests to map a page to nowhere
a300 2
        TEQ     r4, r3                  ; don't actually map anything to nowhere
        MOVEQ   pc, lr
d348 1
a348 1
        ;should only be used for awkward cases
d357 1
a357 1
30      STR     r6, [r1, r3, LSR #10]!          ; update level 2 page table (and update pointer so we can use bank-to-bank offset
@


4.12.2.12
log
@Check-in of the few last-minute changes for the Customer L demo. Nothing
exciting, apart from an extended touchscreen API.

Version 5.35, 4.79.2.13. Tagged as 'Kernel-5_35-4_79_2_13'
@
text
@d372 1
a372 1
        &       (AP_ROM  * L2_APMult) + L2_SmallPage      ; R any W none
@


4.12.2.13
log
@First attempt at ARM9 support, and general clean-up of old ARM-specific
code, now using vectored ARMops.
Not tested.

Version 5.35, 4.79.2.14. Tagged as 'Kernel-5_35-4_79_2_14'
@
text
@d128 8
d180 1
a180 1
 ]  ; HAL
d635 1
a635 2

 ]  ; :LNOT: HAL
d1077 1
a1077 2

 ]   ; HAL
d1259 17
a1275 1

d1277 13
d1606 6
d1959 1
a1959 2

 ] ; :LNOT HAL
a2155 2

        ; note that this old style code wont compile properly if HAL (no table)
a2203 2

        ;note that this old style code wont compile properly if HAL (no table)
a2305 1

a2355 1

d2361 3
a2363 4
        MOV     r3,#0
        LDRB    r5,[r3, #ProcessorArch]
        PHPSEI  r4                      ; disable IRQs while we modify soft copy (and possibly switch caches off/on)

d2365 7
a2371 4
        CMP     r5,#ARMv4
        ARM_read_control lr,HS      
        MOVHS   lr,lr,LSL #19
        MOVHS   lr,lr,LSR #19           ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
d2375 11
a2385 4
        LDR     r5, [r3, #ProcessorFlags]
        TST     r5, #CPUFlag_SplitCache
        BEQ     %FT05
        TST     r2,#&4                  ; if split caches, then I bit mirrors C bit
d2399 3
d2403 8
a2410 2
        TST     lr, #MMUC_C             ; if cache turning off then clean data cache first
        BEQ     %FT15
d2412 2
a2413 2
        MOV     r0, #0
        ARMop   Cache_CleanAll,,,r0
d2415 15
d2435 1
a2435 4
        Push    "r0"
        MOV     r0, #0
        ARMop   Cache_InvalidateAll,,,r0
        Pull    "r0"
d2441 1
a2442 1
        LDRB    r5, [r3, #ProcessorArch]
d2444 8
a2451 5
        CMP     r5, #ARMv4
        ARM_read_control lr,HS
        MOVHS   lr,lr,LSL #19
        MOVHS   lr,lr,LSR #19           ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
        STRHS   lr, [r3, #MMUControlSoftCopy]
d2457 3
a2459 2
       Push     "r0,r1"
       MOV      r1, #0
d2462 28
a2489 1
       ARMop    Cache_CleanInvalidateAll,,,r1
d2491 10
a2500 3
       TST      r0,#&40000000
       BEQ      MMUC_flush_done
       ARMop    TLB_InvalidateAll,,,r1
d2502 1
a2502 1
       Pull     "r0,r1,pc"
d2685 8
a2692 7
;writeback will have been performed for ARMs with CPUFlag_BaseRestored clear
;
        MOV     r6, #0
        LDR     r6, [r6, #ProcessorFlags]
        TST     r6, #CPUFlag_BaseRestored
        MOVNE   r6, r7
        SUBEQ   r6, r7, r1, ASL #2
d2696 1
a2696 1
;
d2893 6
a2898 5
        MOV     r8, #0
        LDR     r8, [r8, #ProcessorFlags]
        TST     r8, #CPUFlag_BaseRestored
        BNE     %FT62
;not base restored
d2910 1
a2910 1
;base restored
d2929 6
a2934 5
        MOV     r1, #0
        LDR     r1, [r1, #ProcessorFlags]
        TST     r1, #CPUFlag_BaseRestored
        SUBEQ   r0, r6, r0                      ; compute adjusted base register (if not base restored)
        STREQ   r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all
d3481 18
d3568 1
a3568 2


d3576 4
d3591 7
d3609 18
a3626 12
        Push    "r0-r2, lr"
        MOV     r0, r1
        ADD     r1, r2, #4                 ;exclusive end address
        MOV     r2, #0
        LDR     lr, [r2, #DCache_LineLen]
        SUB     lr, lr, #1
        ADD     r1, r1, lr                 ;rounding up end address
        MVN     lr, lr
        AND     r0, r0, lr                 ;cache line aligned
        AND     r1, r1, lr                 ;cache line aligned
        ARMop   IMB_Range,,,r2
        Pull    "r0-r2, pc"
d3629 21
a3649 4
        Push    "r0, lr"
        MOV     r0, #0
        ARMop   IMB_Full,,,r0
        Pull    "r0, pc"
d3652 88
@


4.12.2.14
log
@kernel now attempts to substitute video mode numbers in face of
h/w with limited bits-per-pixel support (not tested yet)
HAL_API document added - early draft only, of interest to those
writing or modifying HALs for new h/w
ARMop_API document added - early draft only, of interest only
to those modifying kernel to support new ARM cores
*** polite comments on HAL_API welcome ***

Version 5.35, 4.79.2.15. Tagged as 'Kernel-5_35-4_79_2_15'
@
text
@a2394 1
       LDR      r0, [sp]
@


4.12.2.15
log
@ fix for IMB_range
Detail:
  ARM600.s
Admin:
  (highlight level of testing that has taken place)
  (bugfix number if appropriate)
@
text
@d3481 1
a3481 1
        LDRB    lr, [r2, #DCache_LineLen]
@


4.12.2.16
log
@Various L7200 tweaks, plus working ARM920T code.

Version 5.35, 4.79.2.17. Tagged as 'Kernel-5_35-4_79_2_17'
@
text
@d2333 3
a2335 3
        ARM_read_control lr,HS
;        MOVHS   lr,lr,LSL #19
;        MOVHS   lr,lr,LSR #19           ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
d2382 2
a2383 2
;        MOVHS   lr,lr,LSL #19
;        MOVHS   lr,lr,LSR #19           ; if ARMv4 or later, we can read control reg. - trust this more than soft copy
@


4.12.2.17
log
@Reimplement Lazy task swapping, an amusing idea from Ursula,
would have done it sooner but couldn't be bothered (humour).
Currently activates for all ARMs flagged as base-restored
abort model. No handling of eg. StrongARM pre-revT bug, but
then the kernel no longer runs on StrongARM (progress).
Still some details to fix: all aborts in current app space
assumed to be missing pages, but this must be fixed to
handle abort code in app space, things like debuggers
marking code read only.

Plus, small fixes:
  OS_Memory 8 returns vaguely useful info for RAM,VRAM
  in HAL build (temporary partial implementation)
  Broken handling of old BBC commands with (fx,tv etc)
  with no spaces fixed (fudgeulike code from Ursula,
  now 32-bit).

Version 5.35, 4.79.2.31. Tagged as 'Kernel-5_35-4_79_2_31'
@
text
@a2441 16
 [ No26bitCode :LAND: ChocolateAMB
;  Instruction fetch abort pre-veneer, just to field possible lazy AMB aborts
;
PAbPreVeneer    ROUT
        Push    "r0-r7, lr"               ; wahey, we have an abort stack
        SUB     r0, lr_abort, #4          ; aborting address
        BL      AMB_LazyFixUp             ; can trash r0-r7, returns NE status if claimed and fixed up
        Pull    "r0-r7, lr", NE           ; restore regs and
        SUBNES  pc, lr_abort, #4          ; restart aborting instruction if fixed up
        LDR     lr, [sp, #8*4]            ; (not a lazy abort) restore lr
        LDR     r0, =PAbHan               ; we want to jump to PAb handler, in abort mode
        LDR     r0, [r0]
        STR     r0, [sp, #8*4]
        Pull    "r0-r7, pc"
 ]

a2495 9

  [ ChocolateAMB
        ARM_read_FAR r0                         ; aborting address
        BL      AMB_LazyFixUp                   ; can trash r0-r7, returns NE status if claimed and fixed up
        LDR     lr_abort, [r13_abort, #15*4]    ; restore lr_abort
        LDMIA   r13_abort, {r0-r7}              ; restore regs
        ADDNE   r13_abort, r13_abort, #17*4     ; if fixed up, restore r13_abort
        SUBNES  pc, lr_abort, #8                ; and restart aborting instruction 
  ]
@


4.12.2.18
log
@* Allows interrupt-driven use of PointerV (as well as polled).
* Allows HAL-driven software resets.
* Sound buffers corrected to be uncacheable.

Version 5.35, 4.79.2.33. Tagged as 'Kernel-5_35-4_79_2_33'
@
text
@d635 5
a639 1
; in:   r1 = 0 if reset, 1 if break
d996 4
d1006 14
@


4.12.2.19
log
@Lots of Tungsten work.

Version 5.35, 4.79.2.48. Tagged as 'Kernel-5_35-4_79_2_48'
@
text
@a298 1
 [ {FALSE}
a305 17
 |
        ASSERT  DynAreaFlags_CPBits = 7 :SHL: 12
        ASSERT  DynAreaFlags_NotCacheable = 1 :SHL: 5
        ASSERT  DynAreaFlags_NotBufferable = 1 :SHL: 4

        ORR     r0, r0, r1

        MOV     r6, #ZeroPage
        LDR     r6, [r6, #MMU_PCBTrans]
        AND     r4, r11, #DynAreaFlags_CPBits
        AND     r1, r11, #DynAreaFlags_NotCacheable + DynAreaFlags_NotBufferable
        TST     r11, #PageFlags_TempUncacheableBits
        ORRNE   r1, r1, #DynAreaFlags_NotCacheable      ; if temp uncache, set NC bit, ignore P
        ORREQ   r1, r1, r4, LSR #6                      ; else use NC, NB and P bits
        LDRB    r1, [r6, r1, LSR #4]                    ; convert to X, C and B bits for this CPU
        ORR     r0, r0, r1
 ]
d329 1
a329 1
        TSTEQ   r11, #DynAreaFlags_NotCacheable ;EQ if also cacheable (overcautious for temp uncache+illegal PCB combos)
d346 1
a346 1
        TSTEQ   r11, #DynAreaFlags_NotCacheable ;EQ if also cacheable (overcautious for temp uncache+illegal PCB combos)
a365 6
PPLTransX
        &       (AP_Full * L2X_APMult) + L2_ExtPage       ; R any W any
        &       (AP_Read * L2X_APMult) + L2_ExtPage       ; R any W sup
        &       (AP_None * L2X_APMult) + L2_ExtPage       ; R sup W sup
        &       (AP_ROM  * L2X_APMult) + L2_ExtPage       ; R any W none

a411 10
 [ UseGraphicsV
        Push  "r0,r1,r4, r14"
        TST   r11, #(1 :SHL: 10)
        MOVEQ r0, #1             ; blank (video DMA disable)
        MOVNE r0, #0             ; unblank (video DMA enable)
        MOV   r1, #0             ; no funny business with DPMS
        MOV   r4, #GraphicsV_SetBlank
        BL    CallGraphicsV
        Pull  "r0,r1,r4, r14"
 |
a416 2
        MOV     r0, #0
        MOV     r1
a419 1
 ]
d859 2
a860 2
        ; MOV     r0, #0                        ; Podule manager will set ECTCR to TypeA cycles
        ; STRB    r0, [r12, #IOMD_ECTCR]
d985 2
a986 2
        ; MOV     r0, #0                        ; Podule manager will set ECTCR to TypeA cycles
        ; STRB    r0, [r12, #IOMD_ECTCR]
a2265 1
;          r0 bit 28 set if write buffer to be flushed (implied by bit 31)
d2368 12
a2379 9
       MOVS     r10, r0
       MOV      r12, #0
       ARMop    Cache_CleanInvalidateAll,MI,,r12
       TST      r10,#&40000000
       ARMop    TLB_InvalidateAll,NE,,r12
       TST      r10,#&10000000
       ARMop    WriteBuffer_Drain,NE,,r12
       ADDS     r0,r10,#0
       Pull     "pc"
a2491 4
        ARM_read_FSR r0
        AND     r0, r0, #&F
        TEQ     r0, #7
        BNE     DAb_NotTranslationFault
d2497 1
a2497 2
        SUBNES  pc, lr_abort, #8                ; and restart aborting instruction
DAb_NotTranslationFault
a2553 3
        TST     r0, #T32_bit                    ; were they in Thumb mode? if so, give up now
        BNE     %FT90

a3318 18

        ;mjs change for Ursula:
        ;improved kernel workspace protection
        ; - user access to bottom 3k restricted to read only (things like Clib tmpnam counter prevent
        ;   going further)
        ; - Java VM will probably require bottom 1k restricted to no user access (so that VM can avoid
        ;   all run-time checks for null pointers), but this currently makes various things like ShareFS
        ;   go pop-bang, so not done yet (see TRUE/FALSE choice below)
        ;
        MOV     r0,#L2PT                ;L2PT address for page at 0
        LDR     r1,[r0]
        BIC     r1,r1,#&FF0             ;clear current AP bits for all four 1k sub-pages (S0 to S3)
     [ {FALSE}                          ;this would be good for Java VM:
        ORR     r1,r1,#&E90             ;S0=user none, S1=user read, S2=user read, S3=user read/write
     |                                  ;this makes less current things go pop-bang:
        ORR     r1,r1,#&EA0             ;S0=user read, S1=user read, S2=user read, S3=user read/write
     ]
        STR     r1,[r0]
@


4.12.2.20
log
@In the No26bitCode case (ie when abort handlers are entered in ABT32 mode),
if lazy task swapping was enabled and a data abort occurred that was not a
page translation fault, then the code in AMB_LazyFixUp to map in the whole
application slot was being circumvented, leading to problems for abort
handlers in application space because r14_abt was corrupted by any abort
due to accessing the abort handler itself. The test of the FSR (to
compensate for the FAR being unusable for external aborts) which prompted
the circumvention has therefore been moved inside AMB_LazyFixup.
Also now preserves the FSR and FAR across AMB_LazyFixUp, so they are now
visible from application abort handlers if desired.

Version 5.35, 4.79.2.50. Tagged as 'Kernel-5_35-4_79_2_50'
@
text
@a2460 1
        MOV     r1,#1
d2527 4
a2531 1
        MOV     r1,#0
d2537 1
@


4.12.2.21
log
@  Commit of kernel as featured in release 5.00.
Detail:
  Lots of changes since last version, at least the following:
  * Updated OS timestamp, removed alpha status
  * Negative INKEY OS version changed to &AA
  * GraphicsV is now alocated vector number &2A
  * ROM moved up to &FC000000
  * Max application slot increased to 512 Mbytes (for now)
  * Max size of RMA increased to 256 Mbytes
  * RMA is now first-created dynamic area (so it gets lowest address after
    top of application slot)
  * OS_Memory 10 reimplemeted
  * New OS_ReadSysInfo 6 values 18-22 added
  * OS_ReadSysInfo 8 gains flag bit to indicate soft power-off
  * Misc internal top-bit-set-address fixes
  * *ChangeDynamicArea can take sizes in megabytes or gigabytes
  * Magic word "&off" in R0 passed to OS_Reset powers down if possible
  * Added acceleration: block copy; CLS; text window scroll up; rectangle
    fill
  * Disabled LED flashing in page mode (liable to crash)
  * Masked sprite plot and VDU 5 text avoids reading the screen if possible
  * Framestore made USR mode accessible
  * Fix for VDU 5,127 bug - now relies on font definitions being in extreme
    quarters of memory, rather than bottom half
  * Allocated 64-bit OS_Convert... SWIs
  * IIC errors use allocated error numbers
  * Looks for Dallas RTC before Philips RTC because we're using a Philips
    NVRAM device with the same ID
  * Fix to bug that meant the oscillator in the Dallas RTC wasn't enabled
  * Default mouse type (USB) changed to allocated number
  * Ram disc max size increased to 128 Mbytes (Ursula merge) and made
    cacheable for StrongARMs (not XScale)
  * Branch through zero handler now works in USR mode, by use of a
    trampoline in the system stack to allow PC-relative register storage
  * Address exception handler changed to not use 0 as workspace
  * OS_Memory 13 extended to allow specification of cacheability and access
    privileges
  * Added OS_Memory 16 to return important memory addresses
  * RISCOS_MapInIO() takes cacheable flag in bit 3, access permissions in
    bits 10 and 11, doubly-mapped flag in bit 20, and access permissions
    specified flag in bit 21
  * Bug fix in last version for application abort handlers didn't quite
    work; register shuffle required
  * "Module is not 32-bit compatible" error now reports the module name
  * Default configured language changed from 10 to 11 (now Desktop again)

Version 5.35, 4.79.2.51. Tagged as 'Kernel-5_35-4_79_2_51'
@
text
@a111 1
CAMspace                *       &02000000-CamEntriesForVicky
a377 6
PPLTransL1
        &       (AP_Full * L1_APMult) + L1_Section        ; R any W any
        &       (AP_Read * L1_APMult) + L1_Section        ; R any W sup
        &       (AP_None * L1_APMult) + L1_Section        ; R sup W sup
        &       (AP_ROM  * L1_APMult) + L1_Section        ; R any W none

d2461 1
a2461 1
        MOV     r2, #1
d2529 1
a2529 1
        MOV     r2, #0
d2690 1
a2690 1
        TST     r1, #&F                         ; test if transfer took place in USR mode
d2899 1
a2899 1
        TST     r1, #&F                         ; test if transfer took place in USR mode
d3269 2
a3277 2
        ANDS    r7, lr, #3                              ; 00 => trans.fault, 01 => large page
                                                        ; 10 => small page, 11 => reserved (fault)
@


4.12.2.22
log
@* HAL can choose to limit amount of screen memory to allocate
  [Not fully implemented - for now leaves at least 16MB free if only
  one RAM area; was 1MB].
* Added HAL_USBControllerInfo, HAL_MonitorLeadID and HAL_Video_Render.
* Added HAL->OS call OS_IICOpV.
* OS_MMUControl now allows independent control of I and C bits.
* Added facility to deactivate keyboard debounce (magic word "NoKd" in
  R2 in KeyV 0).
* Fixed problem with RAM amounts not a multiple of 4MB.
* Supremacy bit (in VDU 19) now sets all 8 bits of supremacy.
* Added PaletteV 14 (reads gamma tables).
* Added Supremacy transfer functions (like gamma correction, but for
  supremacy). Allows easy global supremacy effects in a mode-independent
  fashion. Controlled with PaletteV 15,16.
* Added modes 50-53 (320x240, 1,2,4,8bpp). Intended for small LCD.
* Added 13.5kHz versions of TV modes (selected by Hdr:Machine).
* Upped desktop version to 5.06.

Version 5.35, 4.79.2.66. Tagged as 'Kernel-5_35-4_79_2_66'
@
text
@d2354 1
a2355 1
        LDRLO   lr, [r3, #MMUControlSoftCopy]
d2365 3
a2367 5
 [ {FALSE}
        TST     r2,#MMUC_C              ; if split caches, then I bit mirrors C bit
        ORRNE   r2,r2,#MMUC_I
        BICEQ   r2,r2,#MMUC_I
 ]
a2371 1
        TSTEQ   lr, #MMUC_I
a2389 1
        TSTNE   lr, #MMUC_I
d2402 1
a2403 1
        LDRLO   lr, [r3, #MMUControlSoftCopy]
@


4.12.2.23
log
@Merge Cortex kernel into HAL branch
Detail:
  This is a full merge of the Cortex kernel back into the HAL branch. Since the Cortex kernel is/was just a superset of the HAL branch, at this point in time both branches are identical.
  Main features the HAL branch gains from this merge:
  - ARMv6/ARMv7 support
  - High processor vectors/zero page relocation support
  - objasm 4 warning fixes
  - Improved HAL related functionality:
    - Support for HAL-driven RTCs instead of kernel-driven IIC based ones
    - Support for arbitrary size machine IDs
    - Support for multiple IIC busses
    - Support for any HAL size, instead of hardcoded 64k size
    - Probably some other stuff I've forgotten
  - Probably a few bug fixes here and there
Admin:
  Tested on BB-xM & Iyonix.
  Was successfully flashed to ROM on an Iyonix to test the Cortex branch implementation of the 2010 RTC bug fix.
  IOMD build untested - but has been known to work in the past.


Version 5.35, 4.79.2.123. Tagged as 'Kernel-5_35-4_79_2_123'
@
text
@a19 3
        GBLL    UseProcessTransfer
UseProcessTransfer SETL :LNOT: HiProcVecs ; Needs updating to cope with HiProcVecs (for proc. vector protection)

d214 1
a214 1
        LDR     r1, =ZeroPage
d220 1
a220 1
        LDR     r1, =ZeroPage+PhysRamTable      ; go through phys RAM table
d283 1
a283 1
        LDR     r1, =ZeroPage+PhysRamTable ; go through phys RAM table
d315 1
a315 1
        LDR     r6, =ZeroPage
d351 1
a351 1
        LDR     r4, =ZeroPage
d367 1
a367 1
        LDR     r4, =ZeroPage
d413 1
a413 1
        LDR     r12, =ZeroPage
d468 206
d1072 1
a1072 1
        LDR     r0, =ZeroPage
d2350 1
a2350 1
        LDR     r3,=ZeroPage
d2378 2
a2379 1
        ARMop   Cache_InvalidateAll,,,r3
d2386 2
a2387 1
        ARMop   Cache_CleanAll,,,r3
d2396 2
a2397 1
        ARMop   Cache_InvalidateAll,,,r3
d2404 1
a2404 1
        LDR     r3, =ZeroPage
d2418 1
a2418 1
       LDR      r12, =ZeroPage
d2477 1
a2477 1
        LDR     r0, =ZeroPage+PAbHan      ; we want to jump to PAb handler, in abort mode
d2552 1
a2552 1
        LDR     r4, =ZeroPage+Abort32_dumparea+3*4 ;use temp area (avoid overwriting main area for expected aborts)
a2601 1
 [ UseProcessTransfer
d2640 1
a2640 1
        LDR     r6, =ZeroPage
d2845 1
a2845 1
        LDR     r8, =ZeroPage
d2880 1
a2880 1
        LDR     r1, =ZeroPage
a2985 2
 ] ; UseProcessTransfer

d2992 1
a2992 1
        LDR     r0, =ZeroPage+Abort32_dumparea
d3001 1
a3001 2
        LDR     r0, =ZeroPage                           ; we're going to call abort handler
      [ ZeroPage = 0
a3002 4
      |
        MOV     r2, #0
        STR     r2, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      ]
d3004 2
a3005 1
        LDR     r0, [r0, #DAbHan]                       ; get address of data abort handler
d3063 1
d3065 1
a3065 2
        LDR     r0, =ZeroPage                           ; we're going to call abort handler
      [ ZeroPage = 0
a3066 4
      |
        MOV     r2, #0
        STR     r2, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      ]
d3068 2
a3069 2
        LDR     r0, =ZeroPage+DAbHan
        LDR     r0, [r0, #DAbHan]                       ; get address of data abort handler
a3075 3
 ]

 [ UseProcessTransfer
a3170 1
        ASSERT  (:LNOT: HiProcVecs) ; Needs updating for high vectors!
d3315 1
a3315 1
        LDR     r6, =ZeroPage
d3391 1
a3391 1
        LDR     r0,=ZeroPage
d3393 1
a3393 1
        TST     r1,#MMUC_R
d3453 1
a3453 1
        LDR     r0,=ZeroPage+MaxCamEntry
d3460 1
a3460 1
        LDR     r1,=ZeroPage+AppSpaceDANode
d3469 1
a3469 1
        LDR     r3,=ZeroPage+FreePoolDANode
d3513 1
a3513 1
        LDR     r0,=ZeroPage+FreePoolDANode
a3518 1
 ] ; UseProcessTransfer
d3552 1
a3552 3
        LDR     r2, =ZeroPage
        LDRB    lr, [r2, #Cache_Type]
        CMP     lr, #CT_ctype_WB_CR7_Lx ; DCache_LineLen lin or log?
a3553 3
        MOVEQ   r2, #4
        MOVEQ   lr, r2, LSL lr
        LDREQ   r2, =ZeroPage
d3564 1
a3564 1
        LDR     r0, =ZeroPage
@


4.12.2.24
log
@Reindent Arthur2.
Expand tabs.
Swap DCI for instructions now Objasm 4 is out.
Symbols for FSControl_CAT/RUN/OPT changed to non Arthur definitions.
Still boots on IOMD class, no other testing.

Version 5.35, 4.79.2.124. Tagged as 'Kernel-5_35-4_79_2_124'
@
text
@d232 1
a232 1
        LDR     r6, [sp]                        ; reload old logical address
@


4.12.2.25
log
@OS_ChangeDynamicArea performance optimisations
Detail:
  s/ChangeDyn:
    - Apply various optimisations to OS_ChangeDynamicArea to reduce the execution time when performing large grows/shrinks.
    - Optimisations can be toggled on/off with FastCDA_* flags for debugging.
    - On a 1GHz 512MB BB-xM, the initial *FreePool call now takes 0.15s instead of 13.46s. On a 512MB Iyonix the time has dropped from 1.18s to 0.23s.
    - Growing screen memory (on BB-xM) has also seen significant gains - between 2x and 4x speedup, depending on what state the source pages are in.
    - Added/updated documentation for a few functions and made more use of ROUTs for safety
  s/ARM600, s/VMSAv6:
    - Update BangCamUpdate, etc. to add support for the PageFlags_Unsafe flag that OS_ChangeDynamicArea uses to bypass cache/TLB maintenance in some situations
    - Avoid BangCamUpdate calling BangL2PT to map out the page if the page isn't mapped in (avoids unnecessary cache/TLB flush)
  s/ArthurSWIs:
    - Add extra ASSERT for safety
  s/AMBcontrol/memory
    - Fix incorrect assumption that the usable size of a heap block is always 8 less than the value stored in the header. Even with the old 8 byte aligned allocations the usable size will always be 4 bytes less than the value in the header. This code would have resulted in some slight memory wasteage, as AMBcontrol will have always tried growing the block four bytes bigger than needed.
Admin:
  Tested on Iyonix & BB-xM


Version 5.35, 4.79.2.146. Tagged as 'Kernel-5_35-4_79_2_146'
@
text
@d221 1
a221 2
        BIC     r4, r11, #PageFlags_Unsafe
        STMIA   r1, {r3, r4}                    ; store new address, PPL
a250 1
        AND     r4, r11, #PageFlags_Unsafe
a253 3
        LDR     r0, =DuffEntry                  ; Nothing to do if wasn't mapped in
        ORR     r11, r11, r4
        TEQ     r3, r0
d255 1
a255 1
        BLNE    BangL2PT                        ; map page out
a342 3
        TST     r11, #PageFlags_Unsafe
        BNE     %FT30

@


4.12.2.25.2.1
log
@  Merged OS_Memory 8 changes across from HAL branch to RPi branch
Detail:
  Revisions Kernel-5_35-4_79_2_153 and Kernel-5_35-4_79_2_161 merged with one
  trivial conflict.
Admin:
  Confirmed that this builds, but not tested on hardware.

Version 5.35, 4.79.2.147.2.15. Tagged as 'Kernel-5_35-4_79_2_147_2_15'
@
text
@d1642 1
d1713 1
a1713 1
        MemInitSection   PhysSpaceSize:SHR:20, 1, 0, 0, PhysSpace, AP_None, &00000000      ; map of physical space
@


4.12.2.25.2.2
log
@Merge with HAL branch
Detail:
  Merge the HAL branch into the RPi branch, prior to merging RPi to HAL
  Brief summary of main changes brought in:
  * Added *cache functionality previously provided by ARM module
  * Added "CMOS RAM reset" message on startup when CMOS has been wiped by keypress
  * Renamed HAL Video entries from HAL_Video_XXX to HAL_VideoXXX
  * Dropped mjsHAL macros, GRAB/STASH macros
  * Fixed pseudo-VRAM allocation when machine has exactly 16MB of RAM
  * Added OS_Hardware 5
  * Use OS_SerialOp GetDeviceName for getting serial device name
  * Drop HAL_MonitorLeadID
  * Rework default GraphicsV_IICOp handler
Admin:
  Tested on Raspberry Pi with high processor vectors


Version 5.35, 4.79.2.147.2.23. Tagged as 'Kernel-5_35-4_79_2_147_2_23'
@
text
@d183 6
d471 2
a472 2
        AddressHAL
        CallHAL HAL_VideoSetBlank
@


4.12.2.26
log
@Make Mike's macros permanent.
While the HAL and kernel were being split some temporary macros were used for the bits being worked on, after 12 years of use they're probably safe to adopt.
mjsCallHAL -> CallHAL; mjsAddressHAL -> AddressHAL; mjsHAL -> HAL.
OS_VIDCDividerSWI code now always does NoSuchSWI (had been switched out previously).
File vduhint.s no longer assembled (was empty).


Version 5.35, 4.79.2.150. Tagged as 'Kernel-5_35-4_79_2_150'
@
text
@d183 6
d471 2
a472 2
        AddressHAL
        CallHAL HAL_Video_SetBlank
@


4.12.2.27
log
@Make OS_Memory 8 return more correct values
The only fake result now is the hard ROM amount, which is hardwired to 4MB and might not be correct.
Unrelated changes
 hdr.HALDevice: Assign a device for VIDC20.
 hdr.KernelWS: Reorder into ascending order, remove legacy addresses.
 s.ARM600: Move PhysSpaceSize inside :LNOT:HAL switch.
 s.Kernel: Move PhysSpaceSize inside :LNOT:HAL switch.

Version 5.35, 4.79.2.153. Tagged as 'Kernel-5_35-4_79_2_153'
@
text
@d1636 1
d1707 1
a1707 1
        MemInitSection   PhysSpaceSize:SHR:20, 1, 0, 0, PhysSpace, AP_None, &00000000      ; map of physical space
@


4.12.2.28
log
@Make GraphicsV_IICOp more consistent
No accepts  r0 = b31-24 set 0
                 b23-16 fully qualified IIC address
                 b15-0  starting offset
            r1 = buffer pointer
            r2 = number of bytes to tranfer
            r4 = b31-24 display number
                 b23-16 head
                 b15-0  reason code (=14)
Now returns r0 = result codes as per HAL_IICTransfer()
            r1 = buffer pointer incremented by number of bytes transferred
            r2 = number of bytes *not* transferred
            r4 = 0
Removed '_' after Video in entry numbers to be consistent with other HAL entry naming, and HAL_VideoFlybackDevice.
Added IICStatus return numbers to Hdr:HALEntries.
Stop calling HAL_MonitorLeadID as only IOMD implemented it - just guess VGA until the graphics driver says otherwise.

Version 5.35, 4.79.2.159. Tagged as 'Kernel-5_35-4_79_2_159'
@
text
@d466 1
a466 1
        CallHAL HAL_VideoSetBlank
@


4.12.2.29
log
@Review of Internation switch
Variously the call to TranslateError was either followed (outside the switch) by an unnecessary SETV, or missing SETV for the non international case.
Added DMA controller HAL device for IOMD.

Version 5.35, 4.79.2.174. Tagged as 'Kernel-5_35-4_79_2_174'
@
text
@d2137 2
a2138 1
 |
d2140 1
a2140 2
 ]
        Pull    "pc"
@


4.12.2.30
log
@Teach the kernel about different memory attributes
Detail:
  Briefly, this set of changes:
  * Adjusts PhysRamTable so that it retains the flags passed in by the HAL from OS_AddRAM (by storing them in the lower 12 bits of the size field)
  * Sorts the non-VRAM entries of PhysRamTable by speed and DMA capability, to ensure optimal memory allocation during OS startup.
  * Adjust the initial memory allocation logic to allow the cursor/sound chunk and HAL noncacheable workspace to come from DMA capable memory
  * Extends OS_Memory 12 to accept a 'must be DMA capable' flag in bit 8 of R0. This is the same as available in ROL's OS.
  * Extends OS_DynamicArea 0 to allow the creation of dynamic areas that automatically allocate from DMA capable memory. In ROL's OS this was done by setting bit 12 of R4, but we're using bits 12-14 for specifying the cache policy, so instead bit 15 is used.
  * Fixes OS_ReadSysInfo 6 to return the correct DevicesEnd value now that the IRQ/device limit is computed at runtime
  File changes:
  * hdr/OSEntries - Add definitions of the various flags passed to OS_AddRAM by the HAL. Add a new flag, NoDMA, for memory which can't be used for DMA.
  * hdr/KernelWS - Tidy PhysRamTable definition a bit by removing all the DRAM bank definitions except the first - this makes it easier to search for code which is interacting with the table. Remove VRAMFlags, it's redundant now that the flags are kept in the table. Add DMA allocation info to InitWs.
  * s/AMBControl/memmap - Updated to mask out the flags from PhysRamTable when reading RAM block sizes.
  * s/ARM600 - Strip out a lot of IOMD specific pre-HAL code.
  * s/ChangeDyn - Updated to cope with the flags stored in PhysRamTable. Implement support for DMA-capable dynamic areas. Rewrite InitDynamicAreas to insert pages into the free pool in the right order so that the fastest memory will be taken from it first.
  * s/GetAll, s/Middle - Fix OS_ReadSysInfo 6 to return the correct HAL-specific DevicesEnd value
  * s/HAL - Significant rework of initial RAM allocation code to allow the kernel workspace to come from the fastest DMA incapable RAM, while also allowing allocation of DMA capable memory for HAL NCNB workspace & kernel cursor/sound chunks. ClearPhysRAM rewritten as part of this.
  * s/MemInfo - Updated to cope with the flags stored in PhysRamTable. Add support for the new OS_Memory 12 flag. Update OS_Memory 7 to not assume PhysRamTable entries are sorted in address order, and rip out the old pre-HAL IOMD implementation.
  * s/NewReset - Remove GetPagesFromFreePool option, assume TRUE (as this has been the case for the past 10+ years). Revise a few comments and strip dead code. Update to cope with PhysRamTable flags.
  * s/VMSAv6 - Remove a couple of unused definitions
  * s/vdu/vdudriver - Update to cope with PhysRamTable flags
Admin:
  Tested in Kinetic RiscPC ROM softload, Iyonix softload, & OMAP3


Version 5.35, 4.79.2.186. Tagged as 'Kernel-5_35-4_79_2_186'
@
text
@d80 1
a80 1
 [ :LNOT: HAL
d84 1
d94 1
d103 4
d113 10
a129 1
 ] ; :LNOT: HAL
d132 49
d473 1618
a3176 3
; L1L2PTenhancements not currently used for HAL, but let's keep it as reference in case we want to implement it later
 [ :LNOT: HAL

a3328 2
 ] ; :LNOT: HAL

@


4.12.2.31
log
@Assorted GraphicsV improvements
Detail:
  This set of changes:
  * Adds basic support for multiple GraphicsV drivers, by way of some new OS_ScreenMode reason codes for registering/deregistering, selecting and enumerating drivers (11, 64-68)
  * Tidies up handling of HAL video calls so that the HAL calls will be transformed into a bona fide GraphicsV driver if they're implemented
  * Changes handling of 16bpp gamma table entries so that they're sent to GraphicsV in a generic form instead of in a VIDC-specific form
  * Adds a new GraphicsV call and defines new VIDC list items to allow GraphicsV drivers to utilise the new pixel formats
  File changes:
  * h/VIDCList, hdr/VIDCList, Makefile - Add new header export containing VIDC list type 3 definitions, to avoid repeated definitions in other components
  * Resources/UK/Messages - Add new GraphicsV/OS_ScreenMode error strings and some missing processor type strings
  * hdr/KernelWS - Clean up some pre-GraphicsV definitions, and add new workspace locations for storing the current GraphicsV driver number and the driver list
  * hdr/Options - Remove obsolete InverseTextTransparency option
  * hdr/VduExt - Add VDU variable 192 for storing GraphicsV driver number (same as ROL's VideoV driver number). Remove old 'Flag_*' mode flag definitions (use new 'ModeFlag_*' defintions instead). Add new OS_ScreenMode reason codes.
  * s/ARM600, s/VMSAv6, s/vdu/vdu23, s/vdu/vdugrafa, s/vdu/vdugrafd, s/vdu/vdupalxx, s/vdu/vdupointer, s/vdu/vduwrch - Strip out pre-GraphicsV code. Update GraphicsV code to use correct driver number.
  * s/ArthurSWIs - Pass the default GraphicsV claimant the VduDriverWorkSpace instead of ZeroPage
  * s/Getall - Add Hdr:VIDCList and s/vdu/VduGrafHAL to list of GETs
  * s/NewIRQs - Remove HAL VSync IRQ initialisation, is now handled by grafvhal. Remove old HAL VsyncIRQ entry point, all VSyncs are now handled by VsyncIRQ_ExtEntry.
  * s/PMF/osbyte - Stop OS_Byte 19 waiting forever if no video driver is active
  * s/PMF/osinit - Remove HAL VSync IRQ initialisation, is now handled by grafvhal
  * s/vdu/vducursoft - Use new workspace variable names and flag names
  * s/vdu/vdudecl - Remove old HALDAG_* definitions, GVDAG_* definitions are used instead. Add definition of the per-driver workspace structure and flags.
  * s/vdu/vdudriver - Remove pre-GraphicsV code. Update InitialiseMode to check for and initialise a HAL driver. Use cached driver features word in a few places instead of calling GraphicsV each time. Update PalIndexTable to disable VIDC mangling of 16bpp gamma tables.
  * s/vdu/vdugrafv, s/vdu/vdugrafhal - HAL<->GraphicsV code split off into its own file (vdugrafhal). Default GraphicsV claimant now only deals with VSync events for the active driver.
  * s/vdu/vdumodes - Get rid of old VIDC List type 3 definiton; now in hdr/VIDCList
  * s/vdu/vduswis - Added OS_ScreenMode reason codes 11 and 64-68 for registering, deregistering, selecting and enumerating GraphicsV drivers. Update mode set code to not bother checking if the driver supports the pixel format; instead we assume that the driver's vet mode call will do the check for us.
Admin:
  Tested in Tungsten, IOMD, OMAP3 & BCM2835 ROMs
  Requires HdrSrc-2_38 and updated video driver modes


Version 5.35, 4.79.2.203. Tagged as 'Kernel-5_35-4_79_2_203'
@
text
@d384 1
d390 1
a390 4
        ADD   r4, r12, #VduDriverWorkSpace
        LDR   r4, [r4, #CurrentGraphicsVDriver]
        MOV   r4, r4, LSL #24
        ORR   r4, r4, #GraphicsV_SetBlank
d393 12
@


4.12.2.32
log
@Add support for LDRSB to data abort handler
ARM600:
Decode LDRSB, do the sign extend, and fault all the other loads and stores not understood.
VMSAv6:
As the loads and stores not understood are now vetted properly, it should be safe to UseProcessTransfer (previously they'd have been disassembled incorrectly).
Paste in LDRSB code from ARM600.
Fix dubious looking access of CurrentGraphicsVDriver from WsPtr.

Tested briefly on StrongARM.

Version 5.35, 4.79.2.209. Tagged as 'Kernel-5_35-4_79_2_209'
@
text
@d709 2
a710 3
;ARMv4+ allow half-word load/stores - not supported at present
;ARMv5TE+ allow double-word load/stores - not supported at present
;ARMv6 allow load/store exclusive - not supported at present
d712 2
a713 2
        AND     r9, r10, #2_1110 :SHL: 24
        TEQ     r9, #2_1000 :SHL: 24            ; test for LDM/STM
d716 2
d889 1
a889 1
; it's an LDR/STR
a890 2
        TEQ     r9, #2_0000 :SHL: 24            ; is it the extra load/store family?
        BNE     %FT55                           ; no, plain LDR[B]
d892 1
a892 1
        DLINE   "It's LDR[EX|SB|H|SH|D]/STR[EX|H|D]"
a893 5
        AND     r9, r10, #2_1111 :SHL: 4
        TEQ     r9, #2_1101 :SHL: 4
        BNE     %FT90                           ; Abort if LDR[EX|H|SH]/STR[EX|H|D]
        TST     r10, #1 :SHL: 20
        BEQ     %FT90                           ; Abort if LDRD (encoded where STRSB would be)
a894 17
        TST     r10, #1 :SHL: 22                ; if immediate
        BICNE   r9, r10, 2_1111 :SHL: 4
        ORRNE   r9, r9, r9, LSR #4
        ANDNE   r9, r9, #&FF                    ; then extract imm8 bits
        ANDEQ   r8, r10, #&0F                   ; register offset
        LDREQ   r9, [r11, r8, LSL #2]           ; get actual value of register
        ORR     r10, r10, #1 :SHL: 22           ; ensure it looks like a byte access
        B       %FT60
        ; We've effectively reencoded the weird load/stores to look like
        ; cccc 0zxp ubwl nnnn tttt xxxx xxxx xxxx
        ; z = zero/sign extend     b = byte/word
        ; p = pre/post             l = load/store
        ; u = up/down              x = don't care from here on
55
 [ DebugAborts
        DLINE   "It's an LDR[B]/STR[B]"
 ]
d926 23
d979 5
d1035 7
a1041 13
        Pull    "r6"                            ; LDR/LDRB/LDRSB: get value to load into register
        TST     r10, #1 :SHL: 22
        BEQ     %FT67
        TST     r10, #1 :SHL: 26                ; LDRB: see if zero fill or sign extend is needed
        MOVEQ   r6, r6, LSL #24
        MOVEQ   r6, r6, ASR #24                 ; fill with b7
        ANDNE   r6, r6, #&FF                    ; fill with zero
        B       %FT69
67
        AND     r9, r9, #3                      ; LDR: rotate word to correct position - r9 = bottom 2 bits of address
        MOV     r9, r9, LSL #3                  ; multiply by 8 to get rotation factor
        MOV     r6, r6, ROR r9                  ; rotate to correct position in register
69
@


4.12.2.33
log
@Fix ProcessTransfer bug with LDM
Detail:
  s/ARM600, s/VMSAv6 - When processing an LDM which wasn't the "user mode registers" form, the initialisation of lr was being skipped, resulting in the registers being loaded from garbage addresses. Shuffle things around slightly so that the branch to label 34 works as intended.
Admin:
  Issue spotted by Willi Theiss
  Builds, but untested


Version 5.35, 4.79.2.211. Tagged as 'Kernel-5_35-4_79_2_211'
@
text
@d841 1
a842 2
        MOV     lr, #0
35
d851 1
a851 1
        BNE     %BT35                           ; no, then loop
@


4.12.2.34
log
@Missing hash
One less warning in each of ARM600/VMSAv6.
@
text
@d903 1
a903 1
        BICNE   r9, r10, #2_1111 :SHL: 4
@


4.12.2.35
log
@Fix corrupt L2PT page flags being generated on Iyonix
Detail:
  s/ARMops - If extended pages aren't supported, make sure we use a PCBTrans table which doesn't use L2_X, otherwise the AP flags for some of the sub-pages will be corrupted when the PCB flags get merged in. Add some more comments to the PCBTrans tables so it's easier to see what the different columns are.
  s/ARM600 - Fix BangCam to use extended pages if they're supported; otherwise (assuming ARMops has selected the right PCBTrans table) we'll end up corrupting the AP flags again
  s/HAL - Fix ConstructCAMfromPageTables using the wrong register for ZeroPage when looking up MMU_PCBTrans. Correct a few comments.
Admin:
  Tested on Iyonix
  Page table examination now shows that all subpages have the correct (i.e. identical) AP flags. Previously some pages would have incorrect access (e.g. every 4th subpage in some FileCore disc map/dir buffer DAs were writable in user mode)
  ARMops fix will presumably mean extended pages will now work correctly on IOP 80200, as before it would have been using small pages with corrupt AP flags


Version 5.35, 4.79.2.221. Tagged as 'Kernel-5_35-4_79_2_221'
@
text
@d232 1
a232 1
        LDR     r6, =ZeroPage
a233 1
        LDR     r1, [r6, #ProcessorFlags]
a234 1
        TST     r1, #CPUFlag_ExtendedPages
a235 2
        ADREQ   r1, PPLTrans
        ADRNE   r1, PPLTransX           ; always use extended pages if supported
d238 9
d253 1
d262 1
@


4.12.2.36
log
@Disable ProcessTransfer code indefinitely
Detail:
  s/ARM600, s/VMSAv6 - Disable ProcessTransfer code for all kernel configurations.
  For VMSAv6 it was definitely broken (needs to be taught about VMSAv6 page tables and ARMv6+ unaligned loads).
  For ARM600 it seems to work OK, but is of no real use as (a) we're always running in 32bit mode and so don't need to worry about processor vector writes and (b) OS_AbortTrap isn't implemented so there's no way for anyone to register an abort handling routine.
  Code is being kept around instead of deleting it straight away just in case there are some hidden knock-ons to disabling it, or we decide to implement our own OS_AbortTrap some day.
Admin:
  Tested on Iyonix, BB-xM


Version 5.35, 4.79.2.223. Tagged as 'Kernel-5_35-4_79_2_223'
@
text
@a19 6
; Disable ProcessTransfer code pending execution.
; If we want to reuse the code at some point in the future, be aware that it
; needs the following work performing:
; * Updating to cope with HiProcVecs (or special zero page handling removed)
; * (preferablly) add support for all the 'new' load/store instructions.
;   LDRH/STRH, LDRD/STRD, coprocessor transfers, etc.
d21 1
a21 1
UseProcessTransfer SETL {FALSE}
@


4.12.2.37
log
@Improve support for VMSAv6 cache policies & memory types. Expose raw ARMops via OS_MMUControl & cache information via OS_PlatformFeatures.
Detail:
  Docs/HAL/ARMop_API - Document two new ARMops: Cache_Examine and IMB_List
  hdr/KernelWS - Shuffle workspace round a bit to allow space for the two new ARMops. IOSystemType now deleted (has been deprecated and fixed at 0 for some time)
  s/ARM600 - Cosmetic changes to BangCam to make it clearer what's going on. Add OS_MMUControl 2 (get ARMop) implementation.
  s/ARMops - Switch out different ARMop implementations and XCB tables depending on MMU model - helps reduce assembler warnings and make it clearer what code paths are and aren't possible. Add implementations of the two new ARMops. Simplify ARM_Analyse_Fancy by removing some tests which we know will have certain results. Use CCSIDR constants in ARMv7 ARMops instead of magic numbers. Update XCB table comments, and add a new table for VMSAv6
  s/ChangeDyn - Define constant for the new NCB 'idempotent' cache policy (VMSAv6 normal, non-cacheable memory)
  s/HAL - Use CCSIDR constants instead of magic numbers. Extend RISCOS_MapInIO to allow the TEX bits to be specified.
  s/Kernel - OS_PlatformFeatures 33 (read cache information) implementation (actually, just calls through to an ARMop)
  s/MemInfo - Modify VMSAv6 OS_Memory 0 cache/uncache implementation to use the XCB table instead of modifying L2_C directly. This allows the cacheability to be changed without affecting the memory type - important for e.g. unaligned accesses to work correctly. Implement cache policy support for OS_Memory 13.
  s/Middle - Remove IOSystemType from OS_ReadSysInfo 6.
  s/VMSAv6 - Make sure BangCam uses the XCB table for working out the attributes of temp-uncacheable pages instead of manipulating L2_C directly. Add OS_MMUControl 2 implementation.
  s/AMBControl/memmap - Update VMSAv6 page table pokeing to use XCB table
  s/PMF/osinit - Remove IOSystemType reference, and switch out some pre-HAL code that was trying to use IOSystemType.
Admin:
  Tested on Iyonix, ARM11, Cortex-A7, -A8, -A9, -A15
  Note that contrary to the comments in the source the default NCB policy currently maps to VMSAv6 Device memory type (as per previous kernel versions). This is just a temporary measure, and it will be switched over to Normal, non-cacheable once appropriate memory barriers have been added to the affected IO code.


Version 5.35, 4.79.2.273. Tagged as 'Kernel-5_35-4_79_2_273'
@
text
@d248 3
a250 3
        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4
d259 1
a259 1
        ORREQ   r1, r1, r4, LSR #10-4                   ; else use NC, NB and P bits
a418 5
; in:   r0 bits 0-7 = 2: reason code 2, read ARMop
;          r0 bits 15-8 = ARMop index
;
; out:  r0 = ARMop function ptr
;
a422 1
MMUCReason_GetARMop             # 1
a438 1
        B       MMUControl_GetARMop
a528 9
MMUControl_GetARMop
       AND      r0, r0, #&FF00
       CMP      r0, #(ARMopPtrTable_End-ARMopPtrTable):SHL:6
       BHS      MMUControl_Unknown
       ADRL     lr, ARMopPtrTable
       LDR      r0, [lr, r0, LSR #6]
       LDR      r0, [r0]
       Pull     "pc"

@


4.12.2.38
log
@Replace WriteBuffer_Drain ARMop with a suite of memory barrier ARMops
Detail:
  - Docs/HAL/ARMop_API - Updated with documentation for the new ARMops.
  - s/ARMops - Set up pointers for the new memory barrier ARMops. Add full implementations for ARMv6 & ARMv7; older architectures should be able to get by with a mix of null ops & write buffer drain ops. Update ARMopPtrTable to validate structure against the list in hdr/OSMisc
  - hdr/KernelWS - Reserve workspace for new ARMops. Free up a bit of space by limiting ourselves to 2 cache levels with ARMv7. Remove some unused definitions.
  - hdr/OSMisc - New header defining OS_PlatformFeatures & OS_MMUControl reason codes, OS_PlatformFeatures 0 flags, and OS_MMUControl 2 ARMop indices
  - Makefile - Add export rules for OSMisc header
  - hdr/ARMops, s/ARM600, s/VMSAv6 - Remove CPUFlag_* and MMUCReason_* definitions. Update OS_MMUControl write buffer drain to use DSB_ReadWrite ARMop (which is what most existing write buffer drain implementations have been renamed to).
  - s/GetAll - Get Hdr:OSMisc
  - s/Kernel - Use OS_PlatformFeatures reason code symbols
  - s/vdu/vdudecl - Remove unused definition
Admin:
  Tested on ARM11, Cortex-A8, Cortex-A9


Version 5.35, 4.79.2.279. Tagged as 'Kernel-5_35-4_79_2_279'
@
text
@d425 6
d532 1
a532 1
       ARMop    DSB_ReadWrite,NE,,r12
@


4.12.2.39
log
@Add initial support for "physical memory pools"
Detail:
  This set of changes adds support for "physical memory pools" (aka PMPs), a new type of dynamic area which allow physical pages to be claimed/allocated without mapping them in to the logical address space. PMPs have full control over which physical pages they use (similar to DAs which request specific physical pages), and also have full control over the logical mapping of their pages (which pages go where, and per-page access/cacheability control).
  Currently the OS makes use of two PMPs: one for the free pool (which now has a logical size of zero - freeing up gigabytes of logical space), and one for the RAM disc (logical size of 1MB, allowing for a physical size limited only by the amount of free memory)
  Implementing these changes has required a number of other changes to be made:
  * The CAM has been expanded from 8 bytes per entry to 16 bytes per entry, in order to allow each RAM page to store information about its PMP association
  * The system heap has been expanded to 32MB in size (from just under 4MB), in order to allow it to be used to store PMP page lists (1 word needed per page, but PMP pages may not always have physical pages assigned to them - so to allow multiple large PMPs to exist we need more than just 1 word per RAM page)
  * The &FA000000-&FBFFFFFF area of fixed kernel workspace has been shuffled around to accomodate the larger CAM, and the system heap is now located just above the RMA.
  * SoftResets code stripped out (unlikely we'll ever want to fix and re-enable it)
  * A couple of FastCDA options are now permanently on
  * Internal page flags shuffled around a bit. PageFlags_Unavailable now publicly exposed so that PMP clients can lock/unlock pages at will.
  * When OS_ChangeDynamicArea is asked to grow or shrink the free pool, it now implicitly converts it into a shrink or grow of application space (which is what would happen anyway). This simplifies the implementation; during a grow, pages (or replacement pages) are always sourced from the free pool, and during a shrink pages are always sent to the free pool.
  File changes:
  - hdr/KernelWS - Extend DANode structure. Describe CAM format. Adjust kernel workspace.
  - hdr/OSRSI6, s/Middle - Add new item to expose the CAM format
  - hdr/Options - Remove SoftResets switch. Add some PMP switches.
  - s/ARM600, s/VMSAv6 - Updated for new CAM format. Note that although the CAM stores PMP information, BangCamUpdate currently doesn't deal with updating that data - it's the caller's responsibility to do so where appropriate.
  - s/ChangeDyn - Lots of changes to implement PMP support, and to cope with the new CAM format.
  - s/HAL - Updated to cope with new CAM format, and lack of logical mapping of free pool.
  - s/MemInfo - Updated to cope with new CAM format. OS_Memory 0 updated to cope with converting PPN to PA for pages which are mapped out. OS_Memory 24 updated to decode the access permissions on a per-page basis for PMPs, and fixed its HWM usage for sparse DAs.
  - s/NewReset - Soft reset code and unused AddCamEntries function removed. Updated to cope with new CAM format, PMP free pool, PMP RAMFS
  - s/AMBControl/allocate - Update comment (RMA hasn't been used for AMBControl nodes for a long time)
  - s/AMBControl/growp, s/AMBControl/memmap, s/AMBControl/shrinkp - Update for new CAM format + PMP free pool
  - s/vdu/vdudriver - Strip out soft reset code.
Admin:
  Tested on Pandaboard
  This is just a first iteration of the PMP feature, with any luck future changes will improve functionality. This means APIs are subject to change as well.


Version 5.35, 4.79.2.284. Tagged as 'Kernel-5_35-4_79_2_284'
@
text
@d155 1
a155 3
        ADD     r1, r1, r2, LSL #CAM_EntrySizeLog2 ; point at cam entry (logaddr, PPL)
        ASSERT  CAM_LogAddr=0
        ASSERT  CAM_PageFlags=4
@


4.12.2.40
log
@Cache maintenance fixes
Detail:
  This set of changes tackles two main issues:
  * Before mapping out a cacheable page or making it uncacheable, the OS performs a cache clean+invalidate op. However this leaves a small window where data may be fetched back into the cache, either accidentally (dodgy interrupt handler) or via agressive prefetch (as allowed for by the architecture). This rogue data can then result in coherency issues once the pages are mapped out or made uncacheable a short time later.
    The fix for this is to make the page uncacheable before performing the cache maintenance (although this isn't ideal, as prior to ARMv7 it's implementation defined whether address-based cache maintenance ops affect uncacheable pages or not - and on ARM11 it seems that they don't, so for that CPU we currently force a full cache clean instead)
  * Modern ARMs generally ignore unexpected cache hits, so there's an interrupt hole in the current OS_Memory 0 "make temporarily uncacheable" implementation where the cache is being flushed after the page has been made uncacheable (consider the case of a page that's being used by an interrupt handler, but the page is being made uncacheable so it can also be used by DMA). As well as affecting ARMv7+ devices this was found to affect XScale (and ARM11, although untested for this issue, would have presumably suffered from the "can't clean uncacheable pages" limitation)
    The fix for this is to disable IRQs around the uncache sequence - however FIQs are currently not being dealt with, so there's still a potential issue there.
  File changes:
  - Docs/HAL/ARMop_API, hdr/KernelWS, hdr/OSMisc - Add new Cache_CleanInvalidateRange ARMop
  - s/ARM600, s/VMSAv6 - BangCam updated to make the page uncacheable prior to flushing the cache. Add GetTempUncache macro to help with calculating the page flags required for making pages uncacheable. Fix abort in OS_MMUControl on Raspberry Pi - MCR-based ISB was resetting ZeroPage pointer to 0
  - s/ARMops - Cache_CleanInvalidateRange implementations. PL310 MMU_ChangingEntry/MMU_ChangingEntries refactored to rely on Cache_CleanInvalidateRange_PL310, which should be a more optimal implementation of the cache cleaning code that was previously in MMU_ChangingEntry_PL310.
  - s/ChangeDyn - Rename FastCDA_UpFront to FastCDA_Bulk, since the cache maintenance is no longer performed upfront. CheckCacheabilityR0ByMinusR2 now becomes RemoveCacheabilityR0ByMinusR2. PMP LogOp implementation refactored quite a bit to perform cache/TLB maintenance after making page table changes instead of before. One flaw with this new implementation is that mapping out large areas of cacheable pages will result in multiple full cache cleans while the old implementation would have (generally) only performed one - a two-pass approach over the page list would be needed to solve this.
  - s/GetAll - Change file ordering so GetTempUncache macro is available earlier
  - s/HAL - ROM decompression changed to do full MMU_Changing instead of MMU_ChangingEntries, to make sure earlier cached data is truly gone from the cache. ClearPhysRAM changed to make page uncacheable before flushing cache.
  - s/MemInfo - OS_Memory 0 interrupt hole fix
  - s/AMBControl/memmap - AMB_movepagesout_L2PT now split into cacheable+non-cacheable variants. Sparse map out operation now does two passes through the page list so that they can all be made uncacheable prior to the cache flush + map out.
Admin:
  Tested on StrongARM, XScale, ARM11, Cortex-A7, Cortex-A9, Cortex-A15, Cortex-A53
  Appears to fix the major issues plaguing SATA on IGEPv5


Version 5.35, 4.79.2.306. Tagged as 'Kernel-5_35-4_79_2_306'
@
text
@a28 13
        ; Convert given page flags to the equivalent temp uncacheable L2PT flags
        ; n.b. temp not used here but included for VMSAv6 compatibility
        MACRO
        GetTempUncache $out, $pageflags, $pcbtrans, $temp
        ASSERT  DynAreaFlags_CPBits = 7*XCB_P :SHL: 10
        ASSERT  DynAreaFlags_NotCacheable = XCB_NC :SHL: 4
        ASSERT  DynAreaFlags_NotBufferable = XCB_NB :SHL: 4
        AND     $out, $pageflags, #DynAreaFlags_NotCacheable + DynAreaFlags_NotBufferable
        ORR     $out, $out, #DynAreaFlags_NotCacheable      ; treat as temp uncache
        LDRB    $out, [$pcbtrans, $out, LSR #4]             ; convert to X, C and B bits for this CPU
        MEND

TempUncache_L2PTMask * L2_X+L2_C+L2_B
d285 3
a287 8
        ;In order to safely map out a cacheable page and remove it from the
        ;cache, we need to perform the following process:
        ;* Make the page uncacheable
        ;* Flush TLB
        ;* Clean+invalidate cache
        ;* Write new mapping (r6)
        ;* Flush TLB
        ;For uncacheable pages we can just do the last two steps
d291 2
d294 2
a295 13
        BNE     %FT20
        LDR     lr, [r4, #MMU_PCBTrans]
        GetTempUncache r0, r11, lr
        LDR     lr, [r1, r3, LSR #10]           ;get current L2PT entry
        BIC     lr, lr, #TempUncache_L2PTMask   ;remove current attributes
        ORR     lr, lr, r0
        STR     lr, [r1, r3, LSR #10]           ;Make uncacheable
        MOV     r0, r3
        ARMop   MMU_ChangingUncachedEntry,,, r4 ; TLB flush
        MOV     r0, r3
        ADD     r1, r3, #4096
        ARMop   Cache_CleanInvalidateRange,,, r4 ; Cache flush
        LDR     r1, =L2PT
d298 2
a299 3
        Pull    "lr"
        MOV     r0, r3
        ARMop   MMU_ChangingUncachedEntry,,tailcall,r4
@


4.12.2.22.2.1
log
@Add VMSAv6 MMU support, fixes to allow booting on beagleboard
Detail:
  s/ARM600 - fix to SyncCodeAreasRange to correctly read cache line length for WB_CR7_Lx caches
  s/ARMops - Cortex cache handling fixes. Enable L2 cache for Cortex.
  s/ChangeDyn - VMSAv6 support in AllocateBackingLevel2
  s/HAL - Improve RISCOS_InitARM to set/clear correct CP15 flags for ARMv6/v7. VMSAv6 support in code to generate initial page tables.
  s/NewReset - Extra DebugTX calls during OS startup. Disable pre-HAL Processor_Type for HAL builds.
  s/VMSAv6 - Main VMSAv6 MMU code - stripped down version of s/ARM600 with support for basic VMSAv6 features.
  hdr/Options - Use VMSAv6 MMU code, not ARM600. Disable ARM6support since current VMSAv6 code will conflict with it.
Admin:
  Tested basic OS functionality under qemu-omap3 and revision B6 beagleboard.


Version 5.35, 4.79.2.98.2.3. Tagged as 'Kernel-5_35-4_79_2_98_2_3'
@
text
@a3552 6
        LDRB    lr, [r2, #Cache_Type]
        CMP     lr, #CT_ctype_WB_CR7_Lx ; DCache_LineLen lin or log?
        LDRB    lr, [r2, #DCache_LineLen]
        MOVEQ   r2, #4
        MOVEQ   lr, r2, LSL lr
        MOVEQ   r2, #0
@


4.12.2.22.2.2
log
@Fix bug when creating code variables via OS_SetVarVal, remove errant line from s.ARM600, automatically enable alignment exceptions if NoUnaligned is TRUE (Cortex branch)
Detail:
  s/ARM600 - Removed an errant line that could have caused problems if the ARM600 MMU model was used with the WB_CR7_Lx cache type
  s/Arthur2 - OS_SetVarVal was failing to call XOS_SynchroniseCodeAreas after copying the code variables code block into the system heap. This has now been fixed.
  s/HAL - Alignment exceptions are now automatically enabled when the kernel is built with the NoUnaligned option turned on.
Admin:
  Tested on rev C2 beagleboard. OS_SetVarVal fix means the Debugger module now shows the right register names instead of ofla!


Version 5.35, 4.79.2.98.2.15. Tagged as 'Kernel-5_35-4_79_2_98_2_15'
@
text
@d3559 1
@


4.12.2.22.2.3
log
@Add zero page relocation support
Detail:
  A whole mass of changes to add high processor vectors + zero page relocation support to the Cortex branch of the kernel
  At the moment the code can only cope with two ZeroPage locations, &0 and &FFFF0000. But with a bit more tweaking those restrictions can probably be lifted, allowing ZeroPage to be hidden at almost any address (assuming it's fixed at compile time). If I've done my job right, these restrictions should all be enforced by asserts.
  There's a new option, HiProcVecs, in hdr/Options to control whether high processor vectors are used. When enabling it and building a ROM, remember:
  * FPEmulator needs to be built with the FPEAnchor=High option specified in the components file (not FPEAnchorType=High as my FPEmulator commit comments suggested)
  * ShareFS needs unplugging/removing since it can't cope with it yet
  * Iyonix users will need to use the latest ROOL boot sequence, to ensure the softloaded modules are compatible (OMAP, etc. don't really softload much so they're OK with older sequences)
  * However VProtect also needs patching to fix a nasty bug there - http://www.riscosopen.org/tracker/tickets/294
  The only other notable thing I can think of is that the ProcessTransfer code in s/ARM600 & s/VMSAv6 is disabled if high processor vectors are in use (it's fairly safe to say that code is obsolete in HAL builds anyway?)
  Fun challenge for my successor: Try setting ZeroPage to &FFFF00FF (or similar) so its value can be loaded with MVN instead of LDR. Then use positive/negative address offsets to access the contents.
  File changes:
  - hdr/ARMops - Modified ARMop macro to take the ZeroPage pointer as a parameter instead of 'zero'
  - hdr/Copro15ops - Corrected $quick handling in myISB macro
  - hdr/Options - Added ideal setting for us to use for HiProcVecs
  - s/AMBControl/allocate, s/AMBControl/growp, s/AMBControl/mapslot, s/AMBControl/memmap, s/AMBControl/service, s/AMBControl/shrinkp, s/Arthur2, s/Arthur3, s/ArthurSWIs, s/ChangeDyn, s/ExtraSWIs, s/HAL, s/HeapMan, s/Kernel, s/MemInfo, s/Middle, s/ModHand, s/MoreSWIs, s/MsgCode, s/NewIRQs, s/NewReset, s/Oscli, s/PMF/buffer, s/PMF/IIC, s/PMF/i2cutils, s/PMF/key, s/PMF/mouse, s/PMF/osbyte, s/PMF/oseven, s/PMF/osinit, s/PMF/osword, s/PMF/oswrch, s/SWINaming, s/Super1, s/SysComms, s/TickEvents, s/Utility, s/vdu/vdu23, s/vdu/vdudriver, s/vdu/vdugrafl, s/vdu/vdugrafv, s/vdu/vdupalxx, s/vdu/vdupointer, s/vdu/vduswis, s/vdu/vduwrch - Lots of updates to deal with zero page relocation
  - s/ARM600 - UseProcessTransfer option. Zero page relocation support. Deleted pre-HAL ClearPhysRAM code to tidy the file up a bit.
  - s/ARMops - Zero page relocation support. Set CPUFlag_HiProcVecs when high vectors are in use.
  - s/KbdResPC - Disable compilation of dead code
  - s/VMSAv6 - UseProcessTransfer option. Zero page relocation support.
Admin:
  Tested with OMAP & Iyonix ROM softloads, both with high & low zero page.
  High zero page hasn't had extensive testing, but boot sequence + ROM apps seem to work.


Version 5.35, 4.79.2.98.2.48. Tagged as 'Kernel-5_35-4_79_2_98_2_48'
@
text
@a19 3
        GBLL    UseProcessTransfer
UseProcessTransfer SETL :LNOT: HiProcVecs ; Needs updating to cope with HiProcVecs (for proc. vector protection)

d214 1
a214 1
        LDR     r1, =ZeroPage
d220 1
a220 1
        LDR     r1, =ZeroPage+PhysRamTable      ; go through phys RAM table
d283 1
a283 1
        LDR     r1, =ZeroPage+PhysRamTable ; go through phys RAM table
d315 1
a315 1
        LDR     r6, =ZeroPage
d351 1
a351 1
        LDR     r4, =ZeroPage
d367 1
a367 1
        LDR     r4, =ZeroPage
d413 1
a413 1
        LDR     r12, =ZeroPage
d468 206
d1072 1
a1072 1
        LDR     r0, =ZeroPage
d2350 1
a2350 1
        LDR     r3,=ZeroPage
d2378 2
a2379 1
        ARMop   Cache_InvalidateAll,,,r3
d2386 2
a2387 1
        ARMop   Cache_CleanAll,,,r3
d2396 2
a2397 1
        ARMop   Cache_InvalidateAll,,,r3
d2404 1
a2404 1
        LDR     r3, =ZeroPage
d2418 1
a2418 1
       LDR      r12, =ZeroPage
d2477 1
a2477 1
        LDR     r0, =ZeroPage+PAbHan      ; we want to jump to PAb handler, in abort mode
d2552 1
a2552 1
        LDR     r4, =ZeroPage+Abort32_dumparea+3*4 ;use temp area (avoid overwriting main area for expected aborts)
a2601 1
 [ UseProcessTransfer
d2640 1
a2640 1
        LDR     r6, =ZeroPage
d2845 1
a2845 1
        LDR     r8, =ZeroPage
d2880 1
a2880 1
        LDR     r1, =ZeroPage
a2985 2
 ] ; UseProcessTransfer

d2992 1
a2992 1
        LDR     r0, =ZeroPage+Abort32_dumparea
d3001 1
a3001 2
        LDR     r0, =ZeroPage                           ; we're going to call abort handler
      [ ZeroPage = 0
a3002 4
      |
        MOV     r2, #0
        STR     r2, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      ]
d3004 2
a3005 1
        LDR     r0, [r0, #DAbHan]                       ; get address of data abort handler
d3063 1
d3065 1
a3065 2
        LDR     r0, =ZeroPage                           ; we're going to call abort handler
      [ ZeroPage = 0
a3066 4
      |
        MOV     r2, #0
        STR     r2, [r0, #CDASemaphore]                 ; so allow recovery if we were in CDA
      ]
d3068 2
a3069 2
        LDR     r0, =ZeroPage+DAbHan
        LDR     r0, [r0, #DAbHan]                       ; get address of data abort handler
a3075 3
 ]

 [ UseProcessTransfer
a3170 1
        ASSERT  (:LNOT: HiProcVecs) ; Needs updating for high vectors!
d3315 1
a3315 1
        LDR     r6, =ZeroPage
d3391 1
a3391 1
        LDR     r0,=ZeroPage
d3393 1
a3393 1
        TST     r1,#MMUC_R
d3453 1
a3453 1
        LDR     r0,=ZeroPage+MaxCamEntry
d3460 1
a3460 1
        LDR     r1,=ZeroPage+AppSpaceDANode
d3469 1
a3469 1
        LDR     r3,=ZeroPage+FreePoolDANode
d3513 1
a3513 1
        LDR     r0,=ZeroPage+FreePoolDANode
a3518 1
 ] ; UseProcessTransfer
d3552 1
a3552 1
        LDR     r2, =ZeroPage
d3558 1
a3558 1
        LDREQ   r2, =ZeroPage
d3569 1
a3569 1
        LDR     r0, =ZeroPage
@


4.11
log
@  32-bit Kernel.

Details:
  The Kernel will now compile to produce a pure 32-bit system if No26bitCode is
  set to TRUE.
  If No26bitCode is FALSE, then the Kernel will be a standard 26-bit Kernel,
  although some internal changes have taken place to minimise compile
  switches between the two cases. See Docs.32bit for more technical info.

  The hardest part was the flood-fill...

Other changes:
  Pointer shape changes now take place on the next VSync, rather than actually
  WAITING for the VSync. Turning the Hourglass on shouldn't slow your machine
  down by 5% now :)

  Lots of really crusty pre-IOMD code removed.

Admin:
  Tested in 32 and 26-bit forms in a limited desktop build. Basically, this
  will need to see a lot of use to iron out difficulties. I'd like anyone who
  has a non-frozen project to at least attempt using this Kernel.

Version 5.23. Tagged as 'Kernel-5_23'
@
text
@d698 4
a701 1
    [ :LNOT: RunningOnEmul
d805 1
a805 1
    ] ;RunningOnEmul
@


4.10
log
@  Added OS_ReadSysInfo 6, 7 and 8 from Ursula branch.
  Ensured that M_Phoebe builds set UtilityModule version to 4.00
Detail:
  The softload utility relies on the existence of the extra reason codes
    to OS_ReadSysInfo introduced in Ursula.  The main kernel now supports
    these too (they are simply interfaces to read kernel capabilities and
    configuration - eg. addresses and sizes of UND and SVC mode stacks)
  Avoid OS_ReadSysInfo 9 - ROL have used it for reading the ROM personality
    information (and it's not in our kernel)
  Added some of the new macros into Copro15ops required by the ABT dump
    area code (returned by OS_ReadSysInfo 7) and added the code into ARM600
    to store abort information there.
Admin:
  Required by softload utility for Ursula builds.
  Tested on Risc PC.

Version 5.15. Tagged as 'Kernel-5_15'
@
text
@d49 2
d87 4
d108 1
a108 1
CamEntriesForVicky      *       UndStackSoftCamChunk + &2000
d110 5
d122 1
a122 1
ARMA_Cleaners_address  * 31*1024*1024 + 64*1024
d125 1
d131 1
a186 1
 [ MEMC_Type = "IOMD"
a279 46
 |

; DMA address generators - still controlled by MEMC1 currently

VInit   * &03600000
VStart  * &03620000
VEnd    * &03640000
CInit   * &03660000

; *****************************************************************************
;
;       SetDAG - Program DMA address generator R1 with physical address R0
;
; in:   r0 = physical address offset from 32M
;       r1 = index of DMA address generator to program, as defined in vdudecl
;
; out:  All registers preserved, operation ignored if illegal
;

SetDAG  ENTRY   "r0"
        CMP     r1, #MEMCDAG_MaxReason
        EXIT    HI
        ADR     r14, DAGAddressTable
        LDR     r14, [r14, r1, LSL #2]          ; load base address in MEMC1
        MOV     r0, r0, LSR #4                  ; bottom 4 bits irrelevant
        CMP     r0, #(1 :SHL: 15)               ; ensure in range
        ORRCC   r14, r14, r0, LSL #2
        STRCC   r14, [r14]                      ; any old data will do
        EXIT

        GBLA    DAGIndex
DAGIndex SETA   0

        MACRO
        DAGTab  $reason, $address
        ASSERT  ($reason)=DAGIndex
        &       $address
DAGIndex SETA   DAGIndex + 1
        MEND

DAGAddressTable
        DAGTab  MEMCDAG_VInit, VInit
        DAGTab  MEMCDAG_VStart, VStart
        DAGTab  MEMCDAG_VEnd, VEnd
        DAGTab  MEMCDAG_CInit, CInit
 ]
d381 1
a381 1
AssumeNoCodeAbove64Mb  SETL    {TRUE}
d629 1
a629 1
        TEQP    pc, #SVC_mode+I_bit+F_bit
a648 1
 [ MEMC_Type = "IOMD"
a662 1
 |
d664 1
a664 7
; Just change the page size to the real MEMC page size and leave other bits alone

        ORR     r11, r11, #&0C          ; force 32K page size
        STR     r11, [r11]              ; any old data will do
 ]

        TEQP    pc, #SVC_mode+I_bit
a852 3
 [ :LNOT: NewStyle_Screen
        MakeSkipTable   0, 0, 32                        ; in video RAM skip 1st 32 bytes (kbd workspace)
 ]
a876 1
 [ MEMC_Type = "IOMD"
a1231 4
 |
        LDR     R0, ResetMemC_Value
        STR     R0, [R0]     ; set ROM access times, refresh on flyback, no DMA
 ]
d1255 1
a1255 1
        mrs     AL, r2, CPSR_all        ; read back PSR
d1310 1
d1313 1
a1393 2
 [ MEMC_Type = "IOMD"

a1659 147
 |

; MEMC based memory sizing

        MOV     r0, #PhysRamPhys

        ADD     r1, r0, #A13
        BL      DistinctAddresses
        BNE     %05
        ADD     r1, r0, #A21
        BL      DistinctAddresses
        MOVNE   r0, #Page32K
        MOVNE   r1, #2048*1024
        BNE     MemSizeDone

        ADD     r1, r0, #4*1024*1024
        BL      DistinctAddresses
        MOVNE   r0, #Page32K
        MOVNE   r1, #4*1024*1024
        BNE     MemSizeDone

        ADD     r1, r0, #8*1024*1024
        BL      DistinctAddresses
        MOVNE   r0, #Page32K
        MOVNE   r1, #8*1024*1024
        BNE     MemSizeDone

        ADD     r1, r0, #12*1024*1024
        BL      DistinctAddresses
        MOV     r0, #Page32K
        MOVNE   r1, #12*1024*1024
        MOVEQ   r1, #16*1024*1024
        B       MemSizeDone

05
        ADD     r1, r0, #A20
        BL      DistinctAddresses
        BNE     %10
        MOV     r0, #Page16K
        MOV     r1, #2048*1024
        B       MemSizeDone

10
        ADD     r1, r0, #A19
        BL      DistinctAddresses
        BEQ     %15
        MOV     r0, #Page8K
        MOV     r1, #512*1024
        B       MemSizeDone

15
        ADD     r1, r0, #A18
        BL      DistinctAddresses
        BEQ     %20
        MOV     r0, #Page4K
        MOV     r1, #256*1024
        B       MemSizeDone

20
        ADD     r1, r0, #A12
        BL      DistinctAddresses
        BEQ     %25
        MOV     r0, #Page4K
        MOV     r1, #512*1024
        B       MemSizeDone

25
        MOV     r0, #Page8K
        MOV     r1, #1024*1024

MemSizeDone
        LDR     r3, =PhysRamPhys                ; Base of "video RAM"
        MOV     r4, #480*1024                   ; 480K of "video RAM"
        ADD     r5, r3, r4                      ; Base of "1st bank of DRAM"
        SUB     r6, r1, r4                      ; Size of "1st bank of DRAM"

        LDR     r2, =DRAMOffset_PageZero + PhysRamTable
        ADD     r2, r5, r2                      ; physical address of table of physical RAM addresses/sizes
        STMIA   r2, {r3-r6}

        ADD     r3, r2, #4*4                    ; indicate just 2 areas

        LDR     r4, =38400000                   ; indicate 38.4E6 bytes/sec video bandwidth
        STR     r4, [r2, #VideoBandwidth-PhysRamTable]

        ADRL    r4, ROM                         ; use PC-relative addressing to get to start of image
        TEQ     r4, #PhysROM                    ; then see if it's the normal ROM address
  [ STB
	TEQNE	r4, #PhysExtROM			; or if it's the 2nd ROM bank
  ]
        BEQ     %FT55                           ; if so, then we're OK

        SUB     r1, r1, #OSROM_ImageSize*1024   ; if we've been soft-loaded, then we have ?M less than we thought
        ADD     r5, r4, #OSROM_ImageSize*1024   ; point r5 at end of ROM

; now go through the declared RAM areas looking for our image (we assume it's not split across two banks)

        MOV     r6, r2                          ; make copy of start pointer
30
        TEQ     r6, r3
        BEQ     %FT55
        LDMIA   r6!, {r7,r8}                    ; load address, size
        ADD     r8, r8, r7                      ; r8 -> end
        SUBS    r9, r8, r5
        SUBCSS  r10, r4, r7                     ; test for r4>=r7 and r5<=r8
        BCC     %BT30

; we've found where the ROM is

        BNE     %FT40                           ; if NE from last comparison then r4<>r7 ie start(ROM)<>start(region)
                                                ; else start(ROM)=start(region), so modify region to be end(ROM)..end(region)
        TEQ     r9, #0                          ; test if region completely removed
        STMNEDB r6, {r5, r9}                    ; if region not completely removed, store updated (address, size)
        BNE     %FT55

; region completely removed, so shunt down remaining ones

35
        TEQ     r6, r3                          ; if not got to end
        LDMNEIA r6, {r7, r8}                    ; then load next pair
        STMNEDB r6, {r7, r8}                    ; and store in last
        ADD     r6, r6, #8                      ; advance pointer
        BNE     %BT35
        SUB     r3, r3, #8                      ; move back end pointer
        B       %FT55

; there is a lump at the start

40
        STMDB   r6, {r7, r10}                   ; reduce start bit
        TEQ     r9, #0                          ; is there an end bit?
        BEQ     %FT55                           ; [no, so we've finished]

; now shunt up all remaining areas, to make room for new one

        MOV     r8, r3
45
        TEQ     r8, r6
        LDMNEDB r8, {r7, r10}
        STMNEIA r8, {r7, r10}
        SUBNE   r8, r8, #8
        BNE     %BT45
        STMIA   r8, {r5, r9}                    ; store end lump
        ADD     r3, r3, #8                      ; advance end pointer

 ]

d1868 6
d1875 1
a1880 3
 [ MEMC_Type <> "IOMD"
        STR     r2, [r2]                        ; set MEMC to right state
 ]
a1882 1
 [ MEMC_Type = "IOMD"
a1886 1
 ]
a1888 1
 [ MEMC_Type = "IOMD"
a2067 1
 ]
a2161 3
 [ :LNOT: NewStyle_Screen
        MemInitVideo    16, 1, 0, 1, &05000000, AP_None                 ; real screen (section-mapped)
 ]
d2164 1
d2169 1
d2187 3
d2336 1
a2336 1
        Push    "r0,lr"
d2349 1
a2349 1
        Pull    "r0,pc",,^
d2591 1
a2591 3
        MOV     r4, pc
        ORR     lr, r4, #I_bit
        TEQP    lr, #0                  ; disable IRQs while we modify soft copy
d2689 1
a2689 1
        TEQP    r4, #0                  ; restore IRQ state
d2760 1
a2767 6
; entered in undef32, and we've branched up to &FF80xxxx, so we need to jump
; back to normal ROM space

        BIC     pc, pc, #&FC000000      ; remove silly bits from pc
        NOP                             ; (this instruction skipped)

d2773 1
a2773 1
        mrs     AL, r1, SPSR_all                        ; r1 = saved PSR
d2779 1
a2779 1
        mrs     AL, r2, CPSR_all        ; now switch into SVC26
d2782 2
a2783 2
        msr     AL, SPSR_all, r3        ; set SPSR_undef to be CPSR but with SVC26
        msr     AL, CPSR_all, r3        ; and select this mode now
d2787 1
a2787 1
        msr     AL, CPSR_all, r2        ; go back into undef mode
d2793 1
d2795 1
a2799 5
; entered in abort32, and we've branched up to &FF80xxxx, so we need to jump
; back to normal ROM space

        BIC     pc, pc, #&FC000000      ; remove silly bits from pc
        NOP                             ; (this instruction skipped)
d2806 1
a2806 1
        mrs     AL, r1, SPSR_all                        ; r1 = saved PSR
d2817 1
a2817 1
        mrs     AL, r2, CPSR_all        ; now switch into SVC26
d2820 1
a2820 1
        msr     AL, CPSR_all, r2
d2827 1
d2840 3
a2842 6
; entered in abort32, and we've branched up to &FF80xxxx, so we need to jump
; back to normal ROM space

        BIC     pc, pc, #&FC000000              ; remove silly bits from pc
        NOP                                     ; (this instruction skipped)

d2844 1
d2848 2
a2849 2
        mrs     AL, r0, SPSR_all                ; r0 = PSR when we aborted
        mrs     AL, r1, CPSR_all                ; r1 = CPSR
d2870 1
a2870 1
        msr     AL, CPSR_all, r3                ; switch to user's mode
d2874 1
a2874 1
        mrs     AL, r5, SPSR_all                ; get the SPSR for the aborter's mode
d2877 6
d2884 4
a2887 2
        ORR     r1, r1, #SVC26_mode
        msr     AL, CPSR_all, r1                ; then switch to SVC26 for the rest of this
a2888 2
        Push    "r0, lr_svc"                    ; save SPSR_abort and lr_svc
        SUB     sp_svc, sp_svc, #8*4            ; make room for r8_usr to r14_usr and PC
d2890 2
a2891 2
        STMIA   sp_svc!,{r8-r12}
        STMIA   sp_svc, {r13,r14}^
d2893 1
a2893 2
        STR     pc, [sp_svc,#2*4]
        SUB     sp_svc, sp_svc, #5*4            ; save USR bank in case STM ^, and also so we can corrupt them
d2895 2
a2896 1
        STMIA   sp_svc, {r8-r15}^               ; save USR bank in case STM ^, and also so we can corrupt them
d2900 1
a2900 1
        STR     r4, [sp_svc, #7*4]              ; store aborter's PC in user register bank
d2903 1
d3029 1
a3029 1
        ANDS    r2, r2, #3                      ; get bottom 2 bits of mode (EQ => USR26 or USR32)
d3064 1
a3064 1
        TST     r8, #&10                        ; if 32-bit mode
d3253 4
d3260 1
d3262 3
a3264 4
        mrs     AL, r6, SPSR_all                ; get original SPSR, with aborter's original mode
        AND     r7, r6, #&1F
        TEQ     r7, #USR26_mode
        TEQNE   r7, #USR32_mode                 ; test also for USR32
d3270 2
a3271 1
        msr     AL, CPSR_all, r6                ; switch to aborter's mode
d3273 1
a3273 1
        msr     AL, CPSR_all, r1                ; switch back to ABT32
d3277 1
a3277 1
        msr     AL, SPSR_all, r0                ; set up new SPSR (may have changed for LDM {PC}^)
d3280 3
d3300 40
d3363 1
a3364 1
 [ NewStyle_All
a3366 1
 ]
d3368 2
a3369 4
        CMP     r2, #&20                                ; if aborting address <&20
        ADRCCL  r0, ABORTD                              ; then use MOS's default abort handler
        LDRCS   r0, =DAbHan                             ; else use current handler
        LDRCS   r0, [r0]                                ; get address of data abort handler
d3390 1
a3390 1
;       SVC26 mode
d3489 1
d3491 1
d3535 1
d3537 1
a3830 1
        BIC     LR,LR,#V_bit                 ;clear return V
d3851 5
a3855 11
        MOV     R10,PC
        ORR     R12,R10,#I_bit
        TEQP    R12,#0                     ;disable IRQs to read-modify-write semaphore
        MOV     R12,#0
        LDRB    R11,[R12,#SyncCodeA_sema]
        CMP     R11,#0
        TEQNEP  R10,#0                     ;restore and...
        BNE     SLVK                       ;semaphore set, avoid reentrancy, let first call do it
        MOV     R11,#1
        STRB    R11,[R12,#SyncCodeA_sema]  ;set semaphore
        TEQP    R10,#0                     ;restore IRQ state
d3950 1
d3955 1
@


4.9
log
@* Meaning of FEIOSpeedHalf was accidentally inverted.
* Wasn't allowing writes to most of EEPROM.
* Old prototype OS_SetTime SWI code removed.
* MPEGPoduleNTSCNotPALMask option support removed to simplify things a bit.
* Now can cope with a system with a PAL/NTSC link, but no monitor detect line.
* Default PAL & NTSC modes now always 12 & 46 respectively.
* Kernel now knows about monitor type 8 (NTSC) - modes 44-46 (640x200) are
  available.
* STB/NC CMOS test removed from POST pending further investigation.

Version 4.90. Tagged as 'Kernel-4_90'
@
text
@d3012 5
d3058 4
d3480 10
@


4.8
log
@Added support for ATMEL 4K and 8K EEPROM parts, including write protection
of top quarter. Untested.
Added support for ARM7500FE IO clock divide by 2.

Version 4.89. Tagged as 'Kernel-4_89'
@
text
@d969 2
a971 2
     |
	MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkHalf
d975 2
a977 2
     |
	MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkHalf
@


4.7
log
@* Added support for 24LC64 8K EEPROM (untested).
* Integrated Ursula fast service call dispatch code.
* Added Interruptible32bitModes from Ursula.
* Stopped allowing ROM modules (other than the Kernel/UtilityModule) to write
  to the hardware vectors in 26-bit mode.

Version 4.81. Tagged as 'Kernel-4_81'
@
text
@d968 1
d970 3
d974 1
d976 3
@


4.6
log
@Up to 16M of ROM now mapped in from 03800000-04800000.
Video memory now limited to 8M (instead of 16M) to make room.
OS_Memory 7 now reports ROM correctly when the image is >4M.

Version 4.76. Tagged as 'Kernel-4_76'
@
text
@a3597 1
 [ {TRUE}
d3599 12
a3610 3
 |
        CMP     r2, #&20                                ; if in abort area
 ]
d3614 1
@


4.5
log
@ROM speed not taken from the Machine header file.  POST can now exist
in a softloaded OS, since it searches for a zero word in the ROM
instead of using one within the POST when trying to communicate with
the POST adapter (the zero word must be in ROM).  Fixed to build on
non-chrontel STB/NC products.  Lots of duplicate code merged in
MemSize.  MemSize copes better with the softload case, and is less
willing to use the region the OS occupies as video memory, or
page tables.  POST is now ON (memory tests disabled).
OS_ReadSysInfo 4 now uses the NVRAM module to access the ethernet
address in NVRAM/CMOS, so that the availability/location of the
MAC address can be changed.  CMOS location 0 is now unprotected on
STB/NC products to try to stop people poking the hardware directly.
Fixed a CMOS resetting problem on STBs where the value expected in a
location was different from the value written on a CMOS reset, so the
CMOS would be reset every time...

Version 4.69. Tagged as 'Kernel-4_69'
@
text
@d1642 2
a1643 2
	CMP	r7, #16*1024*1024
	MOVCS	r7, #16*1024*1024			; Limit allocation to 16M - the size of the logical space
d2193 1
a2193 1
;     The pairs of words before 
d2325 8
a2332 3
 [ STB
  [ ExtROMSupport							; System build option
	ASSERT (OSROM_ImageSize <= 4096)	; No room for extension ROMs with an 8MB OS image
d2335 3
a2338 3
        MemInitROMs      8, 1, 1, 1, &03800000, AP_Read			; ROM (1st or 2nd bank)
  ]
 |
d2349 1
d3775 3
d3779 1
@


4.4
log
@Spinner branch merged.
Bandwidth limit for 7500FE fixed.
RO371Timings flag set to :LNOT:STB

Version 4.64. Tagged as 'Kernel-4_64'
@
text
@d992 1
a992 1
        ORR     r0, r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
d994 1
a994 1
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
d1073 1
a1073 1
        ORR     r0, r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
d1075 1
a1075 1
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
a1411 2
Z_Flag     * &40000000

a1462 8

 [ 1 = 0
        MOV     R10, #DRAM0PhysRam
        MOV     R11, #(2*OneMByte)
        STMIA   R10!, {R10, R11}
        B       AllocateTheRAM
        ! 0, "*** WARNING *** Bodged RAM sizing version ment for PSwindell"
 ]
d1483 1
a1483 1
        BEQ     %FT1010                                   ;32bit wide memory
d1489 1
d1493 1
a1493 1
1010
a1497 110
;
; minimum ram test
;
        ADD     r1, r0, #A18
        BL      DistinctAddresses
        BNE     NoRamInBank                             ;Less than 512KBytes, so ignore this bank

        MOV     r6, #0                                  ;Fragment address
        MOV     r7, #0                                  ;Fragment address
        MOV     r8, #A19                                ; now go through address lines A19-A25
1015
        ADD     r1, r0, r8                              ; see if this address line is unique
        BL      DistinctAddresses
        BNE     %FT1020                                   ; if we've failed then r8 is true size, so exit
        MOV     r8, r8, LSL #1                          ; else shift up to next
        TEQ     r8, #A26                                ; only test up to A25
        BNE     %BT1015
        BEQ     %FT1035                           ;Bank fully occupied, DON'T test for higher fragments
1020
;
; Found some DRAM, at address r0, size r8.
; There may be one or two higher address lines connected, so scan upto A25 looking for
; extra DRAM chunks.
;
        MOV     r1, r8
1025
        TEQ     r1, #A25
        BEQ     %FT1035                           ;No higher active address lines found ie one lump of DRAM
        ADD     r1, r0, r1,LSL #1
        BL      DistinctAddresses
        SUB     r1, r1, r0                              ;Recover bit value
        BNE     %BT1025
;
; Got a 2nd fragment, at address r1 (also of size r8)
;
        MOV     r6, r1
1030
        TEQ     r1, #A25
        BEQ     %FT1035                           ;No higher active address lines found ie two lumps of DRAM
        ADD     r1, r0, r1,LSL #1
        BL      DistinctAddresses
        SUB     r1, r1, r0                              ;Recover bit value
        BNE     %BT1030
;
; Got another active address line (ie total four fragments)
;
        MOV     r7, r1
;
1035
;
; Found 1, 2 or 4 lumps of DRAM
;
  [ 1 = 1
;
; New code which relies on reflection to merge fragments into larger blocks
;
        TEQ     r10, #0                         ;Need some ram to dump block/fragment data
        MOVEQ   r10, r0                         ;

        TEQ     r6, #0                          ;Do we have one fragment?
        MOVEQ   r1, r0                          ;EQ: First and only fragment in this bank
        MOVEQ   r2, r8                          ;EQ:   so save actual address and size
        ADDNE   r1, r0, r6                      ;NE: Use reflection to make 1st fragment appear
        SUBNE   r1, r1, r8                      ;NE:   to start just below 2nd fragment
        MOVNE   r2, r8, LSL #1                  ;NE:   treat as one double size fragment

        STMIA   r10!, {r1, r2}                  ; {address, size}

        TEQ     r7, #0                          ;Do 3rd and 4th fragments exist
        ADDNE   r1, r1, r7                      ;NE: yes, merge 3 and 4 together
        STMNEIA r10!, {r1, r2}                  ;  {address, size}
  |
;
; Old code which enters each fragment as found
;
        TEQ     r10, #0                         ;Need some ram to dump block/fragment data
        MOVEQ   r10, r0                         ;

        STMIA   r10!, {r0, r8}                  ;First fragment

        TEQ     r6, #0
        ADDNE   r1, r0, r6
        STMNEIA r10!, {r1, r8}                  ;Second fragment

        TEQ     r7, #0
        ADDNE   r1, r0, r7
        STMNEIA r10!, {r1, r8}                  ;Third
        ADDNE   r1, r1, r6
        STMNEIA r10!, {r1, r8}                  ;and fourth fragments
  ]
  [ Simulator
        TubeString r2, r3, r4, "Address  Size"
        TubeDumpNoStack r0, r2, r3, r4
        TubeDumpNoStack r8, r2, r3, r4
        TubeNewlNoStack r3, r4

        TEQ     R7, #0
        BEQ     skip1
        TubeString r2, r3, r4, "Fragment (1): "
        TubeDumpNoStack r7, r2, r3, r4
        TubeNewlNoStack r3, r4
skip1
        TEQ     R6, #0
        BEQ     skip2
        TubeString r2, r3, r4, "Fragment (2): "
        TubeDumpNoStack r6, r2, r3, r4
        TubeNewlNoStack r3, r4
skip2
  ]

d1499 1
a1501 1
        ADD     r0, r0, #DRAM1PhysRam-DRAM0PhysRam      ; move onto next bank
d1506 2
a1507 77
        TEQ     r10, #0                                 ; have we got any DRAM?
;NoDRAMPanic
        BEQ     NoDRAMPanic                             ; we'd better stop now

;
; Having dumped our block/fragment data to the first bit of DRAM that we found.
; We now go back through it, allocating some for the screen, and some for 'PageZero'.
; The data has been dumped into RAM that we now allocate as screen ram, so it needs
; to be copied into 'PageZero'.
;
; r10 -> byte after last fragment(address, size) pair
;
AllocateTheRAM
        AND     r7, r10, #DRAMBaseAddressMask           ;point to first fragment data
        MOV     r2, #0                                  ;MOS workspace not yet allocated

        LDMIA   r7!, {r4, r5}                           ;first fragment address & size
        CMP     r10, r7                                 ;is there only 1 fragment
 [ 1 = 1
;
; New - requested by Tim Dobson
;
        MOVHI   r1, r5                                  ;if >1 fragments, take first fragment for the screen
        SUBLS   r1, r5, #OneMByte                       ;if this is the only fragment, take all but 1MByte of it
        MOV     r0, r4                                  ;screen starts at beginning of fragment
  [ 1 = 1
;
; New - also requested by Tim Dobson
;
        CMP     r1, #SixteenMByte                       ;Limit our claim to 16Mbyte
        MOVGT   r1, #SixteenMByte
  ]
 |
        MOVHI   r1, r5                                  ;if >1 fragments, consider taking first fragment for the screen
        MOVLS   r1, r5, LSR #1                          ;if this is the only fragment, try for half of it
        MOV     r0, r4                                  ;screen starts at beginning of fragment

        CMP     r1, #OneMByte                           ;Limit our claim to 1Mbyte
        MOVGT   r1, #OneMByte
 ]
        ADD     r4, r4, r1                              ;adjust fragment for amount claimed by screen
        SUBS    r5, r5, r1
        BEQ     %FT1065                                 ;EQ whole fragment used
                                                        ;NE part of fragment remains to be allocated
1060
        TEQ     r2, #0                                  ;allocate MOS workspace if not already done so
        LDREQ   r2, =DRAMOffset_PageZero + DRAMPhysAddrA
        ADDEQ   r2, r2, r4
        MOVEQ   r3, r2

        STMIA   r3!, {r4, r5}                           ;write fragment data to correct place in PageZero
1065
        CMP     r10, r7                                 ;any more fragment (address, size) pairs?
        LDMHIIA r7!, {r4, r5}                           ;HI, yes so load next fragment pair (size
        BHI     %BT1060                                 ;HI, mustbe non-zero) and loop back

        STMDB   r2!, {r0, r1}                           ;write VideoPhysAddr, VideoSize
;
; r2 -> start of PhysRamTable
; r3 -> byte after last used entry in PhysRamTable
;
        MOV     r7, r2
       ;MOV     r2, r2                                  ; r2 -> start of PhysRamTable
        MOV     r10, r3
       ;MOV     r3, r3                                  ; r3 -> byte after last used entry in PhysRamTable


;
; r0 screen start address
; r1 screen size
; r2 -> start of PhysRamTable
; r3 -> byte after last used entry in PhysRamTable

        MOV     r4, #0                                  ;Morris cannot support VRAM, so...
        STR     r4, [r2, #VRAMWidth-PhysRamTable]       ; store width of VRAM (0,1 or 2)
        STR     r4, [r2, #VRAMSize-PhysRamTable]        ; and size of VRAM (fixes DForth's bug of 6/3/95)

a1509 8
        MOV     r4, #IOMD_VIDCR_DRAMMode :OR: &10       ; if no VRAM, then turn on DRAM mode, and set increment to &10
        STRB    r4, [r14, #IOMD_VIDCR]
        STR     r0, [r14, #IOMD_VIDCUR]                 ; set up VIDCUR to start of video RAM
        STR     r0, [r14, #IOMD_VIDSTART]               ; do same for VIDSTART
        STR     r0, [r14, #IOMD_VIDINIT]                ; and for VIDINIT
                                                        ; so we don't get a mess when we turn video DMA on later


d1515 1
a1515 1
	LDREQ	r4, =80000000				; so allow 80E6 bytes/s
d1517 1
a1517 1
	LDRNE	r4, =44000000				; else only allow 44E6 bytes/s
d1519 1
a1519 1
        LDRNE   r4, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
d1521 1
a1521 10
        STR     r4, [r2, #VideoBandwidth-PhysRamTable]  ; store video bandwidth

        ADD     r4, r0, r1                              ;form VIDEND (will be on mult. of SAM)
        SUB     r4, r4, #4096
        STR     r4, [r14, #IOMD_VIDEND]                 ;this instruction put in on 6/3/95 after inspection of RPC code
;
;
;
        MOV     r7, r2
        MOV     r10, r3
d1523 1
a1523 1
        B       MemSizeTotalRAM
a1529 5
; First, we check out the VRAM. This is so that if there's no VRAM, we know to take out the 1st Mbyte of DRAM
; that we find.

; Don't bother checking for more than 2M of VRAM, because we don't know what the 1/2 SAM length is for larger sizes

a1558 23
        MOV     r2, #IOMD_VREFCR_VRAM_256Kx64 :OR: IOMD_VREFCR_REF_16 ; assume 2 banks of VRAM by default
        STRB    r2, [r12, #IOMD_VREFCR]

        MOV     r0, #VideoPhysRam                       ; point at VRAM
        ADD     r1, r0, #A2                             ; test A2
        BL      DistinctAddresses
        MOVEQ   r6, #2                                  ; we've got 2M of VRAM
        BEQ     %FT08

        MOV     r2, #IOMD_VREFCR_VRAM_256Kx32 :OR: IOMD_VREFCR_REF_16
        STRB    r2, [r12, #IOMD_VREFCR]
        ADD     r1, r0, #A2                             ; check for any VRAM at all
        BL      DistinctAddresses
        MOVEQ   r6, #1                                  ; we've got 1M of VRAM
        MOVNE   r6, #0                                  ; no VRAM
08
 [ IgnoreVRAM
        MOV     r6, #0                                  ; pretend there's no VRAM
 ]
        MOVS    r12, r6                                 ; if no VRAM, then video RAM has yet to be found
        MOVNE   r12, r0                                 ; else point at VRAM

; Now, we have to find a bank of DRAM, so we've got somewhere to store our results!
d1570 2
a1571 1
        BNE     %FT25                                   ; [no RAM in this bank at all]
a1577 2
        MOVNE   r8, #1024*1024                          ; must be 1Mbyte at this address
        BNE     %FT20
d1579 1
a1579 2
; it's bigger than 256K words, so test address lines A21-A25 in sequence
; we assume that the size of each bank is a power of 2
d1581 1
a1581 1
        MOV     r8, #A21                                ; now go through address lines A21-A25
a1582 23
        ADD     r1, r0, r8                              ; see if this address line is unique
        BL      DistinctAddresses
        BNE     %FT20                                   ; if we've failed then r8 is true size, so exit
        MOV     r8, r8, LSL #1                          ; else shift up to next
        TEQ     r8, #A26                                ; only test up to A25
        BNE     %BT15
20
        TEQ     r12, #0                                 ; have we found any video RAM yet?
        BNE     %FT22                                   ; yes, so no worries

        MOV     r12, r0                                 ; no, so use this as video RAM
        ADD     r0, r0, #1024*1024                      ; advance RAM pointer by 1M
        SUBS    r8, r8, #1024*1024                      ; take 1 Mbyte off the size
        BEQ     %FT25                                   ; if that's all there was, then go look for the next bank
22
        TEQ     r10, #0                                 ; is this the first lot we've found?
        LDREQ   r10, =DRAMOffset_PageZero + DRAMPhysAddrA
        ADDEQ   r10, r10, r0                            ; then point r10 at DRAM part of PhysRamTable
        MOVEQ   r7, r10                                 ; points to beginning of table
        STMIA   r10!, {r0, r8}                          ; store address, size
25
        AND     r0, r0, #DRAMBaseAddressMask            ; move back to start of DRAM bank (in case we stole some video DRAM)
        ADD     r0, r0, #DRAM1PhysRam-DRAM0PhysRam      ; move onto next bank
d1587 39
a1625 1
        TEQ     r10, #0                                 ; have we got any DRAM?
d1627 32
a1658 1
        BEQ     NoDRAMPanic                             ; we'd better stop now
d1662 1
a1662 8
        STR     r6, [r7, #VRAMWidth-DRAMPhysAddrA]      ; store width of VRAM (0,1 or 2)
        CMP     r6, #1
        MOVCC   r2, #IOMD_VIDCR_DRAMMode :OR: &10       ; if no VRAM, then turn on DRAM mode, and set increment to &10
        MOVEQ   r2, #SAMLength/2/256                    ; if 1M VRAM, then use VRAM mode, and set increment for 1/2 SAM
        MOVHI   r2, #SAMLength/2/256*2                  ; if 2M VRAM, then use VRAM mode, and set increment for 2*1/2 SAM
        LDRCC   r3, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
        LDREQ   r3, =80000000                           ; if 1M VRAM, then 80E6   ---------""--------
        LDRHI   r3, =160000000                          ; if 2M VRAM, then 160E6  ---------""--------
d1664 4
a1667 4
        STRB    r2, [r14, #IOMD_VIDCR]
        STR     r12, [r14, #IOMD_VIDCUR]                ; set up VIDCUR to start of video RAM
        STR     r12, [r14, #IOMD_VIDSTART]              ; do same for VIDSTART
        STR     r12, [r14, #IOMD_VIDINIT]               ; and for VIDINIT
d1669 1
a1669 1
        STR     r3, [r7, #VideoBandwidth-DRAMPhysAddrA] ; store video bandwidth
d1671 2
a1672 2
        ADD     r3, r12, #1024*1024-4096                ; add on a bit to form VIDEND (will be on mult. of SAM)
        STR     r3, [r14, #IOMD_VIDEND]                 ; yes I know it's a bit of a bodge
d1674 2
a1675 2
        MOVS    r14, r6, LSL #20                        ; convert amount of VRAM to bytes
        STR     r14, [r7, #VRAMSize-DRAMPhysAddrA]      ; and store
d1677 2
a1678 5
        MOVEQ   r14, #1024*1024                         ; if no VRAM, then video RAM size is 1M
        STMDB   r7!, {r12, r14}                         ; store video information

        MOV     r2, r7                                  ; r2 -> start of PhysRamTable
        MOV     r3, r10                                 ; r3 -> byte after last used entry in PhysRamTable
d1686 2
a1687 1
26
d1695 2
a1696 2
        TEQ     r7, r10
        BNE     %BT26
d1700 2
a1785 1
 ]
d1847 8
d2076 182
a2557 5
  [ STB
        BIC     r9, r9, #3 :SHL: 8
        STR     r9, [r9]                ; turn off refresh for a bit
  ]

d3841 4
a3844 5
        ADD     r0,r0,#1               ; = no. of 4k RAM pages in machine
        MOV     r0,r0,LSR #8           ; = no. of Mbytes in machine
        ADD     r0,r0,#3
        BIC     r0,r0,#3               ; round up to next 4 Mb
        CMP     r0,#28                 ; if 28Mb or more, no pages to be rescued from L2PT AppSpace
d3848 2
a3849 2
        STR     r2,[r1,#DANode_MaxSize] ; update AppSpace max size
        MOV     r0,r0,LSR #2           ; no. of L2PT AppSpace pages which cannot be rescued
d3851 4
a3854 2
        ADD     r1,r1,#(L2PT :SHR: 10) ;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r1,r0,LSL #2        ;first entry for rescue
d3857 2
a3858 3
        LDR     r3,[r3,#DANode_Size]
        ADD     r2,r2,r3               ; r2 -> next logical address for a rescued page
        MOV     r5,r3                  ; FreePool size so far
d3860 1
a3860 1
        SUB     sp,sp,#16              ; room for 1 page block entry + terminator
d3863 7
a3869 5
        LDR     r4,[r1],#4             ; pick up the L2PT entry
        BIC     r4,r4,#&0FF
        BIC     r4,r4,#&F00            ; mask to leave physical address only
        STR     r4,[r3,#8]             ; store physical address in word 2 of page block entry
        Push    "r0-r2"
d3873 9
a3881 8
        SWI     XOS_Memory             ; fill in page number, given physical address
        Pull    "r0-r2"
        MOV     r4,#2                  ; means inaccessible in user mode (destined for FreePool)
        STR     r4,[r3,#8]
        MOV     r4,#-1
        STR     r4,[r3,#12]            ; terminator
        STR     r2,[r3,#4]             ; new logical address for page
        Push    "r0"
d3884 7
d3893 1
a3893 1
        ADD     r5,r5,#4096            ; next page
d3895 1
a3895 1
        CMP     r0,#7                  ;7 entries in total for full 28Mb AppSpace
d3897 1
a3897 1
        ADD     sp,sp,#16              ;drop the workspace
d3899 2
a3900 2
        LDR     r4,=FreePoolDANode
        STR     r5,[r4,#DANode_Size]   ;update FreePoolSize
@


4.3
log
@RISC OS 3.71 kernel changes merged.
Not fully tested on all hardware permutations.
@
text
@d963 1
a963 1
;	CPUCLK divide by 2
d967 3
d971 1
d991 5
a995 1
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_4
d1001 1
d1005 21
a1025 16
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank?
        STRNEB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
      [ ExtROMis16bit
	MOVEQ	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOVEQ	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STREQB	r0, [r12, #IOMD_ROMCR1]
    |;CanLiveOnROMCard
      [ ExtROMis16bit
	MOV	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOV	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STRB	r0, [r12, #IOMD_ROMCR1]
    ];CanLiveOnROMCard
d1028 1
d1034 1
d1072 5
a1076 1
        ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_4
d1082 1
d1086 21
a1106 16
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank?
        STRNEB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
      [ ExtROMis16bit
	MOVEQ	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOVEQ	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STREQB	r0, [r12, #IOMD_ROMCR1]
    |;CanLiveOnROMCard
      [ ExtROMis16bit
	MOV	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOV	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STRB	r0, [r12, #IOMD_ROMCR1]
    ];CanLiveOnROMCard
d1109 1
d1115 1
a1724 5
        LDR     r4, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
        STR     r4, [r2, #VideoBandwidth-PhysRamTable]  ; store video bandwidth



d3796 2
d3812 1
@


4.3.2.1
log
@Added following enhancements:

 - Chocolate screen mapping (section mapped and cached), StrongARM only
   Phoebe h/w (IOMD 2) will have register to assist this, but code currently
   relies on data abort mechanism to keep screen up to date wrt write-back
   data cache.

 - Chocolate AMBControl task switching (lazy page mapping), StrongARM only
   Improves task swapping speed. There appears to be a StrongAEM silicon
   bug rev 2 and 3) which means that LDMIB rn, {regs includind rn} cannot
   be reliably restarted after a data abort. This stuffs Chocolate AMBControl
   (awaiting response from Digital).

Both enhancements need more work to complete for Phoebe. Chocolate AMBControl
may well have to be made dormant because of silicon bug.

Note that this kernel *will* cause problems with task switching on StrongARM,
unless Chocolate task switching is disabled via !Flavour application.
@
text
@d32 1
a32 2
;15-05-97 MJS  support for ChocolateScreen (section mapped, cached) and ChocolateAMB
;              (lazy task swapping) added
d66 1
a66 1
; 17-Jun-96     BAR     Change speed settings for the second bank of ROM space.
d69 7
a75 7
; 25-Jul-96     BAR     Correct bug in video bandwidth code, wrong label used.
; 16-Aug-96     JRH     Programming of 2nd ROM bank (IOMD ROMCR1 register):
;                               reinstated ExtROMSupport code, added CanLiveOnROMCard code
;                       MemInitTable:
;                               If ExtROMSupport: added assertion that ImageSize <= 4096
;                               and maps 4MB of each ROM bank.
;                               Otherwise: always maps 8MB of ROM space independant of ImageSize
a112 3
; - address for virtual area for StrongARM data cache clean for screen (32k, for two 16k areas)
; - this area is used if necessary, on VSync's, to keep cached screen up to date
ARMA_ScreenCleaners_address * 31*1024*1024 + 96*1024
a620 4
;we deliberately don't update ARMA_Cleaner_status here, since we are an 'uncommon' case - although we are doing
; a full clean, it is only SynchroniseCodeAreas and AMBControl that usefully need to update status (so that
; screen cleaning may be able to avoid a clean of its own)
;
d939 4
a942 4
        LDRB    r2,[r12,#IOMD_ID1]      ; load r2 with IOMD ID high byte
        LDRB    r0,[r12,#IOMD_ID0]      ; load r0 with IOMD ID low byte
        ORR     r0,r0,r2, LSL #8        ; Or r0 and r2 - shifted left 8, put in r0
        LDR     r2,=IOMD_7500           ; get Ref IOMD ID code for IOMD in a 7500
d944 1
a944 1
        BEQ     init7500cpu             ; If equal, got to init7500cpu
d946 2
a947 2
        LDRNE   r2,=IOMD_7500FE         ; If not, get ID code for IOMD in a 7500FE
        CMPNES  r0,r2                   ; If not, check for IOMD ID Code for IOMD in a 7500FE
d957 3
a959 3
;       CPUCLK divide by 1
;       MEMCLK divide by 2
;       IOCLK  divide by 2
d961 1
a961 1
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkHalf + IOMD_CLKCTL_IOclkHalf
d963 3
a965 3
;       CPUCLK divide by 2
;       MEMCLK divide by 1
;       IOCLK  divide by 1
d967 1
a967 1
        MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
d996 2
a997 2
        TST     pc, #PhysExtROM                 ; are we running out of the 2nd ROM bank?
        STRNEB  r0, [r12, #IOMD_ROMCR1]         ; Program the 2nd bank the same as the 1st
d999 1
a999 1
        MOVEQ   r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1001 1
a1001 1
        MOVEQ   r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1003 1
a1003 1
        STREQB  r0, [r12, #IOMD_ROMCR1]
d1006 1
a1006 1
        MOV     r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1008 1
a1008 1
        MOV     r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1010 1
a1010 1
        STRB    r0, [r12, #IOMD_ROMCR1]
d1015 1
a1015 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; Program the 2nd bank the same as the 1st
d1017 1
a1017 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; 2nd bank unused: program it the same anyway
d1023 2
a1024 2
        MOV     r0, #IOMD_ASTCR_WaitStates
        STRB    r0, [r12, #IOMD_ASTCR]
d1026 1
a1026 1
        B       init7500cpu_common              ; branch to common init code.
d1033 3
a1035 3
;       CPUCLK divide by 1
;       MEMCLK divide by 1
;       IOCLK  divide by 1
d1065 2
a1066 2
        TST     pc, #PhysExtROM                 ; are we running out of the 2nd ROM bank?
        STRNEB  r0, [r12, #IOMD_ROMCR1]         ; Program the 2nd bank the same as the 1st
d1068 1
a1068 1
        MOVEQ   r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1070 1
a1070 1
        MOVEQ   r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1072 1
a1072 1
        STREQB  r0, [r12, #IOMD_ROMCR1]
d1075 1
a1075 1
        MOV     r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1077 1
a1077 1
        MOV     r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
d1079 1
a1079 1
        STRB    r0, [r12, #IOMD_ROMCR1]
d1084 1
a1084 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; Program the 2nd bank the same as the 1st
d1086 1
a1086 1
        STRB    r0, [r12, #IOMD_ROMCR1]         ; 2nd bank unused: program it the same anyway
d1092 2
a1093 2
        MOV     r0, #IOMD_ASTCR_Minimal
        STRB    r0, [r12, #IOMD_ASTCR]
d1227 2
a1228 2
        MOV     r0, #IOMD_ROMCR_16bit + IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff
        STRB    r0, [r12, #IOMD_ROMCR1]         ; 16bit 156.25nS noburst (Lowest common denominator)
d1414 3
a1416 3
        LDRB    r0, [r12, #IOMD_ID0]    ; load r1 with IOMD ID high byte
        LDRB    r1, [r12, #IOMD_ID1]    ; load r0 with IOMD ID low byte
        ORR     r0,r0,r1,LSL#8          ; Or r0 and r1, shifted left 8, put in r0
d1429 4
a1432 4
        LDR     r1, =IOMD_7500FE
        TEQ     r0, r1                                  ; are we on FE part?
        ORREQ   r11, r11, #IOMD_DRAMWID_EDO_Enable :OR: IOMD_DRAMWID_RASCAS_3 :OR: IOMD_DRAMWID_RASPre_3
                                                        ; if so, then enable EDO and slower RASCAS and RASPre times
d1684 6
a1689 6
        LDRB    r4, [r14, #IOMD_ID0]
        LDRB    r7, [r14, #IOMD_ID1]
        ORR     r4, r4, r7, LSL #8
        LDR     r7, =IOMD_7500FE                        ; if FE part, then assume EDO DRAM
        TEQ     r4, r7
        LDREQ   r4, =80000000                           ; so allow 80E6 bytes/s
d1691 1
a1691 1
        LDRNE   r4, =44000000                           ; else only allow 44E6 bytes/s
d1970 1
a1970 1
        TEQNE   r4, #PhysExtROM                 ; or if it's the 2nd ROM bank
d2316 2
a2317 2
  [ ExtROMSupport                                                       ; System build option
        ASSERT (OSROM_ImageSize <= 4096)        ; No room for extension ROMs with an 8MB OS image
d2321 1
a2321 1
        MemInitROMs      8, 1, 1, 1, &03800000, AP_Read                 ; ROM (1st or 2nd bank)
a2359 2
;and similarly for the 32k screen cleaner area
        MemInitPagesL2  &8000, 1, 1, ARMA_ScreenCleaners_address, AP_Read, DRAMOffset_PageZero
a2840 1
        ;'uncommon' case, regarded as not needing to update ARMA_Cleaner_status
a2912 1
;'uncommon' case, regarded as not needing to update ARMA_Cleaner_status
a2987 11

  [ ChocolateAMB
        SUB     r0,lr_abort,#4
        STR     lr_abort, [r13_abort, #15*4]
        BL      AMB_LazyFixUp
        LDR     lr_abort, [r13_abort, #15*4]
        CMP     r0,#0
        LDMIA   r13_abort, {r0-r7}           ;restore regs
        SUBNES  pc,lr_abort,#4               ;restart aborting instruction if fixed up
  ]

a3029 31
  [ ChocolateAMB
        ARM_read_FAR r0
        BL      AMB_LazyFixUp
        LDR     lr_abort, [r13_abort, #15*4]
        CMP     r0,#0
        LDMIA   r13_abort, {r0-r7}           ;restore regs
        SUBNES  pc,lr_abort,#8               ;restart aborting instruction if fixed up
  ]

  [ ChocolateScreen
    ;check for domain fault, which will be a screen access - if so, set screen (domain 1) access to
    ;normal, restart VSC countdown (if enabled), and restart instruction
        ARM_read_FSR r0
        AND     r0,r0,#&F
        CMP     r0,#&9                       ;section domain fault (screen section mapped)
        BNE     DABP_notchocolate
        ARMA_read_MMUdomain r0
        ORR     r0,r0,#&4                    ;set domain 1 access to normal (was 00, set to 01)
        ARMA_write_MMUdomain r0
        MOV     r1,#0                        ;only start VSC countdown if screen clean neither disabled nor suspended
        LDR     r0,[r1,#ARMA_Cleaner_status]
        TST     r0,#ACS_SCdisable:OR:ACS_SCsuspend
        BICEQ   r0,r0,#ACS_VSCcountdown_MASK
        ANDEQ   r2,r0,#ACS_VSClazy_MASK
        ORREQ   r0,r0,r2,LSR #(ACS_VSClazy_SHIFT-ACS_VSCcountdown_SHIFT)  ;VSC countdown := VSC lazy
        STREQ   r0,[r1,#ARMA_Cleaner_status]
        LDMIA   r13_abort, {r0-r2}           ;restore regs
        SUBS    pc,lr_abort,#8               ;restart aborting instruction
DABP_notchocolate
  ]

d3773 1
a3773 2
;go for best available memory speed for data cache cleaner areas (StrongARM)
;there is 32k for 2 main cleaner areas, followed directly by 32k for 2 screen cleaner areas 
d3779 1
a3779 1
        MOV     r2,#16                          ;16 L2PT entries to fiddle in total
d3917 1
a3917 1
        BIC     LR,LR,#V_bit                     ;clear return V
d3921 2
a3922 2
        BNE     SLVK                             ;not StrongARM
        TST     R0,#1                            ;range variant of SWI?
d3924 2
a3925 2
        MOV     R11,R1                           ;R11 := low address (inclusive)
        ADD     R12,R2,#4                        ;R12 := high address (exclusive)
d3928 1
a3928 1
        BHS     %FT01                            ;do full IMB
d3933 1
a3933 1
        MOV     R0,R0                            ;NOPs to ensure 4 instructions after IC flush before return
d3940 1
a3940 1
        TEQP    R12,#0                           ;disable IRQs to mess with ARMA_Cleaner_status
d3942 9
a3950 10
        LDR     R11,[R12,#ARMA_Cleaner_status]
        TST     R11,#ACS_SynchCAsemaphore        ;guard against reentrancy
        BEQ     %FT02                            ;carry on if not reentered
        TEQP    R10,#0                           ;restore IRQ state and...
        B       SLVK                             ;semaphore set, avoid reentrancy, let first call do it
02
        ORR     R11,R11,#ACS_NSCsemaphore:OR:ACS_SynchCAsemaphore
        STR     R11,[R12,#ARMA_Cleaner_status]
        TEQP    R10,#0                           ;restore IRQ state
        LDR     R11,[R12,#ARMA_Cleaner_flipflop]
d3952 2
a3953 2
        STR     R11,[R12,#ARMA_Cleaner_flipflop] ;next cleaner area
        ARMA_clean_DC R11,R12,R10                ;fully clean/flush DC wrt non-interrupt stuff
d3955 4
a3958 15
        ARMA_flush_IC WithoutNOPs                ;do *not* flush DC - may be stuff from interrupt routines
        MOV     R10,PC                           ;even if paranoid, at least 4 instructions follow IC flush before return
        ORR     R12,R10,#I_bit
        TEQP    R12,#0                           ;disable IRQs to mess with ARMA_Cleaner_status and MMUdomain
        MOV     R12,#0                           ;now clear NSC and SynchCA semaphores, and VSC countdown
        LDR     R11,[R12,#ARMA_Cleaner_status]
        BIC     R11,R11,#ACS_NSCsemaphore:OR:ACS_SynchCAsemaphore:OR:ACS_VSCcountdown_MASK
        STR     R11,[R12,#ARMA_Cleaner_status]
  [ ChocolateScreen
        TST     R11,#ACS_SCdisable:OR:ACS_SCsuspend
        ARMA_read_MMUdomain R11,EQ
        BICEQ   R11,R11,#&C
        ARMA_write_MMUdomain R11,EQ              ;if SC not disabled or suspended, reset screen (domain 1) to fault
  ]
        TEQP    R10,#0                           ;restore IRQ state
a4023 1
;'uncommon' case, regarded as not needing to update ARMA_Cleaner_status
@


4.3.2.2
log
@ 1 Simplify source by removing various long-standing compile flags
   and pre-Medusa h/w support

 2 Fix bug with Pages_Unsafe/Pages_Safe page moving for StrongARM
   (interrupt hole) - also better performance for StrongARM

 3 Improve perfromance of physical memory clear for StrongARM
   (make sure it uses burst write for STM)

 4 Suspend Chocolate task switching for StrongARM if SALDMIBbroken
   is TRUE
@
text
@d20 4
d135 4
d141 1
d146 4
d152 1
d273 44
d534 18
d563 1
d593 4
d707 5
d751 3
a753 8
;            and cacheable if StrongARM. This is a big speed benefit for StrongARM (which won't burst
;            write in non bufferable+cacheable areas). There is no cache coherency issue after this,
;            since we only do writes to this space and StrongARM does not allocate cache lines on write
;
        ARM_read_ID r0
        AND     r0, r0, #&F000
        CMP     r0, #&A000
        BNE     %FT06
d762 3
a764 2
        BIC     r1,r1,#3                                ; in case address picked up was not 1Mb aligned

d767 1
a767 1
        ORR     r2,r2,#&C                               ; set cacheable and bufferable bits
d773 1
a773 2
        ARMA_flush_DTLB                                 ; make sure we benefit from the mapping change
06
d829 3
a831 7
;StrongARM - now let us remove bufferable and cacheable status of logical representation of physical space,
;            if running on StrongARM
;
        ARM_read_ID r0
        AND     r0, r0, #&F000
        CMP     r0, #&A000
        BNE     %FT36
d840 3
a842 2
        BIC     r1,r1,#3                                ; in case address picked up was not 1Mb aligned

d845 1
a845 1
        BIC     r2,r2,#&C                               ; clear cacheable and bufferable bits
a850 2
        ARMA_flush_DTLB
36
d903 3
d921 1
a921 1
;       InitMEMC - Initialise memory controller - now for IOMD only
d930 1
d936 2
d1128 74
d1203 20
a1222 1
        MOV     r0, #&12                                        ; 5-3 cycle ROM access
d1226 4
a1230 1

d1250 4
d1258 4
d1268 14
d1285 1
d1287 3
d1337 1
d1339 3
d1446 7
d1539 1
a1539 1

d1558 40
d1623 4
a1626 1

d1630 4
a1633 1

d1636 5
d1642 3
d1872 3
d1879 5
a1883 1

d1890 83
d2068 1
a2068 1

d2074 1
d2243 3
a2245 1

d2248 6
d2343 3
a2461 4
;
; TimeCPU - only for IOMD, no longer tries to do any auto timing (problems with
;           StrongARM at least)
;
d2464 1
d2466 1
a2466 1
; Out
d2471 1
d2473 1
a2473 5
  [ RO371Timings
;
;assumes timings (and EDO for 7500FE) according to IOMD id, sets up ROM timings etc. as side effect
;
TimeCPU ROUT 
d2512 3
a2514 17
  | ; else if not RO371Timings
;
;simple 16 MHz nominal value (as on original Risc PC) returned
;
TimeCPU
        LDR     r7, =(1 :SHL: 16) :OR: 16000    ; indicate 16MHz RAM
        MOV     pc, lr

  ] ;RO371Timings conditional


  [ RO371Timings
;
;
; finalmemoryspeed 
;
;used by NewReset, after main kernel boot, sets full 64MHz memory if on 7500FE, preserves registers _and_ flags
d2532 159
a2692 1

d2765 1
d2767 1
d2807 12
d2820 1
d2859 12
d2872 1
d3345 22
a3366 2
;assume ARM 6 configured for LateAbort - others cannot be configured
;so, at run time, ARM 6 or 7 means late, ARM 8 or StrongARM means early
d3399 5
d3531 1
d3534 1
d3632 4
d3641 1
d3643 3
d3699 11
a3940 1

d4042 14
d4064 1
@


4.3.2.3
log
@1) Fixes and tidy ups:
   - mapping of Cur/Sys/Sound area done more elegantly, and soft CAM info
     is now consistent with it
   - cached screen cleaning on VSync performed *after* VSync events
   - comments at top of ARM600 modernised
   - Pages_Unsafe/Safe code fixed to work properly on StrongARM with
     pages that are involved in interrupts (there is no fix for ARM8,
     since that is unlikely to be needed - an ASSERT checks use of ARM8
   - OS_DynamicArea code souped up, to be much more efficient for large
     numbers of dynamic areas (see comments near top of ChangeDyn)
   - cached screen is now suspended on h/w scroll (avoids possible cache
     incoherency)
2) API changes:
   - new OS_Memory reason code (10) allows Wimp to inform kernel of
     Wimp_ClaimFreeMemory, and can control VRAM rescue (see below)
   - new OS_ReadSysInfo reason code (6) allows reading of kernel values
     (reserved for Acorn use, eg. for SoftLoad, ROMPatch)
   - new OS_DynamicArea reason codes (6 and 7) allow for more efficient
     monitoring of dynamic areas by TaskManager (reserved for Acorn use)
3) Changes for Phoebe:
   - kernel runs a VRAM rescue process, which ensures that any VRAM not
     used for the screen is reclaimed if necessary and sinks to the bottom
     of the Free Pool. This is important for Phoebe, where VRAM is slower
     than SDRAM, but does no harm on other platforms.
   - logical copy of physical RAM is removed from memory map. This frees
     up 256M of address space that will later be used for PCI on Phoebe,
     but should do no harm on other platforms (this space is marked
     private in PRMs, so 3rd parties should not use it).
@
text
@d33 8
a40 13
; * Level 2 page tables for a logical area starting at zero. This consists of:
;       a) a fixed size bit covering 0 to 96M
;       b) a variable size bit covering the free pool - 96M to 96M + (memsize rounded up to 4M)
;     - Note that the 96M value is sufficient to cover all the fixed size areas (including screen).
;     - Free pool must always start at the end of the fixed areas.
;     - Level 2 for areas outside this region are allocated dynamically afterwards (eg. to support
;       dynamic areas).
;     - Level 2 is always 'monotonic' for RAM mappings - ie. the logical address of the L2 entry
;       for an address (*if* it is validly L2 mapped) can be calculated directly as an offset from
;       the L2PT base. Non-RAM addresses will normally be Level 1 mapped (I/O, ROM). A patched
;       ROM will cause Level 2 mapping of ROM that is *not* in the monotonic area.
;     - The monotonic Level 2 is not always contiguous. Most/all of the areas a) and b) will be, except
;       that some Level 2 pages may be rescued after initial boot (see L1L2PTenhancements routine). 
d52 1
a52 1
; (Note: when OS is soft-loaded, an ROM-sized chunk of DRAM is removed from the RAM map, therefore the model allows for
d101 1
a101 10

; logical base address of map of IOMD physical space, excluding RAM
;
; after kernel boot, this mapping covers IOMD physical space 0..256M, but is set to fault
; for 32M..48M - hence VRAM and DRAM are not accessible through this physical copy
;
; during kernel boot, the ClearPhysRAM routine uses a temporary mapping of RAM here (hence
; mapping is temporarily extended to 0..512M)
;
PhysSpace               *       &80000000
a400 2
        ASSERT  DuffEntry :AND: &0FFFF000 = DuffEntry
;
a401 4
        MOV     r4,#DuffEntry:AND:&0FF00000
        ORR     r4,r4,#DuffEntry:AND:&000FF000  ; logical address of Nowhere
        TEQ     r3,r4
        MOVEQ   pc,lr                           ; never need to (nor should) MMU map a page moved to Nowhere
a646 3
; This routine assumes that there is to be no mapping of VRAM or DRAM in the PhysSpace
; area after boot, but that it can create such a mapping temporarily

a659 13

    ASSERT MEMC_Type = "IOMD"
;
CPRTempMappingBase * PhysSpace   ;base address for temporary logical mapping of physical RAM
;
CPRTable
        DCD     &02000000        ;VRAM physical start
        DCD     &01000000        ;VRAM physical size (16M)
        DCD     &10000000        ;DRAM physical start
        DCD     &10000000        ;DRAM physical size (256M)
        DCD     0                ;terminator
        DCD     0                ;terminator

d664 4
a667 7
; When creating the temporary mapping for physical RAM, we make it bufferable and cacheable. This is
; a big speed benefit for StrongARM (which won't burst write in non bufferable+cacheable areas). There
; is no cache coherency issue after this, since we only do writes to this space and ARMs do not allocate
; cache lines on write.
;

;make temporary logical mapping for all physical RAM areas
d669 4
d674 2
a675 1
        ADR     r12, CPRTable
d677 6
a682 8
        LDMIA   r12!, {r10, r11}                        ; load next physical address, size (1Mb aligned)
        CMP     r10, #0
        BEQ     %FT06

        ORR     r4, r10, #CPRTempMappingBase            ; logical address for temporary mapping
        ADD     r1, r0, r4, LSR #(20-2)                 ; L1PT address for same
        ORR     r4, r10, #&410
        ORR     r4, r4, #&00E                           ; L1PT value - section mapped, svc access, C=1, B=1
d684 8
a691 7
        STR     r4,[r1],#4                              ; update L1PT
        ADD     r4, r4, #&100000
        SUBS    r11, r11, #&100000                      ; another 1 Mb done
        BNE     %BT04
        B       %BT02                                   ; next physical RAM area
        ARM_flush_TLB r11                               ; mapping change

d714 1
a714 1
        ORR     r10, r10, #CPRTempMappingBase           ; point to temporary RAM mapping
d748 2
a749 1
;remove temporary mapping of physical RAM
d751 4
d756 2
a757 1
        ADR     r12, CPRTable
d759 6
a764 7
        LDMIA   r12!, {r10, r11}                        ; load next address, size (1Mb aligned)
        CMP     r10, #0
        BEQ     %FT36

        ORR     r4, r10, #CPRTempMappingBase            ; logical address for temporary mapping
        ADD     r1, r0, r4, LSR #(20-2)                 ; L1PT address for same
        MOV     r4, #0                                  ; L1PT value - fault
d766 8
a773 6
        STR     r4,[r1],#4                              ; update L1PT
        SUBS    r11, r11, #&100000                      ; another 1 Mb done
        BNE     %BT34
        B       %BT32                                   ; next physical RAM area
        ARM_flush_TLB r11                               ; mapping change

d844 6
a849 2
; in:   r1 = 0 if reset, 1 if break
;
d1099 5
a1103 11
;
; mjs 02 Oct 97 - modernised code here, provoked by desire to remove reliance on PhysSpace copy of RAM:
;
; We only map in the 1st Mb of ROM at its own physical address - ie. we are assuming kernel reset
; stuff all fits in 1st Mb (reasonable since whole kernel is much less than 1 Mb).
; Now, this involves the mapping of 1M at either logical address 0 (the physical address of hard ROM)
; or at logical address somewhere within &10000000 to &20000000 (the physical address of softloaded
; ROM somewhere in DRAM). We can do this without stuffing things because interrupts are off, so
; the only old mapping that might be relevant is the L1PT itself (no clash with these addresses),
; and soon we are going to completely recast things as part of reset.
;
d1105 5
a1109 1
        LDR     r0,=L1PT
d1111 1
a1111 1
        MOV     r1, r1, LSR #20                 ; r1 := physical address of ROM >> 20
d1114 4
a1117 2
        ORR     r2, r2, r1, LSL #20             ; munge in physical address
        STR     r2, [r0, r1, LSL #2]            ; store flat mapping in L1PT for physical address of 1st Mbyte of ROM
d1122 2
a1123 2
        SUB     r0, r0, #ROM                    ; form physical minus logical offset
        ADD     pc, pc, r0                      ; jump to ourselves at equivalent physical address (having flat mapped)
d1126 1
a1126 2
; we're now in flat map physical equivalent, so it's safe to turn the MMU off, 
; but leave us in 32-bit config (and 32-bit mode)
d1841 1
a1841 1
        LDR     r3, =L1PT                       ; when we put L1 entry back later, we will want to use logical address
d1849 6
d1862 1
a1862 1
; now we can jump into the logical ROM space
d1911 1
a1911 1
PSS     *       PhysSpaceSize_Full  :SHR: 20  ; Number of megabytes in full IOMD physical space
d1975 1
a1975 3
        ; map of IOMD physical space, including RAM (need for POST) - RAM part will be reset to inaccessible after
        ; ClearPhysRAM (and hence this mapping will be reduced to cover only PhysSpaceSize_NoDRAM by end of boot)
        MemInitSection PSS, 1, 0, 0, PhysSpace, AP_None, &00000000
d1984 1
a1984 7
;3.6 has whole cursor chunk ~C~B which is disaster for SWI dispatcher etc
;3.7 still declares like this but 'fixes' it in the L2PT later (5 pages CB, 3 pages ~CB)
;now we just do what 3.7 did, but do it more elegantly by declaring properly in the table
;note this all assumes 4k pages, but kernel no longer supports pre-Medusa stuff anyway
;
        MemInitPagesL2  &5000, 1, 1, CursorChunkAddress, AP_Read, DRAMOffset_CursorChunk              ;first 5 pages CB (SWI dispatcher etc)
        MemInitPagesL2  &3000, 0, 1, CursorChunkAddress+&5000, AP_Read, DRAMOffset_CursorChunk+&5000  ;next 3 pages ~CB (cursor data)
d3129 2
a3130 6
; lr = L1PT entry
;
; mjs 02 Oct 97: We can no longer use logical copy of physical space (now removed for RAM) to look up L2PT
;                entry. We cannot use trick of assumed monotonic L2PT because this is not true
;                for a patched ROM, for example. Therefore, we have to explicitly find logical
;                address of L2PT entry from physical address.
a3132 18
        MOV     lr, lr, LSR #10
        MOV     lr, lr, LSL #10                         ; physical address of base of page table, from L1PT entry

        Push    "r6,r8"
        MOV     r5, #PhysRamTable                       ; converting physical address to page number...
        MOV     r6, #0                                  ; start at page number 0
checkpage_loop
        LDMIA   r5!, {r7,r8}                            ; start address, size of physical chunk
        SUB     r7, lr, r7                              ; see if we are in this chunk
        CMP     r7, r8
        ADDCS   r6, r6, r8, LSR #SmallPageSizeShift     ; move on to next chunk
        BCS     checkpage_loop
        ADD     r6, r6, r7, LSR #SmallPageSizeShift     ; found page number
        MOV     r5, #0                                  ; converting page number to logical address...
        LDR     r5, [r5, #CamEntriesPointer]
        LDR     lr, [r5, r6, LSL #3]                    ; found logical address
        Pull    "r6,r8"

d3137 3
d3141 1
d3260 21
d3448 2
d3452 23
d3477 2
a3478 2
;
;some service routines here for easy patchability
d3504 1
@


4.3.2.4
log
@Various speed ups
Memory map changes:
remove shadow ROM
move UNDEF stack, SoftCAM and MMU tables above 64M
expand RMA limit to 15M from 11M
expand SysHeap limit to 3M-32k from 2M-8k
expand SVC stack to 32k from 8k
partially protect kernel workspace from user access
protect SVC stack from user access
@
text
@a82 2
SysHeapPlusSVCStackSize * 64*1024

d84 4
a87 4
DRAMOffset_CursorChunk  #       32*1024                   ; ie on MEMC1 this is the last 32K of DAG-addressable memory
DRAMOffset_PageZero     #       32*1024                   ; 32K at location zero
DRAMOffset_SystemHeap   #       SysHeapPlusSVCStackSize   ; system heap/svc stack (changed for Ursula, was 32*1024)
DRAMOffset_L2PT         #       0                         ; static L2PT (variable size, with embedded L1PT)
d97 2
a98 2
L2PT                    *       &08000000       ; L1PT and L2PT moved for Ursula (were &02C00000 &02C0C000)
L1PT                    *       &0800C000       ; in the middle of L2PT, where the mapping for 03000000 to 03FFFFFF would be
d100 1
a100 4
FixedAreasL2Size        *       136*1024        ; amount of L2 to cover fixed areas, excluding free pool
                                                ; Changed for Ursula (was 96k, extra 32k for bigger fixed heap/svc stack allocation,
                                                ; extra 4k for moved 4M of L2PT+L1PT tables, another extra 4k for moved 1M of
                                                ; SoftCAM+UNDSTK plus 3M reserved)
d102 2
a103 2
UndStackSoftCamChunk    *       &08400000       ; Changed for Ursula (was &01E00000)
UndStackSize            *       &2000           ; 8k
d105 1
a105 1
UNDSTK                  *       CamEntriesForVicky ; points to end of stack (no 26-bit code allowed in UNDSTK since Ursula!)
d680 2
a681 2
                    GBLL PartialClearBigRAM ;if true, save time by clearing only some RAM
PartialClearBigRAM  SETL {TRUE}
a682 4
  [ PartialClearBigRAM
ClearMaxSizeLo * &200000   ;max of 2 Mb cleared at bottom of DRAM
ClearMaxSizeHi * &200000   ;max of 2 Mb cleared at top of DRAM
  ]
d729 8
a743 16
  [ PartialClearBigRAM
        MOV     r5, #48                                 ; 32 bytes of workspace at address 32 ...
        STMIA   r5, {r7, r8}                            ; ... currently, we just preserve r7,r8 at address 48
        MOV     r7, #ClearMaxSizeLo
        MOV     r8, #ClearMaxSizeHi
        LDR     r5, [r12, #20]                          ; fetch size of 2nd DRAM chunk
        CMP     r5, #0
        BNE     %FT08                                   ; if there are at least 2 DRAM chunks, use ClearMaxSize Lo,Hi normally
        LDR     r5, [r12, #12]                          ; only 1 DRAM chunk, check its size
        CMP     r5, #ClearMaxSizeLo+ClearMaxSizeHi
        MOVLS   r7, r5                                  ; if size <= Lo+Hi, then clear all of DRAM as normal
        MOVLS   r8, #0
08
        LDR     r5, [r12,#4]                            ; size of video chunk, plus ...
        ADD     r7, r7, r5                              ; ... amount to clear at bottom of DRAM
  ]
a747 5
  [ PartialClearBigRAM
        CMP     r11, r7
        MOVHI   r11, r7                                 ; don't clear beyond max limit at bottom of DRAM
        SUB     r7, r7, r11                             ; remainder of max limit
  ]
d757 3
d761 1
a771 4
  [ PartialClearBigRAM
        TEQ     r7, #0                                  ; have we exhausted max limit of bottom clear?
        TEQNE   r12, r4                                 ; or, have we done all areas?
  |
a772 1
  ]
d775 1
a775 22
  [ PartialClearBigRAM
        TEQ     r8, #0                                  ; do we have to clear top of last chunk?
        BEQ     CPR_lastch_done
        LDR     r12, =PhysRamTable
CPR_lastch_loop1
        LDMIA   r12!, {r10, r11}
        CMP     r11, #0
        BNE     CPR_lastch_loop1
        SUB     r12, r12, #4*4
        LDMIA   r12!, {r10, r11}                        ; address, size of last DRAM chunk
        CMP     r11, r8
        SUBHI   r11, r11, r8
        ADDHI   r10, r10, r11
        MOVHI   r11, r8
        ORR     r10, r10, #CPRTempMappingBase           ; point to temporary RAM mapping
        ADD     r11, r11, r10                           ; r11 -> end address of this area
CPR_lastch_loop2
        TEQ     r10, r11
        BEQ     CPR_lastch_done
        STMIA   r10!, {r0-r3}
        B       CPR_lastch_loop2
CPR_lastch_done
d777 2
a778 2
        LDMIA   r12, {r7, r8}                           ;restore r7, r8
        MOV     r12,#32                                 ;clear our workspace (32 bytes, at address 32)
d855 1
a855 1
 [ PartialClearBigRAM ; allow some workspace to speed up ClearPhysRAM  Mike says whoosh
d1061 1
a1061 1
   [ Japanese16BitSound
d1994 2
a1995 5
        ; mjs behaviour change for Ursula:
        ; map of IOMD physical space, including RAM as before (need for POST), but RAM part will be now be reset
        ; to inaccessible after ClearPhysRAM (and hence this mapping will be reduced to cover only
        ; PhysSpaceSize_NoDRAM by end of boot)
        ;
d1998 4
a2001 3
        ; mjs change for Ursula:
        ; used to be mapping here for shadow ROM in top 8M of address space - this is vestigial, and can
        ; be removed (exception vectors no longer use Branches that would have 26/32 bit wrap problems).
d2005 5
a2009 6
        ; mjs change for Ursula:
        ;3.6 has whole cursor chunk ~C~B which is disaster for SWI dispatcher etc
        ;3.7 still declares like this but 'fixes' it in the L2PT later (5 pages CB, 3 pages ~CB)
        ;now we just do what 3.7 did, but do it more elegantly by declaring properly in the table (means soft CAM is correct)
        ;note this all assumes 4k pages, but kernel no longer supports pre-Medusa stuff anyway
        ;
d2012 2
a2013 12

        ; mjs changes for Ursula:
        ; let us have a bigger SVC stack, and a semblance of security
        ; SVC stack is now 32k, and AP_Read (svc=r/w,usr=r/-) rather than 8k and AP_Full (svc=r/w,usr=r/w)
        ; sadly, some of kernel workspace needs user access (eg. cointer for Clib tmpnam), but Ursula sets some
        ; higher protection on 1k granularity, using MMU sub-pages (see L1L2PTenhancements)
        ;
        ASSERT SVCStackSize            = 32*1024
        ASSERT SysHeapPlusSVCStackSize = 64*1024
        MemInitPagesL2  &8000, 1, 1, &00000000, AP_Full, DRAMOffset_PageZero                          ;kernel workspace
        MemInitPagesL2  &8000, 1, 1, SysHeapChunkAddress, AP_Read, DRAMOffset_SystemHeap              ;SVC stack (32k)
        MemInitPagesL2  &8000, 1, 1, SysHeapChunkAddress+&8000, AP_Full, DRAMOffset_SystemHeap+&8000  ;SysHeap (initially 32k from remainder of 64k fixed area)
d2447 5
a2451 1
; entered in undef32
d2483 2
a2484 1
; entered in abort32
d2486 2
d2533 5
a2537 1
; entered in abort32
d3167 1
a3167 2
        Push    "r6,r8,r9"
        BIC     r9, lr, #&C00                           ; physical page address from L1PT
d3172 1
a3172 1
        SUB     r7, r9, r7                              ; see if we are in this chunk
d3179 2
a3180 4
        LDR     r9, [r5, r6, LSL #3]                    ; logical page address
        AND     lr, lr, #&C00
        ADD     lr, lr, r9                              ; full logical L2PT base address from L1PT
        Pull    "r6,r8,r9"
a3270 18

        ;mjs change for Ursula:
        ;improved kernel workspace protection
        ; - user access to bottom 3k restricted to read only (things like Clib tmpnam counter prevent
        ;   going further)
        ; - Java VM will probably require bottom 1k restricted to no user access (so that VM can avoid
        ;   all run-time checks for null pointers), but this currently makes various things like ShareFS
        ;   go pop-bang, so not done yet (see TRUE/FALSE choice below)
        ;
        MOV     r0,#L2PT                ;L2PT address for page at 0
        LDR     r1,[r0]
        BIC     r1,r1,#&FF0             ;clear current AP bits for all four 1k sub-pages (S0 to S3)
     [ {FALSE}                          ;this would be good for Java VM:
        ORR     r1,r1,#&E90             ;S0=user none, S1=user read, S2=user read, S3=user read/write
     |                                  ;this makes less current things go pop-bang:
        ORR     r1,r1,#&EA0             ;S0=user read, S1=user read, S2=user read, S3=user read/write
     ]
        STR     r1,[r0]
@


4.3.2.5
log
@added support for Sparse dynamic areas
fixed performance disaster caused by naff API for Shrinkable areas
implemented clamps for dynamic areas max size
configured kernel to not own or create RAMFS area (needs new RAMFS)
AMBControl now uses system heap for space, not RMA
AMBControl enables Lazy task swapping if running on rev T or better SA
kernel now assumes there could be code above 64M
SWIS for limited 32 bit user code support implemented
Long command lines implemented (1k instead of 256)
Fast service call distribution implemented (uses Ursula module format)
*fx,*key etc now allow missing space before first parameter
*configure is reinstated (bug fix)
@
text
@d34 3
a36 3
;       a) a fixed size bit covering 0 to 136M
;       b) a variable size bit covering the free pool - 136M to 136M + (memsize rounded up to 4M)
;     - Note that the 136M value is sufficient to cover all the fixed size areas (including screen).
d133 2
a134 2
;;;arm600stuff_before_align
;;;         ALIGN   4096     ;align to page boundary to allow for easy ROMpatch
d136 2
a137 2
;;;arm600stuff_startofstuff
;;;  ! 0, "-- start of (4k aligned) ARM600+ stuff at ":CC::STR:(arm600stuff_startofstuff)
d380 1
a380 2
AssumeNoCodeAbove64Mb  SETL    {FALSE}   ;cannot set this TRUE for Ursula (32-bit code
                                         ;allowed in dynamic areas)
a2555 5

        LDR     r2, =Abort32_dumparea
        STMIA   r2, {r1,lr_abort}                       ;dump 32-bit PSR, fault address (PC)
        STR     lr_abort,[r2,#2*4]                      ;dump 32-bit PC

a2623 4
        LDR     r4, =Abort32_dumparea+3*4       ;use temp area (avoid overwriting main area for expected aborts)
        ARM_read_FAR r3
        STMIA   r4, {r0,r3,lr_abort}            ; dump 32-bit PSR, fault address, 32-bit PC

a3017 10
; copy temp area to real area (we believe this is an unexpected data abort now)

        LDR     r0, =Abort32_dumparea
        LDR     r1, [r0,#3*4]
        STR     r1, [r0]
        LDR     r1, [r0,#4*4]
        STR     r1, [r0,#4]
        LDR     r1, [r0,#5*4]
        STR     r1, [r0,#2*4]

d3579 4
a3582 4
;;;        DCB     "GROT"                  ;spare words marker
;;;        ALIGN   4096                    ;align to page boundary for easy ROMpatch
;;;arm600stuff_endofstuff
;;; ! 0,"-- size of ARM600+ stuff (4k aligned) is ":CC::STR:(arm600stuff_endofstuff - arm600stuff_startofstuff)
@


4.3.2.5.2.1
log
@Changed compile switches, to build Ursula kernel for RPC and A7000(+),
switches now set as follows:
  ARM67Support      TRUE  (for 610,710,7500,7500FE)
  ARMSASupport      TRUE  (for StrongARM)
  ARMSASupport_RevS FALSE (for StrongARMs before rev S)
  IOMD1Support      TRUE  (for old machines)
  IOMD2Support      FALSE (They killed Phoebe!)
Version set to 4.00 (RISC OS 4)
This is the same as my last commit to the Ursula branch
@
text
@a29 1
;25-05-98 MJS  a bit of a clean up for RISC OS 4 (Ursula/Phoebe), ARM810 support removed as part of this
d117 2
a118 1
; during kernel boot, the ClearPhysRAM routine uses a temporary mapping of RAM here
a122 6
; PCI space is 256M, PCI config space is 1M
;
PCISpace                *       &90000000
PCIConfig               *       &a0000000


a141 1
  [ :LNOT: KeepCachesOff
d159 2
a160 3
  |
ARM_default_MMU_CR_table   ;same as cacheoff then
  ]
d183 1
d212 1
d217 1
d259 1
d264 1
a272 1
  [ :LNOT: PhoebeBodge_Bernard
a274 1
  ]
d277 3
d434 17
d452 1
a452 1
  [ :LNOT: ARMSASupport_Only
a458 1
  [ :LNOT: ARMSASupport_Only
d461 6
a472 1
  [ ARMSASupport
d475 1
a475 1
    [ AssumeNoCodeAbove64Mb
d478 1
a478 1
    ]
a479 1
  ]
a482 1
  [ :LNOT: ARMSASupport_Only
d485 5
d495 1
a495 1
  ]
a496 1
  [ ARMSASupport
d516 1
a516 1
    [ AssumeNoCodeAbove64Mb
d519 1
a519 1
    ]
a523 1
  ] ;ARMSASupport
d527 14
a551 1
  [ :LNOT: ARMSASupport_Only
d556 5
a565 1
  ]
a566 1
  [ ARMSASupport
a584 1
  ] ;ARMSASupport
a587 1
  [ ARMSASupport
a589 1
  ]
d636 1
d643 1
a643 11

70
        LDRB    r10,[r12,#IOMD_ID0]
        TEQ     r10,#IOMD_IOMD2    :AND: &FF
        ORREQ   r11,r11,#&80                                    ;bit 7 means use async SAM clock on Phoebe
        BEQ     %FT90
        TEQ     r10,#IOMD_Original :AND: &FF
        TEQNE   r10,#IOMD_7500     :AND: &FF
        TEQNE   r10,#IOMD_7500FE   :AND: &FF
        BNE     %BT70                                           ;deliberate panic hang up

d648 1
a648 1
90
d651 2
a658 86
;       SoftCopyROM
;
; automagically softload ROM into reserved space, if required
;
; in:  -
; out: corrupts r0-r4, r10-r12
;

SCRTempMappingBase * PhysSpace + DRAM0PhysRam   ;handy base address for temporary logical mapping

SoftCopyROM ROUT

        MOV     r0, #0
        LDR     r10, [r0, #SoftROMaddr]         ;physical address of reserved space
        TEQ     r10, #0
        MOVEQ   PC, LR                          ;no soft copy required if 0

;map in the RAM temporarily for copy
;
        MOV     r11, #OSROM_ImageSize*1024
        LDR     r0,  =L1PT
        MOV     r4, #SCRTempMappingBase         ; logical address for temporary mapping
        ADD     r1, r0, r4, LSR #(20-2)         ; L1PT address for same
        ORR     r4, r10, #&410
        ORR     r4, r4, #&00E                   ; L1PT value - section mapped, svc access, C=1, B=1
                                                ; no cache coherency worries - we just write to this space
10
        STR     r4, [r1], #4                    ; update L1PT
        ADD     r4, r4, #&100000
        SUBS    r11, r11, #&100000              ; another 1 Mb done
        BNE     %BT10
        ARM_flush_TLB r11                       ; mapping change

;copy the ROM into RAM
;
        MOV     r4, #ROM                        ; source
        MOV     r11, #SCRTempMappingBase        ; dest
        ADD     r12, r11, #OSROM_ImageSize*1024 ; size
20
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        TEQ     r11, r12
        BNE     %BT20

;remove temporary mapping of physical RAM
;
        MOV     r11, #OSROM_ImageSize*1024
        LDR     r0,  =L1PT
        MOV     r4, #SCRTempMappingBase         ; logical address for temporary mapping
        ADD     r1, r0, r4, LSR #(20-2)         ; L1PT address for same
        MOV     r4, #0                          ; L1PT value - fault
30
        STR     r4, [r1], #4                    ; update L1PT
        SUBS    r11, r11, #&100000              ; another 1 Mb done
        BNE     %BT30

;remap ROM logical space to soft loaded ROM (we can do this live, because it is identical)
;

        MOV     r11, #OSROM_ImageSize*1024
        LDR     r0,  =L1PT
        MOV     r4, #ROM                        ; logical address of ROM
        ADD     r1, r0, r4, LSR #(20-2)         ; L1PT address for same

40
        LDR     r4, [r1]                        ; read L1PT entry
        MOV     r4, r4, LSL #20
        MOV     r4, r4, LSR #20                 ; zap old physical address
        ORR     r4, r4, r10                     ; munge in new physical address
        STR     r4, [r1], #4                    ; update L1PT entry
        ADD     r10, r10, #&100000
        SUBS    r11, r11, #&100000              ; another 1 Mb done
        BNE     %BT40

        ARM_flush_TLB r11                       ; mapping change

        MOV     PC, LR

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
d694 1
d699 1
a699 1
        DCD     VideoPhysRam     ;VRAM physical start
d701 2
a702 2
        DCD     DRAM0PhysRam     ;DRAM physical start
        DCD     &20000000        ;DRAM physical size (512M is size for IOMD2, also takes care of 256M IOMD1)
d925 1
d931 1
a931 1
;
d934 10
a943 20
;decision point based on IOMD variant
;checks variants exhaustively, and deliberately hangs up for unknown/unsupported
;
10
        LDRB    r0, [r12,#IOMD_ID0]
  [ IOMD2Support
        TEQ     r0, #IOMD_IOMD2    :AND: &FF
        BEQ     PhoebeInit                            ; IOMD2 (Phoebe)
  ]
  [ IOMD1Support
        TEQ     r0, #IOMD_Original :AND: &FF
        BEQ     MedusaInit                            ; IOMD1 (Risc PC)
        TEQ     r0, #IOMD_7500     :AND: &FF
        BEQ     init7500cpu                           ; 7500 (A7000)
        TEQ     r0, #IOMD_7500FE   :AND: &FF
        BEQ     init7500FEcpu                         ; 7500FE (A7000+)
  ]
        B       %BT10                                 ; deliberate panic hang-up (unrecognised IOMD)

  [ IOMD2Support
a944 41
PhoebeInit
;
 [ PhoebeBodge
   ;still some values to sort out for 64 MHz ASIC
 ]
        MOV     r0,#12
        STR     r0,[r12,#IOMD_ROMCR0]                 ;ROM timings, bank 0
        STR     r0,[r12,#IOMD_ROMCR1]                 ;ROM timings, bank 1
        MOV     r0,#&5c
        STR     r0,[r12,#IOMD_VREFCR]                 ;vram control, refresh
        STR     r0,[r12,#IOMD2_PRECHG]                ;trigger SDRAM precharge
        MOV     r0,#&0a
        STR     r0,[r12,#IOMD2_SDTMG]                 ;SDRAM timing control
        MOV     r0,#&20
        STR     r0,[r12,#IOMD2_SDMODE]                ;SDRAM mode
        MOV     r0,#2
        STR     r0,[r12,#IOMD2_SCDIV]                 ;SC clock division to MCLK/2
        MOV     r0,#&04
        STR     r0,[r12,#IOMD2_VRAMTMG]               ;vram timing
        MOV     r0,#&85
        STR     r0,[r12,#IOMD2_BMSPD]                 ;bus master speed

        MOV     r0,#&5000
        STR     r0,[r12,#IOMD2_INTRTEB]               ;make sure floppy request is routed to (cpu 0) FIQ

        MOV     r0,#&2000000                          ;just in case, init video DMA
        ORR     r0,r0,#&60
        STR     r0,[r12,#IOMD_CURSINIT]
        MOV     r0,#&2000000
        STR     r0,[r12,#IOMD_CURSCUR]

        MOV     r0, #&0002
        ORR     r0, r0, #&2a00
        STR     r0, [r12, #IOMD_IOTCR]
        MOV     r0, #0                          ; Podule manager wants TypeA setting by default for all podules
        STRB    r0, [r12, #IOMD_ECTCR]
        B       CommonInit

  ] ;IOMD2Support

  [ IOMD1Support
d947 8
d956 5
a960 1
;       CPUCLK divide by 1, MEMCLK divide by 2, IOCLK  divide by 2
d962 3
a964 2
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkHalf + IOMD_CLKCTL_IOclkHalf
        STRB    r0, [r12, #IOMD_CLKCTL]
d968 9
d979 1
d981 29
a1009 1
        STRB    r0, [r12, #IOMD_ROMCR0]
d1011 5
a1015 1
;
d1017 1
a1017 1
;
d1020 1
d1025 6
a1030 2
;
;       CPUCLK divide by 1, MEMCLK divide by 1, IOCLK  divide by 1
d1033 1
a1033 1
        STRB    r0, [r12, #IOMD_CLKCTL]
d1037 9
d1047 2
a1048 1
        AND     r0, r0, #&40                     ; clear all but the 16-bit mode flag
d1050 29
a1078 1
        STRB    r0, [r12, #IOMD_ROMCR0]
d1080 5
a1084 1
;
d1086 1
a1086 1
;
d1089 2
d1113 3
a1115 1
;
d1117 3
d1121 3
d1125 7
a1131 1

a1140 2
  ] ;IOMD1Support

d1269 1
d1273 1
d1278 1
a1278 32
;signal cyan on screen (if kernel panics with bad DRAM, screen should remain cyan)
;
        LDR     R0, =&40000000+&FFFF00 ;border colour to cyan
        LDR     R2, =VIDCPhys
        STR     R0, [R2]

; StrongARM - turn on I cache (allowed with MMU off), and fast core clock now - this avoids dreadful
;             performance, and is ok until MMU etc comes on (near CritStart)
;
  [ :LNOT: ARMSASupport_Only
        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&A000
        BNE     MemSize_notSA
  ]
  [ ARMSASupport
    [ :LNOT: KeepCachesOff
        ARM_read_control r2
        ORR     r2,r2,#&1000     ;I cache bit is bit 12
        ARM_write_control r2
    ]
    [ PhoebeBodge
        ;current SA120 sample(s) fall over with fast core clock
        ARM_read_ID r2
        AND     r2,r2,#&F
        CMP     r2,#SA120minimumrev
        ARMA_fastcoreclock LO
    |
        ARMA_fastcoreclock
    ]
  ] ;ARMSASupport
MemSize_notSA
a1280 16
;
10
        LDRB    r0, [r12, #IOMD_ID0]
  [ IOMD2Support
        TEQ     r0, #IOMD_IOMD2    :AND: &FF
        BEQ     MemSizePhoebe                         ; IOMD2 (Phoebe)
  ]
  [ IOMD1Support
        TEQ     r0, #IOMD_Original :AND: &FF
        BEQ     MemSizeIOMD                           ; IOMD1 (Risc PC)
        TEQ     r0, #IOMD_7500     :AND: &FF
        BEQ     MemSizeMorris                         ; 7500 (A7000)
        TEQ     r0, #IOMD_7500FE   :AND: &FF
        BEQ     MemSizeMorris                         ; 7500FE (A7000+)
  ]
        B       %BT10                                 ; deliberate panic hang-up (unrecognised IOMD)
d1282 1
a1282 1
  [ IOMD2Support
d1284 8
a1291 1
MemSizePhoebe
d1293 1
a1293 1
; for VRAM, we currently assume 4M is always there
d1295 2
a1296 10
; for SDRAM, we can cope with organisation of 11..14 rows, 8..11 columns, capacity of 4 to 128M
; in one DIMM, 1 or 2 banks in DIMM (if 2 banks, must be symmetric) (max total of 256M currently
; supported - 512M may be possible but will need looking at when/if suitable DIMMs exist)

; symbols for serial presence detect (SPD) 
; (we assume that Timer0 is already set up and running - needed by SPD routines)
;
  [ PhoebeBodge
SDRAMI2C_addr0       * &a4        ;address for slot 0  (old FPGA PCB)
SDRAMI2C_addr1       * &a2        ;address for slot 1  (old FPGA PCB)
d1298 6
a1303 2
SDRAMI2C_addr0       * &a8        ;address for slot 0
SDRAMI2C_addr1       * &a4        ;address for slot 1
a1304 198
SDRAMI2C_Nrows       * 3          ;byte 3 holds number of rows in SDRAM organisation
SDRAMI2C_Ncolumns    * 4
SDRAMI2C_Nbanks      * 5
SDRAMI2C_bankdensity * 31

;first, determine organisation (rows,columns) of SDRAM in each slot, and program SDRAMCR
;
        MOV     r7,#0                 ;accumulate bits for programming SDRAMCR
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        BVS     %FT10                 ;nothing in slot0
        MOV     r0,#SDRAMI2C_Nrows
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read number of rows for slot0 SDRAM
        SUBS    r0,r0,#11
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0,LSL #2       ;(11..14 rows means 0..3 in RAS0 bits of SDRAMCR)
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_Ncolumns
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read number of columns for slot0 SDRAM
        SUBS    r0,r0,#8
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0              ;(8..11 columns means 0..3 in CAS0 bits of SDRAMCR)
10
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        BVS     %FT20                 ;nothing in slot1
        MOV     r0,#SDRAMI2C_Nrows
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read number of rows for slot1 SDRAM
        SUBS    r0,r0,#11
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0,LSL #6       ;(11..14 rows means 0..3 in RAS1 bits of SDRAMCR)
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_Ncolumns
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read number of columns for slot1 SDRAM
        SUBS    r0,r0,#8
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0,LSL #4       ;(8..11 columns means 0..3 in CAS1 bits of SDRAMCR)
20
        MOV     r12,#IOMD_Base
        STR     r7,[r12,#IOMD2_SDRAMCR]

;next determine sizes of SDRAM in each slot, and fill in PhysRamTable
;
        MOV     r7,#0                 ;accumulate 4 bytes of info in r7
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        BVS     %FT30                 ;nothing in slot0
        MOV     r0,#SDRAMI2C_Nbanks
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read number of banks for slot0 SDRAM
        ORR     r7,r7,r0
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_bankdensity
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read bank density for slot0 SDRAM
        ORR     r7,r7,r0,LSL #8
30
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        BVS     %FT40                 ;nothing in slot1
        MOV     r0,#SDRAMI2C_Nbanks
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read number of banks for slot1 SDRAM
        ORR     r7,r7,r0,LSL #16
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_bankdensity
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read bank density for slot1 SDRAM
        ORR     r7,r7,r0,LSL #24
40
        TEQ     r7,#0
        BEQ     BadSDRAMPanic         ;no SDRAM!

;note that we can safely use SDRAM now (wait for Precharge has happened, and we have programmed correct rows,columns)

        LDR     r3, =DRAMOffset_PageZero + PhysRamTable
        TST     r7, #&FF
        ADDNE   r3, r3, #DRAM0PhysRam                       ;address of first fragment pair in PhysRamTable (slot 0 present)
        ADDEQ   r3, r3, #DRAM4PhysRam                       ;address of first fragment pair in PhysRamTable (slot 0 absent)
        MOV     r2, r3
        MOV     r1, #&400000       ;always assume 4M VRAM
        MOV     r0, #VideoPhysRam
        STMIA   r3!, {r0,r1}       ;video fragment is 4M VRAM
;
        MOV     r0, #DRAM0PhysRam  ;first fragment address for slot 0
42
        ANDS    r8, r7, #&FF
        BEQ     %FT50              ;nothing in slot
        CMP     r8, #2
        BHI     BadSDRAMPanic
        ADD     r8, r8, r8         ;no. of fragments for slot 0 (2 or 4, for 1 or 2 banks)   
        MOV     r1, r7, LSR #8
        AND     r1, r1, #&FF
        TEQ     r1, #1             ;4M in one or both banks
        TEQNE   r1, #2             ;8M
        TEQNE   r1, #4             ;16M
        TEQNE   r1, #8             ;32M
        TEQNE   r1, #16            ;64M
        TEQNE   r1, #32            ;128M
        BNE     BadSDRAMPanic
        MOV     r1, r1, LSL #21    ;size of each fragment (bank splits into two half-size fragments)
        TEQ     r8, #2
        MOVEQ   r9, #DRAM2PhysRam - DRAM0PhysRam  ;step between fragments if 2 fragments
        MOVNE   r9, #DRAM1PhysRam - DRAM0PhysRam  ;step between fragments if 4 fragments
44
        STMIA   r3!, {r0,r1}       ;next fragment
        ADD     r0, r0, r9
        SUBS    r8, r8, #1
        BNE     %BT44
50
        MOVS    r7, r7, LSR #16    ;move to slot 1, if not already done
        MOV     r0, #DRAM4PhysRam  ;first fragment address for slot 1
        BNE     %BT42

        ASSERT  Phoebe_VRAMsize = &400000
        MOV     r6, #4                                   ; 4M of VRAM
        STR     r6, [r2, #VRAMWidth-PhysRamTable]        ; store width of VRAM (4M)
        MOV     r7, #SAMLength/2/256*2                   ; use VRAM mode, and set increment for 2*1/2 SAM
        LDR     r10, =320000000                          ; 320E6 bytes/sec bandwidth (about right for 50MHz SAM clk ???)
        MOV     r14, #IOMD_Base
        STRB    r7, [r14, #IOMD_VIDCR]
        MOV     r12, #VideoPhysRam
        STR     r12, [r14, #IOMD_VIDCUR]                 ; set up VIDCUR to start of video RAM
        STR     r12, [r14, #IOMD_VIDSTART]               ; do same for VIDSTART
        STR     r12, [r14, #IOMD_VIDINIT]                ; and for VIDINIT
                                                         ; so we don't get a mess when we turn video DMA on later
        STR     r10, [r2, #VideoBandwidth-PhysRamTable]  ; store video bandwidth

        ADD     r10, r12, #1024*1024-4096                ; add on a bit to form VIDEND (will be on mult. of SAM)
        STR     r10, [r14, #IOMD_VIDEND]                 ; yes I know it's a bit of a bodge

        MOV     r14, r6, LSL #20                         ; convert amount of VRAM to bytes
        STR     r14, [r2, #VRAMSize-PhysRamTable]        ; and store

  [ Phoebe_SoftROM
    ;
    ; we want to automagically soft load ROM into RAM if not already done (warm reset), because of the enormous speed
    ; advantage of SDRAM versus ROM

        ADRL    r14, ROM                                 ; use PC-relative addressing to get to start of image
        TEQ     r14, #PhysROM                            ; see if we are currently running from ROM
        BNE     %FT70                                    ; if not, then it's a warm reset and we're already running from RAM

        ADD     r7, r2, #2*4                             ; -> first of SDRAM chunks in PhysRamTable
        MOV     r14, #0                                  ; suitable chunk not found yet
        MOV     r10, #0                                  ; used to sum total SDRAM size

60
        LDMIA   r7!, {r4, r5}                            ; address, size
        ADD     r10, r10, r5                             ; total size so far
        CMP     r5, #OSROM_ImageSize*1024
        MOVHS   r14, r4                                  ; big enough chunk (we know it's 1M aligned), so remember it
        CMP     r7, r3
        BLO     %BT60

        CMP     r10, #OSROM_ImageSize*1024 + &1000000
        MOVLT   r14, #0                                  ; don't soft load if it will leave less than 16M of SDRAM
        TEQ     r14, #0
        BEQ     %FT70
        STR     r14, [r2, #SoftROMaddr-PhysRamTable]     ; if we found a suitable chunk, reserve start of chunk for soft ROM
        MOV     r7, r2                                   ; -> start of PhysRamTable
        MOV     r10, r3                                  ; -> 1st byte after end of table
        B       MemSizeSoftROMreserved

70
  ] ; Phoebe_SoftROM

        MOV     r7, r2                                   ; -> start of PhysRamTable
        MOV     r10, r3                                  ; -> 1st byte after end of table
        B       MemSizeTotalRAM

;
BadSDRAMPanic
        B       BadSDRAMPanic

  ] ;IOMD2Support

  [ IOMD1Support
;
MemSizeMorris
;
        MOV     r11, #&70     ;all 4 banks assumed 32 bit - EDO and timing bits set in case 7500FE (don't care bits otherwise)
d1492 1
a1492 2
;we only need to distinguish Morris variants here
MemSize_whichmorris
d1494 13
a1506 7
        TEQ     r4, #IOMD_7500FE :AND: &FF
        TEQNE   r4, #IOMD_7500   :AND: &FF
        BNE     MemSize_whichmorris                     ; deliberate panic hang up
        TEQ     r4, #IOMD_7500FE :AND: &FF
        LDREQ   r4, =80000000                           ; FE implies EDO, so allow 80E6 bytes/s
        TEQ     r4, #IOMD_7500   :AND: &FF
        LDREQ   r4, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
d1509 2
d1523 1
d1532 29
d1588 1
d1670 2
a1672 11
  ] ;IOMD1Support

;
MemSizeTotalRAM
        MOV     r1, #0
        STR     r1, [r2, #SoftROMaddr-PhysRamTable]     ; no soft ROM chunk reserved for later copy
;
MemSizeSoftROMreserved
;
; Now we have to work out the total RAM size, allowing for any reserved or active soft loaded ROM chunk
;
d1683 2
d1686 6
a1691 5
        LDR     r4, [r2, #SoftROMaddr-PhysRamTable]     ; reserved soft ROM physical address, if any
        TEQ     r4, #0
        ADREQL  r4, ROM                                 ; if none reserved, use PC-relative addressing to get to address of active ROM
        TEQ     r4, #PhysROM                            ; then see if required ROM address is the physical ROM address
        BEQ     %FT55                                   ; if so, then we're OK
d1693 2
a1694 2
        SUB     r1, r1, #OSROM_ImageSize*1024           ; if we've been (or will be) soft-loaded, then we have ?M less than we thought
        ADD     r5, r4, #OSROM_ImageSize*1024           ; point r5 at end of ROM
a1748 1
        ADRL    r4, ROM                                 ; r4 := physical address of active ROM (may be in RAM)
d1913 2
a1914 2
        MOV     r7, #5                          ; allow domain 0 and 1, with client permission checks
        ARM_MMU_domain r7                       ; OS mainly uses domain 0, but ChocolateScreen may use domain 1
a1917 6
;signal green on screen - this is at point where we turn on MMU
;
        LDR     R7, =&40000000+&00FF00 ;border colour to green
        LDR     R2, =VIDCPhys
        STR     R7, [R2]

d1973 3
a1975 3
ROMbit      *       1 :SHL: 12
Vidbit      *       1 :SHL: 13
PSS_NoDRAM  *       PhysSpaceSize_NoDRAM  :SHR: 20  ; Number of megabytes in IOMD physical space (excluding DRAM)
d2015 1
a2015 6
        ;mjs change for Ursula:
        ; - on IOMD1 this will remain as abort (was reserved as VIDC1 emulation zone)
        ; - on IOMD2 this will be set to access devsel 6 (IDE discs)
        ;   (see L1L2PTenhancements)
        MemInitAbort     1,          &03400000                          ; 

d2019 9
d2037 1
d2039 4
a2042 5
        ; mjs change for Ursula:
        ; map of IOMD physical space now excludes DRAM (would be even more profligate on IOMD2)
        ; note that old POST code stuff won't like this - I'm not losing sleep over it
        ;
        ASSERT :LNOT: IncludeTestSrc
d2044 1
a2044 1
        MemInitSection PSS_NoDRAM, 1, 0, 0, PhysSpace, AP_None, &00000000
d2073 1
d2084 1
d2189 1
d2191 1
a2191 1
;assumes timings (and EDO for 7500FE) according to IOMD id, may set up ROM timings etc. as side effect
d2197 8
a2204 13
10
        LDRB    r7, [r2,#IOMD_ID0]
        TEQ     r7, #IOMD_IOMD2    :AND: &FF
        BEQ     timecpuphoebe                         ; IOMD2 (Phoebe)
        TEQ     r7, #IOMD_Original :AND: &FF
        BEQ     timecpuriscpc                         ; IOMD1 (Risc PC)
        TEQ     r7, #IOMD_7500     :AND: &FF
        BEQ     timecpu7500                           ; 7500 (A7000)
        TEQ     r7, #IOMD_7500FE   :AND: &FF
        BEQ     timecpu7500FE                         ; 7500FE (A7000+)
        B       %BT10                                 ; deliberate panic hang-up (unrecognised IOMD)
;
timecpu7500
d2232 6
a2237 2
timecpuphoebe
        LDR     r7, =(1 :SHL: 16) :OR: 64000  ; indicate 64MHz RAM
d2240 1
d2242 2
d2253 4
a2256 5
10
        LDRB    r0, [lr, #IOMD_ID0]
        TEQ     r0, #IOMD_Original :AND: &FF
        TEQNE   r0, #IOMD_7500     :AND: &FF
        TEQNE   r0, #IOMD_IOMD2    :AND: &FF
d2258 5
a2262 7
        TEQ     r0, #IOMD_7500FE   :AND: &FF
        BNE     %BT10                        ;deliberate panic hang up

        MOV     r0, #&80
        STRB    r0, [lr, #&CC]          ; ASTCR register: set i/o asynchronous timing for fast memory clock
        MOV     r0, #&06                ; clock dividers: /1 for CPU, /1 for memory, /2 for I/O
        STRB    r0, [lr, #IOMD_CLKCTL]
d2266 3
d2358 3
d2367 8
d2387 19
a2410 1
  [ ARMSASupport
a2417 12
        ARM_read_ID r0
        AND     r0,r0,#&F
        CMP     r0,#SA120minimumrev
        BLO     %FT14
        ;clean mini data cache too (only used for screen, but we should still avoid losing dirty screen data)
        LDR     r1,=ARMA_ScreenCleaners_address+8*1024  ;use part of area that is not used for screen cleaning
        ADD     r2,r1,#2*1024                           ;2k for 1k mini cache size (we're not doing flipflop)
12
        LDR     r0,[r1],#32
        CMP     r1,r2
        BLO     %BT12
14
a2418 1
  ] ;ARMSASupport
d2434 3
a2446 1
  [ :LNOT: ARMSASupport_Only
a2448 1
  ]
a2451 1
  [ :LNOT: ARMSASupport_Only
d2453 3
d2458 12
a2470 1
  [ ARMSASupport
a2477 15
       ARM_read_ID r2
       AND     r2,r2,#&F
       CMP     r2,#SA120minimumrev
       BLO     MMUC_no_minicache
       ;flush mini data cache too, for completeness
       LDR     r1,=ARMA_ScreenCleaners_address+8*1024  ;use part of area that is not used for screen cleaning
       ADD     r2,r1,#2*1024                           ;2k for 1k mini cache size (we're not doing flipflop)
MMUC_minicache_loop
       LDR     r3,[r1],#32
       LDR     r3,[r1],#32
       LDR     r3,[r1],#32
       LDR     r3,[r1],#32
       CMP     r1,r2
       BLO     MMUC_minicache_loop
MMUC_no_minicache
a2479 1
  ] ;ARMSASupport
d2483 4
a2486 1
  [ :LNOT: ARMSASupport_Only
a2489 2
  |
       ARMA_flush_TLBs
d2604 3
a2606 8
  [ ChocolateScreen :LAND: ARMSASupport
    ;
    ; - emulation of h/w VIDMRD (slightly more pessimistic than real VIDMRD, since triggered by writes
    ;   as well as reads)
    ; - check for domain fault, which will be a screen access - if so, set screen (domain 1) access to
    ;   normal, set emulated VIDMRD flag (if screen cleaning enabled), and restart instruction
    ; - note that domain aborts are *only* expected for screen (and only when h/w VIDMRD absent)
    ;
d2614 1
a2614 1
        MOV     r1,#0                        ;only set emulated VIDMRD flag if screen clean neither disabled nor suspended
d2617 3
a2619 1
        ORREQ   r0,r0,#ACS_SoftVIDMRD
d2621 1
a2621 1
        LDMIA   r13_abort, {r0-r1}           ;restore regs
a2625 15
        ; RestartExternalAborts
        ; - part of PCI support on Phoebe (PCI master aborts CPU access to PCI space, which must be uncached, unbuffered)
        ; - should never happen on older h/w (so this code should do no harm)
        ; - simply restart instruction on external abort (assumes core that doesn't need fix-ups; eg. StrongARM)
        ;
        ARM_read_FSR r0
        AND     r0,r0,#&D
        CMP     r0,#8                           ;PCI abort will be external abort on non-linefetch (page or section)
  [ PhoebeBodge_Bernard2
        MOVEQ   r0, #IOMD_Base
        LDREQ   r0, [r0,#&80]                   ;harmless IOMD access to catch on analyzer
  ]
        LDREQ   r0,[r13_abort]                  ;restore r0 and...
        SUBEQS  pc,lr_abort,#8                  ;...restart instruction if so

d3337 1
a3337 3
; - some tricks to improve performance, looking at MMU level 1 and level 2 page tables
; - also now maps in devsel 6 space (IDE discs) and PCI config space, if running on IOMD2
;
d3376 2
a3377 28
;go for best available memory speed for data cache cleaner areas for StrongARM
;there is 32k for 2 main cleaner areas, followed directly by 32k for 2 screen cleaner areas
;
;since we discriminate IOMD variants here, sort out PCI mapping here too
;
SA_cleanerzoom_eh
        MOV     r0,#IOMD_Base
        LDRB    r0,[r0,#IOMD_ID0]
        TEQ     r0,#IOMD_7500     :AND: &FF
        TEQNE   r0,#IOMD_7500FE   :AND: &FF
        BEQ     SA_cleanerzoom_done
        TEQ     r0,#IOMD_Original :AND: &FF
        BEQ     SA_cleanerzoom_IOMD1
        TEQ     r0,#IOMD_IOMD2    :AND: &FF
        BEQ     SA_cleanerzoom_IOMD2
        B       SA_cleanerzoom_eh            ;deliberate panic hang up

SA_cleanerzoom_IOMD1
        MOV     r2,#&01000000                ;physical address of ROM bank 1 (which we'll use for fast clean)
        MOV     r1,#5
        MOV     r0,#IOMD_Base
        STRB    r1,[r0, #IOMD_ROMCR1]        ;program ROM bank 1 speed to fastest (62.5 ns)
        B       SA_cleanerzoom

SA_cleanerzoom_IOMD2
        BL      L1PT_forIOMD2                ;we know we're on IOMD2, so map IOMD2 specific stuff while we're about it
        MOV     r2,#&3c000000                ;physical address of IOMD2 fast cache flush area
SA_cleanerzoom
d3381 3
a3383 3
        MOV     r1,r1,LSR #20                ;zap physical address field
        ORR     r1,r1,r2                     ;and munge in the appropriate physical address from above
        MOV     r2,#8                        ;8 L2PT entries to fiddle for main cleaner area (32k)
d3388 3
a3390 10
        ARM_read_ID r2
        AND     r2,r2,#&F
        CMP     r2,#SA120minimumrev          ;check for SA-120 (has mini data cache)
        BICHS   r1,r1,#4                     ;clear B bit on SA-120 (C=1,B=0 space, means mini cacheable)
        MOV     r2,#8                        ;8 L2PT entries to fiddle for screen cleaner area (32k)
01
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT01
SA_cleanerzoom_done
a3393 1
;
d3470 1
a3470 25

PCIConfig_PhAddr * &40000000     ;physical start of PCI config space
Devsel6_PhAddr   * &03800000     ;physical start of devsel 6 space (IDE discs)
Devsel6          * &03400000     ;logical start of devsel 6 space
IO_L1PTbits      * &412          ;svc r/w, usr -/-, ~B, ~C, Section
;
L1PT_forIOMD2  ROUT
        Push    "r0-r2,lr"
        LDR     r0,=PCI_status
        MOV     r1,#1
        STR     r1,[r0]                                ;initialise as PCI present
;
        LDR     r0,=L1PT
;
;1M of PCI config space
        ADD     r1,r0,#PCIConfig :SHR: (20-2)          ;L1PT address for PCI config space
        LDR     r2,=PCIConfig_PhAddr :OR: IO_L1PTbits  ;L1PT entry
        STR     r2,[r1]
;
;1M of devsel 6 space
        ADD     r1,r0,#Devsel6 :SHR: (20-2)            ;L1PT address for devsel 6 space
        LDR     r2,=Devsel6_PhAddr :OR: IO_L1PTbits    ;L1PT entry
        STR     r2,[r1]
        Pull    "r0-r2,pc"

a3501 1
  [ :LNOT: ARMSASupport_Only
a3505 2
  ]
  [ ARMSASupport
a3532 2
        TST     R11,#ACS_MiniDataCache
        BICEQ   R11,R11,#ACS_VSCpending_MASK     ;unless screen uses mini cache, force this clear since we are about to clean cache
d3546 1
a3546 1
        BIC     R11,R11,#ACS_NSCsemaphore:OR:ACS_SynchCAsemaphore
d3548 1
a3548 1
    [ ChocolateScreen
a3549 2
        BNE     %FT04                            ;do nothing if disabled or suspended
        TST     R11,#ACS_HardVIDMRD              ;check for presence of h/w VIDMRD
d3552 2
a3553 3
        ARMA_write_MMUdomain R11,EQ              ;if h/w VIDMRD absent, reset screen (domain 1) to fault for VIDMRD emulation
04
    ]
a3554 1
  ] ;ARMSASupport
d3561 1
a3566 1
  [ :LNOT: ARMSASupport_Only
d3571 4
a3577 1
  ]
a3578 1
  [ ARMSASupport
d3587 9
a3596 1
        MOV     pc,lr
@


4.3.2.6
log
@Phoebe aware version of kernel
Source currently builds for Phoebe only. Flipping source switches will
build for Risc PC and/or A7000(+) as well (or instead). Not tested
much on older platforms.
Known issues remaining:
 - on Phoebe, kernel does not always set up the video (new VCO)
   properly. It appears that anything via the display manager is ok,
   old modes are ok before a monitor definition is seen, but mode
   changes via applications in the desktop always/often (?) aren't.
   Most likely area for investigation is whether kernel catches all
   mode change routes for ensuring it programs the new VCO.
 - on Phoebe, kernel does not yet have the hooks to support multiple
   CPU(s) (to park the slaves and allow them to be used later). I
   have a technical note on this, which should be archived as part of
   the Ursula burial work.
 - on older platforms, the areas that need checking most are CMOS
   power on reset (when in ROM) and mode changes by all routes (since
   these areas are bent by Phoebe support)
Note that kernel currently builds for rev S or better StrongARM. The
switch ARMSASupport_RevS should be set false if building for Risc PC.
@
text
@a29 1
;25-05-98 MJS  a bit of a clean up for RISC OS 4 (Ursula/Phoebe), ARM810 support removed as part of this
d117 2
a118 1
; during kernel boot, the ClearPhysRAM routine uses a temporary mapping of RAM here
a122 6
; PCI space is 256M, PCI config space is 1M
;
PCISpace                *       &90000000
PCIConfig               *       &a0000000


a141 1
  [ :LNOT: KeepCachesOff
d159 2
a160 3
  |
ARM_default_MMU_CR_table   ;same as cacheoff then
  ]
d183 1
d212 1
d217 1
d259 1
d264 1
a272 1
  [ :LNOT: PhoebeBodge_Bernard
a274 1
  ]
d277 3
d434 17
d452 1
a452 1
  [ :LNOT: ARMSASupport_Only
a458 1
  [ :LNOT: ARMSASupport_Only
d461 6
a472 1
  [ ARMSASupport
d475 1
a475 1
    [ AssumeNoCodeAbove64Mb
d478 1
a478 1
    ]
a479 1
  ]
a482 1
  [ :LNOT: ARMSASupport_Only
d485 5
d495 1
a495 1
  ]
a496 1
  [ ARMSASupport
d516 1
a516 1
    [ AssumeNoCodeAbove64Mb
d519 1
a519 1
    ]
a523 1
  ] ;ARMSASupport
d527 14
a551 1
  [ :LNOT: ARMSASupport_Only
d556 5
a565 1
  ]
a566 1
  [ ARMSASupport
a584 1
  ] ;ARMSASupport
a587 1
  [ ARMSASupport
a589 1
  ]
d636 1
d643 1
a643 11

70
        LDRB    r10,[r12,#IOMD_ID0]
        TEQ     r10,#IOMD_IOMD2    :AND: &FF
        ORREQ   r11,r11,#&80                                    ;bit 7 means use async SAM clock on Phoebe
        BEQ     %FT90
        TEQ     r10,#IOMD_Original :AND: &FF
        TEQNE   r10,#IOMD_7500     :AND: &FF
        TEQNE   r10,#IOMD_7500FE   :AND: &FF
        BNE     %BT70                                           ;deliberate panic hang up

d648 1
a648 1
90
d651 2
a658 86
;       SoftCopyROM
;
; automagically softload ROM into reserved space, if required
;
; in:  -
; out: corrupts r0-r4, r10-r12
;

SCRTempMappingBase * PhysSpace + DRAM0PhysRam   ;handy base address for temporary logical mapping

SoftCopyROM ROUT

        MOV     r0, #0
        LDR     r10, [r0, #SoftROMaddr]         ;physical address of reserved space
        TEQ     r10, #0
        MOVEQ   PC, LR                          ;no soft copy required if 0

;map in the RAM temporarily for copy
;
        MOV     r11, #OSROM_ImageSize*1024
        LDR     r0,  =L1PT
        MOV     r4, #SCRTempMappingBase         ; logical address for temporary mapping
        ADD     r1, r0, r4, LSR #(20-2)         ; L1PT address for same
        ORR     r4, r10, #&410
        ORR     r4, r4, #&00E                   ; L1PT value - section mapped, svc access, C=1, B=1
                                                ; no cache coherency worries - we just write to this space
10
        STR     r4, [r1], #4                    ; update L1PT
        ADD     r4, r4, #&100000
        SUBS    r11, r11, #&100000              ; another 1 Mb done
        BNE     %BT10
        ARM_flush_TLB r11                       ; mapping change

;copy the ROM into RAM
;
        MOV     r4, #ROM                        ; source
        MOV     r11, #SCRTempMappingBase        ; dest
        ADD     r12, r11, #OSROM_ImageSize*1024 ; size
20
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        LDMIA   r4!, {r0-r3}
        STMIA   r11!, {r0-r3}
        TEQ     r11, r12
        BNE     %BT20

;remove temporary mapping of physical RAM
;
        MOV     r11, #OSROM_ImageSize*1024
        LDR     r0,  =L1PT
        MOV     r4, #SCRTempMappingBase         ; logical address for temporary mapping
        ADD     r1, r0, r4, LSR #(20-2)         ; L1PT address for same
        MOV     r4, #0                          ; L1PT value - fault
30
        STR     r4, [r1], #4                    ; update L1PT
        SUBS    r11, r11, #&100000              ; another 1 Mb done
        BNE     %BT30

;remap ROM logical space to soft loaded ROM (we can do this live, because it is identical)
;

        MOV     r11, #OSROM_ImageSize*1024
        LDR     r0,  =L1PT
        MOV     r4, #ROM                        ; logical address of ROM
        ADD     r1, r0, r4, LSR #(20-2)         ; L1PT address for same

40
        LDR     r4, [r1]                        ; read L1PT entry
        MOV     r4, r4, LSL #20
        MOV     r4, r4, LSR #20                 ; zap old physical address
        ORR     r4, r4, r10                     ; munge in new physical address
        STR     r4, [r1], #4                    ; update L1PT entry
        ADD     r10, r10, #&100000
        SUBS    r11, r11, #&100000              ; another 1 Mb done
        BNE     %BT40

        ARM_flush_TLB r11                       ; mapping change

        MOV     PC, LR

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
d694 1
d699 1
a699 1
        DCD     VideoPhysRam     ;VRAM physical start
d701 2
a702 2
        DCD     DRAM0PhysRam     ;DRAM physical start
        DCD     &20000000        ;DRAM physical size (512M is size for IOMD2, also takes care of 256M IOMD1)
d925 1
d931 1
a931 1
;
d934 10
a943 20
;decision point based on IOMD variant
;checks variants exhaustively, and deliberately hangs up for unknown/unsupported
;
10
        LDRB    r0, [r12,#IOMD_ID0]
  [ IOMD2Support
        TEQ     r0, #IOMD_IOMD2    :AND: &FF
        BEQ     PhoebeInit                            ; IOMD2 (Phoebe)
  ]
  [ IOMD1Support
        TEQ     r0, #IOMD_Original :AND: &FF
        BEQ     MedusaInit                            ; IOMD1 (Risc PC)
        TEQ     r0, #IOMD_7500     :AND: &FF
        BEQ     init7500cpu                           ; 7500 (A7000)
        TEQ     r0, #IOMD_7500FE   :AND: &FF
        BEQ     init7500FEcpu                         ; 7500FE (A7000+)
  ]
        B       %BT10                                 ; deliberate panic hang-up (unrecognised IOMD)

  [ IOMD2Support
a944 41
PhoebeInit
;
 [ PhoebeBodge
   ;still some values to sort out for 64 MHz ASIC
 ]
        MOV     r0,#12
        STR     r0,[r12,#IOMD_ROMCR0]                 ;ROM timings, bank 0
        STR     r0,[r12,#IOMD_ROMCR1]                 ;ROM timings, bank 1
        MOV     r0,#&5c
        STR     r0,[r12,#IOMD_VREFCR]                 ;vram control, refresh
        STR     r0,[r12,#IOMD2_PRECHG]                ;trigger SDRAM precharge
        MOV     r0,#&0a
        STR     r0,[r12,#IOMD2_SDTMG]                 ;SDRAM timing control
        MOV     r0,#&20
        STR     r0,[r12,#IOMD2_SDMODE]                ;SDRAM mode
        MOV     r0,#2
        STR     r0,[r12,#IOMD2_SCDIV]                 ;SC clock division to MCLK/2
        MOV     r0,#&04
        STR     r0,[r12,#IOMD2_VRAMTMG]               ;vram timing
        MOV     r0,#&85
        STR     r0,[r12,#IOMD2_BMSPD]                 ;bus master speed

        MOV     r0,#&5000
        STR     r0,[r12,#IOMD2_INTRTEB]               ;make sure floppy request is routed to (cpu 0) FIQ

        MOV     r0,#&2000000                          ;just in case, init video DMA
        ORR     r0,r0,#&60
        STR     r0,[r12,#IOMD_CURSINIT]
        MOV     r0,#&2000000
        STR     r0,[r12,#IOMD_CURSCUR]

        MOV     r0, #&0002
        ORR     r0, r0, #&2a00
        STR     r0, [r12, #IOMD_IOTCR]
        MOV     r0, #0                          ; Podule manager wants TypeA setting by default for all podules
        STRB    r0, [r12, #IOMD_ECTCR]
        B       CommonInit

  ] ;IOMD2Support

  [ IOMD1Support
d947 8
d956 5
a960 1
;       CPUCLK divide by 1, MEMCLK divide by 2, IOCLK  divide by 2
d962 3
a964 2
        MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkHalf + IOMD_CLKCTL_IOclkHalf
        STRB    r0, [r12, #IOMD_CLKCTL]
d968 9
d979 1
d981 29
a1009 1
        STRB    r0, [r12, #IOMD_ROMCR0]
d1011 5
a1015 1
;
d1017 1
a1017 1
;
d1020 1
d1025 6
a1030 2
;
;       CPUCLK divide by 1, MEMCLK divide by 1, IOCLK  divide by 1
d1033 1
a1033 1
        STRB    r0, [r12, #IOMD_CLKCTL]
d1037 9
d1047 2
a1048 1
        AND     r0, r0, #&40                     ; clear all but the 16-bit mode flag
d1050 29
a1078 1
        STRB    r0, [r12, #IOMD_ROMCR0]
d1080 5
a1084 1
;
d1086 1
a1086 1
;
d1089 2
d1113 3
a1115 1
;
d1117 3
d1121 3
d1125 7
a1131 1

a1140 2
  ] ;IOMD1Support

d1269 1
d1273 1
d1278 1
a1278 32
;signal cyan on screen (if kernel panics with bad DRAM, screen should remain cyan)
;
        LDR     R0, =&40000000+&FFFF00 ;border colour to cyan
        LDR     R2, =VIDCPhys
        STR     R0, [R2]

; StrongARM - turn on I cache (allowed with MMU off), and fast core clock now - this avoids dreadful
;             performance, and is ok until MMU etc comes on (near CritStart)
;
  [ :LNOT: ARMSASupport_Only
        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&A000
        BNE     MemSize_notSA
  ]
  [ ARMSASupport
    [ :LNOT: KeepCachesOff
        ARM_read_control r2
        ORR     r2,r2,#&1000     ;I cache bit is bit 12
        ARM_write_control r2
    ]
    [ PhoebeBodge
        ;current SA120 sample(s) fall over with fast core clock
        ARM_read_ID r2
        AND     r2,r2,#&F
        CMP     r2,#SA120minimumrev
        ARMA_fastcoreclock LO
    |
        ARMA_fastcoreclock
    ]
  ] ;ARMSASupport
MemSize_notSA
a1280 16
;
10
        LDRB    r0, [r12, #IOMD_ID0]
  [ IOMD2Support
        TEQ     r0, #IOMD_IOMD2    :AND: &FF
        BEQ     MemSizePhoebe                         ; IOMD2 (Phoebe)
  ]
  [ IOMD1Support
        TEQ     r0, #IOMD_Original :AND: &FF
        BEQ     MemSizeIOMD                           ; IOMD1 (Risc PC)
        TEQ     r0, #IOMD_7500     :AND: &FF
        BEQ     MemSizeMorris                         ; 7500 (A7000)
        TEQ     r0, #IOMD_7500FE   :AND: &FF
        BEQ     MemSizeMorris                         ; 7500FE (A7000+)
  ]
        B       %BT10                                 ; deliberate panic hang-up (unrecognised IOMD)
d1282 1
a1282 1
  [ IOMD2Support
d1284 8
a1291 1
MemSizePhoebe
d1293 1
a1293 1
; for VRAM, we currently assume 4M is always there
d1295 2
a1296 10
; for SDRAM, we can cope with organisation of 11..14 rows, 8..11 columns, capacity of 4 to 128M
; in one DIMM, 1 or 2 banks in DIMM (if 2 banks, must be symmetric) (max total of 256M currently
; supported - 512M may be possible but will need looking at when/if suitable DIMMs exist)

; symbols for serial presence detect (SPD) 
; (we assume that Timer0 is already set up and running - needed by SPD routines)
;
  [ PhoebeBodge
SDRAMI2C_addr0       * &a4        ;address for slot 0  (old FPGA PCB)
SDRAMI2C_addr1       * &a2        ;address for slot 1  (old FPGA PCB)
d1298 6
a1303 2
SDRAMI2C_addr0       * &a8        ;address for slot 0
SDRAMI2C_addr1       * &a4        ;address for slot 1
a1304 198
SDRAMI2C_Nrows       * 3          ;byte 3 holds number of rows in SDRAM organisation
SDRAMI2C_Ncolumns    * 4
SDRAMI2C_Nbanks      * 5
SDRAMI2C_bankdensity * 31

;first, determine organisation (rows,columns) of SDRAM in each slot, and program SDRAMCR
;
        MOV     r7,#0                 ;accumulate bits for programming SDRAMCR
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        BVS     %FT10                 ;nothing in slot0
        MOV     r0,#SDRAMI2C_Nrows
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read number of rows for slot0 SDRAM
        SUBS    r0,r0,#11
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0,LSL #2       ;(11..14 rows means 0..3 in RAS0 bits of SDRAMCR)
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_Ncolumns
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read number of columns for slot0 SDRAM
        SUBS    r0,r0,#8
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0              ;(8..11 columns means 0..3 in CAS0 bits of SDRAMCR)
10
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        BVS     %FT20                 ;nothing in slot1
        MOV     r0,#SDRAMI2C_Nrows
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read number of rows for slot1 SDRAM
        SUBS    r0,r0,#11
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0,LSL #6       ;(11..14 rows means 0..3 in RAS1 bits of SDRAMCR)
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_Ncolumns
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read number of columns for slot1 SDRAM
        SUBS    r0,r0,#8
        BMI     BadSDRAMPanic
        CMP     r0,#3
        BHI     BadSDRAMPanic
        ORR     r7,r7,r0,LSL #4       ;(8..11 columns means 0..3 in CAS1 bits of SDRAMCR)
20
        MOV     r12,#IOMD_Base
        STR     r7,[r12,#IOMD2_SDRAMCR]

;next determine sizes of SDRAM in each slot, and fill in PhysRamTable
;
        MOV     r7,#0                 ;accumulate 4 bytes of info in r7
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        BVS     %FT30                 ;nothing in slot0
        MOV     r0,#SDRAMI2C_Nbanks
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read number of banks for slot0 SDRAM
        ORR     r7,r7,r0
        MOV     r0,#SDRAMI2C_addr0
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_bankdensity
        MOV     r1,#SDRAMI2C_addr0
        BL      SPD_ReadValue         ;read bank density for slot0 SDRAM
        ORR     r7,r7,r0,LSL #8
30
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        BVS     %FT40                 ;nothing in slot1
        MOV     r0,#SDRAMI2C_Nbanks
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read number of banks for slot1 SDRAM
        ORR     r7,r7,r0,LSL #16
        MOV     r0,#SDRAMI2C_addr1
        BL      SPD_PreRead
        MOV     r0,#SDRAMI2C_bankdensity
        MOV     r1,#SDRAMI2C_addr1
        BL      SPD_ReadValue         ;read bank density for slot1 SDRAM
        ORR     r7,r7,r0,LSL #24
40
        TEQ     r7,#0
        BEQ     BadSDRAMPanic         ;no SDRAM!

;note that we can safely use SDRAM now (wait for Precharge has happened, and we have programmed correct rows,columns)

        LDR     r3, =DRAMOffset_PageZero + PhysRamTable
        TST     r7, #&FF
        ADDNE   r3, r3, #DRAM0PhysRam                       ;address of first fragment pair in PhysRamTable (slot 0 present)
        ADDEQ   r3, r3, #DRAM4PhysRam                       ;address of first fragment pair in PhysRamTable (slot 0 absent)
        MOV     r2, r3
        MOV     r1, #&400000       ;always assume 4M VRAM
        MOV     r0, #VideoPhysRam
        STMIA   r3!, {r0,r1}       ;video fragment is 4M VRAM
;
        MOV     r0, #DRAM0PhysRam  ;first fragment address for slot 0
42
        ANDS    r8, r7, #&FF
        BEQ     %FT50              ;nothing in slot
        CMP     r8, #2
        BHI     BadSDRAMPanic
        ADD     r8, r8, r8         ;no. of fragments for slot 0 (2 or 4, for 1 or 2 banks)   
        MOV     r1, r7, LSR #8
        AND     r1, r1, #&FF
        TEQ     r1, #1             ;4M in one or both banks
        TEQNE   r1, #2             ;8M
        TEQNE   r1, #4             ;16M
        TEQNE   r1, #8             ;32M
        TEQNE   r1, #16            ;64M
        TEQNE   r1, #32            ;128M
        BNE     BadSDRAMPanic
        MOV     r1, r1, LSL #21    ;size of each fragment (bank splits into two half-size fragments)
        TEQ     r8, #2
        MOVEQ   r9, #DRAM2PhysRam - DRAM0PhysRam  ;step between fragments if 2 fragments
        MOVNE   r9, #DRAM1PhysRam - DRAM0PhysRam  ;step between fragments if 4 fragments
44
        STMIA   r3!, {r0,r1}       ;next fragment
        ADD     r0, r0, r9
        SUBS    r8, r8, #1
        BNE     %BT44
50
        MOVS    r7, r7, LSR #16    ;move to slot 1, if not already done
        MOV     r0, #DRAM4PhysRam  ;first fragment address for slot 1
        BNE     %BT42

        ASSERT  Phoebe_VRAMsize = &400000
        MOV     r6, #4                                   ; 4M of VRAM
        STR     r6, [r2, #VRAMWidth-PhysRamTable]        ; store width of VRAM (4M)
        MOV     r7, #SAMLength/2/256*2                   ; use VRAM mode, and set increment for 2*1/2 SAM
        LDR     r10, =320000000                          ; 320E6 bytes/sec bandwidth (about right for 50MHz SAM clk ???)
        MOV     r14, #IOMD_Base
        STRB    r7, [r14, #IOMD_VIDCR]
        MOV     r12, #VideoPhysRam
        STR     r12, [r14, #IOMD_VIDCUR]                 ; set up VIDCUR to start of video RAM
        STR     r12, [r14, #IOMD_VIDSTART]               ; do same for VIDSTART
        STR     r12, [r14, #IOMD_VIDINIT]                ; and for VIDINIT
                                                         ; so we don't get a mess when we turn video DMA on later
        STR     r10, [r2, #VideoBandwidth-PhysRamTable]  ; store video bandwidth

        ADD     r10, r12, #1024*1024-4096                ; add on a bit to form VIDEND (will be on mult. of SAM)
        STR     r10, [r14, #IOMD_VIDEND]                 ; yes I know it's a bit of a bodge

        MOV     r14, r6, LSL #20                         ; convert amount of VRAM to bytes
        STR     r14, [r2, #VRAMSize-PhysRamTable]        ; and store

  [ Phoebe_SoftROM
    ;
    ; we want to automagically soft load ROM into RAM if not already done (warm reset), because of the enormous speed
    ; advantage of SDRAM versus ROM

        ADRL    r14, ROM                                 ; use PC-relative addressing to get to start of image
        TEQ     r14, #PhysROM                            ; see if we are currently running from ROM
        BNE     %FT70                                    ; if not, then it's a warm reset and we're already running from RAM

        ADD     r7, r2, #2*4                             ; -> first of SDRAM chunks in PhysRamTable
        MOV     r14, #0                                  ; suitable chunk not found yet
        MOV     r10, #0                                  ; used to sum total SDRAM size

60
        LDMIA   r7!, {r4, r5}                            ; address, size
        ADD     r10, r10, r5                             ; total size so far
        CMP     r5, #OSROM_ImageSize*1024
        MOVHS   r14, r4                                  ; big enough chunk (we know it's 1M aligned), so remember it
        CMP     r7, r3
        BLO     %BT60

        CMP     r10, #OSROM_ImageSize*1024 + &1000000
        MOVLT   r14, #0                                  ; don't soft load if it will leave less than 16M of SDRAM
        TEQ     r14, #0
        BEQ     %FT70
        STR     r14, [r2, #SoftROMaddr-PhysRamTable]     ; if we found a suitable chunk, reserve start of chunk for soft ROM
        MOV     r7, r2                                   ; -> start of PhysRamTable
        MOV     r10, r3                                  ; -> 1st byte after end of table
        B       MemSizeSoftROMreserved

70
  ] ; Phoebe_SoftROM

        MOV     r7, r2                                   ; -> start of PhysRamTable
        MOV     r10, r3                                  ; -> 1st byte after end of table
        B       MemSizeTotalRAM

;
BadSDRAMPanic
        B       BadSDRAMPanic

  ] ;IOMD2Support

  [ IOMD1Support
;
MemSizeMorris
;
        MOV     r11, #&70     ;all 4 banks assumed 32 bit - EDO and timing bits set in case 7500FE (don't care bits otherwise)
d1492 1
a1492 2
;we only need to distinguish Morris variants here
MemSize_whichmorris
d1494 13
a1506 7
        TEQ     r4, #IOMD_7500FE :AND: &FF
        TEQNE   r4, #IOMD_7500   :AND: &FF
        BNE     MemSize_whichmorris                     ; deliberate panic hang up
        TEQ     r4, #IOMD_7500FE :AND: &FF
        LDREQ   r4, =80000000                           ; FE implies EDO, so allow 80E6 bytes/s
        TEQ     r4, #IOMD_7500   :AND: &FF
        LDREQ   r4, =46500000                           ; if no VRAM, then 46.5E6 bytes/sec bandwidth
d1509 2
d1523 1
d1532 29
d1588 1
d1670 2
a1672 11
  ] ;IOMD1Support

;
MemSizeTotalRAM
        MOV     r1, #0
        STR     r1, [r2, #SoftROMaddr-PhysRamTable]     ; no soft ROM chunk reserved for later copy
;
MemSizeSoftROMreserved
;
; Now we have to work out the total RAM size, allowing for any reserved or active soft loaded ROM chunk
;
d1683 2
d1686 6
a1691 5
        LDR     r4, [r2, #SoftROMaddr-PhysRamTable]     ; reserved soft ROM physical address, if any
        TEQ     r4, #0
        ADREQL  r4, ROM                                 ; if none reserved, use PC-relative addressing to get to address of active ROM
        TEQ     r4, #PhysROM                            ; then see if required ROM address is the physical ROM address
        BEQ     %FT55                                   ; if so, then we're OK
d1693 2
a1694 2
        SUB     r1, r1, #OSROM_ImageSize*1024           ; if we've been (or will be) soft-loaded, then we have ?M less than we thought
        ADD     r5, r4, #OSROM_ImageSize*1024           ; point r5 at end of ROM
a1748 1
        ADRL    r4, ROM                                 ; r4 := physical address of active ROM (may be in RAM)
d1913 2
a1914 2
        MOV     r7, #5                          ; allow domain 0 and 1, with client permission checks
        ARM_MMU_domain r7                       ; OS mainly uses domain 0, but ChocolateScreen may use domain 1
a1917 6
;signal green on screen - this is at point where we turn on MMU
;
        LDR     R7, =&40000000+&00FF00 ;border colour to green
        LDR     R2, =VIDCPhys
        STR     R7, [R2]

d1973 3
a1975 3
ROMbit      *       1 :SHL: 12
Vidbit      *       1 :SHL: 13
PSS_NoDRAM  *       PhysSpaceSize_NoDRAM  :SHR: 20  ; Number of megabytes in IOMD physical space (excluding DRAM)
d2015 1
a2015 6
        ;mjs change for Ursula:
        ; - on IOMD1 this will remain as abort (was reserved as VIDC1 emulation zone)
        ; - on IOMD2 this will be set to access devsel 6 (IDE discs)
        ;   (see L1L2PTenhancements)
        MemInitAbort     1,          &03400000                          ; 

d2019 9
d2037 1
d2039 4
a2042 5
        ; mjs change for Ursula:
        ; map of IOMD physical space now excludes DRAM (would be even more profligate on IOMD2)
        ; note that old POST code stuff won't like this - I'm not losing sleep over it
        ;
        ASSERT :LNOT: IncludeTestSrc
d2044 1
a2044 1
        MemInitSection PSS_NoDRAM, 1, 0, 0, PhysSpace, AP_None, &00000000
d2073 1
d2084 1
d2189 1
d2191 1
a2191 1
;assumes timings (and EDO for 7500FE) according to IOMD id, may set up ROM timings etc. as side effect
d2197 8
a2204 13
10
        LDRB    r7, [r2,#IOMD_ID0]
        TEQ     r7, #IOMD_IOMD2    :AND: &FF
        BEQ     timecpuphoebe                         ; IOMD2 (Phoebe)
        TEQ     r7, #IOMD_Original :AND: &FF
        BEQ     timecpuriscpc                         ; IOMD1 (Risc PC)
        TEQ     r7, #IOMD_7500     :AND: &FF
        BEQ     timecpu7500                           ; 7500 (A7000)
        TEQ     r7, #IOMD_7500FE   :AND: &FF
        BEQ     timecpu7500FE                         ; 7500FE (A7000+)
        B       %BT10                                 ; deliberate panic hang-up (unrecognised IOMD)
;
timecpu7500
d2232 6
a2237 2
timecpuphoebe
        LDR     r7, =(1 :SHL: 16) :OR: 64000  ; indicate 64MHz RAM
d2240 1
d2242 2
d2253 4
a2256 5
10
        LDRB    r0, [lr, #IOMD_ID0]
        TEQ     r0, #IOMD_Original :AND: &FF
        TEQNE   r0, #IOMD_7500     :AND: &FF
        TEQNE   r0, #IOMD_IOMD2    :AND: &FF
d2258 5
a2262 7
        TEQ     r0, #IOMD_7500FE   :AND: &FF
        BNE     %BT10                        ;deliberate panic hang up

        MOV     r0, #&80
        STRB    r0, [lr, #&CC]          ; ASTCR register: set i/o asynchronous timing for fast memory clock
        MOV     r0, #&06                ; clock dividers: /1 for CPU, /1 for memory, /2 for I/O
        STRB    r0, [lr, #IOMD_CLKCTL]
d2266 3
d2358 3
d2367 8
d2387 19
a2410 1
  [ ARMSASupport
a2417 12
        ARM_read_ID r0
        AND     r0,r0,#&F
        CMP     r0,#SA120minimumrev
        BLO     %FT14
        ;clean mini data cache too (only used for screen, but we should still avoid losing dirty screen data)
        LDR     r1,=ARMA_ScreenCleaners_address+8*1024  ;use part of area that is not used for screen cleaning
        ADD     r2,r1,#2*1024                           ;2k for 1k mini cache size (we're not doing flipflop)
12
        LDR     r0,[r1],#32
        CMP     r1,r2
        BLO     %BT12
14
a2418 1
  ] ;ARMSASupport
d2434 3
a2446 1
  [ :LNOT: ARMSASupport_Only
a2448 1
  ]
a2451 1
  [ :LNOT: ARMSASupport_Only
d2453 3
d2458 12
a2470 1
  [ ARMSASupport
a2477 15
       ARM_read_ID r2
       AND     r2,r2,#&F
       CMP     r2,#SA120minimumrev
       BLO     MMUC_no_minicache
       ;flush mini data cache too, for completeness
       LDR     r1,=ARMA_ScreenCleaners_address+8*1024  ;use part of area that is not used for screen cleaning
       ADD     r2,r1,#2*1024                           ;2k for 1k mini cache size (we're not doing flipflop)
MMUC_minicache_loop
       LDR     r3,[r1],#32
       LDR     r3,[r1],#32
       LDR     r3,[r1],#32
       LDR     r3,[r1],#32
       CMP     r1,r2
       BLO     MMUC_minicache_loop
MMUC_no_minicache
a2479 1
  ] ;ARMSASupport
d2483 4
a2486 1
  [ :LNOT: ARMSASupport_Only
a2489 2
  |
       ARMA_flush_TLBs
d2604 3
a2606 8
  [ ChocolateScreen :LAND: ARMSASupport
    ;
    ; - emulation of h/w VIDMRD (slightly more pessimistic than real VIDMRD, since triggered by writes
    ;   as well as reads)
    ; - check for domain fault, which will be a screen access - if so, set screen (domain 1) access to
    ;   normal, set emulated VIDMRD flag (if screen cleaning enabled), and restart instruction
    ; - note that domain aborts are *only* expected for screen (and only when h/w VIDMRD absent)
    ;
d2614 1
a2614 1
        MOV     r1,#0                        ;only set emulated VIDMRD flag if screen clean neither disabled nor suspended
d2617 3
a2619 1
        ORREQ   r0,r0,#ACS_SoftVIDMRD
d2621 1
a2621 1
        LDMIA   r13_abort, {r0-r1}           ;restore regs
a2625 15
        ; RestartExternalAborts
        ; - part of PCI support on Phoebe (PCI master aborts CPU access to PCI space, which must be uncached, unbuffered)
        ; - should never happen on older h/w (so this code should do no harm)
        ; - simply restart instruction on external abort (assumes core that doesn't need fix-ups; eg. StrongARM)
        ;
        ARM_read_FSR r0
        AND     r0,r0,#&D
        CMP     r0,#8                           ;PCI abort will be external abort on non-linefetch (page or section)
  [ PhoebeBodge_Bernard2
        MOVEQ   r0, #IOMD_Base
        LDREQ   r0, [r0,#&80]                   ;harmless IOMD access to catch on analyzer
  ]
        LDREQ   r0,[r13_abort]                  ;restore r0 and...
        SUBEQS  pc,lr_abort,#8                  ;...restart instruction if so

d3337 1
a3337 3
; - some tricks to improve performance, looking at MMU level 1 and level 2 page tables
; - also now maps in devsel 6 space (IDE discs) and PCI config space, if running on IOMD2
;
d3376 2
a3377 28
;go for best available memory speed for data cache cleaner areas for StrongARM
;there is 32k for 2 main cleaner areas, followed directly by 32k for 2 screen cleaner areas
;
;since we discriminate IOMD variants here, sort out PCI mapping here too
;
SA_cleanerzoom_eh
        MOV     r0,#IOMD_Base
        LDRB    r0,[r0,#IOMD_ID0]
        TEQ     r0,#IOMD_7500     :AND: &FF
        TEQNE   r0,#IOMD_7500FE   :AND: &FF
        BEQ     SA_cleanerzoom_done
        TEQ     r0,#IOMD_Original :AND: &FF
        BEQ     SA_cleanerzoom_IOMD1
        TEQ     r0,#IOMD_IOMD2    :AND: &FF
        BEQ     SA_cleanerzoom_IOMD2
        B       SA_cleanerzoom_eh            ;deliberate panic hang up

SA_cleanerzoom_IOMD1
        MOV     r2,#&01000000                ;physical address of ROM bank 1 (which we'll use for fast clean)
        MOV     r1,#5
        MOV     r0,#IOMD_Base
        STRB    r1,[r0, #IOMD_ROMCR1]        ;program ROM bank 1 speed to fastest (62.5 ns)
        B       SA_cleanerzoom

SA_cleanerzoom_IOMD2
        BL      L1PT_forIOMD2                ;we know we're on IOMD2, so map IOMD2 specific stuff while we're about it
        MOV     r2,#&3c000000                ;physical address of IOMD2 fast cache flush area
SA_cleanerzoom
d3381 3
a3383 3
        MOV     r1,r1,LSR #20                ;zap physical address field
        ORR     r1,r1,r2                     ;and munge in the appropriate physical address from above
        MOV     r2,#8                        ;8 L2PT entries to fiddle for main cleaner area (32k)
d3388 3
a3390 10
        ARM_read_ID r2
        AND     r2,r2,#&F
        CMP     r2,#SA120minimumrev          ;check for SA-120 (has mini data cache)
        BICHS   r1,r1,#4                     ;clear B bit on SA-120 (C=1,B=0 space, means mini cacheable)
        MOV     r2,#8                        ;8 L2PT entries to fiddle for screen cleaner area (32k)
01
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT01
SA_cleanerzoom_done
a3393 1
;
d3470 1
a3470 25

PCIConfig_PhAddr * &40000000     ;physical start of PCI config space
Devsel6_PhAddr   * &03800000     ;physical start of devsel 6 space (IDE discs)
Devsel6          * &03400000     ;logical start of devsel 6 space
IO_L1PTbits      * &412          ;svc r/w, usr -/-, ~B, ~C, Section
;
L1PT_forIOMD2  ROUT
        Push    "r0-r2,lr"
        LDR     r0,=PCI_status
        MOV     r1,#1
        STR     r1,[r0]                                ;initialise as PCI present
;
        LDR     r0,=L1PT
;
;1M of PCI config space
        ADD     r1,r0,#PCIConfig :SHR: (20-2)          ;L1PT address for PCI config space
        LDR     r2,=PCIConfig_PhAddr :OR: IO_L1PTbits  ;L1PT entry
        STR     r2,[r1]
;
;1M of devsel 6 space
        ADD     r1,r0,#Devsel6 :SHR: (20-2)            ;L1PT address for devsel 6 space
        LDR     r2,=Devsel6_PhAddr :OR: IO_L1PTbits    ;L1PT entry
        STR     r2,[r1]
        Pull    "r0-r2,pc"

a3501 1
  [ :LNOT: ARMSASupport_Only
a3505 2
  ]
  [ ARMSASupport
a3532 2
        TST     R11,#ACS_MiniDataCache
        BICEQ   R11,R11,#ACS_VSCpending_MASK     ;unless screen uses mini cache, force this clear since we are about to clean cache
d3546 1
a3546 1
        BIC     R11,R11,#ACS_NSCsemaphore:OR:ACS_SynchCAsemaphore
d3548 1
a3548 1
    [ ChocolateScreen
a3549 2
        BNE     %FT04                            ;do nothing if disabled or suspended
        TST     R11,#ACS_HardVIDMRD              ;check for presence of h/w VIDMRD
d3552 2
a3553 3
        ARMA_write_MMUdomain R11,EQ              ;if h/w VIDMRD absent, reset screen (domain 1) to fault for VIDMRD emulation
04
    ]
a3554 1
  ] ;ARMSASupport
d3561 1
a3566 1
  [ :LNOT: ARMSASupport_Only
d3571 4
a3577 1
  ]
a3578 1
  [ ARMSASupport
d3587 9
a3596 1
        MOV     pc,lr
@


4.2
log
@Kernel merged
@
text
@d29 3
a31 3
;now effectively codes for ARM 6 onwards (6,7,8,A, where A = StrongARM) - MJS, 24-01-96

;but ARM8 not done yet! (29-01-96)
d131 4
d137 1
d462 17
d480 1
d483 1
d489 6
d498 1
d513 5
d574 14
d607 5
d743 1
a743 1
;            (on any ARM). This is harmless for ARM 6,7 but a big speed benefit for StrongARM (which
d754 3
d832 3
d955 8
d968 1
d984 3
d988 1
d1053 3
d1057 1
d1193 5
d1219 3
d1425 3
d1434 1
d1735 3
a1737 1

d1739 13
d2201 3
d2206 1
d2452 1
a2452 1
; In    r0=0 -> Coming from the Test routine, just go back!
d2454 1
a2454 1
;       r9 = Current MEMC CR (true MEMC value, not fudged to look like 4K page size)
d2456 1
a2456 1
; Out   r9 MEMC value with slowest ROM speed, correct pagesize
d2461 63
d2534 12
a2545 8
        LDRB    r0, [r3, #IOMD_ID0]     ; Is
        CMP     r0, #&98                ; It
        LDRB    r0, [r3, #IOMD_ID1]     ; A
        CMPEQ   r0, #&5B                ; Morris?
        MOVNE   r7,#&3e00               ;for non-Morris force 16MHz timing, assumed Risc PC
        ORRNE   r7,r7,#&80
        ORRNE   r7,r7,#&10000           ;and note we're on IOMD
        MOVNE   pc,lr
d2621 1
a2621 1
        CMP     r0, #&98                ; It
d2623 2
a2624 2
        CMPEQ   r0, #&5B                ; Morris?
        LDREQ   r0, =(4*15*500*ncpuloops)               ;Morris timing values [reordered to prevent miscalculation
d2626 1
a2626 1
        LDRNE   r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
d2681 2
d2774 3
d2783 8
d2797 2
d2801 6
a2806 2
        BICEQ   lr,r2,#&0008                   ;sorry guys, we can't use write buffer (safe-ish - safer would zap data cache bit as well)
        MOVNE   lr,r2
d2816 19
d2848 2
d2852 6
a2857 2
        BICEQ   lr,r2,#&0008            ;sorry guys, we can't use write buffer
        MOVNE   lr,r2
d2875 3
d2894 4
a2897 1
       ARM67_flush_cache NE       ;if not StrongARM, assume 6,7
d2899 13
d2923 4
d2930 1
d3038 5
d3044 1
d3061 7
d3069 1
a3421 3
   [ SAUBxferbroken
        NOP                                     ; 'fraid so
   ]
a3433 3
   [ SAUBxferbroken
        NOP                                     ; 'fraid so
   ]
d3577 1
d4006 4
d4015 4
d4031 10
a4040 1

@


4.1
log
@Initial revision
@
text
@d29 5
d62 16
d98 1
a98 1
FixedAreasL2Size        *       96*1024         ; amount of L2 to cover fixed areas, excluding free pool
d106 59
a164 5
 [ LateAborts
DefaultMMUControlRegister *     MMUC_M + MMUC_C + MMUC_W + MMUC_P + MMUC_D + MMUC_L + MMUC_F
 |
DefaultMMUControlRegister *     MMUC_M + MMUC_C + MMUC_W + MMUC_P + MMUC_D + MMUC_F
 ]
d181 1
a181 1
SetDAG  ENTRY   "r0,r12"
d197 21
d224 2
d244 10
d408 8
d444 94
a537 1
BangL2PT                                ; internal entry point used only by BangCamUpdate
d553 8
a560 2
        SetCop  r0, CR_IDCFlush         ; flush cache
        SetCop  r0, CR_TLBFlush         ; and TLB
d562 22
d629 1
d635 7
d680 3
d684 33
d737 3
d741 1
d755 30
d786 1
d790 4
d795 1
a795 2
        LDR     r1, =DefaultMMUControlRegister          ; set up MMU soft copy
        STR     r1, [r0, #MMUControlSoftCopy]
d799 2
d837 4
d842 1
d867 3
a869 1
 [ MorrisSupport
d874 1
a874 1
; anyway. 
d878 19
a896 6
        LDRB    r0, [r12, #IOMD_ID0]
        CMP     r0, #&98
        LDRB    r0, [r12, #IOMD_ID1]
        CMPEQ   r0, #&5B
       ;MOVEQ   r3, #xxxx
        BNE     MedusaInit                            ; NOT MORRIS assume Medusa hardware
d898 2
a899 2
; MORRIS contains IOMD equivalant circuitry. Due to lack of VRAM, presence of 16/32 bit support
; and a different ROM speed register, we program it slightly differently.
d901 1
a901 1

d903 59
a961 1
; PSwindell wants all prescalers set to divide by 1
a964 1

d969 48
a1017 1
; We assume that the extension ROMs are the same access time and width as the main OS ROMS.
d1019 2
a1020 16
        LDRB    r0, [r12, #IOMD_ROMCR0]
        AND     r0, r0, #&40            ; clear all but 16-bit mode bit
 [ NormalSpeedROMS
   ;Normal code
        ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_Burst93
                                                                ; initialise ROM speed to 156.25nS, 93.75nS burst
        ; the fast EPROMS used for Kryten testing should be able to cope even though they aren't
        ; burst devices
 |
   ;Slow ROM access for PSwindells test EPROMS. Paul requested 156nS (or slower), burst off.
        ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_187 + IOMD_ROMCR_BurstOff

        ! 0, "*** WARNING *** Slow ROM version ment for PSwindell"
 ]
        STRB    r0, [r12, #IOMD_ROMCR0]
        STRB    r0, [r12, #IOMD_ROMCR1]         ; and do the same for extension ROMs (just in case)
d1022 1
a1022 1
; MORRIS doesn't support VRAM. Kryten has same DRAM speed as Medusa 
d1033 1
a1033 2
 [ Select16BitSound
; All MORRIS based machines have 16bit 'Japanese' format sound DAC's
d1036 1
a1036 1
 ]
d1040 74
a1113 1
 ]
d1137 2
d1140 7
a1146 1

d1164 3
d1175 1
d1229 1
a1229 2
        SetCop  r0, CR_TLBFlush                 ; flush TLB (data is ignored)
        SetCop  r0, CR_IDCFlush                 ; and flush cache as well
d1241 2
d1248 1
a1248 1
        SetCop  r0, CR_Control
d1252 1
d1280 1
a1280 1
; 
d1286 1
a1286 1
;   
d1294 2
a1295 2
; 256Kbyte       4K           8*64kx4        A13,A20,A12,A18 fail, A21,A19 ok  
; 256Kbyte       4K          32*64kx1        A13,A20,A12,A18 fail, A21,A19 ok  
d1328 8
a1335 6
        LDRB    r0, [r12, #IOMD_ID0]
        CMP     r0, #&98
        LDRB    r0, [r12, #IOMD_ID1]
        CMPEQ   r0, #&5B
       ;MOVEQ   r3, #xxxx
        BNE     MemSizeIOMD                             ; NOT MORRIS assume Medusa hardware
d1340 5
d1347 1
d1593 14
d1610 2
d1633 14
d1864 3
d2085 1
a2085 1
        STR     r7, [r3, r5, LSL #2]            ; store replacment entry in L1 (not U,C or B)
d2087 1
a2087 1
        SetCop  r3, CR_TTabBase                 ; set up MMU pointer to L1
d2091 3
a2093 1
        SetCop  r7, CR_Domains                  ; only use domain 0
d2095 6
a2100 2
        SetCop  r7, CR_IDCFlush                 ; flush cache + TLB just in case
        SetCop  r7, CR_TLBFlush                 ; (data written is irrelevant)
a2101 1
        LDR     r7, =DefaultMMUControlRegister  ; turn on MMU, cache + write-buffer and select 32-bit configuration
d2103 1
a2103 1
        SetCop  r7, CR_Control
d2115 1
a2115 1
        SetCop  r7, CR_TLBFlush                 ; flush TLB (no need to flush cache, as there's nothing in it)
d2164 1
a2164 1
        MACRO                                                                                                                
a2204 1
 
d2206 9
d2224 1
d2238 1
a2238 1
        MemInitPagesL2  &8000, 0, 0, CursorChunkAddress, AP_Read, DRAMOffset_CursorChunk
d2241 12
d2257 1
d2343 2
a2344 1
; In    r0-r6 trashable
d2350 1
a2350 1
; This routine must work in 32-bit mode
d2355 2
a2356 2
TimeCPU ROUT
 [ MEMC_Type = "IOMD"
d2359 14
d2375 1
d2378 2
d2381 23
a2403 2
        LDR     r1, =&7FFE              ; 32K @@ 2MHz = ~16ms limit
        MOV     r3, #IOC
d2405 1
a2405 1
        MOV     r0, r1, LSR #8
d2407 3
a2409 3
        STRB    r0, [r3, #Timer1LH]
        LDR     r0, =ncpuloops
        STRB    r0, [r3, #Timer1GO]     ; start the timer NOW
a2411 1

d2413 1
a2413 1
        SUBS    r0, r0, #1              ; 1S
d2416 1
a2416 1
        STRB    r0, [r3, #Timer1LR]     ; latch count NOW
d2418 2
a2419 2
        LDRB    r0, [r3, #Timer1CH]
        ADD     r2, r2, r0, LSL #8      ; count after looping is ...
d2422 17
a2438 1
        MOV     r2, r2, LSR #1          ; IOC clock decrements at 2MHz
d2440 2
a2441 1
; Time CPU/MEMC Multiply time
d2443 13
a2455 1
        MOV     r4, #-1                 ; Gives worst case MUL
d2457 42
a2498 7
        MOV     r0, r1, LSR #8
        STRB    r1, [r3, #Timer1LL]
        STRB    r0, [r3, #Timer1LH]
        LDR     r0, =nmulloops
        STRB    r0, [r3, #Timer1GO]     ; start the timer NOW
        B       %FT20                   ; Looks superfluous, but is required
                                        ; to get nmulloops pipeline breaks
d2500 3
a2502 39
20
        MUL     r5, r4, r4              ; 1S + 16I
        MUL     r5, r4, r4              ; 1S + 16I
        SUBS    r0, r0, #1              ; 1S
        BNE     %BT20                   ; 1N + 2S

        STRB    r0, [r3, #Timer1LR]     ; latch count NOW
        LDRB    r4, [r3, #Timer1CL]
        LDRB    r0, [r3, #Timer1CH]
        ADD     r4, r4, r0, LSL #8      ; count after looping is ...

        SUB     r4, r1, r4              ; decrements !
        MOV     r4, r4, LSR #1          ; IOC clock decrements at 2MHz

        ORR     r9, r9, #1 :SHL: 8      ; set refresh on flyback
        STR     r9, [r9]                ; restore MEMC state a.s.a.p.

; In ROM - each cpu loop took 4R cycles @@ 8/f*500ns/cycle

        LDR     r0, =4*(8*500/1000)*ncpuloops*1000
        DivRem  r7, r0, r2, r1          ; r2 preserved
        MOV     r0, #&80                ; At 8 MHz and below, run fast ROMs
        LDR     r1, =8050               ; Over 8 MHz, need medium ROMs
        CMP     r7, r1
        MOVHI   r0, #&40
        LDR     r1, =13000              ; Over 13 MHz, need slowest ROMs
        CMP     r7, r1
        MOVHI   r0, #&00
        ORR     r9, r9, r0
        STR     r9, [r9]                ; Set ROM speed appropriately

 ASSERT ncpuloops = 8*nmulloops ; for given ratio cutoff <------------

        MOV     r4, r4, LSL #10         ; *1024 to get resolution on divide
        DivRem  r0, r4, r2, r1
        LDR     r1, =1100               ; Cutoff point; MEMC1 longer than this
        CMP     r0, r1
        ORRLO   r7, r7, #1 :SHL: 16     ; Note MEMC1a prescence
 ]
d2505 1
a2505 1
; Typical figures give (in ROM at 8MHz):
d2507 24
a2530 2
; MEMC1  2048 CPU, 2432 MEMC -> MUL ratio 1216
; MEMC1a 2048       864                    432
d2532 1
d2538 1
a2538 1
; in:   r0 = 0 (reason code for modify control register)
d2546 8
d2556 2
a2557 1
MMUCReason_ModifyControl        # 1
d2567 4
a2570 2
        CMP     r0, #MMUCReason_Unknown
        ADDCC   pc, pc, r0, LSL #2
d2573 1
a2577 1
        Push    lr
d2579 1
a2580 1
 ]
d2584 5
a2588 1
MMUControl_ModifyControl ENTRY "r3, r4"
d2592 1
d2595 4
d2602 12
d2615 1
a2615 1

d2617 32
a2648 2
        TST     lr, #MMUC_C             ; if cache turning on
        SetCop  r0, CR_IDCFlush, NE     ; then flush cache before we do it
d2650 12
a2661 5
        SetCop  r2, CR_Control          ; write to control register

        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off
        SetCop  r0, CR_IDCFlush, NE     ; then flush cache afterwards
d2663 26
a2688 2
        TEQP    r4, #0                  ; restore IRQ state
        EXIT
d2781 1
d2816 1
d2843 16
a2858 2
        SUBNE   r6, r7, r9, LSL #2              ; if up then subtract offset
        ADDEQ   r6, r7, r9, LSL #2              ; else add it
d2862 1
a2862 1
        MOVEQ   r6, r7                          ; if not wb, original base register is OK
d3033 29
a3061 1
 [ LateAborts
d3071 3
a3073 1
 |
a3080 1
 ]
d3082 1
d3087 11
a3097 4
 [ LateAborts
        SUB     r0, r6, r0                      ; compute adjusted base register
        STR     r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all
 ]
d3164 3
d3179 3
d3323 3
d3328 1
d3330 1
a3330 1
; it's a store to memory (may be a vector write)
d3343 24
a3366 1
        SetMode SVC32_mode, lr                          ; go into SVC32 so we can poke vector area
d3368 1
d3392 1
a3393 1

d3402 1
d3497 281
@


4.1.7.1
log
@NCOS 1.06 Imported from Zip drive
@
text
@a56 11
;
; 17-Jun-96	BAR	Change speed settings for the second bank of ROM space.
; 09-Jul-96     BAR     Improve IOMD ID vsn code - two places.
;                       Change ROM Speed settings for 7500FE and non-7500FE parts.
; 25-Jul-96	BAR	Correct bug in video bandwidth code, wrong label used.
; 16-Aug-96	JRH	Programming of 2nd ROM bank (IOMD ROMCR1 register):
;				reinstated ExtROMSupport code, added CanLiveOnROMCard code
;			MemInitTable:
;				If ExtROMSupport: added assertion that ImageSize <= 4096 
;				and maps 4MB of each ROM bank.
;				Otherwise: always maps 8MB of ROM space independant of ImageSize
a523 3
	LTORG


a534 1
;
d541 1
a541 1
  [ MorrisSupport
d546 1
a546 1
; anyway.
d550 6
a555 19
        LDRB    r2,[r12,#IOMD_ID1]	; load r2 with IOMD ID high byte
        LDRB    r0,[r12,#IOMD_ID0]	; load r0 with IOMD ID low byte
        ORR     r0,r0,r2, LSL #8	; Or r0 and r2 - shifted left 8, put in r0
        LDR     r2,=IOMD_7500		; get Ref IOMD ID code for IOMD in a 7500
        CMPS    r0,r2                   ; check for IOMD ID Code for IOMD in a 7500
	BEQ	init7500cpu		; If equal, got to init7500cpu

        LDRNE   r2,=IOMD_7500FE		; If not, get ID code for IOMD in a 7500FE
        CMPNES  r0,r2			; If not, check for IOMD ID Code for IOMD in a 7500FE
        BNE     MedusaInit              ; NOT MORRIS assume Medusa hardware


init7500FEcpu
; Here bceause its an ARM7500 'FE' variant
; Program the CPU, Memory and IO clock prescalers
; Set the prescalers to :-
;	CPUCLK divide by 2
;	MEMCLK divide by 1
;	IOCLK  divide by 1
d557 2
a558 2
	MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
        STRB    r0, [r12, #IOMD_CLKCTL] ; initialise all the prescalers.
d560 1
a560 1
; Set ROM speed, take care to preserve 16-bit mode bit...
d562 1
a562 59
; According to BSiddle on the 15-May-96, Omega will use burst mode roms: use 93nS burst, 156nS initial.
; According to TDbson on the 09-Jul-96, Omega will handle ROMS up to 120nS and 70nS.
; Thus the ROM speed should be initilised to :-
; Half Speed or H bit, clear, which is ON ! : Half the delays, thus DOUBLE all clock ticks.
; Non-Sequental delay : 10 Ticks : Half speed on, so select 5 ticks (5*2)
; Burst delay         :  8 Ticks : Half speed on, so select 4 ticks (4*2)
; Remember the Memory clock on Omega is faster than on previous products.
; The fast flash devices used for Omega testing should be able to cope even
; though they aren't burst devices.
        LDRB    r0, [r12, #IOMD_ROMCR0]         ; Get contents of ROMCR0 in to r0
        AND     r0, r0, #&40                    ; clear all but the 16-bit mode flag
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_4
        STRB    r0, [r12, #IOMD_ROMCR0]         ; Prog. the reg.s

; Program the 2nd ROM bank
  [ ExtROMSupport
;   Unless we're actually running from the 2nd ROM bank (CanLiveOnROMCard), we don't know how fast
;   the extension ROM in the 2nd bank goes, so program it for a slow default speed
    [ CanLiveOnROMCard
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank?
        STRNEB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
      [ ExtROMis16bit
	MOVEQ	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOVEQ	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STREQB	r0, [r12, #IOMD_ROMCR1]
    |;CanLiveOnROMCard
      [ ExtROMis16bit
	MOV	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOV	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STRB	r0, [r12, #IOMD_ROMCR1]
    ];CanLiveOnROMCard

  |;ExtROMSupport
    [ CanLiveOnROMCard
        STRB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
    |
        STRB	r0, [r12, #IOMD_ROMCR1]		; 2nd bank unused: program it the same anyway
    ]
  ];ExtROMSupport

; Now program ASTCR to add wait states, since MEMCLK is fast relative to IOCLK

	MOV	r0, #IOMD_ASTCR_WaitStates
	STRB	r0, [r12, #IOMD_ASTCR]

	B	init7500cpu_common		; branch to common init code.
;

init7500cpu
; Here because its an ARM7500 variant - NON 'FE' device.
; Program the CPU, Memory and IO clock prescalers
; Set the prescalers to :-
;	CPUCLK divide by 1
;	MEMCLK divide by 1
;	IOCLK  divide by 1
d566 1
a570 48
; According to BSiddle on 09-Jul-96 - Omenga will need to set the burst speed to 4 ticks from 3 ticks.
; Thus the ROM speed should be initilised to :-
; Half Speed or H bit, Set, which is OFF ! : Don't half the delays.
; Non-Sequental delay :  5 Ticks : Half speed off, so select 5 ticks
; Burst delay         :  4 Ticks : Half speed off, so select 4 ticks
; The fast EPROMS used for Kryten testing should be able to cope even though
; they aren't burst devices

        LDRB    r0, [r12, #IOMD_ROMCR0]          ; Get contents of ROMCR0 in to r0
        AND     r0, r0, #&40                    ; clear all but the 16-bit mode flag
        ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_4
        STRB    r0, [r12, #IOMD_ROMCR0]          ; Prog. the reg.s

; Program the 2nd ROM bank
  [ ExtROMSupport
;   Unless we're actually running from the 2nd ROM bank (CanLiveOnROMCard), we don't know how fast
;   the extension ROM in the 2nd bank goes, so program it for a slow default speed
    [ CanLiveOnROMCard
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank?
        STRNEB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
      [ ExtROMis16bit
	MOVEQ	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOVEQ	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STREQB	r0, [r12, #IOMD_ROMCR1]
    |;CanLiveOnROMCard
      [ ExtROMis16bit
	MOV	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOV	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STRB	r0, [r12, #IOMD_ROMCR1]
    ];CanLiveOnROMCard

  |;ExtROMSupport
    [ CanLiveOnROMCard
        STRB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
    |
        STRB	r0, [r12, #IOMD_ROMCR1]		; 2nd bank unused: program it the same anyway
    ]
  ];ExtROMSupport

; Now program ASTCR to *NOT* add wait states, since MEMCLK is slow relative to IOCLK

	MOV	r0, #IOMD_ASTCR_Minimal
	STRB	r0, [r12, #IOMD_ASTCR]

d572 1
d574 16
a589 2
init7500cpu_common
; Common setup requirments for BOTH 7500 and 7500FE.
d591 1
a591 1
; MORRIS doesn't support VRAM. Kryten has same DRAM speed as Medusa
d602 2
a603 1
   [ Japanese16BitSound
d606 1
a606 1
   ]
d610 1
a610 1
  ] ; MorrisSupport
d612 1
a612 1
  [ Simulator
d615 3
a617 3
  |
   [ RISCPCBurstMode
    [ 1 = 1
d625 1
a625 1
    |
d628 2
a629 2
    ]
   |
d631 2
a632 2
   ]
  ] ; Simulator
a633 1
  [ :LNOT: ExtROMis16bit
a634 4
  |
        MOV	r0, #IOMD_ROMCR_16bit + IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff
	STRB    r0, [r12, #IOMD_ROMCR1]		; 16bit 156.25nS noburst (Lowest common denominator)
  ]
d645 1
a645 1
 | ; MEMC_Type = "IOMD"
d648 1
a648 2
 ] ; MEMC_Type = "IOMD"

d763 1
a763 1
;
d769 1
a769 1
;
d777 2
a778 2
; 256Kbyte       4K           8*64kx4        A13,A20,A12,A18 fail, A21,A19 ok
; 256Kbyte       4K          32*64kx1        A13,A20,A12,A18 fail, A21,A19 ok
d811 6
a816 8
        LDRB    r0, [r12, #IOMD_ID0]	; load r1 with IOMD ID high byte
        LDRB    r1, [r12, #IOMD_ID1]	; load r0 with IOMD ID low byte
        ORR     r0,r0,r1,LSL#8		; Or r0 and r1, shifted left 8, put in r0
        LDR     r1,=IOMD_Original       ; get Ref IOMD ID code - original
        CMPS    r0,r1                   ; check for IOMD ID Code - original
        BEQ     MemSizeIOMD             ; Not ID Code - original,
                                        ;    therefore jump to Medusa hardware code
                                        ;    else fall through to Morris code.
a820 5
 	LDR	r1, =IOMD_7500FE
	TEQ	r0, r1					; are we on FE part?
	ORREQ	r11, r11, #IOMD_DRAMWID_EDO_Enable :OR: IOMD_DRAMWID_RASCAS_3 :OR: IOMD_DRAMWID_RASPre_3
							; if so, then enable EDO and slower RASCAS and RASPre times

d1067 2
a1068 7
	LDRB	r4, [r14, #IOMD_ID0]
	LDRB	r7, [r14, #IOMD_ID1]
	ORR	r4, r4, r7, LSL #8
	LDR	r7, =IOMD_7500FE			; if FE part, then assume EDO DRAM
	TEQ	r4, r7
	LDREQ	r4, =80000000				; so allow 80E6 bytes/s
	LDRNE	r4, =44000000				; else only allow 44E6 bytes/s
d1307 3
a1309 4
	ADRL	r4, ROM				; use PCrelative addressing to get to start of image
	TEQ	r4, #PhysROM			; then see if it's the normal ROM address
	TEQNE	r4, #PhysExtROM			; or if it's the 2nd ROM bank
        BEQ     %FT55                           ; if so, then we're not soft-loaded
d1601 1
a1601 1
        MACRO
d1642 1
d1644 1
a1644 2
  [ ExtROMSupport							; System build option
	ASSERT (OSROM_ImageSize <= 4096)	; No room for extension ROMs with an 8MB OS image
d1646 7
a1652 4
        MemInitSection   4, 1, 1, 1, &03C00000, AP_Read, &01000000      ; Extension ROM
  |
        MemInitROMs      8, 1, 1, 1, &03800000, AP_Read			; ROM (1st or 2nd bank)
  ]
@


4.1.7.2
log
@Now uses global variable "ROMSpeedNormal".
@
text
@d601 1
a601 5
    [ ROMSpeedNormal
        ORR     r0, r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
    |
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
    ]
a605 1

d609 16
a624 21
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank? Program the 2nd bank the same as the 1st if so
	STRNE   r0, [r12, #IOMD_ROMCR1]
    ]
    [ ExtROMis16bit
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    |
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    ]
    [ CanLiveOnROMCard
        STREQB	r0, [r12, #IOMD_ROMCR1]
    |
        STRB	r0, [r12, #IOMD_ROMCR1]
    ]
a626 1

a631 1

d666 1
a666 5
    [ ROMSpeedNormal
        ORR     r0, r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
    |
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_NSTicks_5 :OR: IOMD_ROMCR_BTicks_4
    ]
a670 1

d674 16
a689 21
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank? Program the 2nd bank the same as the 1st if so
	STRNE   r0, [r12, #IOMD_ROMCR1]
    ]
    [ ExtROMis16bit
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_16bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    |
     [ ROMSpeedNormal
        MOV     r0, #IOMD_ROMCR_Normal :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     |
        MOV     r0, #IOMD_ROMCR_HalfSpeed :OR: IOMD_ROMCR_32bit :OR: IOMD_ROMCR_NSTicks_7 :OR: IOMD_ROMCR_BurstOff
     ]
    ]
    [ CanLiveOnROMCard
        STREQB	r0, [r12, #IOMD_ROMCR1]
    |
        STRB	r0, [r12, #IOMD_ROMCR1]
    ]
a691 1

a696 1

@


4.1.7.3
log
@Speed up Boca CPU clock
@
text
@d581 1
a581 1
;	CPUCLK divide by 2 unless FECPUSpeedNormal set
a584 3
 [ FECPUSpeedNormal
	MOV     r0, #IOMD_CLKCTL_CpuclkNormal + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
 |
a585 1
 ]
@


4.1.5.1
log
@Import from SrcFiler
@
text
@a56 11
;
; 17-Jun-96	BAR	Change speed settings for the second bank of ROM space.
; 09-Jul-96     BAR     Improve IOMD ID vsn code - two places.
;                       Change ROM Speed settings for 7500FE and non-7500FE parts.
; 25-Jul-96	BAR	Correct bug in video bandwidth code, wrong label used.
; 16-Aug-96	JRH	Programming of 2nd ROM bank (IOMD ROMCR1 register):
;				reinstated ExtROMSupport code, added CanLiveOnROMCard code
;			MemInitTable:
;				If ExtROMSupport: added assertion that ImageSize <= 4096 
;				and maps 4MB of each ROM bank.
;				Otherwise: always maps 8MB of ROM space independant of ImageSize
a523 3
	LTORG


a534 1
;
d541 1
a541 1
  [ MorrisSupport
d546 1
a546 1
; anyway.
d550 6
a555 19
        LDRB    r2,[r12,#IOMD_ID1]	; load r2 with IOMD ID high byte
        LDRB    r0,[r12,#IOMD_ID0]	; load r0 with IOMD ID low byte
        ORR     r0,r0,r2, LSL #8	; Or r0 and r2 - shifted left 8, put in r0
        LDR     r2,=IOMD_7500		; get Ref IOMD ID code for IOMD in a 7500
        CMPS    r0,r2                   ; check for IOMD ID Code for IOMD in a 7500
	BEQ	init7500cpu		; If equal, got to init7500cpu

        LDRNE   r2,=IOMD_7500FE		; If not, get ID code for IOMD in a 7500FE
        CMPNES  r0,r2			; If not, check for IOMD ID Code for IOMD in a 7500FE
        BNE     MedusaInit              ; NOT MORRIS assume Medusa hardware


init7500FEcpu
; Here bceause its an ARM7500 'FE' variant
; Program the CPU, Memory and IO clock prescalers
; Set the prescalers to :-
;	CPUCLK divide by 2
;	MEMCLK divide by 1
;	IOCLK  divide by 1
d557 2
a558 2
	MOV     r0, #IOMD_CLKCTL_CpuclkHalf + IOMD_CLKCTL_MemclkNormal + IOMD_CLKCTL_IOclkNormal
        STRB    r0, [r12, #IOMD_CLKCTL] ; initialise all the prescalers.
d560 1
a560 1
; Set ROM speed, take care to preserve 16-bit mode bit...
d562 1
a562 59
; According to BSiddle on the 15-May-96, Omega will use burst mode roms: use 93nS burst, 156nS initial.
; According to TDbson on the 09-Jul-96, Omega will handle ROMS up to 120nS and 70nS.
; Thus the ROM speed should be initilised to :-
; Half Speed or H bit, clear, which is ON ! : Half the delays, thus DOUBLE all clock ticks.
; Non-Sequental delay : 10 Ticks : Half speed on, so select 5 ticks (5*2)
; Burst delay         :  8 Ticks : Half speed on, so select 4 ticks (4*2)
; Remember the Memory clock on Omega is faster than on previous products.
; The fast flash devices used for Omega testing should be able to cope even
; though they aren't burst devices.
        LDRB    r0, [r12, #IOMD_ROMCR0]         ; Get contents of ROMCR0 in to r0
        AND     r0, r0, #&40                    ; clear all but the 16-bit mode flag
        ORR     r0, r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_4
        STRB    r0, [r12, #IOMD_ROMCR0]         ; Prog. the reg.s

; Program the 2nd ROM bank
  [ ExtROMSupport
;   Unless we're actually running from the 2nd ROM bank (CanLiveOnROMCard), we don't know how fast
;   the extension ROM in the 2nd bank goes, so program it for a slow default speed
    [ CanLiveOnROMCard
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank?
        STRNEB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
      [ ExtROMis16bit
	MOVEQ	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOVEQ	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STREQB	r0, [r12, #IOMD_ROMCR1]
    |;CanLiveOnROMCard
      [ ExtROMis16bit
	MOV	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOV	r0, #IOMD_ROMCR_HalfSpeed + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STRB	r0, [r12, #IOMD_ROMCR1]
    ];CanLiveOnROMCard

  |;ExtROMSupport
    [ CanLiveOnROMCard
        STRB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
    |
        STRB	r0, [r12, #IOMD_ROMCR1]		; 2nd bank unused: program it the same anyway
    ]
  ];ExtROMSupport

; Now program ASTCR to add wait states, since MEMCLK is fast relative to IOCLK

	MOV	r0, #IOMD_ASTCR_WaitStates
	STRB	r0, [r12, #IOMD_ASTCR]

	B	init7500cpu_common		; branch to common init code.
;

init7500cpu
; Here because its an ARM7500 variant - NON 'FE' device.
; Program the CPU, Memory and IO clock prescalers
; Set the prescalers to :-
;	CPUCLK divide by 1
;	MEMCLK divide by 1
;	IOCLK  divide by 1
d566 1
a570 48
; According to BSiddle on 09-Jul-96 - Omenga will need to set the burst speed to 4 ticks from 3 ticks.
; Thus the ROM speed should be initilised to :-
; Half Speed or H bit, Set, which is OFF ! : Don't half the delays.
; Non-Sequental delay :  5 Ticks : Half speed off, so select 5 ticks
; Burst delay         :  4 Ticks : Half speed off, so select 4 ticks
; The fast EPROMS used for Kryten testing should be able to cope even though
; they aren't burst devices

        LDRB    r0, [r12, #IOMD_ROMCR0]          ; Get contents of ROMCR0 in to r0
        AND     r0, r0, #&40                    ; clear all but the 16-bit mode flag
        ORR     r0, r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_NSTicks_5 + IOMD_ROMCR_BTicks_4
        STRB    r0, [r12, #IOMD_ROMCR0]          ; Prog. the reg.s

; Program the 2nd ROM bank
  [ ExtROMSupport
;   Unless we're actually running from the 2nd ROM bank (CanLiveOnROMCard), we don't know how fast
;   the extension ROM in the 2nd bank goes, so program it for a slow default speed
    [ CanLiveOnROMCard
	TST	pc, #PhysExtROM			; are we running out of the 2nd ROM bank?
        STRNEB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
      [ ExtROMis16bit
	MOVEQ	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOVEQ	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STREQB	r0, [r12, #IOMD_ROMCR1]
    |;CanLiveOnROMCard
      [ ExtROMis16bit
	MOV	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_16bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      |
	MOV	r0, #IOMD_ROMCR_Normal + IOMD_ROMCR_32bit + IOMD_ROMCR_NSTicks_7 + IOMD_ROMCR_BurstOff
      ]
	STRB	r0, [r12, #IOMD_ROMCR1]
    ];CanLiveOnROMCard

  |;ExtROMSupport
    [ CanLiveOnROMCard
        STRB	r0, [r12, #IOMD_ROMCR1]		; Program the 2nd bank the same as the 1st
    |
        STRB	r0, [r12, #IOMD_ROMCR1]		; 2nd bank unused: program it the same anyway
    ]
  ];ExtROMSupport

; Now program ASTCR to *NOT* add wait states, since MEMCLK is slow relative to IOCLK

	MOV	r0, #IOMD_ASTCR_Minimal
	STRB	r0, [r12, #IOMD_ASTCR]

d572 1
d574 16
a589 2
init7500cpu_common
; Common setup requirments for BOTH 7500 and 7500FE.
d591 1
a591 1
; MORRIS doesn't support VRAM. Kryten has same DRAM speed as Medusa
d602 2
a603 1
   [ Japanese16BitSound
d606 1
a606 1
   ]
d610 1
a610 1
  ] ; MorrisSupport
d612 1
a612 1
  [ Simulator
d615 3
a617 3
  |
   [ RISCPCBurstMode
    [ 1 = 1
d625 1
a625 1
    |
d628 2
a629 2
    ]
   |
d631 2
a632 2
   ]
  ] ; Simulator
a633 1
  [ :LNOT: ExtROMis16bit
a634 4
  |
        MOV	r0, #IOMD_ROMCR_16bit + IOMD_ROMCR_Normal + IOMD_ROMCR_156 + IOMD_ROMCR_BurstOff
	STRB    r0, [r12, #IOMD_ROMCR1]		; 16bit 156.25nS noburst (Lowest common denominator)
  ]
d645 1
a645 1
 | ; MEMC_Type = "IOMD"
d648 1
a648 2
 ] ; MEMC_Type = "IOMD"

d763 1
a763 1
;
d769 1
a769 1
;
d777 2
a778 2
; 256Kbyte       4K           8*64kx4        A13,A20,A12,A18 fail, A21,A19 ok
; 256Kbyte       4K          32*64kx1        A13,A20,A12,A18 fail, A21,A19 ok
d811 6
a816 8
        LDRB    r0, [r12, #IOMD_ID0]	; load r1 with IOMD ID high byte
        LDRB    r1, [r12, #IOMD_ID1]	; load r0 with IOMD ID low byte
        ORR     r0,r0,r1,LSL#8		; Or r0 and r1, shifted left 8, put in r0
        LDR     r1,=IOMD_Original       ; get Ref IOMD ID code - original
        CMPS    r0,r1                   ; check for IOMD ID Code - original
        BEQ     MemSizeIOMD             ; Not ID Code - original,
                                        ;    therefore jump to Medusa hardware code
                                        ;    else fall through to Morris code.
a820 5
 	LDR	r1, =IOMD_7500FE
	TEQ	r0, r1					; are we on FE part?
	ORREQ	r11, r11, #IOMD_DRAMWID_EDO_Enable :OR: IOMD_DRAMWID_RASCAS_3 :OR: IOMD_DRAMWID_RASPre_3
							; if so, then enable EDO and slower RASCAS and RASPre times

d1067 2
a1068 7
	LDRB	r4, [r14, #IOMD_ID0]
	LDRB	r7, [r14, #IOMD_ID1]
	ORR	r4, r4, r7, LSL #8
	LDR	r7, =IOMD_7500FE			; if FE part, then assume EDO DRAM
	TEQ	r4, r7
	LDREQ	r4, =80000000				; so allow 80E6 bytes/s
	LDRNE	r4, =44000000				; else only allow 44E6 bytes/s
d1307 3
a1309 4
	ADRL	r4, ROM				; use PCrelative addressing to get to start of image
	TEQ	r4, #PhysROM			; then see if it's the normal ROM address
	TEQNE	r4, #PhysExtROM			; or if it's the 2nd ROM bank
        BEQ     %FT55                           ; if so, then we're not soft-loaded
d1601 1
a1601 1
        MACRO
d1642 1
d1644 1
a1644 2
  [ ExtROMSupport							; System build option
	ASSERT (OSROM_ImageSize <= 4096)	; No room for extension ROMs with an 8MB OS image
d1646 7
a1652 4
        MemInitSection   4, 1, 1, 1, &03C00000, AP_Read, &01000000      ; Extension ROM
  |
        MemInitROMs      8, 1, 1, 1, &03800000, AP_Read			; ROM (1st or 2nd bank)
  ]
@


4.1.3.1
log
@Import from cleaned 370 CD
@
text
@a16 1

a28 5
;now effectively codes for ARM 6 onwards (6,7,8,A, where A = StrongARM) - MJS, 24-01-96

;but ARM8 not done yet! (29-01-96)


d77 1
a77 1
FixedAreasL2Size        *       96*1024        ; amount of L2 to cover fixed areas, excluding free pool   
d85 5
a89 59

; - address for virtual area for StrongARM data cache cleaning (32k, for two 16k areas)
; - the two areas are used in strict rotation for each full clean, so that we can do a full
;   clean (and not flush) with interrupts on
; - the address must be aligned such that EOR with 16*1024 flipflops between the two addresses
ARMA_Cleaners_address  * 31*1024*1024 + 64*1024


arm600stuff_before_align
         ALIGN   4096     ;align to page boundary to allow for easy ROMpatch

arm600stuff_startofstuff
  ! 0, "-- start of (4k aligned) ARM600+ stuff at ":CC::STR:(arm600stuff_startofstuff)

;note that we use the R bit if supported (not 610), so that we can write protect ROM space
;fully (user and supervisor)
;
ARM_default_MMU_CR_table
;
;ARM 6              SBLDPWCAM
         DCD  2_0000001111101
;
;ARM 7            FRSB1DPWCAM
         DCD  2_0011001111101
;
;ARM 8           Z0RSB111WCAM
         DCD  2_0101001111101
;
;ARM 9 ??
         DCD  0
;
  [ SAWBbroken  ;write buffer broken! - turn off write buffer (safe-ish - safer would turn off DC as well)
;StrongARM      I00RSB111WCAM
         DCD  2_1001001110101
  |
;StrongARM      I00RSB111WCAM
         DCD  2_1001001111101
  ]
;


ARM_cacheoff_MMU_CR_table
;
;ARM 6              SBLDPWCAM
         DCD  2_0000001110001
;
;ARM 7            FRSB1DPWCAM
         DCD  2_0011001110001
;
;ARM 8           Z0RSB111WCAM
         DCD  2_0001001110001
;
;ARM 9 ??
         DCD  0
;
;StrongARM      I00RSB111WCAM
         DCD  2_0001001110001
;

d106 1
a106 1
SetDAG  ENTRY   "r0-r1,r12"
a121 19

        MOV     r1, #0
        LDRB    r1, [r1, #LCD_Active]
        TST     r1, #&80
        EXIT    EQ                              ;Exit if not a dual-panel LC display

        ;Otherwise, we are going to have to update VIDINITB too...
        MOV     r1, #VduDriverWorkSpace
        LDR     r1, [r1, #ScreenSize]
        BIC     r0, r0, #IOMD_DMA_L_Bit
        ADD     r0, r0, r1, LSR #1              ;R0 = VIDINIT+(screensize/2)
        CMP     r0, r14                         ;If VIDINITB>=VEnd...
        ORREQ   r0, r0, #IOMD_DMA_L_Bit         ;Set the L bit if =
        SUBGT   r0, r0, r14                     ;VIDINITB=VIDINITB-VEnd
        MOVGT   r14, #0
        LDRGT   r1, [r14, #VStartSoftCopy]
        ADDGT   r0, r0, r1                      ;VIDINITB=VIDINITB+VStart
        SUBGT   r0, r0, #16                     ;Quad word correction. /** You are not expected to understand this **/ :-)
        STR     r0, [r12, #IOMD_VIDINITB]
a127 2
        MOV     r14, #0
        STR     r0, [r14, #VStartSoftCopy]
a145 8

        MOV     r14, #0
        LDRB    r14, [r14, #LCD_Active]
        TST     r14, #&80
        EXIT    EQ                              ; Not a dual-panel LCD so no need to hang around....

        ;Check whether we need to update VIDINITB or not...

a299 8
;if we can assume no code above 64Mb (ie. 26bit code space), big optimise for StrongARM
        GBLL    AssumeNoCodeAbove64Mb
AssumeNoCodeAbove64Mb  SETL    {TRUE}

;if we just use sledgehammer approach anyway
        GBLL    AlwaysSledgehammer
AlwaysSledgehammer SETL {FALSE}

d328 1
a328 94
;internal entry point for updating L2PT entry
;
; entry: r0 = new L2PT value, r1 -> L2PT, r3 = logical address (4k aligned), r11 = PPL
;
; exit: r0,r1,r4,r6 corrupted
;
BangL2PT                                        ; internal entry point used only by BangCamUpdate
  [ AlwaysSledgehammer
        B       BangL2PT_sledgehammer
  |
        TST     r11, #DynAreaFlags_DoublyMapped
        BNE     BangL2PT_sledgehammer           ;if doubly mapped, don't try to be clever
  ]
        STR     r0, [r1, r3, LSR #10]           ;update L2PT
        ARM_read_ID r4
        AND     r4,r4,#&F000                    ;ARM ID nibble in r4
        CMP     r0,#0     
        BEQ     BangL2PT_mapout                 ;the update is a map out => cache(s) may need clean/flush
;else update is a map in (and nothing should be there at the moment) => no cache worries
        CMP     r4,#&A000
        BEQ     BangL2PT_mapin_StrongARM
;else assume ARM 6,7
        ARM67_flush_TLBentry r3                 ;flush TLB entry for this page
        MOV     pc,lr

BangL2PT_mapin_StrongARM
        ARMA_drain_WB                           ;in case L2PT entry itself is in a bufferable area
        ARMA_flush_DTLBentry r3                 ;flush data TLB entry for this page
  [ AssumeNoCodeAbove64Mb
        CMP     r3,#64*1024*1024                ;if logical address above 64Mb, assume no code (26 bit)
        MOVHS   pc,lr
  ]
        ARMA_flush_ITLB                         ;but if there is code, we must flush instruction TLB
        MOV     pc,lr

BangL2PT_mapout
        CMP     r4,#&A000
        BEQ     BangL2PT_mapout_StrongARM
;else assume ARM 6,7
        TST     r11,#DynAreaFlags_NotCacheable
        ARM67_flush_cache EQ                    ;flush instruction/data cache if necessary
        ARM67_flush_TLBentry r3                 ;flush TLB entry for this page
        MOV     pc,lr

BangL2PT_mapout_StrongARM
        TST     r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_mapin_StrongARM        ;if NotCacheable, no flush needed (ie. same as mapin)
;note that we are cleaning *after* remapping, so relying on StrongARM writebacks using physical address
        MOV     r4,r3
        ADD     r6,r3,#4*1024                   ;clean/flush data cache over 4k range of page

  [ SAcleanflushbroken        ; ARMA_cleanflush_DCentry instruction seems to be ineffective
01
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        ARMA_clean_DCentry r4
        ARMA_flush_DCentry r4
        ADD     r4,r4,#32
        CMP     r4,r6
        BLO     %BT01
  |
01
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        ARMA_cleanflush_DCentry r4
        ADD     r4,r4,#32
        CMP     r4,r6
        BLO     %BT01
  ]

        ARMA_drain_WB
        ARMA_flush_DTLBentry r3                 ;flush data TLB entry for this page
  [ AssumeNoCodeAbove64Mb
        CMP     r3,#64*1024*1024                ;if logical address above 64Mb, assume no code (26 bit)
        MOVHS   pc,lr
  ]
        ARMA_flush_IC WithoutNOPs
        MOV     r0,r0                           ;NOPs to ensure 4 instructions before return, after IC flush
        MOV     r0,r0
        ARMA_flush_ITLB
        MOV     pc,lr

BangL2PT_sledgehammer
d344 2
a345 8
        ARM_read_ID r4
        AND     r4,r4,#&F000
        CMP     r4,#&A000
        BEQ     BangL2PT_sledgehammer_StrongARM
;else assume ARM 6,7
        TST     r11,#DynAreaFlags_NotCacheable
        ARM67_flush_cache EQ
        ARM67_flush_TLB
a346 22
BangL2PT_sledgehammer_StrongARM
        TST     r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_sledgehammer_StrongARM_NotC

        MOV     r4,#ARMA_Cleaner_flipflop
        LDR     r0,[r4]                   ;last cleaner address
        EOR     r0,r0,#16*1024            ;flip it (r0 -> cleaner address to use)
        STR     r0,[r4]

        ARMA_clean_DC r0,r4,r6            ;effectively, clean/flush DC fully with respect to non-interrupt stuff
        ARMA_drain_WB
        ARMA_flush_IC WithoutNOPs         ;do *not* flush DC - there may be some stuff from interrupt routines
        MOV     r0,r0                     ;NOPs to ensure 4 instructions before return, after IC flush
        MOV     r0,r0
        ARMA_flush_TLBs
        MOV     pc,lr

BangL2PT_sledgehammer_StrongARM_NotC    ;no flush necessary if NotCacheable
        ARMA_drain_WB
        ARMA_flush_TLBs
        MOV     pc,lr

a391 1
        Push    "r10"
a396 5
        MOV     r10, #0
        LDRB    r10, [r10, #LCD_Active]
        TST     r10, #&80
        ORRNE   r11, r11, #IOMD_VIDCR_Dup                       ;Set bit 7 if we're on an LCD dual-panel display
        Pull    "r10"
a434 3
     GBLL ClearPhysRAMspeedup
ClearPhysRAMspeedup SETL {TRUE}

a435 33

    [ :LNOT: RunningOnEmul

;StrongARM - We will make the logical representation of physical space for RAM temporarily bufferable
;            (on any ARM). This is harmless for ARM 6,7 but a big speed benefit for StrongARM (which
;            won't burst write in non bufferable areas).

        LDR     r0,  =L1PT
        LDR     r12, =PhysRamTable
        ADD     r4, r12, #PhysRamTableEnd-PhysRamTable  ; r4 -> end of table
02
        LDMIA   r12!, {r10, r11}                        ; load next address, size
        SUB     r11,r11,#&100000                        ; 1 Mb will be done on first L1PT update
        ORR     r10, r10, #PhysSpace                    ; point to logical representation of physical space
        ADD     r1,r0,r10,LSR #(20-2)                   ; L1PT address for same
04
        LDR     r2,[r1]
        ORR     r2,r2,#4                                ; bufferable bit
        STR     r2,[r1],#4
        SUBS    r11,r11,#&100000                        ; another 1 Mb done
        BPL     %BT04
        TEQ     r12, r4                                 ; have we done all areas?
        BNE     %BT02

;now let us do the clear
  [ ClearPhysRAMspeedup
        MOV     r0,#48                                  ;we can preserve r7-r9,r13 at logical address 48..63
        STMIA   r0,{r7-r9,r13}
        MOV     r7,  #0
        MOV     r8,  #0
        MOV     r9,  #0
        MOV     r13, #0
  ]
a455 3
  [ ClearPhysRAMspeedup
        STMNEIA r10!, {r0-r3,r7-r9,r13}
  |
a456 1
  ]
a469 30
  [ ClearPhysRAMspeedup
        MOV     r12,#48 
        LDMIA   r12,{r7-r9,r13}                         ;restore
        MOV     r12,#32                                 ;clear our speed up workspace
        STMIA   r12!,{r0-r3}
        STMIA   r12!,{r0-r3}
  ]

;StrongARM - now let us remove bufferable status of logical representation of physical space (perhaps we could
;            leave it? not sure at the mo.)

        LDR     r0,  =L1PT
        LDR     r12, =PhysRamTable
        ADD     r4, r12, #PhysRamTableEnd-PhysRamTable  ; r4 -> end of table
32
        LDMIA   r12!, {r10, r11}                        ; load next address, size
        SUB     r11,r11,#&100000                        ; 1 Mb will be done on first L1PT update
        ORR     r10, r10, #PhysSpace                    ; point to logical representation of physical space
        ADD     r1,r0,r10,LSR #(20-2)                   ; L1PT address for same
34
        LDR     r2,[r1]
        BIC     r2,r2,#4                                ; bufferable bit
        STR     r2,[r1],#4
        SUBS    r11,r11,#&100000                        ; another 1 Mb done
        BPL     %BT34
        TEQ     r12, r4                                 ; have we done all areas?
        BNE     %BT32

    ] ;RunningOnEmul

a470 1

a473 4
        ARM_number r0
        SUB     r0,r0,#6
        ADRL    r1,ARM_default_MMU_CR_table
        LDR     r1,[r1,r0,LSL #2]
d475 2
a476 1
        STR     r1, [r0, #MMUControlSoftCopy]           ; set up MMU soft copy
a479 2
        LTORG

a515 4
 [ ClearPhysRAMspeedup ; allow some workspace to speed up ClearPhysRAM  Mike says whoosh
        MakeSkipTable   1, DRAMOffset_PageZero + 0, 64  ; skip 1st 32 bytes of LogRAM, so IRQs work!
                                                        ; additional 32 bytes for workspace
 |
a516 1
 ]
d546 1
a546 1
; anyway.
d575 2
a576 3
        AND     r0, r0, #&40            ; clear all but 16-bit mode bit, giving us the slowest ROMs possible
 [ :LNOT: AutoSpeedROMS
  [ NormalSpeedROMS
d582 1
a582 1
  |
a586 1
  ]
d591 1
a591 1
; MORRIS doesn't support VRAM. Kryten has same DRAM speed as Medusa
a652 3
;mjs - must now (if not before) be true, since 26 bit configuration does not exist in Architecture 4 (ARM 810/StrongARM)
        ASSERT ResetIndirected

a660 1

d714 2
a715 1
        ARM_flush_cacheandTLB r0
a726 2

;mjs - the MMU off values are ok for all ARMs; some will ignore P,D,L bits
d732 1
a732 1
        ARM_write_control r0
a735 1
        LTORG
d763 1
a763 1
;
d769 1
a769 1
;
d777 2
a778 2
; 256Kbyte       4K           8*64kx4        A13,A20,A12,A18 fail, A21,A19 ok
; 256Kbyte       4K          32*64kx1        A13,A20,A12,A18 fail, A21,A19 ok
a1091 14
; StrongARM - aha! but we still have no nice MMU, nor even fast core clock, and this memory sizing type
; stuff is going to be very slow for large memory. So turn on I cache (allowed with MMU off), and fast
; core clock now - this is then ok until MMU etc comes on (near CritStart)

        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&A000
        BNE     MemSizeIOMD_notSA
        ARM_read_control r2
        ORR     r2,r2,#&1000     ;I cache bit is bit 12
        ARM_write_control r2
        ARMA_fastcoreclock

MemSizeIOMD_notSA
d1527 1
a1527 1
        STR     r7, [r3, r5, LSL #2]            ; store replacement entry in L1 (not U,C or B)
d1529 1
a1529 1
        ARM_MMU_transbase r3                    ; set up MMU pointer to L1
d1533 1
a1533 3
        ARM_MMU_domain r7                       ; only use domain 0

        ARM_flush_cacheandTLB r7                ; flush cache + TLB just in case
d1535 2
a1536 6
        ARM_number r2                           ;should be 6,7,8 or &A
        CMP     r2,#&A
        ARMA_fastcoreclock EQ                   ;otherwise StrongARM is going to have a limp wrist
        SUB     r2,r2,#6                        ; r2 := 0..4 for ARM 6,7,8,(9),&A
        ADRL    r7,ARM_default_MMU_CR_table
        LDR     r7,[r7,r2,LSL #2]               ;get appropriate default value for MMU control reg
d1538 1
d1540 1
a1540 1
        ARM_write_control r7
d1552 1
a1552 1
        ARM_flush_TLB r2                        ; flush TLB (no need to flush cache, as there's nothing in it)
d1601 1
a1601 1
        MACRO
d1642 1
a1642 1

d1666 1
a1666 1
        MemInitPagesL2  &8000, 0, 0, CursorChunkAddress, AP_Read, DRAMOffset_CursorChunk  ;but see L1L2PTenhancements
a1668 12

  [ StrongARM
;StrongARM requires 2*16k of private logical space (used for absolutely nothing else), which is
;readable and cacheable, for data cache cleaning purposes. We want to map the space to
;start of ROM bank 1 (physical target), so that IOMD timings can be poked for maximum read speed 
;(only requirement of physical space is that it is readable without h/w abort). Here, though,
;we have to conform to format for MemInitPagesL2, so we just point to some convenient RAM,
;and fix things up later (see L1L2PTenhancements)
;
        MemInitPagesL2  &8000, 1, 1, ARMA_Cleaners_address, AP_Read, DRAMOffset_PageZero
  ]

a1672 1
        LTORG
d1758 1
a1758 2
; In    r0=0 -> Coming from the Test routine, just go back!
;       r1-r6 trashable
d1764 1
a1764 1
; This routine must work in 32-bit mode, and should not use any memory!!!!
d1769 2
a1770 2
TimeCPU ROUT            ;ONLY WORKS FOR IOMD(L) machines - this shouldn't be a problem though
 [ :LNOT: AutoSpeedROMS
d1773 2
d1776 1
a1776 11
   [ {TRUE}
;don't do timing for Risc PC
        LDRB    r0, [r3, #IOMD_ID0]     ; Is
        CMP     r0, #&98                ; It
        LDRB    r0, [r3, #IOMD_ID1]     ; A
        CMPEQ   r0, #&5B                ; Morris?
        MOVNE   r7,#&3e00               ;for non-Morris force 16MHz timing, assumed Risc PC
        ORRNE   r7,r7,#&80
        ORRNE   r7,r7,#&10000           ;and note we're on IOMD
        MOVNE   pc,lr
  ]
a1777 1
; Time CPU/Memory speed
d1779 1
a1779 1
        MOV     r3, #IOC                ; Address of the IO controller
d1781 1
a1781 25
        CMP     r0, #0
        LDREQ   r7, =(1 :SHL: 16) :OR: 16000    ; indicate 16MHz RAM - a little lie :-)
        MOVEQ   pc, lr                          ; Quick, leg it while they're not looking!

        ;Turn off the CPU cache
        ARM_number r4
        SUB     r4,r4,#6
        ADRL    r2,ARM_cacheoff_MMU_CR_table
        LDR     r2,[r2,r4,LSL #2]                 ;get appropriate cache-off value for MMU control reg
        ARM_write_control r2

        ;And don't forget to flush afterwards :-)
        ;SetCop r0, CR_IDCFlush
        ;SetCop  r0, CR_TLBFlush

        ;Turn off DMA/refreshes, but keep the reg contents for future restoration
        LDRB    r4, [r3, #IOMD_VREFCR]  ;Refresh
        LDRB    r5, [r3, #IOMD_SD0CR]   ;Sound
        LDRB    r6, [r3, #IOMD_VIDCR]   ;Video
        MOV     r2, #0
        STRB    r2, [r3, #IOMD_VREFCR]  ;Refresh off
        STRB    r2, [r3, #IOMD_SD0CR]   ;Sound off
        STRB    r2, [r3, #IOMD_VIDCR]   ;Video off

        MOV     r2, r1, LSR #8
d1783 3
a1785 3
        STRB    r2, [r3, #Timer1LH]
        LDR     r2, =ncpuloops
        STRB    r2, [r3, #Timer1GO]     ; start the timer NOW
d1788 1
d1790 1
a1790 1
        SUBS    r2, r2, #1              ; 1S
d1793 1
a1793 1
        STRB    r2, [r3, #Timer1LR]     ; latch count NOW
d1795 2
a1796 2
        LDRB    r7, [r3, #Timer1CH]
        ADD     r2, r2, r7, LSL #8      ; count after looping is ...
d1799 3
a1801 1
        MOV     r7, r2, LSR #1          ; IOC clock decrements at 2MHz, so we now have ticks in 1MHz
d1803 1
a1803 15
        ;Put DMA/refreshes back to what they were
        STRB    r4, [r3, #IOMD_VREFCR]  ;Refresh back
        STRB    r5, [r3, #IOMD_SD0CR]   ;Sound back
        STRB    r6, [r3, #IOMD_VIDCR]   ;Video back

        ;And don't forget to flush first
        ;SetCop r0, CR_IDCFlush
        ;SetCop r0, CR_TLBFlush

        ;Turn on the CPU cache
        ARM_number r4
        SUB     r4,r4,#6
        ADRL    r2,ARM_default_MMU_CR_table
        LDR     r2,[r2,r4,LSL #2]                 ;get appropriate default value for MMU control reg
        ARM_write_control r2
d1805 7
a1811 2
        MOV     r2, r7
; In ROM - each cpu loop took 4R cycles @@ [MEMCLK cycles+1]/f*500ns/cycle
d1813 38
a1850 12
 [ MorrisSupport
        LDRB    r0, [r3, #IOMD_ID0]     ; Is
        CMP     r0, #&98                ; It
        LDRB    r0, [r3, #IOMD_ID1]     ; A
        CMPEQ   r0, #&5B                ; Morris?
        LDREQ   r0, =(4*15*500*ncpuloops)               ;Morris timing values [reordered to prevent miscalculation
                                                        ;due to Aasm integering mid-calculation] (30720000)
        LDRNE   r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
        DivRem  r7, r0, r2, r1          ; r2 preserved,   R7=memory speed in kHz (MEMCLK/2)
 |
        LDR     r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
        DivRem  r7, r0, r2, r1          ; r2 preserved,   R7=memory speed in kHz (MEMCLK/2)
d1852 1
d1854 1
a1854 39
        ;Set the ROM speeds appropriately here, including Burst/NoBurst
        MOV     r4, #SystemROMspeed     ;
        MUL     r0, r7, r4              ; r0 = number of cycles/ROM access *500000
        LDR     r1, =500000
        DivRem  r2, r0, r1, r4          ; r2 = divisor, r0 = remainder, r4 is trashed
        CMP     r0, #0
        ADDGT   r2, r2, #1              ; Always round _UPWARDS_
        CMP     r2, #14
        MOVGT   r2, #14                 ; Top out at 14 cycles

        MOV     r5, #BurstROMspeed      ;
        MUL     r0, r7, r5              ; r0 = number of cycles/ROM burst access *500000
        DivRem  r3, r0, r1, r4          ; r3 = divisor, r0 = remainder, r4 is trashed
        CMP     r0, #0
        ADDGT   r3, r3, #1              ; Always round _upwards_
        CMP     r3, #4
        MOVGT   r3, #4                  ; Top out at 4 cycles

  [ :LNOT: NormalSpeedROMS
    ;limit speeds to 4 cycles minimum (125 ns) - eg. for StrongARM with EPROM
    CMP   r2,#4
    MOVLT r2,#4
    CMP   r3,#4
    MOVLT r3,#4
    ! 0, "*** WARNING Autospeed ROM speed limited to 4 cycles (125 ns) minimum ***"
  ]
        ;So we have R2=cycles for normal access, R3=cycles for burst access
        ;Load the iomd reg into R1, clear the bits we're messing with
        MOV     r4, #IOC
        LDRB    r1, [r4, #IOMD_ROMCR0]  ; Read ROMCR0
        AND     r1, r1, #2_11000000     ; Only preserve bits 6 & 7

        ADR     r0, MemClkTable
        LDRB    r5, [r0, r2]            ; Grab the relevant byte
        ORR     r1, r1, r5

        ADR     r0, BurstTable
        LDRB    r5, [r0, r3]            ; Grab the relevant info
        ORR     r1, r1, r5
d1856 2
a1857 2
        STRB    r1, [r4, #IOMD_ROMCR0]  ; Write ROMCR0
        STRB    r1, [r4, #IOMD_ROMCR1]  ; Write ROMCR1
a1858 31
        ORR     r7, r7, #1 :SHL: 16     ; Note MEMC1a presence (we're on IOMD)
  ]
timecpu_sodthefancytimingstuff
        MOV     pc, lr

MemClkTable
        DCB     2_100101                ; 0 cycles (set to min which is 2)
        DCB     2_100101                ; 1 cycle (set to min. which is 2)
        DCB     2_100101                ; 2 cycles
        DCB     2_100100                ; 3 cycles
        DCB     2_100011                ; 4 cycles
        DCB     2_100010                ; 5 cycles
        DCB     2_100001                ; 6 cycles
        DCB     2_100000                ; 7 cycles
        DCB     2_000011                ; 8 cycles (2x4)
        DCB     2_000010                ; 9 cycles (same as 10)
        DCB     2_000010                ; 10 cycles (2x5)
        DCB     2_000001                ; 11 cycles (same as 12)
        DCB     2_000001                ; 12 cycles (2x6)
        DCB     2_000000                ; 13 cycles (same as 14)
        DCB     2_000000                ; 14 cycles (2x7)

        ALIGN
BurstTable
        DCB     2_000000                ; 0 cycles (no burst)
        DCB     2_011000                ; 1 cycle
        DCB     2_011000                ; 2 cycles
        DCB     2_010000                ; 3 cycles
        DCB     2_001000                ; 4 cycles

        ALIGN
d1864 1
a1864 1
; in:   r0 = 0 (reason code 0, for modify control register)
a1871 8
;
; in:   r0 bits 1 to 28 = 0, bit 0 = 1  (reason code 1, for flush request)
;          r0 bit 31 set if cache(s) to be flushed
;          r0 bit 30 set if TLB(s) to be flushed
;          r0 bit 29 set if flush of entry only (else whole flush)
;       r1 = entry specifier, if r0 bit 29 set
;       (currently, flushing by entry is ignored, and just does full flush)
;
d1874 1
a1874 2
MMUCReason_ModifyControl        # 1    ; reason code 0
MMUCReason_Flush                # 1    ; reason code 1
d1884 2
a1885 4
        Push    lr
        AND     lr,r0,#&FF
        CMP     lr, #MMUCReason_Unknown
        ADDCC   pc, pc, lr, LSL #2
a1887 1
        B       MMUControl_Flush
d1892 1
d1894 1
a1895 1
        Pull    lr
d1899 1
a1899 5
MMUControl_ModifyControl ROUT
        Push    "r3,r4,r5"
        CMP     r1,#0
        CMPEQ   r2,#&FFFFFFFF
        BEQ     MMUC_modcon_readonly
a1902 1
        ARM_number r5
a1904 4
        CMP     r5,#&A
        ARM_read_control lr,EQ
        MOVEQ   lr,lr,LSL #19
        MOVEQ   lr,lr,LSR #19           ; if StrongARM then we can read control reg. - trust this more than soft copy
a1907 12
        CMP     r5,#&A
        BNE     %FT05
        TST     r2,#&4                  ; if StrongARM, then I bit mirrors C bit
        ORRNE   r2,r2,#&1000
        BICEQ   r2,r2,#&1000
05        
   [ SAWBbroken
        CMP     r5,#&A
        BICEQ   lr,r2,#&0008                   ;sorry guys, we can't use write buffer (safe-ish - safer would zap data cache bit as well)
        MOVNE   lr,r2
        STR     lr, [r3, #MMUControlSoftCopy]
   |
d1909 1
a1909 1
   ]
d1911 5
a1915 6
        TST     lr, #MMUC_C             ; if cache turning on then flush cache before we do it
        BEQ     %FT10
        ARM_flush_cache r3
10
        CMP     r5,#&A
        BNE     %FT15
d1917 3
a1919 23
        TST     lr, #MMUC_C             ; if cache turning off then clean StrongARM data cache first
        BEQ     %FT15
        Push    "r0-r2"
        MOV     r1,#ARMA_Cleaner_flipflop
        LDR     r0,[r1]
        EOR     r0,r0,#16*1024
        STR     r0,[r1]
        ARMA_clean_DC r0,r1,r2
        Pull    "r0-r2"
15
   [ SAWBbroken
        CMP     r5,#&A
        BICEQ   lr,r2,#&0008            ;sorry guys, we can't use write buffer
        MOVNE   lr,r2
        ARM_write_control lr
   |
        ARM_write_control r2
   ]
        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off then flush cache afterwards
        BEQ     %FT20
        ARM_flush_cache r3
20
d1921 1
a1921 41
        Pull    "r3,r4,r5,pc"

MMUC_modcon_readonly
        ARM_number r5
        MOV     r3, #0
        LDR     lr, [r3, #MMUControlSoftCopy]
        CMP     r5,#&A
        ARM_read_control lr,EQ
        MOVEQ   lr,lr,LSL #19
        MOVEQ   lr,lr,LSR #19           ; if StrongARM then we can read control reg. - trust this more than soft copy
        STREQ   lr, [r3, #MMUControlSoftCopy]
        MOV     r1, lr
        MOV     r2, lr
        Pull    "r3,r4,r5,pc"

MMUControl_Flush
       Push     "r0-r4"
       ARM_read_ID r4
       AND      r4,r4,#&F000
       TST      r0,#&80000000
       BEQ      MMUC_flush_flushT
;flush cache
       CMP      r4,#&A000
       ARM67_flush_cache NE       ;if not StrongARM, assume 6,7
       BNE      MMUC_flush_flushT
;StrongARM then
       MOV     r2,#ARMA_Cleaner_flipflop
       LDR     r1,[r2]
       EOR     r1,r1,#16*1024
       STR     r1,[r2]       
       ARMA_clean_DC r1,r2,r3     ;effectively, fully clean/flush wrt non-interrupt stuff
       ARMA_drain_WB
       ARMA_flush_IC              ;do *not* flush DC - may be interrupt stuff in it
MMUC_flush_flushT
       TST     r0,#&40000000
       BEQ     MMUC_flush_done
       CMP     r4,#&A000
       ARMA_flush_TLBs EQ
       ARM67_flush_TLB NE         ;if not StrongARM, assume 6,7
MMUC_flush_done
       Pull     "r0-r4,pc"
a2013 1

a2047 1
;ARM 810 or StrongARM allow signed byte load or half-word load/stores - not supported at present
d2074 2
a2075 16
        MOVNE   r1, r9                          ; if up, r1 = +ve no. of regs
        RSBEQ   r1, r9, #0                      ; if down, r1 = -ve no. of regs

;initially assume writeback
;we want r6 = base reg value before assumed writeback (r7 is base reg value after abort)
;ARM 6/7 will have performed any writeback, ARM 8,StrongARM will not

        ARM_read_ID r6
        AND     r6, r6, #&F000
        CMP     r6, #&8000                      ;ARM 8 or
        CMPNE   r6, #&A000                      ;StrongARM
        MOVEQ   r6, r7
        SUBNE   r6, r7, r1, ASL #2

;now we want r6 to be the base register value before the abort, so we will discard
;our adjusted value and take r7, if the instruction in fact had no writeback
d2079 1
a2079 1
        MOVEQ   r6, r7                          ; if not wb, reg after abort is correct
d2250 1
a2250 29
;;;assume ARM 6 configured for LateAbort - others cannot be configured
;;;so, at run time, ARM 6 or 7 means late, ARM 8 or StrongARM means early
;;;
;;; [ LateAborts
;;;        TST     r10, #1 :SHL: 21                ; if write-back
;;;        MOVNE   r8, #0                          ; then no post-inc
;;;        RSBEQ   r8, r9, #0                      ; else post-inc = - pre-inc
;;;        ADD     r0, r8, r9                      ; amount to subtract off base register for correction

;;;        TST     r10, #1 :SHL: 24                ; however, if we're doing post-increment
;;;        MOVEQ   r8, r9                          ; then post-inc = what was pre-inc
;;;        MOVEQ   r0, r9                          ; and adjustment is what was added on
;;;        RSB     r9, r8, #0                      ; and pre-inc = -post-inc
;;; |
;;;        TST     r10, #1 :SHL: 21                ; if write-back
;;;        MOVNE   r8, #0                          ; then no post-inc
;;;        RSBEQ   r8, r9, #0                      ; else post-inc = - pre-inc

;;;        TST     r10, #1 :SHL: 24                ; however, if we're doing post-increment
;;;        MOVEQ   r8, r9                          ; then post-inc = what was pre-inc
;;;        MOVEQ   r9, #0                          ; and pre-inc = 0
;;; ]

        ARM_read_ID r8
        AND     r8, r8, #&F000
        CMP     r8, #&8000
        CMPNE   r8, #&A000
        BEQ     %FT62
;ARM 6 or 7 (late)
d2260 1
a2260 3
        B       %FT63
62
;ARM 8 or StrongARM (early)
d2268 1
a2269 1
63
d2274 4
a2277 11
;;; [ LateAborts
;;;        SUB     r0, r6, r0                      ; compute adjusted base register
;;;        STR     r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all
;;; ]

        ARM_read_ID r1
        AND     r1, r1, #&F000
        CMP     r1, #&8000
        CMPNE   r1, #&A000
        SUBNE   r0, r6, r0                      ; compute adjusted base register (if late)
        STRNE   r0, [r11, r7, LSL #2]           ; and store back in case we decide to abort after all
a2343 3
   [ SAUBxferbroken
        NOP                                     ; 'fraid so
   ]
a2355 3
   [ SAUBxferbroken
        NOP                                     ; 'fraid so
   ]
a2496 3
;ARM 8 and StrongARM will abort for vector reads (as well as writes) in 26bit mode, so we must
;handle vector reads properly as well now
  [ {FALSE}
a2498 1
  ]
d2500 1
a2500 1
; it's a store to memory (may be a vector write), or a read from memory (may be a vector read)
d2513 1
a2513 24
        SetMode SVC32_mode, lr                          ; go into SVC32 so we can poke or peek vector area

        TST     r0, #1                                  ; test for peek/poke
        BEQ     %FT30
26
;peeking
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BEQ     %FT50                                   ; if so then exit if finished else go back to outer loop
        SUBS    r3, r3, #4                              ; have we got at least a word to do?
        LDRCS   lr, [r2], #4                            ; if so then copy word
        STRCS   lr, [r1], #4
        BHI     %BT26                                   ; and if not all done then loop
        BEQ     %FT50                                   ; if all done then switch back to SVC26 and exit

        ADDS    r3, r3, #4
27
        LDRB    lr, [r2], #1                            ; read byte from register bank
        STRB    lr, [r1], #1                            ; and store to memory
        SUBS    r3, r3, #1                              ; decrement byte count
        BEQ     %FT50                                   ; if finished then switch back to SVC26 and exit
        TEQ     r2, r5                                  ; have we gone onto a new block?
        BNE     %BT27                                   ; no, then loop
        B       %FT50

a2514 1
;poking
a2537 1
  [ {FALSE}
d2539 1
a2547 1
  ]
a2641 281


;some tricks to improve performance, looking at MMU level 1 and level 2 page tables
L1L2PTenhancements ROUT
        Push    "r0-r5,lr"

;if the MMU control reg (soft copy) has R bit set (bit 9), then adjust the L1 entries for ROM
;space to give full write protection (user and supervisor)
        MOV     r0,#0
        LDR     r1,[r0,#MMUControlSoftCopy]
        TST     r1,#&200
        BEQ     L1L2PTe_WPROMdone              ;ARM 610 has no R bit, for example
        LDR     r0,=L1PT
        ADD     r0,r0,#ROM :SHR: (20-2)        ;address of first L1PT entry for ROM space
        MOV     r1,#8                          ;8 entries (8 Mbytes)
L1L2PTe_WPROMloop
        LDR     r2,[r0]
        BIC     r2,r2,#&C00                    ;set AP (access permission) bits to 00
        STR     r2,[r0],#4
        SUBS    r1,r1,#1
        BNE     L1L2PTe_WPROMloop
L1L2PTe_WPROMdone

;go for best available memory speed for data cache cleaner area (StrongARM)
        LDR     r0,=L2PT :OR: (ARMA_Cleaners_address :SHR: 10)  ;address of 1st L2PT word for cleaner area
        LDR     r1,[r0]
        MOV     r1,r1,LSL #20
        MOV     r1,r1,LSR #20                   ;zap physical address field
        ORR     r1,r1,#&01000000                ; = physical address of start of ROM bank 1
        MOV     r2,#8                           ;8 L2PT entries to fiddle
00
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT00
        MOV     r0,#IOC
        MOV     r1,#5
        STRB    r1,[r0, #IOMD_ROMCR1]           ;ROM bank 1 speed = fastest (62.5 ns)

;make first 5 pages of cursor chunk cacheable and bufferable - this is rather handy, 'coz things
;like the SWI dispatcher, IRQ dispatcher are here. May be a slight worry over cursor data
;being write-back cached (StrongARM) - should strictly clean,drain write buffer or whatever for shape change.
        LDR     r0,=L2PT :OR: (CursorChunkAddress :SHR: 10)  ;address of 1st L2PT word for CursorChunk
        MOV     R2,#5                           ;5 entries to adjust
01
        LDR     r1,[r0]
        ORR     r1,r1,#&C                       ;make page cacheable and bufferable
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT01

;make other 3 pages of chunk bufferable
        MOV     R2,#3
02
        LDR     r1,[r0]
        ORR     r1,r1,#&4                       ;make page bufferable
        STR     r1,[r0],#4
        SUBS    r2,r2,#1
        BNE     %BT02

;if we are on StrongARM, make the pages of the L2PT itself (for AppSpace only), bufferable (improves task swap speed)
;AppSpace is 0-28M
        ARM_read_ID r0
        AND     r0,r0,#&F000
        CMP     r0,#&A000
        BNE     %FT04
        MOV     r0,#L2PT
        ADD     r0,r0,#(L2PT :SHR: 10) ;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r0,#7*4             ;7 L2PT-of-L2PT entries for 28M of space
03
        LDR     r2,[r0]
        ORR     r2,r2,#4               ;bufferable bit
        STR     r2,[r0],#4
        CMP     r0,r1
        BNE     %BT03
        ARMA_drain_WB                  ;let us be paranoid
04

;try to rescue some pages from the L2PT itself, in the AppSpace region - ie. AppSpace max size can really
;be total RAM size, if that is less than 28 Mb, and for every 4Mb less that is we can rescue a 4k page
;and return it to the free pool - handy on a 2Mb Kryten for instance!

        LDR     r0,=MaxCamEntry
        LDR     r0,[r0]
        ADD     r0,r0,#1               ; = no. of 4k RAM pages in machine
        MOV     r0,r0,LSR #8           ; = no. of Mbytes in machine
        ADD     r0,r0,#3
        BIC     r0,r0,#3               ; round up to next 4 Mb 
        CMP     r0,#28                 ; if 28Mb or more, no pages to be rescued from L2PT AppSpace
        BHS     %FT09
        LDR     r1,=AppSpaceDANode
        MOV     r2,r0,LSL #20
        STR     r2,[r1,#DANode_MaxSize] ; update AppSpace max size
        MOV     r0,r0,LSR #2           ; no. of L2PT AppSpace pages which cannot be rescued
        MOV     r1,#L2PT
        ADD     r1,r1,#(L2PT :SHR: 10) ;the L2PT of the L2PT (and first 7 entries are for App Space)
        ADD     r1,r1,r0,LSL #2        ;first entry for rescue
        LDR     r3,=FreePoolDANode
        LDR     r2,[r3,#DANode_Base]
        LDR     r3,[r3,#DANode_Size]
        ADD     r2,r2,r3               ; r2 -> next logical address for a rescued page
        MOV     r5,r3                  ; FreePool size so far

        SUB     sp,sp,#16              ; room for 1 page block entry + terminator
        MOV     r3,sp
05
        LDR     r4,[r1],#4             ; pick up the L2PT entry
        BIC     r4,r4,#&0FF
        BIC     r4,r4,#&F00            ; mask to leave physical address only
        STR     r4,[r3,#8]             ; store physical address in word 2 of page block entry
        Push    "r0-r2"
        MOV     r0,#&0C00
        MOV     r1,r3
        MOV     r2,#1
        SWI     XOS_Memory             ; fill in page number, given physical address
        Pull    "r0-r2"
        MOV     r4,#2                  ; means inaccessible in user mode (destined for FreePool)
        STR     r4,[r3,#8]
        MOV     r4,#-1
        STR     r4,[r3,#12]            ; terminator
        STR     r2,[r3,#4]             ; new logical address for page
        Push    "r0"
        MOV     r0,r3
        SWI     XOS_SetMemMapEntries
        Pull    "r0"
        ADD     r2,r2,#4096
        ADD     r5,r5,#4096            ; next page
        ADD     r0,r0,#1
        CMP     r0,#7                  ;7 entries in total for full 28Mb AppSpace
        BNE     %BT05
        ADD     sp,sp,#16              ;drop the workspace

        LDR     r4,=FreePoolDANode
        STR     r5,[r4,#DANode_Size]   ;update FreePoolSize

09
        Pull    "r0-r5,pc"

;
; ---------------- XOS_SynchroniseCodeAreas implementation ---------------
;

;this SWI effectively implements IMB and IMBrange (Instruction Memory Barrier)
;for newer ARMs

;max address range before IMBrange is treated as IMB (performance issue,
;since range clean can only specify entries by virtual address)
ARMA_IMBrange_threshold * 128*1024

;entry:
;   R0 = flags
;        bit 0 set ->  R1,R2 specify virtual address range to synchronise
;                      R1 = start address (word aligned, inclusive)
;                      R2 = end address (word aligned, inclusive)
;        bit 0 clear   synchronise entire virtual space
;        bits 1..31    reserved
;
;exit:
;   R0-R2 preserved
;
;method:
;  ARMs 6,7 need do nothing (no IMB consideration)
;  ARM 8 need do nothing (SWI call itself flushes prefetch unit)
;  StrongARM must:
;    (1) clean data cache, (2) drain write buffer, (3) flush instruction cache
;    - the clean is either whole cache or range as appropriate
;
SyncCodeAreasSWI ROUT
        BIC     LR,LR,#V_bit                 ;clear return V
        ARM_read_ID R10
        AND     R10,R10,#&F000
        CMP     R10,#&A000
        BNE     SLVK                         ;not StrongARM
        TST     R0,#1                        ;range variant of SWI?
        BEQ     %FT01
        MOV     R11,R1                       ;R11 := low address (inclusive)
        ADD     R12,R2,#4                    ;R12 := high address (exclusive)
        SUB     R12,R12,R11
        CMP     R12,#ARMA_IMBrange_threshold
        BHS     %FT01                        ;do full IMB
        ADD     R12,R12,R11
        ARMA_clean_DCrange R11,R12
        ARMA_drain_WB
        ARMA_flush_IC WithoutNOPs
        MOV     R0,R0                  ;NOPs to ensure 4 instructions after IC flush before return
        MOV     R0,R0
        MOV     R0,R0
        B       SLVK
01      ;full IMB required
        MOV     R10,PC
        ORR     R12,R10,#I_bit
        TEQP    R12,#0                     ;disable IRQs to read-modify-write semaphore
        MOV     R12,#0
        LDRB    R11,[R12,#SyncCodeA_sema]
        CMP     R11,#0
        TEQNEP  R10,#0                     ;restore and...
        BNE     SLVK                       ;semaphore set, avoid reentrancy, let first call do it
        MOV     R11,#1
        STRB    R11,[R12,#SyncCodeA_sema]  ;set semaphore
        TEQP    R10,#0                     ;restore IRQ state
        MOV     R12,#ARMA_Cleaner_flipflop
        LDR     R11,[R12]
        EOR     R11,R11,#16*1024
        STR     R11,[R12]
        ARMA_clean_DC R11,R12,R10  ;fully clean/flush DC wrt non-interrupt stuff
        ARMA_drain_WB
        ARMA_flush_IC WithoutNOPs  ;do *not* flush DC - may be stuff from interrupt routines
        MOV     R12,#0
        STRB    R12,[R12,#SyncCodeA_sema]  ;reset semaphore
        MOV     R0,R0              ;NOP to ensure 4 instructions after IC flush before return
        B       SLVK

        LTORG

;
;some service routines here for easy patchability
        ALIGN

dtgps_SAcleanflush  ; used during pages_unsafe/safe in ChangeDyn
    ADR     r0,PageBlock1
    ADD     r0,r0,#4        ; r0 -> page block (logical addresses)
    LDR     r1,NumEntries
dtgps_SAloop0
    LDR     r2,[r0],#12
    ADD     r3,r2,#4096     ; 4k page
dtgps_SAloop1
 [ SAcleanflushbroken         ; 2 separate instructions 'coz SA110 cleanflush (1 instruction) seems ineffective
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
    ARMA_clean_DCentry r2
    ARMA_flush_DCentry r2
    ADD     r2,r2,#32
 |
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
    ARMA_cleanflush_DCentry r2
    ADD     r2,r2,#32
  ]
    CMP     r2,r3
    BLO     dtgps_SAloop1
    SUBS    r1,r1,#1
    BNE     dtgps_SAloop0
    ARMA_drain_WB           ; squeeze out those last drops
    MOV     pc,lr


meminfo_flushplease         ; used by MemInfo
        ARM_read_ID r0
        AND     r0,r0,#&F000
        CMP     r0,#&A000
        BEQ     mifp_SA      
;assume ARM 6 or 7 - simple!
        ARM67_flush_cache
        MOV     pc,lr
mifp_SA
;StrongARM - this could take a while...
        MOV     r1,#ARMA_Cleaner_flipflop
        LDR     r0,[r1]
        EOR     r0,r0,#16*1024
        STR     r0,[r1]
        ARMA_clean_DC r0,r1,r2          ;clean/flush data cache wrt non-interrupt stuff (trashes r0,r1,r2)
        ARMA_flush_IC                   ;do *not* flush DC - may be interrupt stuff
        MOV     pc,lr

;

        DCB     "GROT"                  ;spare words marker
        ALIGN   4096                    ;align to page boundary for easy ROMpatch
arm600stuff_endofstuff
  ! 0,"-- size of ARM600+ stuff (4k aligned) is ":CC::STR:(arm600stuff_endofstuff - arm600stuff_startofstuff)

@


4.1.3.2
log
@RISC OS 3.71 version taken
@
text
@d30 3
a32 3
;24-01-96 MJS  now effectively codes for ARM 6 onwards (6,7,8,A, where A = StrongARM)
;              but ARM8 not properly supported (not needed for RO 3.70)
;07-10-96 MJS  proper support for ARM810 added
d83 1
a83 1
FixedAreasL2Size        *       96*1024        ; amount of L2 to cover fixed areas, excluding free pool
a115 4
  [ ARM810bpbroken  ;branch prediction broken!
;ARM 8           Z0RSB111WCAM
         DCD  2_0001001111101
  |
a117 1
  ]
a437 17
  [ ARM810support
    ;if we are mapping out a cacheable page on an ARM810, must clean+flush cache _before_
    ;remapping, since ARM810 relies on virtual addresses for writebacks
        ARM_read_ID r4
        AND     r4,r4,#&F000                    ;ARM ID nibble now in r4
        CMP     r0,#0                           ;EQ if map out
        TSTEQ   r11,#DynAreaFlags_NotCacheable  ;EQ if also cacheable
        CMPEQ   r4,#&8000                       ;EQ if also ARM 8
        BNE     BangL2PT_noARM810flush
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r6,r4
        MOV     r4,#&8000
    |
        ARM8_cleanflush_IDC r6
    ]
BangL2PT_noARM810flush
  ]
a438 1
  [ :LNOT: ARM810support
d441 1
a441 2
  ]
        CMP     r0,#0
a445 6
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLBentry r3,EQ               ;flush TLB entry for this page, ARM 8
        ARM67_flush_TLBentry r3,NE              ;flush TLB entry for this page, ARM 6,7
        MOV     pc,lr
  |
a448 1
  ]
a462 5
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLBentry r3,EQ                 ;flush TLB entry for this page, ARM 8
        MOVEQ   pc,lr                             ;ARM8 cache already flushed, if necessary
  ]
a518 14
  [ ARM810support
        ;if necessary, clean+flush _before_ reamapping, since ARM810 writebacks use virtual addresses
        ARM_read_ID r4
        AND     r4,r4,#&F000
        CMP     r4,#&8000
        TSTEQ   r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_sledge_noARM810flush
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r4,r6
    |
        ARM8_cleanflush_IDC r4
    ]
BangL2PT_sledge_noARM810flush
  ]
a537 5
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLB EQ
        MOVEQ   pc, lr      ;ARM8 cache already flushed if necessary
  ]
d667 1
a667 1
;            (on any ARM). This is small boost for ARM 6,7,8 but a big speed benefit for StrongARM (which
a677 3
;MJS bug fix (since 3.70) for memory fragments not necessarily 1Mb aligned (eg 2 Mb Kryten)
        BIC     r1,r1,#3
;
d735 1
a735 1
        MOV     r12,#48
a752 3
;MJS bug fix (since 3.70) for memory fragments not necessarily 1Mb aligned (eg 2 Mb Kryten)
        BIC     r1,r1,#3
;
d856 1
a856 1
        CMP     r0, #&E7
d858 1
a858 1
        CMPEQ   r0, #&D4
d860 1
a860 1
        BEQ     MedusaInit                            ; Medusa, else assume Morris
a865 21
  [ RO371Timings
        ;IOMD_ID1 still in r0 - check for 7500FE
        CMP     r0, #&aa         ; EQ if 7500FE   => assume 64 MHz bus, EDO RAM
                                 ; NE assume 7500 => assume 32 MHz bus
;7500FE
;set memory to 32MHz for early boot (avoid probs with POST and with power-on key detection)
        MOVEQ   r0, #&12                 ; 5-3 cycle ROM access, Half speed (ie. 10-6)
        STREQB  r0, [r12, #IOMD_ROMCR0]
        STREQB  r0, [r12, #IOMD_ROMCR1]
        MOVEQ   r0, #&70                 ; EDO RAM selected, 32 bit wide, conservative RAS,CAS timing
        STREQB  r0, [r12, #IOMD_DRAMWID] ; DRAM control reg. (more than just width on FE)
        MOVEQ   r0, #&04                 ; clock dividers: /1 for CPU, /2 for memory, /2 for I/O
        STREQB  r0, [r12, #IOMD_CLKCTL]
;7500
        MOVNE   r0, #&32                 ; 5-3 cycle ROM access
        STRNEB  r0, [r12, #IOMD_ROMCR0]
        STRNEB  r0, [r12, #IOMD_ROMCR1]
        MOVNE   r0, #&07                 ; clock dividers: /1 for I/O, /1 for CPU, /1 for memory
        STRNEB  r0, [r12, #IOMD_CLKCTL]

  | ;else if not RO371Timings
a894 1

a896 3

  ] ;RO371Timings conditional

a918 5

  [ RO371Timings
        MOV     r0, #&12    ; 5-3 cycle ROM access
  |

a939 3

  ] ;RO371Timings conditional

d1125 1
a1125 1
        CMP     r0, #&E7
d1127 1
a1127 1
        CMPEQ   r0, #&D4
d1129 1
a1129 1
        BEQ     MemSizeIOMD                             ; IOMD (Medusa), else assume Morris
a1132 3
  [ RO371Timings
        MOV     r11, #&70     ;all 4 banks assumed 32 bit - EDO and timing bits set in case 7500FE (don't care bits otherwise)
  |
a1133 1
  ]
d1417 1
a1417 3
  [ ARM810fastclock
        B       MemSizeIOMD_not810
  ]
a1418 13
  [ ARM810fastclock
    ;fast clock for ARM 810 now
        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&8000
        BNE     MemSizeIOMD_not810
    [ ARM810usePLL
        ARM8_pll_fclk r2
    |
        ARM8_refclk_fclk r2
    ]
MemSizeIOMD_not810
  ]
a1864 3
 [ ARM810support
   ;ARM810 has already had fast clock selected (MemSizeIOMD) - so has StrongARM, therefore code below removed
 |
a1866 1
 ]
d2005 1
a2005 1
;start of ROM bank 1 (physical target), so that IOMD timings can be poked for maximum read speed
d2103 1
a2103 1
; In    r0=0 -> Coming from the Test routine - no fancy business!
d2105 1
a2105 1
;       [[[ r9 = Current MEMC CR (true MEMC value, not fudged to look like 4K page size) ]]]
d2107 1
a2107 1
; Out   [[[ r9 MEMC value with slowest ROM speed, correct pagesize ]]]
a2111 63
  [ RO371Timings

TimeCPU ROUT         ;does not actually measure anything - assumes timings (and EDO for 7500FE) according to IOMD id

        MOV     r2, #IOC                ; Address of the IO controller  (IOMD)

        LDRB    r7, [r2, #IOMD_ID0]     ; Is
        CMP     r7, #&E7                ; It
        LDRB    r7, [r2, #IOMD_ID1]     ; A
        CMPEQ   r7, #&D4                ; Risc PC ?
        BEQ     timecpuriscpc
        CMP     r7, #&AA                ; assume 7500 or 7500FE
        BEQ     timecpu7500FE
;7500 then
        MOV     r7, #&32                      ; 5-3 cycle ROM access
        STRB    r7, [r2, #IOMD_ROMCR0]
        STRB    r7, [r2, #IOMD_ROMCR1]
        MOV     r7, #&07                      ; clock dividers: /1 for I/O, /1 for CPU, /1 for memory
        STRB    r7, [r2, #IOMD_CLKCTL]
        LDR     r7, =(1 :SHL: 16) :OR: 16000  ; assumed 16MHz RAM (32 MHz bus)
        MOV     pc, lr

timecpu7500FE
;set memory to 32MHz for early boot (avoid probs with POST and with power-on key detection)
        MOV     r7, #&12                      ; 5-3 cycle ROM access, half speed (ie. 10-6)
        STRB    r7, [r2, #IOMD_ROMCR0]
        STRB    r7, [r2, #IOMD_ROMCR1]
        MOV     r7, #&70                      ; EDO RAM, 32 bit wide, conservative RAS and CAS timing
        STRB    r7, [r2, #IOMD_DRAMWID]       ; DRAM control reg. (more than just width on FE)
        MOV     r7, #&04                      ; clock dividers: /1 for CPU, /2 for memory, /2 for I/O
        STRB    r7, [r2, #IOMD_CLKCTL]
        LDR     r7, =(1 :SHL: 16) :OR: 32000  ; assumed 32MHz RAM (64 MHz bus), even though /2 at the moment
        MOV     pc, lr

timecpuriscpc
        MOV     r7, #&12                      ; 5-3 cycle ROM access
        STR     r7, [r2, #IOMD_ROMCR0]
        STR     r7, [r2, #IOMD_ROMCR1]
        LDR     r7, =(1 :SHL: 16) :OR: 16000  ; assumed 16MHz RAM (32 MHz bus)
        MOV     pc, lr

;used by NewReset, after main kernel boot
;sets full 64MHz memory if on 7500FE
;preserves registers _and_ flags
;
finalmemoryspeed ROUT
        Push    "r0,lr"
        MOV     lr, #IOC
        LDRB    r0, [lr, #IOMD_ID0]     ; Is
        CMP     r0, #&E7                ; It
        LDRB    r0, [lr, #IOMD_ID1]     ; A
        CMPEQ   r0, #&D4                ; Risc PC ?
        BEQ     fmspeed_done
        CMP     r0, #&AA                ; EQ if 7500FE
        MOVEQ   r0, #&80
        STREQB  r0, [lr, #&CC]          ; ASTCR register: set i/o asynchronous timing for fast memory clock
        MOVEQ   r0, #&06                ; clock dividers: /1 for CPU, /1 for memory, /2 for I/O
        STREQB  r0, [lr, #IOMD_CLKCTL]
fmspeed_done
        Pull    "r0,pc",,^

  | ; else if not RO371Timings

d2122 8
a2129 12
;
;MJS bug fix (since 3.70) - setup r3 properly, and don't corrupt r0 you fool
;
        MOV     r3, #IOC                ; Address of the IO controller
        LDRB    r7, [r3, #IOMD_ID0]     ; Is
        CMP     r7, #&E7                ; It
        LDRB    r7, [r3, #IOMD_ID1]     ; A
        CMPEQ   r7, #&D4                ; Medusa?
        MOVEQ   r7,#&3e00               ;for non-Morris force 16MHz timing, assumed Risc PC
        ORREQ   r7,r7,#&80
        ORREQ   r7,r7,#&10000           ;and note we're on IOMD
        MOVEQ   pc,lr
d2200 1
a2200 1
        CMP     r0, #&E7                ; It
d2202 2
a2203 2
        CMPEQ   r0, #&D4                ; Medusa?
        LDRNE   r0, =(4*15*500*ncpuloops)               ;Morris timing values [reordered to prevent miscalculation
d2205 1
a2205 1
        LDREQ   r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
a2259 2
  ] ;RO371Timings conditional

a2348 3
  [ ARM810support
        CMPNE   r5,#8                   ; can read control reg on ARM 810 too
  ]
a2354 8
  [ ARM810support
        CMP     r5,#8
        BNE     %FT03
        TST     r2,#4
        ORRNE   r2,r2,#&800            ; if ARM810 then Z bit (branch prediction) mirrors C bit
        BICEQ   r2,r2,#&800
03
  ]
d2360 1
a2360 3
05
   [ SAWBbroken :LOR: ARM810bpbroken
        MOV     lr,r2
d2363 2
a2364 6
        BICEQ   lr,lr,#&0008                   ;sorry guys, we can't use write buffer (safe-ish - safer would zap data cache bit as well)
     ]
     [ ARM810bpbroken
        CMP     r5, #8
        BICEQ   lr,lr,#&0800                   ;sorry guys (or sorry Guy!), we can't use branch predictor
     ]
a2373 19
  [ ARM810support
        CMP     r5,#8
        BNE     %FT12
        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off then clean/flush cache first
        BEQ     %FT12
    [ ARM810cleanflushbroken
        Push    "r0,r1"
        ARM8_cleanflush_IDC r0,r1
        ARM8_branchpredict_off r0       ; and turn off branch predict cleanly (must go off with cache)
        Pull    "r0,r1"
    |
        Push    "r0"
        ARM8_cleanflush_IDC r0
        ARM8_branchpredict_off r0       ; and turn off branch predict cleanly (must go off with cache)
        Pull    "r0"
    ]
12
  ]
a2386 2
   [ SAWBbroken :LOR: ARM810bpbroken
        MOV     lr,r2
d2389 2
a2390 6
        BICEQ   lr,lr,#&0008            ;sorry guys, we can't use write buffer
     ]
     [ ARM810bpbroken
        CMP     r5,#8
        BICEQ   lr,lr,#&0800            ;sorry guys, we can't use branch predictor
     ]
a2407 3
  [ ARM810support
        CMPNE   r5,#8                   ; can read control reg on ARM 810 too
  ]
d2424 1
a2424 4
  [ ARM810support
       CMPNE    r4,#&8000
  ]
       ARM67_flush_cache NE       ;if not StrongARM or ARM810, assume 6,7
a2425 13
  [ ARM810support
       CMP      r4,#&A000
       BEQ      MMUC_flush_SA
;ARM810 then
    [ ARM810cleanflushbroken
       ARM8_cleanflush_IDC r1,r4
       MOV      r4,#&8000
    |
       ARM8_cleanflush_IDC r1
    ]
       B        MMUC_flush_flushT
MMUC_flush_SA
  ]
d2430 1
a2430 1
       STR     r1,[r2]
a2436 4
  [ ARM810support
    ;there is a general macro, should have used this before anyway
       ARM_flush_TLB r1
  |
a2439 1
  ]
a2546 5
  [ SASTMhatbroken
        STMEQIA r2!,{r8-r12}
        STMEQIA r2 ,{r13,r14}^
        SUBEQ   r2, r2, #5*4
  |
a2547 1
  ]
a2563 7
  [ SASTMhatbroken
        STMIA   sp_svc!,{r8-r12}
        STMIA   sp_svc, {r13,r14}^
        NOP
        STR     pc, [sp_svc,#2*4]
        SUB     sp_svc, sp_svc, #5*4            ; save USR bank in case STM ^, and also so we can corrupt them
  |
a2564 1
  ]
d2917 3
d2932 3
a3077 1
;In fact, StrongARM does not abort (optional in architecture 4), but ARM 8 does - MJS 08-10-96
d3336 1
a3336 1
        BIC     r0,r0,#3               ; round up to next 4 Mb
a3504 2
;ARM810 equiv of dtgps_SAcleanflush must clean/flush whole cache (cannot clean/flush by virtual address)
;and is shared with code in meminfo_flushplease, below
d3510 1
a3510 5
        BEQ     mifp_SA
  [ ARM810support
        CMP     r0,#&8000
        BEQ     mifp_810
  ]
d3523 1
a3523 10
  [ ARM810support
mifp_810
dtgps_810cleanflush                     ;entry point also used during pages_unsafe/safe in ChangeDyn
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r0,r1
    |
        ARM8_cleanflush_IDC r0
    ]
        MOV     pc,lr
  ]
@


4.1.3.1.2.1
log
@Merged from 3.71 CD
@
text
@d30 3
a32 3
;24-01-96 MJS  now effectively codes for ARM 6 onwards (6,7,8,A, where A = StrongARM)
;              but ARM8 not properly supported (not needed for RO 3.70)
;07-10-96 MJS  proper support for ARM810 added
d83 1
a83 1
FixedAreasL2Size        *       96*1024        ; amount of L2 to cover fixed areas, excluding free pool
a115 4
  [ ARM810bpbroken  ;branch prediction broken!
;ARM 8           Z0RSB111WCAM
         DCD  2_0001001111101
  |
a117 1
  ]
a437 17
  [ ARM810support
    ;if we are mapping out a cacheable page on an ARM810, must clean+flush cache _before_
    ;remapping, since ARM810 relies on virtual addresses for writebacks
        ARM_read_ID r4
        AND     r4,r4,#&F000                    ;ARM ID nibble now in r4
        CMP     r0,#0                           ;EQ if map out
        TSTEQ   r11,#DynAreaFlags_NotCacheable  ;EQ if also cacheable
        CMPEQ   r4,#&8000                       ;EQ if also ARM 8
        BNE     BangL2PT_noARM810flush
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r6,r4
        MOV     r4,#&8000
    |
        ARM8_cleanflush_IDC r6
    ]
BangL2PT_noARM810flush
  ]
a438 1
  [ :LNOT: ARM810support
d441 1
a441 2
  ]
        CMP     r0,#0
a445 6
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLBentry r3,EQ               ;flush TLB entry for this page, ARM 8
        ARM67_flush_TLBentry r3,NE              ;flush TLB entry for this page, ARM 6,7
        MOV     pc,lr
  |
a448 1
  ]
a462 5
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLBentry r3,EQ                 ;flush TLB entry for this page, ARM 8
        MOVEQ   pc,lr                             ;ARM8 cache already flushed, if necessary
  ]
a518 14
  [ ARM810support
        ;if necessary, clean+flush _before_ reamapping, since ARM810 writebacks use virtual addresses
        ARM_read_ID r4
        AND     r4,r4,#&F000
        CMP     r4,#&8000
        TSTEQ   r11,#DynAreaFlags_NotCacheable
        BNE     BangL2PT_sledge_noARM810flush
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r4,r6
    |
        ARM8_cleanflush_IDC r4
    ]
BangL2PT_sledge_noARM810flush
  ]
a537 5
  [ ARM810support
        CMP     r4,#&8000
        ARM8_flush_TLB EQ
        MOVEQ   pc, lr      ;ARM8 cache already flushed if necessary
  ]
d667 1
a667 1
;            (on any ARM). This is small boost for ARM 6,7,8 but a big speed benefit for StrongARM (which
a677 3
;MJS bug fix (since 3.70) for memory fragments not necessarily 1Mb aligned (eg 2 Mb Kryten)
        BIC     r1,r1,#3
;
d735 1
a735 1
        MOV     r12,#48
a752 3
;MJS bug fix (since 3.70) for memory fragments not necessarily 1Mb aligned (eg 2 Mb Kryten)
        BIC     r1,r1,#3
;
d856 1
a856 1
        CMP     r0, #&E7
d858 1
a858 1
        CMPEQ   r0, #&D4
d860 1
a860 1
        BEQ     MedusaInit                            ; Medusa, else assume Morris
a865 21
  [ RO371Timings
        ;IOMD_ID1 still in r0 - check for 7500FE
        CMP     r0, #&aa         ; EQ if 7500FE   => assume 64 MHz bus, EDO RAM
                                 ; NE assume 7500 => assume 32 MHz bus
;7500FE
;set memory to 32MHz for early boot (avoid probs with POST and with power-on key detection)
        MOVEQ   r0, #&12                 ; 5-3 cycle ROM access, Half speed (ie. 10-6)
        STREQB  r0, [r12, #IOMD_ROMCR0]
        STREQB  r0, [r12, #IOMD_ROMCR1]
        MOVEQ   r0, #&70                 ; EDO RAM selected, 32 bit wide, conservative RAS,CAS timing
        STREQB  r0, [r12, #IOMD_DRAMWID] ; DRAM control reg. (more than just width on FE)
        MOVEQ   r0, #&04                 ; clock dividers: /1 for CPU, /2 for memory, /2 for I/O
        STREQB  r0, [r12, #IOMD_CLKCTL]
;7500
        MOVNE   r0, #&32                 ; 5-3 cycle ROM access
        STRNEB  r0, [r12, #IOMD_ROMCR0]
        STRNEB  r0, [r12, #IOMD_ROMCR1]
        MOVNE   r0, #&07                 ; clock dividers: /1 for I/O, /1 for CPU, /1 for memory
        STRNEB  r0, [r12, #IOMD_CLKCTL]

  | ;else if not RO371Timings
a894 1

a896 3

  ] ;RO371Timings conditional

a918 5

  [ RO371Timings
        MOV     r0, #&12    ; 5-3 cycle ROM access
  |

a939 3

  ] ;RO371Timings conditional

d1125 1
a1125 1
        CMP     r0, #&E7
d1127 1
a1127 1
        CMPEQ   r0, #&D4
d1129 1
a1129 1
        BEQ     MemSizeIOMD                             ; IOMD (Medusa), else assume Morris
a1132 3
  [ RO371Timings
        MOV     r11, #&70     ;all 4 banks assumed 32 bit - EDO and timing bits set in case 7500FE (don't care bits otherwise)
  |
a1133 1
  ]
d1417 1
a1417 3
  [ ARM810fastclock
        B       MemSizeIOMD_not810
  ]
a1418 13
  [ ARM810fastclock
    ;fast clock for ARM 810 now
        ARM_read_ID r2
        AND     r2,r2,#&F000
        CMP     r2,#&8000
        BNE     MemSizeIOMD_not810
    [ ARM810usePLL
        ARM8_pll_fclk r2
    |
        ARM8_refclk_fclk r2
    ]
MemSizeIOMD_not810
  ]
a1864 3
 [ ARM810support
   ;ARM810 has already had fast clock selected (MemSizeIOMD) - so has StrongARM, therefore code below removed
 |
a1866 1
 ]
d2005 1
a2005 1
;start of ROM bank 1 (physical target), so that IOMD timings can be poked for maximum read speed
d2103 1
a2103 1
; In    r0=0 -> Coming from the Test routine - no fancy business!
d2105 1
a2105 1
;       [[[ r9 = Current MEMC CR (true MEMC value, not fudged to look like 4K page size) ]]]
d2107 1
a2107 1
; Out   [[[ r9 MEMC value with slowest ROM speed, correct pagesize ]]]
a2111 63
  [ RO371Timings

TimeCPU ROUT         ;does not actually measure anything - assumes timings (and EDO for 7500FE) according to IOMD id

        MOV     r2, #IOC                ; Address of the IO controller  (IOMD)

        LDRB    r7, [r2, #IOMD_ID0]     ; Is
        CMP     r7, #&E7                ; It
        LDRB    r7, [r2, #IOMD_ID1]     ; A
        CMPEQ   r7, #&D4                ; Risc PC ?
        BEQ     timecpuriscpc
        CMP     r7, #&AA                ; assume 7500 or 7500FE
        BEQ     timecpu7500FE
;7500 then
        MOV     r7, #&32                      ; 5-3 cycle ROM access
        STRB    r7, [r2, #IOMD_ROMCR0]
        STRB    r7, [r2, #IOMD_ROMCR1]
        MOV     r7, #&07                      ; clock dividers: /1 for I/O, /1 for CPU, /1 for memory
        STRB    r7, [r2, #IOMD_CLKCTL]
        LDR     r7, =(1 :SHL: 16) :OR: 16000  ; assumed 16MHz RAM (32 MHz bus)
        MOV     pc, lr

timecpu7500FE
;set memory to 32MHz for early boot (avoid probs with POST and with power-on key detection)
        MOV     r7, #&12                      ; 5-3 cycle ROM access, half speed (ie. 10-6)
        STRB    r7, [r2, #IOMD_ROMCR0]
        STRB    r7, [r2, #IOMD_ROMCR1]
        MOV     r7, #&70                      ; EDO RAM, 32 bit wide, conservative RAS and CAS timing
        STRB    r7, [r2, #IOMD_DRAMWID]       ; DRAM control reg. (more than just width on FE)
        MOV     r7, #&04                      ; clock dividers: /1 for CPU, /2 for memory, /2 for I/O
        STRB    r7, [r2, #IOMD_CLKCTL]
        LDR     r7, =(1 :SHL: 16) :OR: 32000  ; assumed 32MHz RAM (64 MHz bus), even though /2 at the moment
        MOV     pc, lr

timecpuriscpc
        MOV     r7, #&12                      ; 5-3 cycle ROM access
        STR     r7, [r2, #IOMD_ROMCR0]
        STR     r7, [r2, #IOMD_ROMCR1]
        LDR     r7, =(1 :SHL: 16) :OR: 16000  ; assumed 16MHz RAM (32 MHz bus)
        MOV     pc, lr

;used by NewReset, after main kernel boot
;sets full 64MHz memory if on 7500FE
;preserves registers _and_ flags
;
finalmemoryspeed ROUT
        Push    "r0,lr"
        MOV     lr, #IOC
        LDRB    r0, [lr, #IOMD_ID0]     ; Is
        CMP     r0, #&E7                ; It
        LDRB    r0, [lr, #IOMD_ID1]     ; A
        CMPEQ   r0, #&D4                ; Risc PC ?
        BEQ     fmspeed_done
        CMP     r0, #&AA                ; EQ if 7500FE
        MOVEQ   r0, #&80
        STREQB  r0, [lr, #&CC]          ; ASTCR register: set i/o asynchronous timing for fast memory clock
        MOVEQ   r0, #&06                ; clock dividers: /1 for CPU, /1 for memory, /2 for I/O
        STREQB  r0, [lr, #IOMD_CLKCTL]
fmspeed_done
        Pull    "r0,pc",,^

  | ; else if not RO371Timings

d2122 8
a2129 12
;
;MJS bug fix (since 3.70) - setup r3 properly, and don't corrupt r0 you fool
;
        MOV     r3, #IOC                ; Address of the IO controller
        LDRB    r7, [r3, #IOMD_ID0]     ; Is
        CMP     r7, #&E7                ; It
        LDRB    r7, [r3, #IOMD_ID1]     ; A
        CMPEQ   r7, #&D4                ; Medusa?
        MOVEQ   r7,#&3e00               ;for non-Morris force 16MHz timing, assumed Risc PC
        ORREQ   r7,r7,#&80
        ORREQ   r7,r7,#&10000           ;and note we're on IOMD
        MOVEQ   pc,lr
d2200 1
a2200 1
        CMP     r0, #&E7                ; It
d2202 2
a2203 2
        CMPEQ   r0, #&D4                ; Medusa?
        LDRNE   r0, =(4*15*500*ncpuloops)               ;Morris timing values [reordered to prevent miscalculation
d2205 1
a2205 1
        LDREQ   r0, =(4*(8*500/1000)*ncpuloops*1000)    ;RiscPC/IOMD timing values      (16384000)
a2259 2
  ] ;RO371Timings conditional

a2348 3
  [ ARM810support
        CMPNE   r5,#8                   ; can read control reg on ARM 810 too
  ]
a2354 8
  [ ARM810support
        CMP     r5,#8
        BNE     %FT03
        TST     r2,#4
        ORRNE   r2,r2,#&800            ; if ARM810 then Z bit (branch prediction) mirrors C bit
        BICEQ   r2,r2,#&800
03
  ]
d2360 1
a2360 3
05
   [ SAWBbroken :LOR: ARM810bpbroken
        MOV     lr,r2
d2363 2
a2364 6
        BICEQ   lr,lr,#&0008                   ;sorry guys, we can't use write buffer (safe-ish - safer would zap data cache bit as well)
     ]
     [ ARM810bpbroken
        CMP     r5, #8
        BICEQ   lr,lr,#&0800                   ;sorry guys (or sorry Guy!), we can't use branch predictor
     ]
a2373 19
  [ ARM810support
        CMP     r5,#8
        BNE     %FT12
        BIC     lr, r1, r2              ; lr = bits going from 1->0
        TST     lr, #MMUC_C             ; if cache turning off then clean/flush cache first
        BEQ     %FT12
    [ ARM810cleanflushbroken
        Push    "r0,r1"
        ARM8_cleanflush_IDC r0,r1
        ARM8_branchpredict_off r0       ; and turn off branch predict cleanly (must go off with cache)
        Pull    "r0,r1"
    |
        Push    "r0"
        ARM8_cleanflush_IDC r0
        ARM8_branchpredict_off r0       ; and turn off branch predict cleanly (must go off with cache)
        Pull    "r0"
    ]
12
  ]
a2386 2
   [ SAWBbroken :LOR: ARM810bpbroken
        MOV     lr,r2
d2389 2
a2390 6
        BICEQ   lr,lr,#&0008            ;sorry guys, we can't use write buffer
     ]
     [ ARM810bpbroken
        CMP     r5,#8
        BICEQ   lr,lr,#&0800            ;sorry guys, we can't use branch predictor
     ]
a2407 3
  [ ARM810support
        CMPNE   r5,#8                   ; can read control reg on ARM 810 too
  ]
d2424 1
a2424 4
  [ ARM810support
       CMPNE    r4,#&8000
  ]
       ARM67_flush_cache NE       ;if not StrongARM or ARM810, assume 6,7
a2425 13
  [ ARM810support
       CMP      r4,#&A000
       BEQ      MMUC_flush_SA
;ARM810 then
    [ ARM810cleanflushbroken
       ARM8_cleanflush_IDC r1,r4
       MOV      r4,#&8000
    |
       ARM8_cleanflush_IDC r1
    ]
       B        MMUC_flush_flushT
MMUC_flush_SA
  ]
d2430 1
a2430 1
       STR     r1,[r2]
a2436 4
  [ ARM810support
    ;there is a general macro, should have used this before anyway
       ARM_flush_TLB r1
  |
a2439 1
  ]
a2546 5
  [ SASTMhatbroken
        STMEQIA r2!,{r8-r12}
        STMEQIA r2 ,{r13,r14}^
        SUBEQ   r2, r2, #5*4
  |
a2547 1
  ]
a2563 7
  [ SASTMhatbroken
        STMIA   sp_svc!,{r8-r12}
        STMIA   sp_svc, {r13,r14}^
        NOP
        STR     pc, [sp_svc,#2*4]
        SUB     sp_svc, sp_svc, #5*4            ; save USR bank in case STM ^, and also so we can corrupt them
  |
a2564 1
  ]
d2917 3
d2932 3
a3077 1
;In fact, StrongARM does not abort (optional in architecture 4), but ARM 8 does - MJS 08-10-96
d3336 1
a3336 1
        BIC     r0,r0,#3               ; round up to next 4 Mb
a3504 2
;ARM810 equiv of dtgps_SAcleanflush must clean/flush whole cache (cannot clean/flush by virtual address)
;and is shared with code in meminfo_flushplease, below
d3510 1
a3510 5
        BEQ     mifp_SA
  [ ARM810support
        CMP     r0,#&8000
        BEQ     mifp_810
  ]
d3523 1
a3523 10
  [ ARM810support
mifp_810
dtgps_810cleanflush                     ;entry point also used during pages_unsafe/safe in ChangeDyn
    [ ARM810cleanflushbroken
        ARM8_cleanflush_IDC r0,r1
    |
        ARM8_cleanflush_IDC r0
    ]
        MOV     pc,lr
  ]
@


4.1.1.1
log
@Import from cleaned 360 CD
@
text
@@
