head	4.8;
access;
symbols
	Kernel-6_14:4.8
	Kernel-6_01-3:4.8
	Kernel-6_13:4.8
	Kernel-6_12:4.8
	Kernel-6_11:4.8
	Kernel-6_10:4.8
	Kernel-6_09:4.8
	Kernel-6_08-4_129_2_10:4.8
	Kernel-6_08-4_129_2_9:4.8
	Kernel-6_08:4.8
	Kernel-6_07:4.8
	Kernel-6_06:4.8
	Kernel-6_05-4_129_2_8:4.8
	Kernel-6_05:4.8
	Kernel-6_04:4.8
	Kernel-6_03:4.8
	Kernel-6_01-2:4.8
	Kernel-6_01-4_146_2_1:4.8
	Kernel-6_02:4.8
	Kernel-6_01-1:4.8
	Kernel-6_01:4.8
	Kernel-6_00:4.8
	Kernel-5_99:4.8
	Kernel-5_98:4.8
	Kernel-5_97-4_129_2_7:4.8
	Kernel-5_97:4.8
	Kernel-5_96:4.8
	Kernel-5_95:4.8
	Kernel-5_94:4.8
	Kernel-5_93:4.8
	Kernel-5_92:4.8
	Kernel-5_91:4.8
	Kernel-5_90:4.8
	Kernel-5_89-4_129_2_6:4.8
	Kernel-5_89:4.8
	Kernel-5_88-4_129_2_5:4.8
	Kernel-5_88-4_129_2_4:4.8
	Kernel-5_88:4.8
	Kernel-5_87:4.8
	Kernel-5_86-4_129_2_3:4.8
	Kernel-5_86-4_129_2_2:4.8
	Kernel-5_86-4_129_2_1:4.8
	Kernel-5_86:4.8
	SMP:4.8.0.2
	SMP_bp:4.8
	Kernel-5_85:4.8
	Kernel-5_54-1:4.8
	Kernel-5_84:4.8
	Kernel-5_83:4.8
	Kernel-5_82:4.8
	Kernel-5_81:4.8
	Kernel-5_80:4.8
	Kernel-5_79:4.8
	Kernel-5_78:4.8
	Kernel-5_77:4.8
	Kernel-5_76:4.8
	Kernel-5_75:4.8
	Kernel-5_74:4.8
	Kernel-5_73:4.8
	Kernel-5_72:4.8
	Kernel-5_71:4.8
	Kernel-5_70:4.8
	Kernel-5_69:4.8
	Kernel-5_68:4.8
	Kernel-5_67:4.8
	Kernel-5_66:4.8
	Kernel-5_65:4.8
	Kernel-5_64:4.8
	Kernel-5_63:4.8
	Kernel-5_62:4.8
	Kernel-5_61:4.8
	Kernel-5_60:4.8
	Kernel-5_59:4.8
	Kernel-5_58:4.8
	Kernel-5_57:4.8
	Kernel-5_56:4.8
	Kernel-5_55:4.8
	Kernel-5_54:4.8
	Kernel-5_53:4.8
	Kernel-5_52:4.8
	Kernel-5_51:4.8
	Kernel-5_50:4.7
	Kernel-5_49:4.7
	HAL_merge:4.5.2.6
	Kernel-5_48:4.7
	Kernel-5_35-4_79_2_327:4.5.2.6
	Kernel-5_35-4_79_2_326:4.5.2.6
	Kernel-5_35-4_79_2_325:4.5.2.6
	Kernel-5_35-4_79_2_324:4.5.2.6
	Kernel-5_35-4_79_2_323:4.5.2.6
	Kernel-5_35-4_79_2_322:4.5.2.6
	Kernel-5_35-4_79_2_321:4.5.2.6
	Kernel-5_35-4_79_2_320:4.5.2.6
	Kernel-5_35-4_79_2_319:4.5.2.6
	Kernel-5_35-4_79_2_318:4.5.2.6
	Kernel-5_35-4_79_2_317:4.5.2.6
	Kernel-5_35-4_79_2_316:4.5.2.6
	Kernel-5_35-4_79_2_315:4.5.2.6
	Kernel-5_35-4_79_2_314:4.5.2.6
	Kernel-5_35-4_79_2_313:4.5.2.6
	Kernel-5_35-4_79_2_312:4.5.2.6
	Kernel-5_35-4_79_2_311:4.5.2.6
	Kernel-5_35-4_79_2_310:4.5.2.6
	Kernel-5_35-4_79_2_309:4.5.2.6
	Kernel-5_35-4_79_2_308:4.5.2.6
	Kernel-5_35-4_79_2_307:4.5.2.6
	Kernel-5_35-4_79_2_306:4.5.2.6
	Kernel-5_35-4_79_2_305:4.5.2.6
	Kernel-5_35-4_79_2_304:4.5.2.6
	Kernel-5_35-4_79_2_303:4.5.2.6
	Kernel-5_35-4_79_2_302:4.5.2.6
	Kernel-5_35-4_79_2_301:4.5.2.6
	Kernel-5_35-4_79_2_300:4.5.2.6
	Kernel-5_35-4_79_2_299:4.5.2.6
	Kernel-5_35-4_79_2_298:4.5.2.6
	Kernel-5_35-4_79_2_297:4.5.2.6
	Kernel-5_35-4_79_2_296:4.5.2.6
	Kernel-5_35-4_79_2_295:4.5.2.6
	Kernel-5_35-4_79_2_294:4.5.2.6
	Kernel-5_35-4_79_2_293:4.5.2.6
	Kernel-5_35-4_79_2_292:4.5.2.6
	Kernel-5_35-4_79_2_291:4.5.2.6
	Kernel-5_35-4_79_2_290:4.5.2.6
	Kernel-5_35-4_79_2_289:4.5.2.6
	Kernel-5_35-4_79_2_288:4.5.2.6
	Kernel-5_35-4_79_2_287:4.5.2.6
	Kernel-5_35-4_79_2_286:4.5.2.6
	Kernel-5_35-4_79_2_285:4.5.2.6
	Kernel-5_35-4_79_2_284:4.5.2.6
	Kernel-5_35-4_79_2_283:4.5.2.6
	Kernel-5_35-4_79_2_282:4.5.2.6
	Kernel-5_35-4_79_2_281:4.5.2.6
	Kernel-5_35-4_79_2_280:4.5.2.6
	Kernel-5_35-4_79_2_279:4.5.2.6
	Kernel-5_35-4_79_2_278:4.5.2.6
	Kernel-5_35-4_79_2_277:4.5.2.6
	Kernel-5_35-4_79_2_276:4.5.2.6
	Kernel-5_35-4_79_2_275:4.5.2.6
	Kernel-5_35-4_79_2_274:4.5.2.6
	Kernel-5_35-4_79_2_273:4.5.2.6
	Kernel-5_35-4_79_2_272:4.5.2.6
	Kernel-5_35-4_79_2_271:4.5.2.6
	Kernel-5_35-4_79_2_270:4.5.2.6
	Kernel-5_35-4_79_2_269:4.5.2.6
	Kernel-5_35-4_79_2_268:4.5.2.6
	Kernel-5_35-4_79_2_267:4.5.2.6
	Kernel-5_35-4_79_2_266:4.5.2.6
	Kernel-5_35-4_79_2_265:4.5.2.6
	Kernel-5_35-4_79_2_264:4.5.2.6
	Kernel-5_35-4_79_2_263:4.5.2.6
	Kernel-5_35-4_79_2_262:4.5.2.6
	Kernel-5_35-4_79_2_261:4.5.2.6
	Kernel-5_35-4_79_2_260:4.5.2.6
	Kernel-5_35-4_79_2_259:4.5.2.6
	Kernel-5_35-4_79_2_258:4.5.2.6
	Kernel-5_35-4_79_2_257:4.5.2.6
	Kernel-5_35-4_79_2_256:4.5.2.6
	Kernel-5_35-4_79_2_255:4.5.2.6
	Kernel-5_35-4_79_2_254:4.5.2.6
	Kernel-5_35-4_79_2_253:4.5.2.6
	Kernel-5_35-4_79_2_252:4.5.2.6
	Kernel-5_35-4_79_2_251:4.5.2.6
	Kernel-5_35-4_79_2_250:4.5.2.6
	Kernel-5_35-4_79_2_249:4.5.2.6
	Kernel-5_35-4_79_2_248:4.5.2.6
	Kernel-5_35-4_79_2_247:4.5.2.6
	Kernel-5_35-4_79_2_246:4.5.2.6
	Kernel-5_35-4_79_2_245:4.5.2.6
	Kernel-5_35-4_79_2_244:4.5.2.6
	Kernel-5_35-4_79_2_243:4.5.2.6
	Kernel-5_35-4_79_2_242:4.5.2.6
	Kernel-5_35-4_79_2_241:4.5.2.6
	Kernel-5_35-4_79_2_240:4.5.2.6
	Kernel-5_35-4_79_2_239:4.5.2.6
	Kernel-5_35-4_79_2_238:4.5.2.6
	Kernel-5_35-4_79_2_237:4.5.2.6
	Kernel-5_35-4_79_2_236:4.5.2.6
	Kernel-5_35-4_79_2_235:4.5.2.6
	Kernel-5_35-4_79_2_234:4.5.2.6
	Kernel-5_35-4_79_2_233:4.5.2.6
	Kernel-5_35-4_79_2_232:4.5.2.6
	Kernel-5_35-4_79_2_231:4.5.2.6
	Kernel-5_35-4_79_2_230:4.5.2.6
	Kernel-5_35-4_79_2_229:4.5.2.6
	Kernel-5_35-4_79_2_228:4.5.2.6
	Kernel-5_35-4_79_2_227:4.5.2.6
	Kernel-5_35-4_79_2_226:4.5.2.6
	Kernel-5_35-4_79_2_225:4.5.2.6
	Kernel-5_35-4_79_2_224:4.5.2.6
	Kernel-5_35-4_79_2_223:4.5.2.6
	Kernel-5_35-4_79_2_222:4.5.2.6
	Kernel-5_35-4_79_2_221:4.5.2.6
	Kernel-5_35-4_79_2_220:4.5.2.6
	Kernel-5_35-4_79_2_219:4.5.2.6
	Kernel-5_35-4_79_2_218:4.5.2.6
	Kernel-5_35-4_79_2_217:4.5.2.6
	Kernel-5_35-4_79_2_216:4.5.2.6
	Kernel-5_35-4_79_2_215:4.5.2.6
	Kernel-5_35-4_79_2_214:4.5.2.6
	Kernel-5_35-4_79_2_213:4.5.2.6
	Kernel-5_35-4_79_2_212:4.5.2.6
	Kernel-5_35-4_79_2_211:4.5.2.6
	Kernel-5_35-4_79_2_210:4.5.2.6
	Kernel-5_35-4_79_2_209:4.5.2.6
	Kernel-5_35-4_79_2_208:4.5.2.6
	Kernel-5_35-4_79_2_207:4.5.2.6
	Kernel-5_35-4_79_2_206:4.5.2.6
	Kernel-5_35-4_79_2_205:4.5.2.6
	Kernel-5_35-4_79_2_204:4.5.2.6
	Kernel-5_35-4_79_2_203:4.5.2.6
	Kernel-5_35-4_79_2_202:4.5.2.6
	Kernel-5_35-4_79_2_201:4.5.2.6
	Kernel-5_35-4_79_2_200:4.5.2.6
	Kernel-5_35-4_79_2_199:4.5.2.6
	Kernel-5_35-4_79_2_198:4.5.2.6
	Kernel-5_35-4_79_2_197:4.5.2.6
	Kernel-5_35-4_79_2_196:4.5.2.6
	Kernel-5_35-4_79_2_195:4.5.2.6
	Kernel-5_35-4_79_2_194:4.5.2.6
	Kernel-5_35-4_79_2_193:4.5.2.6
	Kernel-5_35-4_79_2_192:4.5.2.6
	Kernel-5_35-4_79_2_191:4.5.2.6
	Kernel-5_35-4_79_2_190:4.5.2.6
	Kernel-5_35-4_79_2_189:4.5.2.6
	Kernel-5_35-4_79_2_188:4.5.2.6
	Kernel-5_35-4_79_2_187:4.5.2.6
	Kernel-5_35-4_79_2_186:4.5.2.6
	Kernel-5_35-4_79_2_185:4.5.2.6
	Kernel-5_35-4_79_2_184:4.5.2.6
	Kernel-5_35-4_79_2_183:4.5.2.6
	Kernel-5_35-4_79_2_182:4.5.2.6
	Kernel-5_35-4_79_2_181:4.5.2.6
	Kernel-5_35-4_79_2_180:4.5.2.6
	Kernel-5_35-4_79_2_179:4.5.2.6
	Kernel-5_35-4_79_2_178:4.5.2.6
	Kernel-5_35-4_79_2_177:4.5.2.6
	Kernel-5_35-4_79_2_176:4.5.2.6
	Kernel-5_35-4_79_2_175:4.5.2.6
	Kernel-5_35-4_79_2_174:4.5.2.6
	Kernel-5_35-4_79_2_173:4.5.2.6
	Kernel-5_35-4_79_2_172:4.5.2.6
	Kernel-5_35-4_79_2_171:4.5.2.6
	Kernel-5_35-4_79_2_170:4.5.2.6
	Kernel-5_35-4_79_2_169:4.5.2.6
	Kernel-5_35-4_79_2_168:4.5.2.6
	Kernel-5_35-4_79_2_167:4.5.2.6
	Kernel-5_35-4_79_2_166:4.5.2.6
	Kernel-5_35-4_79_2_165:4.5.2.6
	RPi_merge:4.5.2.4.2.1
	Kernel-5_35-4_79_2_147_2_23:4.5.2.4.2.1
	Kernel-5_35-4_79_2_147_2_22:4.5.2.4
	Kernel-5_35-4_79_2_147_2_21:4.5.2.4
	Kernel-5_35-4_79_2_147_2_20:4.5.2.4
	Kernel-5_35-4_79_2_147_2_19:4.5.2.4
	Kernel-5_35-4_79_2_147_2_18:4.5.2.4
	Kernel-5_35-4_79_2_164:4.5.2.6
	Kernel-5_35-4_79_2_163:4.5.2.6
	Kernel-5_35-4_79_2_147_2_17:4.5.2.4
	Kernel-5_35-4_79_2_147_2_16:4.5.2.4
	Kernel-5_35-4_79_2_147_2_15:4.5.2.4
	Kernel-5_35-4_79_2_162:4.5.2.6
	Kernel-5_35-4_79_2_161:4.5.2.6
	Kernel-5_35-4_79_2_147_2_14:4.5.2.4
	Kernel-5_35-4_79_2_147_2_13:4.5.2.4
	Kernel-5_35-4_79_2_160:4.5.2.6
	Kernel-5_35-4_79_2_159:4.5.2.6
	Kernel-5_35-4_79_2_158:4.5.2.6
	Kernel-5_35-4_79_2_157:4.5.2.6
	Kernel-5_35-4_79_2_156:4.5.2.5
	Kernel-5_35-4_79_2_147_2_12:4.5.2.4
	Kernel-5_35-4_79_2_147_2_11:4.5.2.4
	Kernel-5_35-4_79_2_155:4.5.2.5
	Kernel-5_35-4_79_2_147_2_10:4.5.2.4
	Kernel-5_35-4_79_2_154:4.5.2.5
	Kernel-5_35-4_79_2_153:4.5.2.5
	Kernel-5_35-4_79_2_147_2_9:4.5.2.4
	Kernel-5_35-4_79_2_152:4.5.2.5
	Kernel-5_35-4_79_2_151:4.5.2.5
	Kernel-5_35-4_79_2_147_2_8:4.5.2.4
	Kernel-5_35-4_79_2_147_2_7:4.5.2.4
	Kernel-5_35-4_79_2_150:4.5.2.4
	Kernel-5_35-4_79_2_147_2_6:4.5.2.4
	Kernel-5_35-4_79_2_147_2_5:4.5.2.4
	Kernel-5_35-4_79_2_149:4.5.2.4
	Kernel-5_35-4_79_2_147_2_4:4.5.2.4
	Kernel-5_35-4_79_2_147_2_3:4.5.2.4
	Kernel-5_35-4_79_2_148:4.5.2.4
	Kernel-5_35-4_79_2_147_2_2:4.5.2.4
	Kernel-5_35-4_79_2_147_2_1:4.5.2.4
	RPi:4.5.2.4.0.2
	RPi_bp:4.5.2.4
	Kernel-5_35-4_79_2_98_2_52_2_1:4.5.2.1.2.1
	alees_Kernel_dev:4.5.2.1.2.1.0.2
	alees_Kernel_dev_bp:4.5.2.1.2.1
	Kernel-5_35-4_79_2_147:4.5.2.4
	Kernel-5_35-4_79_2_146:4.5.2.4
	Kernel-5_35-4_79_2_145:4.5.2.4
	Kernel-5_35-4_79_2_144:4.5.2.4
	Kernel-5_35-4_79_2_143:4.5.2.4
	Kernel-5_35-4_79_2_142:4.5.2.4
	Kernel-5_35-4_79_2_141:4.5.2.4
	Kernel-5_35-4_79_2_140:4.5.2.4
	Kernel-5_35-4_79_2_139:4.5.2.4
	Kernel-5_35-4_79_2_138:4.5.2.4
	Kernel-5_35-4_79_2_137:4.5.2.4
	Kernel-5_35-4_79_2_136:4.5.2.4
	Kernel-5_35-4_79_2_135:4.5.2.4
	Kernel-5_35-4_79_2_134:4.5.2.4
	Kernel-5_35-4_79_2_133:4.5.2.4
	Kernel-5_35-4_79_2_132:4.5.2.4
	Kernel-5_35-4_79_2_131:4.5.2.4
	Kernel-5_35-4_79_2_130:4.5.2.4
	Kernel-5_35-4_79_2_129:4.5.2.3
	Kernel-5_35-4_79_2_128:4.5.2.3
	Kernel-5_35-4_79_2_127:4.5.2.2
	Kernel-5_35-4_79_2_126:4.5.2.2
	Kernel-5_35-4_79_2_125:4.5.2.2
	Kernel-5_35-4_79_2_124:4.5.2.2
	Kernel-5_35-4_79_2_123:4.5.2.2
	Cortex_merge:4.5.2.1.2.2
	Kernel-5_35-4_79_2_122:4.5.2.1
	Kernel-5_35-4_79_2_98_2_54:4.5.2.1.2.2
	Kernel-5_35-4_79_2_98_2_53:4.5.2.1.2.2
	Kernel-5_35-4_79_2_98_2_52:4.5.2.1.2.1
	Kernel-5_35-4_79_2_98_2_51:4.5.2.1.2.1
	Kernel-5_35-4_79_2_98_2_50:4.5.2.1.2.1
	Kernel-5_35-4_79_2_98_2_49:4.5.2.1.2.1
	Kernel-5_35-4_79_2_98_2_48:4.5.2.1.2.1
	Kernel-5_35-4_79_2_121:4.5.2.1
	Kernel-5_35-4_79_2_98_2_47:4.5.2.1
	Kernel-5_35-4_79_2_120:4.5.2.1
	Kernel-5_35-4_79_2_98_2_46:4.5.2.1
	Kernel-5_35-4_79_2_119:4.5.2.1
	Kernel-5_35-4_79_2_98_2_45:4.5.2.1
	Kernel-5_35-4_79_2_98_2_44:4.5.2.1
	Kernel-5_35-4_79_2_118:4.5.2.1
	Kernel-5_35-4_79_2_98_2_43:4.5.2.1
	Kernel-5_35-4_79_2_117:4.5.2.1
	Kernel-5_35-4_79_2_116:4.5.2.1
	Kernel-5_35-4_79_2_98_2_42:4.5.2.1
	Kernel-5_35-4_79_2_115:4.5.2.1
	Kernel-5_35-4_79_2_98_2_41:4.5.2.1
	Kernel-5_35-4_79_2_98_2_40:4.5.2.1
	Kernel-5_35-4_79_2_114:4.5.2.1
	Kernel-5_35-4_79_2_98_2_39:4.5.2.1
	Kernel-5_35-4_79_2_98_2_38:4.5.2.1
	Kernel-5_35-4_79_2_113:4.5.2.1
	Kernel-5_35-4_79_2_112:4.5.2.1
	Kernel-5_35-4_79_2_98_2_37:4.5.2.1
	Kernel-5_35-4_79_2_98_2_36:4.5.2.1
	Kernel-5_35-4_79_2_98_2_35:4.5.2.1
	Kernel-5_35-4_79_2_98_2_34:4.5.2.1
	Kernel-5_35-4_79_2_98_2_33:4.5.2.1
	Kernel-5_35-4_79_2_98_2_32:4.5.2.1
	Kernel-5_35-4_79_2_98_2_31:4.5.2.1
	Kernel-5_35-4_79_2_98_2_30:4.5.2.1
	Kernel-5_35-4_79_2_98_2_29:4.5.2.1
	Kernel-5_35-4_79_2_98_2_28:4.5.2.1
	Kernel-5_35-4_79_2_98_2_27:4.5.2.1
	Kernel-5_35-4_79_2_98_2_26:4.5.2.1
	Kernel-5_35-4_79_2_111:4.5.2.1
	Kernel-5_35-4_79_2_98_2_25:4.5.2.1
	Kernel-5_35-4_79_2_98_2_24:4.5.2.1
	Kernel-5_35-4_79_2_98_2_23:4.5.2.1
	Kernel-5_35-4_79_2_110:4.5.2.1
	Kernel-5_35-4_79_2_98_2_22:4.5.2.1
	Kernel-5_35-4_79_2_109:4.5.2.1
	Kernel-5_35-4_79_2_98_2_21:4.5.2.1
	Kernel-5_35-4_79_2_98_2_20:4.5.2.1
	Kernel-5_35-4_79_2_108:4.5.2.1
	Kernel-5_35-4_79_2_107:4.5.2.1
	Kernel-5_35-4_79_2_98_2_19:4.5.2.1
	Kernel-5_35-4_79_2_98_2_18:4.5.2.1
	Kernel-5_35-4_79_2_98_2_17:4.5.2.1
	Kernel-5_35-4_79_2_98_2_16:4.5.2.1
	Kernel-5_35-4_79_2_98_2_15:4.5.2.1
	Kernel-5_35-4_79_2_106:4.5.2.1
	Kernel-5_35-4_79_2_105:4.5.2.1
	Kernel-5_35-4_79_2_104:4.5.2.1
	Kernel-5_35-4_79_2_98_2_14:4.5.2.1
	Kernel-5_35-4_79_2_98_2_13:4.5.2.1
	Kernel-5_35-4_79_2_98_2_12:4.5.2.1
	Kernel-5_35-4_79_2_98_2_11:4.5.2.1
	Kernel-5_35-4_79_2_98_2_10:4.5.2.1
	Kernel-5_35-4_79_2_98_2_9:4.5.2.1
	Kernel-5_35-4_79_2_103:4.5.2.1
	Kernel-5_35-4_79_2_102:4.5.2.1
	Kernel-5_35-4_79_2_98_2_8:4.5.2.1
	Kernel-5_35-4_79_2_98_2_7:4.5.2.1
	Kernel-5_35-4_79_2_98_2_6:4.5.2.1
	Kernel-5_35-4_79_2_98_2_5:4.5.2.1
	Kernel-5_35-4_79_2_98_2_4:4.5.2.1
	Kernel-5_35-4_79_2_101:4.5.2.1
	Kernel-5_35-4_79_2_100:4.5.2.1
	Kernel-5_35-4_79_2_99:4.5.2.1
	Kernel-5_35-4_79_2_98_2_3:4.5.2.1
	Kernel-5_35-4_79_2_98_2_2:4.5.2.1
	Kernel-5_35-4_79_2_98_2_1:4.5.2.1
	Cortex:4.5.2.1.0.2
	Cortex_bp:4.5.2.1
	Kernel-5_35-4_79_2_98:4.5.2.1
	Kernel-5_35-4_79_2_97:4.5.2.1
	Kernel-5_35-4_79_2_96:4.5.2.1
	Kernel-5_35-4_79_2_95:4.5.2.1
	Kernel-5_35-4_79_2_94:4.5.2.1
	Kernel-5_35-4_79_2_93:4.5.2.1
	Kernel-5_35-4_79_2_92:4.5.2.1
	Kernel-5_35-4_79_2_91:4.5.2.1
	Kernel-5_35-4_79_2_90:4.5.2.1
	Kernel-5_35-4_79_2_89:4.5.2.1
	Kernel-5_35-4_79_2_88:4.5.2.1
	Kernel-5_35-4_79_2_87:4.5.2.1
	Kernel-5_35-4_79_2_86:4.5.2.1
	Kernel-5_35-4_79_2_85:4.5.2.1
	Kernel-5_35-4_79_2_84:4.5.2.1
	Kernel-5_35-4_79_2_83:4.5.2.1
	Kernel-5_35-4_79_2_82:4.5.2.1
	Kernel-5_35-4_79_2_81:4.5.2.1
	Kernel-5_35-4_79_2_80:4.5.2.1
	Kernel-5_35-4_79_2_79:4.5.2.1
	Kernel-5_35-4_79_2_78:4.5.2.1
	Kernel-5_35-4_79_2_77:4.5.2.1
	RO_5_07:4.5.2.1
	Kernel-5_35-4_79_2_76:4.5.2.1
	Kernel-5_35-4_79_2_75:4.5.2.1
	Kernel-5_35-4_79_2_74:4.5.2.1
	Kernel-5_35-4_79_2_73:4.5.2.1
	Kernel-5_35-4_79_2_72:4.5.2.1
	Kernel-5_35-4_79_2_71:4.5.2.1
	Kernel-5_35-4_79_2_70:4.5.2.1
	Kernel-5_35-4_79_2_69:4.5.2.1
	Kernel-5_35-4_79_2_68:4.5.2.1
	Kernel-5_35-4_79_2_67:4.5.2.1
	Kernel-5_35-4_79_2_66:4.5.2.1
	Kernel-5_35-4_79_2_65:4.5.2.1
	Kernel-5_35-4_79_2_64:4.5.2.1
	Kernel-5_35-4_79_2_63:4.5.2.1
	Kernel-5_35-4_79_2_62:4.5.2.1
	Kernel-5_35-4_79_2_61:4.5.2.1
	Kernel-5_35-4_79_2_59:4.5.2.1
	Kernel-5_35-4_79_2_58:4.5.2.1
	Kernel-5_35-4_79_2_57:4.5.2.1
	Kernel-5_35-4_79_2_56:4.5.2.1
	Kernel-5_35-4_79_2_55:4.5.2.1
	Kernel-5_35-4_79_2_54:4.5.2.1
	Kernel-5_35-4_79_2_53:4.5.2.1
	Kernel-5_35-4_79_2_52:4.5.2.1
	Kernel-5_35-4_79_2_51:4.5.2.1
	Kernel-5_35-4_79_2_50:4.5.2.1
	Kernel-5_35-4_79_2_49:4.5.2.1
	Kernel-5_35-4_79_2_48:4.5.2.1
	Kernel-5_47:4.6
	Kernel-5_46-4_90_2_1:4.6
	nbingham_Kernel_FastNC_dev_bp:4.6
	nbingham_Kernel_FastNC_dev:4.6.0.2
	Kernel-5_46:4.6
	Kernel-5_45:4.6
	Kernel-5_35-4_79_2_47:4.5.2.1
	Kernel-5_35-4_79_2_46:4.5.2.1
	Kernel-5_35-4_79_2_45:4.5.2.1
	Kernel-5_35-4_79_2_44:4.5.2.1
	Kernel-5_35-4_79_2_25_2_2:4.5.2.1
	Kernel-5_35-4_79_2_43:4.5.2.1
	Kernel-5_35-4_79_2_42:4.5.2.1
	Kernel-5_35-4_79_2_41:4.5.2.1
	Kernel-5_35-4_79_2_40:4.5.2.1
	Kernel-5_35-4_79_2_39:4.5.2.1
	Kernel-5_35-4_79_2_38:4.5.2.1
	Kernel-5_35-4_79_2_37:4.5.2.1
	Kernel-5_35-4_79_2_36:4.5.2.1
	Kernel-5_35-4_79_2_35:4.5.2.1
	Kernel-5_35-4_79_2_34:4.5.2.1
	Kernel-5_35-4_79_2_33:4.5.2.1
	Kernel-5_35-4_79_2_32:4.5.2.1
	Kernel-5_44:4.6
	Kernel-5_35-4_79_2_25_2_1:4.5.2.1
	Kernel-5_43:4.5
	Kernel-5_35-4_79_2_31:4.5.2.1
	Kernel-5_35-4_79_2_30:4.5.2.1
	Kernel-5_35-4_79_2_29:4.5.2.1
	Kernel-5_35-4_79_2_28:4.5.2.1
	Kernel-5_35-4_79_2_27:4.5.2.1
	Kernel-5_35-4_79_2_26:4.5.2.1
	Kernel-5_42:4.5
	Kernel-5_41:4.5
	Kernel-5_40:4.5
	Kernel-5_35-4_79_2_25:4.5.2.1
	Kernel-5_35-4_79_2_24:4.5.2.1
	Kernel-5_35-4_79_2_23:4.5.2.1
	Kernel-5_35-4_79_2_22:4.5.2.1
	Kernel-5_35-4_79_2_21:4.5.2.1
	Kernel-5_35-4_79_2_20:4.5.2.1
	Kernel-5_35-4_79_2_19:4.5.2.1
	Kernel-5_35-4_79_2_18:4.5.2.1
	Kernel-5_35-4_79_2_17:4.5.2.1
	Kernel-5_35-4_79_2_16:4.5.2.1
	Kernel-5_35-4_79_2_15:4.5.2.1
	Kernel-5_35-4_79_2_14:4.5.2.1
	Kernel-5_39:4.5
	Kernel-5_13-4_52_2_1:4.3
	Bethany:4.3.0.2
	Kernel-5_38:4.5
	Kernel-5_35-4_79_2_13:4.5.2.1
	Kernel-5_35-4_79_2_12:4.5.2.1
	Kernel-5_35-4_79_2_11:4.5.2.1
	Kernel-5_37:4.5
	Kernel-5_35-4_79_2_10:4.5.2.1
	Kernel-5_35-4_79_2_9:4.5.2.1
	Kernel-5_36:4.5
	Kernel-5_35-4_79_2_8:4.5.2.1
	Kernel-5_35-4_79_2_7:4.5.2.1
	Kernel-5_35-4_79_2_6:4.5.2.1
	Kernel-5_35-4_79_2_5:4.5.2.1
	Kernel-5_35-4_79_2_4:4.5.2.1
	Kernel-5_35-4_79_2_3:4.5.2.1
	Kernel-5_35-4_79_2_2:4.5.2.1
	dellis_autobuild_BaseSW:4.5
	Kernel-5_35-4_79_2_1:4.5.2.1
	HAL:4.5.0.2
	Kernel-5_35:4.5
	Kernel-5_34:4.5
	Kernel-5_33:4.5
	Kernel-5_32:4.5
	Kernel-5_31:4.5
	Kernel-5_30:4.5
	Kernel-5_29:4.5
	Kernel-5_28:4.5
	Kernel-5_27:4.5
	Kernel-5_26:4.5
	Kernel-5_25:4.5
	Kernel-5_24:4.5
	Kernel-5_23:4.4
	Kernel-5_22:4.3
	sbrodie_sedwards_16Mar2000:4.3
	Kernel-5_21:4.3
	Kernel-5_20:4.3
	Kernel-5_19:4.3
	Kernel-5_18:4.3
	Kernel-5_17:4.3
	Kernel-5_16:4.3
	Kernel-5_15:4.3
	Kernel-5_14:4.3
	Kernel-5_13:4.3
	Kernel-5_12:4.3
	Kernel-5_11:4.3
	Kernel-5_10:4.3
	Kernel-5_09:4.3
	Kernel-5_08:4.3
	Kernel-5_07:4.3
	Kernel-5_06:4.3
	Kernel-5_05:4.3
	Kernel-5_04:4.3
	Kernel-5_03:4.3
	Kernel-5_02:4.3
	Kernel-5_01:4.3
	Kernel-5_00:4.3
	Kernel-4_99:4.3
	Kernel-4_98:4.3
	Kernel-4_97:4.3
	Kernel-4_96:4.3
	Kernel-4_95:4.3
	Kernel-4_94:4.3
	Kernel-4_93:4.3
	Kernel-4_92:4.3
	Kernel-4_91:4.3
	Kernel-4_90:4.3
	dcotton_autobuild_BaseSW:4.6
	Kernel-4_89:4.3
	Kernel-4_88:4.3
	Kernel-4_87:4.3
	Kernel-4_86:4.3
	Kernel-4_85:4.3
	sbrodie_UrsulaRiscPC_Kernel_19Aug99:4.2.2.3.2.1
	Kernel-4_84:4.3
	sbrodie_UrsulaRiscPC_Kernel_18Aug99:4.2.2.3.2.1
	Ursula_RiscPC_bp:4.2.2.3
	Kernel-4_83:4.3
	Kernel-4_82:4.3
	Kernel-4_81:4.3
	Kernel-4_80:4.2
	Kernel-4_79:4.2
	Kernel-4_78:4.2
	Kernel-4_77:4.2
	Kernel-4_76:4.2
	Kernel-4_75:4.2
	Kernel-4_74:4.2
	Kernel-4_73:4.2
	Kernel-4_72:4.2
	Kernel-4_71:4.2
	Kernel-4_70:4.2
	Kernel-4_69:4.2
	Kernel-4_68:4.2
	mstphens_UrsulaRiscPCBuild_20Nov98:4.2.2.3.2.1
	Ursula_RiscPC:4.2.2.3.0.2
	Kernel-4_63-1_1_2_5:4.1.7.1
	Kernel-4_63-1_1_2_4:4.1.7.1
	Kernel-4_67:4.2
	Kernel-4_66:4.2
	Kernel-4_63-1_1_2_3:4.1.7.1
	Kernel-4_65:4.2
	Ursula_merge:4.2
	Kernel-4_64:4.2
	mstphens_Kernel-3_81:4.2.2.4
	Kernel-4_63-1_1_2_2:4.1.7.1
	nicke_Kernel_4_62:4.1.7.1
	rthornb_UrsulaBuild-19Aug1998:4.2.2.3
	UrsulaBuild_FinalSoftload:4.2.2.3
	rthornb_UrsulaBuild-12Aug1998:4.2.2.3
	aglover_UrsulaBuild-05Aug1998:4.2.2.3
	rthornb_UrsulaBuild-29Jul1998:4.2.2.3
	rthornb_UrsulaBuild-22Jul1998:4.2.2.3
	nturton_v459:4.1.7.1
	nturton_v460:4.1.7.1
	rthornb_UrsulaBuild-15Jul1998:4.2.2.3
	rthornb_UrsulaBuild-07Jul1998:4.2.2.3
	rthornb_UrsulaBuild-17Jun1998:4.2.2.3
	rthornb_UrsulaBuild-03Jun1998:4.2.2.3
	rthornb_UrsulaBuild-27May1998:4.2.2.3
	mstphens_Kernel-3_80:4.2.2.3
	rthornb_UrsulaBuild-21May1998:4.2.2.3
	afrost_Boca-1_2-Beta:4.1.7.1
	rthornb_UrsulaBuild_01May1998:4.2.2.3
	afrost_NC2_Generic:4.1.7.1
	Spinner_B20_2:4.1.7.1
	Spinner_19_3:4.1.7.1
	Spinner_B18:4.1.7.1
	Spinner_B17:4.1.7.1
	Spinner_B15:4.1.7.1
	Spinner_B14:4.1.7.1
	Spinner_B13:4.1.7.1
	Spinner_B12:4.1.7.1
	Spinner_B10:4.1.7.1
	Daytona:4.2.0.6
	Daytona_bp:4.2
	Ursula_bp:4.2
	Ursula:4.2.0.2
	Spinner_B7:4.1.7.1
	RO_3_71:4.1.3.1
	ARTtmp_merge:4.1.7.1
	Spin_3Apr97:4.1.7.1
	ARTtmp:4.1.7.1.0.2
	Spin_merge:4.1.7.1
	MergeFiles:4.1.3.1
	RO_3_70:4.1.3.1
	NC_1_06:4.1.7.1
	Spinner:4.1.7
	Spin_xx:4.1.5
	NC_xx:4.1.5.1
	RO_3_60:4.1.1.1
	StrongARM:4.1.3
	Black:4.1.1;
locks; strict;
comment	@# @;


4.8
date	2016.06.30.20.59.46;	author jlee;	state Exp;
branches;
next	4.7;
commitid	skOEjp3ipLHx6xcz;

4.7
date	2016.06.30.20.08.08;	author jlee;	state Exp;
branches;
next	4.6;
commitid	IWoXxARWeuLDOwcz;

4.6
date	2001.06.05.09.20.05;	author sbrodie;	state Exp;
branches;
next	4.5;

4.5
date	2000.04.12.13.58.37;	author sbrodie;	state Exp;
branches
	4.5.2.1;
next	4.4;

4.4
date	2000.04.04.14.27.30;	author kbracey;	state Exp;
branches;
next	4.3;

4.3
date	99.08.03.09.59.01;	author kbracey;	state Exp;
branches;
next	4.2;

4.2
date	97.01.21.14.07.03;	author nturton;	state Exp;
branches
	4.2.2.1;
next	4.1;

4.1
date	96.11.05.09.41.18;	author nturton;	state Exp;
branches
	4.1.1.1
	4.1.3.1
	4.1.5.1
	4.1.7.1;
next	;

4.5.2.1
date	2000.09.15.12.38.01;	author kbracey;	state Exp;
branches
	4.5.2.1.2.1;
next	4.5.2.2;

4.5.2.2
date	2011.11.26.21.11.15;	author jlee;	state Exp;
branches;
next	4.5.2.3;
commitid	cI3W0zbtALQG6TIv;

4.5.2.3
date	2011.12.10.19.03.46;	author jlee;	state Exp;
branches;
next	4.5.2.4;
commitid	tEbdTPC2UwO3XFKv;

4.5.2.4
date	2011.12.10.20.50.06;	author jlee;	state Exp;
branches
	4.5.2.4.2.1;
next	4.5.2.5;
commitid	BN8iJ3uF8zWAxGKv;

4.5.2.5
date	2012.05.26.09.00.27;	author rsprowson;	state Exp;
branches;
next	4.5.2.6;
commitid	EMsCe1GQBPXgdd6w;

4.5.2.6
date	2012.07.01.21.26.41;	author rsprowson;	state Exp;
branches;
next	;
commitid	K3GB4gteEYUubUaw;

4.5.2.1.2.1
date	2011.08.08.23.28.26;	author jlee;	state Exp;
branches;
next	4.5.2.1.2.2;
commitid	D7rzILnwRRSXoLuv;

4.5.2.1.2.2
date	2011.09.24.19.55.54;	author jlee;	state Exp;
branches;
next	;
commitid	kEjQnYmCIZvfIMAv;

4.5.2.4.2.1
date	2012.09.18.15.50.01;	author jlee;	state Exp;
branches;
next	;
commitid	jeuxYpI6CQUxM1lw;

4.2.2.1
date	97.09.09.13.33.10;	author mstphens;	state Exp;
branches;
next	4.2.2.2;

4.2.2.2
date	97.12.08.14.34.24;	author mstphens;	state Exp;
branches;
next	4.2.2.3;

4.2.2.3
date	98.03.26.11.25.46;	author mstphens;	state Exp;
branches
	4.2.2.3.2.1;
next	4.2.2.4;

4.2.2.4
date	98.09.24.13.17.07;	author mstphens;	state Exp;
branches;
next	;

4.2.2.3.2.1
date	98.11.23.14.59.08;	author mstphens;	state Exp;
branches;
next	;

4.1.1.1
date	96.11.05.09.41.18;	author nturton;	state Exp;
branches;
next	;

4.1.3.1
date	96.11.06.02.00.06;	author nturton;	state Exp;
branches;
next	;

4.1.5.1
date	96.11.21.12.10.58;	author nturton;	state Exp;
branches;
next	;

4.1.7.1
date	96.11.29.21.03.31;	author nturton;	state Exp;
branches;
next	;


desc
@@


4.8
log
@Delete lots of old switches
Detail:
  This change gets rid of the following switches from the source (picking appropriate code paths for a 32bit HAL build):
  * FixCallBacks
  * UseProcessTransfer
  * CanLiveOnROMCard
  * BleedinDaveBell
  * NewStyleEcfs
  * DoVdu23_0_12
  * LCDPowerCtrl
  * HostVdu
  * Print
  * EmulatorSupport
  * TubeInfo
  * AddTubeBashers
  * TubeChar, TubeString, TubeDumpNoStack, TubeNewlNoStack macros
  * FIQDebug
  * VCOstartfix
  * AssemblingArthur (n.b. still defined for safety with anything in Hdr: which uses it, but not used explicitly by the kernel)
  * MouseBufferFix
  * LCDInvert
  * LCDSupport
  * DoInitialiseMode
  * Interruptible32bitModes
  * MouseBufferManager
  * StrongARM (new CacheCleanerHack and InterruptDelay switches added to hdr/Options to cover some functionality that StrongARM previously covered)
  * SAcleanflushbroken
  * StrongARM_POST
  * IrqsInClaimRelease
  * CheckProtectionLink
  * GSWorkspaceInKernelBuffers
  * EarlierReentrancyInDAShrink
  * LongCommandLines
  * ECC
  * NoSPSRcorruption
  * RMTidyDoesNowt
  * RogerEXEY
  * StorkPowerSave
  * DebugForcedReset
  * AssembleKEYV
  * AssemblePointerV
  * ProcessorVectors
  * Keyboard_Type
  Assorted old files have also been deleted.
Admin:
  Identical binary to previous revision for IOMD & Raspberry Pi builds


Version 5.51. Tagged as 'Kernel-5_51'
@
text
@; Copyright 1996 Acorn Computers Ltd
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;
        TTL     => HeapMan : Heap Allocation SWI

; Interruptible heap SWI.

; Look down the IRQ stack to see if anybody was in a heap operation.
; If they were, then (with IRQs off) the foreground call is done first, by
; picking up info from a fixed block. Patch the IRQ stack so that the heap SWI
; is returned to at a "it happened in the background" fixup routine. Current
; request can then be dealt with! Ta Nick.


; Also has an interlock on the register restore area; otherwise anybody
; with an IRQ process doing heap ops with interrupts enabled will cause
; trouble.

        GBLL    debheap
debheap SETL    1=0

    [ :LNOT: :DEF: HeapTestbed
              GBLL HeapTestbed
HeapTestbed   SETL {FALSE}
    ]

 [ DebugHeaps
FreeSpaceDebugMask * &04000000
UsedSpaceDebugMask * &08000000
 ]

Nil     *       0

hpd     RN      r1      ; The punter sees these
addr    RN      r2
size    RN      r3
work    RN      r4

HpTemp  RN      r10     ; But not these
tp      RN      r11
bp      RN      r12

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; +                     H E A P   O R G A N I S A T I O N                     +
; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; A heap block descriptor (hpd) has the form

; +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+ -+ -+ -+ -+
; |   magic   |    free   |    base   |    end    |   debug   |
; +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+- +- +- +- +
;  0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20

         ^      0, hpd
hpdmagic #      4
hpdfree  #      4
hpdbase  #      4
hpdend   #      4       ; Needed for debugging heap, and top end validation
 [ debheap
hpddebug #      4       ; 0 -> No debug, ~0 -> Debug
 ]

hpdsize  *      @@-hpdmagic

magic_heap_descriptor * (((((("p":SHL:8)+"a"):SHL:8)+"e"):SHL:8)+"H")

; hpdmagic is a unique identification field
; hpdfree  is the offset of the first block in the free space list
; hpdbase  is the offset of the byte above the last one used
; hpdend   is the offset of the byte above the last one usable

;                               | hpdbase
;                              \|/
;      +---+--------------------+--------+
;  low |hpd|     heap blocks    | unused | high
;      +---+--------------------+---------+
;              /|\                       /|\ 
;               | hpdfree                 | hpdend
;               | in here somewhere.

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; Blocks in the free space list have the form :

; +--+--+--+--+--+--+--+--+--+ ~ -+--+
; | long link | long size |          |
; +--+--+--+--+--+--+--+--+--+ ~ -+--+
;  0  1  2  3  4  5  6  7  8      (size-1)
;
; where the link field is an offset to the next free block

           ^    0 ; Can't use register relative unfortunately as many regs used
frelink    #    4
fresize    #    4
freblksize #    0

; The link field is Nil (0) for the last block in the list

; Block sizes must be forced to a minimum of 8 bytes for subsequent link and
; size information to be stored in them if they are disposed of by the user.

; They must also be capable of storing a 4 byte size field while allocated.
; This field is used to size the block to free when FreeArea is called.

; This is the threshold for minimum heap block fragmentation size.  Splitting a
; free block won't leave a free block which is <= than the size declared here.
; If by choosing to use a particular free block, allocating a new block would
; leave a free block of this size or less, add it on to the original size request
; to avoid generating lots of silly little blocks that slow things down so much.
; This value must not be too large because non-C callers may extend the block
; piecemeal based on their (now wrong) knowledge of the block size.  The C library
; reads the block size straight out of the heap block data, and will thus not
; be fooled.
minheapfragsize # 8

        ALIGN

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; The Macros
; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; Check hpd valid

        MACRO
$label  ValidateHpd $faildest
$label  BL      ValidateHpdSubr
        BNE     $faildest._badhpd
        MEND


; Call XOS_Heap SWI

        MACRO
        CallXOSHeap
      [ HeapTestbed
        BL      DoCallXOSHeap
      |
        SWI     XOS_Heap
      ]
        MEND

;****************************************************************************

; These bits of ExtendBlock are outside the IRQ HeapOp range because they
; don't update the heap structure, so we can safely restore old IRQ status

CopyBackwardsInSafeZone
        LDR     work, [stack, #3*4]     ; get user link
        ANDS    work, work, #I_bit      ; look at I_bit

        WritePSRc SVC_mode, work, EQ    ; if was clear then clear it now

        ADD     bp, bp, #4              ; new block pointer
        STR     bp, [stack]             ; return to user

; copy wackbords: HpTemp-4 bytes from addr+4 to bp, in appropriate order!
cpe_prev
        SUBS    HpTemp, HpTemp, #4
        LDRGT   work, [addr, #4]!
        STRGT   work, [bp], #4
        BGT     cpe_prev

        WritePSRc SVC_mode + I_bit, work; disable IRQs before we venture back
        B       GoodExtension           ; into danger zone

ReallocateInSafeZone
        LDR     work, [addr, hpd]!      ; get block size, set block addr
        ADD     size, size, work
        SUB     size, size, #4          ; block size to claim
        ADD     addr, addr, #4
        MOV     bp, addr                ; address to copy from
        Push    addr                    ; save for later freeing

        MOV     R0, #HeapReason_Get
        CallXOSHeap
        Pull    addr, VS
        BVS     SafeNaffExtension

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT06
 DREG work, "got new block : copying "
06
 ]

        STR     addr, [stack, #4]

; claimed : copy work-4 bytes from bp to addr
CopyForExtension
        SUBS    work, work, #4
        LDRGT   HpTemp, [bp],#4
        STRGT   HpTemp, [addr],#4
        BGT     CopyForExtension

; free the old block!

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT08
 WRLN "freeing old block"
08
 ]

; recursive SWI to free old block; we have invalidated any held information

        MOV     R0, #HeapReason_Free
        Pull    addr                    ; heap block addr
        CallXOSHeap

        MOVVC   R0, #HeapReason_ExtendBlock
        WritePSRc SVC_mode + I_bit,work ; disable IRQs before we venture back
        BVC     GoodExtension           ; into danger zone

SafeNaffExtension
        WritePSRc SVC_mode + I_bit,work  ; disable IRQs before we venture back
        B       NaffExtension           ; into danger zone


;++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; Here's the bit that gets returned to if the heap op was done in the
; background. Pick up the registers, look at the saved PSR to see if error
; return or OK.
; This bit musn't be in range of the IRQ Heap Op checking!!!
;++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

heapopdoneinbackground ROUT
        LDR        R12, =ZeroPage+HeapReturnedReg_R0

        LDMIA     R12, {R0-R4, R10, R11}
        MOV       stack, R10
        MOV       R10, #0
        STR       R10, [R12, #HeapReturnedReg_PSR-HeapReturnedReg_R0]
                                      ; clear the interlock
        TST       R11, #V_bit         ; look at returned error
        BEQ       GoodHeapExit
        ; Recover the error from our buffer
        LDR       R0,=HeapBackgroundError
        LDR       R10,[R0]
        SWI       XMessageTrans_CopyError
        ; Check that it worked - MessageTrans may be dead
        LDR       R11,[R0]
        TEQ       R10,R11
        LDRNE     R0,=HeapBackgroundError ; Just return our internal buffer if MessageTrans couldn't provide one
        B         NaffHeapExit

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; HeapEntry. SWI level entry
; =========
;
; Perform actions on the heap block described by r1(hpd)

; In    r0       =  heap action requested
;       r1(hpd)  -> heap block
;       r2(addr) -> start of block, or required alignment
;       r3(size) =  size of block
;       r4(work) =  boundary limitation

; Out   VClear -> Action performed
;       VSet   -> Something terrible has happened, error set
;       Rest of universe ok

HeapEntry ROUT
        Push    lr
        SavePSR lr                      ; hang on to interrupt state

 ; First check that we aren't in an interrupted Heap Op
        WritePSRc SVC_mode+I_bit, R11
        LDR     R11, =ZeroPage+IRQsema
inspect_IRQ_stack
        LDR     R11, [R11]
        CMP     R11, #0
        BEQ     iis_end
        LDR     R10, [R11, #4*8]        ; Get LR from IRQ stack
        ADR     R12, first_heap_address_to_trap
        CMP     R10, R12
        ADRGEL  R12, HeapCode_end
        CMPGE   R12, R10
        BLT     inspect_IRQ_stack

    ; somebody's in the heap code! Time for perversion.
    ; Pick up registers, do foreground op, poke IRQstack return address

         ADRL   R10, heapopdoneinbackground
         STR    R10, [R11, #4*8]               ; return address zapped
         LDR    R10, [R11, #4*6]               ; get stored SPSR
         BIC    R10, R10, #&FF
         ORR    R10, R10, #I32_bit:OR:SVC2632
         STR    R10, [R11, #4*6]               ; return into SVC26/32 mode with IRQs disabled

         Push  "R0-R4, lr"

         LDR    R10, =ZeroPage+HeapSavedReg_R0

; This can't happen: heap ops are non-interruptible while foreground ops
; are waiting to complete
;         LDR    R12, [R10, #HeapReturnedReg_PSR-HeapSavedReg_R0]
;         CMP    R12, #0
;         BNE    HeapInUse

         LDMIA  R10, {R0-R4, R11}
         SWI    XOS_Heap                ; with interrupts off!
         LDR    R12, =ZeroPage+HeapReturnedReg_R0

   ; Could we poke these into the IRQ stack too...?
   ; would allow interruptible IRQ processes to do heap ops!!!
         MRS    lr, CPSR
         STMIA  R12, {R0-R4, R11, lr}
; Any errors that were generated by the foreground operation may have ended up
; using one of MessageTrans' IRQ buffers. Trouble is, any number of IRQ errors
; could occur between now and when the foreground task gets the error. Avoid
; the error getting clobbered by copying it into a special kernel buffer, and
; then copy it back to a MessageTrans buffer once we're back in the foreground.
         BVC    noheapbackgrounderror
         LDR    R1,=HeapBackgroundError
         MOV    LR,#256
heapbackgrounderrorloop
         LDMIA  R0!,{R2-R4,R12}
         SUBS   LR,LR,#16
         STMIA  R1!,{R2-R4,R12}
         BNE    heapbackgrounderrorloop
         
noheapbackgrounderror
         Pull  "R0-R4, lr"

iis_end                                 ; store the registers in the info block
        LDR     R12, =ZeroPage+HeapSavedReg_R0
        STMIA   R12, {R0-R4}
        STR     stack, [R12, #5*4]

first_heap_address_to_trap              ; because register saveblock now set.
        LDR     R12, [R12, #HeapReturnedReg_PSR-HeapSavedReg_R0]
        CMP     R12, #0
        RestPSR lr, EQ                  ; restore callers interrupt state
                                        ; only if no foreground waiting to
                                        ; complete

        CMP     r0, #MaxHeapCode        ; now despatch it.
        ADDLS   pc, pc, r0, LSL #2      ; Tutu : faster & shorter
        B       NaffHeapReason          ; Return if unknown call reason

HeapJumpTable ; Check reason codes against Hdr:Heap defs

 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_Init
        B       InitHeap
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_Desc
        B       DescribeHeap
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_Get
        B       GetArea
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_Free
        B       FreeArea
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_ExtendBlock
        B       ExtendBlock
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_ExtendHeap
        B       ExtendHeap
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_ReadBlockSize
        B       ReadBlockSize
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_GetAligned
        B       GetAreaAligned
 [ debheap
        B       ShowHeap
 ]
MaxHeapCode * (.-HeapJumpTable-4) :SHR: 2 ; Largest valid reason code


NaffHeapReason
        ADR     R0, ErrorBlock_HeapBadReason
      [ International
        BL      TranslateError
      ]
NaffHeapExit                            ; get here with R0 = error ptr
        SETV
GoodHeapExit                            ; V cleared on entry to SWI dispatch
        SETPSR  I_bit, R12              ; IRQs off
        Pull    lr
        ORRVS   lr, lr, #V_bit          ; VSet Exit

      [ HeapTestbed
        MSR     CPSR_cxsf, lr           ; Fake exit for testbed
        Pull    "r10-r12,pc"
      |
        ExitSWIHandler                  ; Like all good SWI handlers
      ]

; Errors
       MakeErrorBlock  HeapBadReason
       MakeErrorBlock  HeapFail_Init
       MakeErrorBlock  HeapFail_BadDesc
       MakeErrorBlock  HeapFail_BadLink
       MakeErrorBlock  HeapFail_Alloc
       MakeErrorBlock  HeapFail_NotABlock
       MakeErrorBlock  HeapFail_BadExtend
       MakeErrorBlock  HeapFail_ExcessiveShrink
;       MakeErrorBlock  HeapFail_HeapLocked

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
; Subroutine to validate heap pointer
; checks hpd points at existing LogRam
; and also that internal offsets fall into the same block of RAM

ValidateHpdSubr
        Push   "R0-R3, lr"

        SavePSR R3
        WritePSRc SVC_mode+I_bit, R0 ; interrupts off for validation
        MOV     R0, hpd
        ADD     R1, hpd, #hpdsize+freblksize
        SWI     XOS_ValidateAddress
        BCS     vhpds_fail

        TST     R0, #3              ; check alignment
        LDREQ   HpTemp, =magic_heap_descriptor
        LDREQ   tp, [R0, #:INDEX: hpdmagic]
        CMPEQ   tp, HpTemp
        BNE     vhpds_fail           ; failure

        LDR     R1, [R0, #:INDEX: hpdend]
        ADD     R1, R1, R0
        SWI     XOS_ValidateAddress
        BCS     vhpds_fail           ; failure

        ORR     R3, R3, #Z_bit       ; success
        RestPSR R3
        Pull   "R0-R3, PC"

vhpds_fail
        BIC     R3, R3, #Z_bit       ; NE returned ; fails
        RestPSR R3
        Pull   "R0-R3, PC"

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; InitHeap. Top level HeapEntry
; ========
;
; Initialise a heap descriptor block

; In : hpd -> block to initialise, size = size of block

; Out : VClear -> Block initialised
;       VSet   -> Something terrible has happened
;       Rest of universe ok

; To initialise (or even reinitialise) a heap descriptor:
; $(
;   hpd!magic := magic_heap_descriptor
;   hpd!free  := Nil
;   hpd!base  := hpdsize
;   hpd!end   := size
; $)

InitHeap ROUT
        CMP     size,#hpdsize+freblksize
        BLT     NaffHeapInitialise        ; can't get hpd and 1 block in

        Push   "R0, R1"
        MOV     R0, hpd
        ADD     R1, hpd, size
        SWI     XOS_ValidateAddress
        Pull   "R0, R1"
        BCS     NaffHeapInitialise

 [ DebugHeaps
        ORR     lr, hpd, #FreeSpaceDebugMask    ; form word to store throughout heap
        ADD     HpTemp, hpd, size               ; HpTemp -> end of heap
10
        STR     lr, [HpTemp, #-4]!              ; store word, pre-decrementing
        TEQ     HpTemp, hpd                     ; until we get to start
        BNE     %BT10
 ]

        LDR     HpTemp, =magic_heap_descriptor
        STR     HpTemp, hpdmagic          ; hpd!magic := magic_heap_desc
        MOV     HpTemp, #Nil
        STR     HpTemp, hpdfree           ; hpd!free  := Nil
        MOV     HpTemp, #hpdsize
        STR     HpTemp, hpdbase           ; hpd!base  := hpdsize
        STR     size,   hpdend            ; hpd!end   := size

 [ debheap
 MOV HpTemp, #0 ; No debugging until the punter sets this Word
 STR HpTemp, hpddebug
 ]
        B       GoodHeapExit

NaffHeapInitialise
 [ debheap
 WRLN "Unaligned/too big hpd/size: InitHeap failed"
 ]
        ADR     R0, ErrorBlock_HeapFail_Init
      [ International
        BL      TranslateError
      ]
        B       NaffHeapExit               ; VSet exit

        LTORG

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; DescribeHeap. Top level HeapEntry
; ============
;
; Return information about the heap whose descriptor is pointed to by hpd

; In : hpd -> heap descriptor

; Out : VClear -> addr = max block size claimable, size = total free store
;       VSet   -> Something wrong
;       Rest of universe ok

DescribeHeap ROUT
        ValidateHpd describefailed

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT00
 Push  link
 WRLN "DescribeHeap"
 BL iShowHeap
 Pull link
00
 ]
        LDR     addr, hpdend
        LDR     HpTemp, hpdbase

        SUB     addr, addr, HpTemp        ; unused area at base to end
        MOV     size, addr

        LDR     bp, hpdfree
        ADR     tp, hpdfree
        ADD     HpTemp, HpTemp, hpd      ; address of end of allocated memory
        B       %FT20


; Main loop chaining up free space list. size = total, addr = maxvec

15      ADD     tp, tp, bp              ; get address of next
        CMP     tp, HpTemp
        BHS     describefailed_badlink  ; points outside allocated memory
        LDR     bp, [tp, #fresize]      ; Size of this block.
        CMP     bp, addr                ; if size > maxvec then maxvec := size
        MOVHI   addr, bp
        ADD     size, size, bp          ; tfree +:= size
        LDR     bp, [tp, #frelink]      ; Get offset to next block
20      CMP     bp,#Nil                 ; we know Nil is 0!
        BLT     describefailed_badlink  ; -ve are naff
        BNE     %BT15

        CMP     addr, #0
        SUBGT   addr, addr, #4          ; max block claimable
        B       GoodHeapExit            ; VClear Exit


describefailed_badhpd
 [ debheap
 WRLN "Invalid heap descriptor: DescribeHeap failed"
 ]
        ADR     R0, ErrorBlock_HeapFail_BadDesc
      [ International
        BL      TranslateError
      ]
        B       NaffHeapExit            ; VSet Exit

describefailed_badlink
 [ debheap
 WRLN "Invalid heap link: DescribeHeap failed"
 ]
        ADR     R0, ErrorBlock_HeapFail_BadLink
      [ International
        BL      TranslateError
      ]
        B       NaffHeapExit            ; VSet Exit

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; GetArea. Top level HeapEntry
; =======
;
; Allocate a block of memory from the heap

; This will allocate the first block of sufficiently large size in the free
; list, with an oversize block being split.
; Failure to find a large enough block on the free list will try to claim
; space out of the heap block.
; Fails if requesting size = 0

; In : hpd -> heap pointer, size = size of block required

; Out : VClear : addr -> got a block
;       VSet   : addr = 0, couldn't get block
;       Rest of universe ok

GetArea ROUT
        Push   "size"
        ValidateHpd garfailed

 [ debheap
; HpTemp not critical
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT00
 Push  "r0, link"
 MOV r0, size
 DREG r0, "GetArea "
 BL iShowHeap
 Pull "r0, link"
00
 ]

        CMP     size, #0                        ; Can't deallocate 0, so there!
        BLE     garfailed_zero                  ; And -ve is invalid as well!
     ; note sizes of many megabytes thrown out by looking.

        ADD     size, size, #3+4                ; Make block size multiple of 4
        BIC     size, size, #3                  ; including header

        ADR     addr, hpdfree-frelink           ; addr:= @@(hpd!free)-frelink

garloop
        LDR     tp, [addr, #frelink]        ; tp := addr!fre.link
        CMP     tp, #Nil                    ; Is this the end of the chain ?
        BEQ     garmore                     ;  - so try main blk
        ADD     addr, addr, tp              ; convert offset
        LDR     HpTemp, [addr, #fresize]    ; If length < size then no good
        SUBS    HpTemp, HpTemp, size        ; In case this works, for below split
        BLO     garloop

;
; Try and stop very small blocks appearing due to fragmentation - if we fitted with
; a minimal amount of overhead, pretend we had an exact match
;
        CMPNE   HpTemp, #minheapfragsize+1  ; set LO if we can salvage this tiny block
        ADDLO   size, size, HpTemp          ; increment the size to encompass the block
        MOVLOS  HpTemp, #0                  ; pretend we fitted exactly, set EQ

; Now addr -> a block on the free space list that our item will fit in
; If we have an exact fit (or as close as the granularity of the free list will
; allow), unlink this block and return it

        CMP     HpTemp, #freblksize
        BGE     SplitFreeBlock

; Increase allocation size if there wasn't enough space to split the free block
        ADD     size, size, HpTemp

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT60
 WRLN "Got an exact fit block"
60
 ]

        LDR     HpTemp, [addr, #frelink]  ; Move this block's link field
        CMP     HpTemp, #Nil
        ADDNE   HpTemp, HpTemp, tp        ; convert offset into offset from
                                          ; previous block
        WritePSRc SVC_mode+I_bit, lr
        ASSERT  frelink=0
        STR     HpTemp, [addr, -tp]       ; store in link of previous block
        B       ResultIsAddrPlus4

SplitFreeBlock
; Need to split the free block, returning the end portion to the caller

 [ debheap
; HpTemp critical
 Push  HpTemp
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT70
 WRLN "Splitting free block"
70
 Pull HpTemp
 ]

        WritePSRc SVC_mode+I_bit, lr
        STR     HpTemp, [addr, #fresize]  ; Adjust size of free block remaining
        ADD     addr, addr, HpTemp        ; addr -> free block just deallocated

ResultIsAddrPlus4
 [ DebugHeaps
        ORR     lr, hpd, #UsedSpaceDebugMask    ; form word to store throughout block
        ADD     HpTemp, addr, size              ; HpTemp -> end of block
75
        STR     lr, [HpTemp, #-4]!              ; store word, pre-decrementing
        TEQ     HpTemp, addr
        BNE     %BT75
 ]

        STR     size, [addr], #4        ; Store block size and increment addr
        Pull    "size"                  ; Return original value to the punter
                                    ; Note : real size got would be an option!
        CLRV
        B       GoodHeapExit            ; RESULTIS addr


; Got no more free blocks of length >= size, so try to allocate more heap space
; out of the block described by hpd

garmore
 [ debheap
; HpTemp not critical
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT80
 WRLN "Trying to get more from main block"
80
 ]

        LDR     addr, hpdbase
        ADD     tp, addr, size        ; addr := (hpd!base +:= size)
        LDR     HpTemp, hpdend
        WritePSRc SVC_mode+I_bit, lr
        CMP     tp, HpTemp            ; See if we'd fall out of the bottom
        STRLS   tp, hpdbase           ; Only adjust hpdbase if valid alloc
        ADDLS   addr, addr, hpd       ; offset conversion
        BLS     ResultIsAddrPlus4
 [ debheap
 STRIM "Not enough room to allocate in main block"
 ]

garfailed
        ADRL    R0, ErrorBlock_HeapFail_Alloc
      [ International
        BL      TranslateError
      ]
 [ debheap
 WRLN " : GetArea failed"
 ]
garfail_common
        MOV     addr, #0                ; addr := 0 if we couldn't allocate
        Pull    "size"                  ; RESULTIS 0
        B       NaffHeapExit            ; VSet Exit

garfailed_badhpd
 [ debheap
 STRIM "Invalid heap descriptor"
 ]
        ADRL    R0, ErrorBlock_HeapFail_BadDesc
      [ International
        BL      TranslateError
      ]
        B garfail_common

 [ debheap
garfailed_zero
 STRIM "Can't allocate 0 or less bytes"
 B garfailed
 |
garfailed_zero * garfailed
 ]

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; GetAreaAligned. Top level HeapEntry
; ==============
;
; Allocate an aligned block of memory from the heap

; This is the same as GetArea, except it will only allocate areas with the given
; (power-of-two) alignment.
; Fails if requesting size = 0

; In : hpd -> heap pointer
;      size = size of block required
;      addr = alignment (power of 2)
;      work = boundary (power of 2, 0 for none)

; Out : VClear : addr -> got a block
;       VSet   : addr = 0, couldn't get block
;       Rest of universe ok

GetAreaAligned ROUT
        Push   "size,work"
        ValidateHpd garafailed

 [ debheap
; HpTemp not critical
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT00
 Push  "r0, link"
 MOV r0, size
 DREG r0, "GetAreaAligned "
 MOV r0, addr
 DREG r0, "alignment "
 MOV r0, work
 DREG r0, "boundary "
 BL iShowHeap
 Pull "r0, link"
00
 ]

        CMP     size, #0                        ; Can't deallocate 0, so there!
        BLE     garafailed_zero                 ; And -ve is invalid as well!
     ; note sizes of many megabytes thrown out by looking.

        ADD     size, size, #3                  ; Make block size multiple of 4
        BIC     size, size, #3                  ; excluding header

        SUB     bp, addr, #1                    ; Store alignment-1 in bp
        TST     bp, addr
        BNE     garafailed_align                ; Must be power of 2!
        CMP     bp, #3
        MOVLT   bp, #3                          ; Minimum alignment is 4

        SUB     r0, work, #1                    ; Store boundary-1 in r0
        TST     r0, work
        BNE     garafailed_boundary             ; Must be power of 2!

        ADR     addr, hpdfree-frelink           ; addr:= @@(hpd!free)-frelink

        ; If we have a boundary, it must be >= alignment, and >= size
        CMP     r0, #-1
        BEQ     garaloop
        CMP     r0, bp
        CMPHS   work, size
        BLO     garafailed_boundary2

garaloop
        LDR     tp, [addr, #frelink]        ; tp := addr!fre.link
        CMP     tp, #Nil                    ; Is this the end of the chain ?
        BEQ     garamore                    ;  - so try main blk
        ADD     addr, addr, tp              ; convert offset
        LDR     HpTemp, [addr, #fresize]

; Calculate start and end addresses as if we were to allocate from this block
        ADD     work,addr,#4 ; 4 bytes for storing block size
        ADD     HpTemp,HpTemp,addr ; End of free block
        ADD     work,work,bp
garaloop2
        BIC     work,work,bp ; work = start of user block
        SUB     lr,work,addr
        CMP     lr,#4
        BEQ     garastartok ; Start alignment is exact
        CMP     lr,#freblksize+4
        BGE     garastartok ; Enough space to fit a free block at the start

; We need a free block, but there isn't enough space for it.
; Shift 'work' up by one unit of alignment and try again.

        ADD     work,work,bp,LSL #1
        B       garaloop2

garastartok
; Calculate block end address
        ADD     lr,work,size ; End of user block
        SUBS    lr,HpTemp,lr ; Gap after user block
        BLO     garaloop ; Not big enough

; Check boundary requirement
        CMP     r0,#-1
        BEQ     garaboundaryok
        AND     lr,work,r0 ; Start offset within boundary
        ADD     lr,lr,size
        SUB     lr,lr,#1 ; Last byte of allocation
        CMP     lr,r0
        BLS     garaboundaryok

; This allocation crosses a boundary. Shift 'work' up to be boundary aligned.
        ADD     work,work,r0
        BIC     work,work,r0
        B       garaloop2 ; Loop back round to recheck everything (with small boundary sizes, we may have created a situation where we can't fit an initial free block)

garaboundaryok

; We have a suitable space to allocate from.
        ADD     size,size,#4 ; Correct size to store
        SUB     work,work,#4 ; Correct block start

 [ debheap
 LDR lr, hpddebug
 CMP lr, #0
 BEQ %FT60
 WRLN "Using existing free block"
60
 ]

; Note: bp now being used as scratch

        ADD     bp,work,size ; End of user block
        SUB     bp,HpTemp,bp ; Gap after user block

        WritePSRc SVC_mode+I_bit, lr

; Work out if we need a new free block afterwards
        CMP     bp, #freblksize
        ADDLT   size, size, bp ; Not enough space, so enlarge allocated block
        BLT     %FT10

; Create a new free block that will lie after our allocated block
        SUB     HpTemp, HpTemp, bp
        STR     bp, [HpTemp, #fresize]    ; Write size
        LDR     bp, [addr, #frelink]
        CMP     bp, #Nil
        ADDNE   bp, bp, addr
        SUBNE   bp, bp, HpTemp
        STR     bp, [HpTemp, #frelink]    ; Write next ptr
        SUB     HpTemp, HpTemp, addr
        STR     HpTemp, [addr, #frelink]  ; Fix up link from previous block
10

; Shrink this free block to take up the space preceeding the allocated block.
        SUBS    bp,work,addr
        STRNE   bp, [addr, #fresize]
        BNE     ResultIsWorkPlus4 

; No space for an initial free block. Get rid of it.
        ASSERT  frelink=0 ; otherwise LDR bp,[addr,#frelink]!
        LDR     bp, [addr]
        CMP     bp, #0
        ADDNE   bp, bp, tp
        STR     bp, [addr, -tp]
        B       ResultIsWorkPlus4
 
; Got no more free blocks of length >= size, so try to allocate more heap space
; out of the block described by hpd

garamore
 [ debheap
 LDR work, hpddebug
 CMP work, #0
 BEQ %FT80
 WRLN "Trying to get more from main block"
80
 ]
        LDR     work, hpdbase
        ADD     work, work, hpd
        ADD     tp, work, #4
        ADD     tp, tp, bp
garamoreloop
        BIC     tp, tp, bp            ; tp = pointer to return to user

; Make sure there's enough space for a free block if necessary
        SUB     HpTemp, tp, work      ; HpTemp = tp-(hpd+hpdbase)
        CMP     HpTemp, #4
        BEQ     garamoreok
        CMP     HpTemp, #freblksize+4
        ADDLT   tp, tp, bp, LSL #1 ; Not enough space for free block
        BLT     garamoreloop

garamoreok
; Boundary check
        CMP     r0, #-1
        BEQ     garamoreboundaryok
        AND     HpTemp, tp, r0
        ADD     HpTemp, HpTemp, size
        SUB     HpTemp, HpTemp, #1
        CMP     HpTemp, r0
        BLS     garamoreboundaryok

; Shift 'tp' up to be boundary aligned
        ADD     tp, tp, r0
        BIC     tp, tp, r0
        B       garamoreloop

garamoreboundaryok
        ADD     HpTemp, tp, size      ; New heap end
        SUB     HpTemp, HpTemp, hpd   ; New heap size
        LDR     lr, hpdend
        CMP     HpTemp, lr
        BGT     garafailed

        WritePSRc SVC_mode+I_bit, lr

; Set up the block to return to the user
        ADD     size, size, #4
        STR     size, [tp, #-4]!

; Grow the heap
        STR     HpTemp, hpdbase

; Create preceeding free block if necessary
        SUBS    HpTemp, tp, work
        BEQ     ResultIsTpPlus4

; Write the free block
        STR     HpTemp, [work, #fresize]
        MOV     HpTemp, #Nil
        STR     HpTemp, [work, #frelink]

; Patch up the preceeding block
        SUB     HpTemp, work, addr
        STR     HpTemp, [addr, #frelink]

ResultIsTpPlus4
; Block size is already stored
        ADD     addr, tp, #4
        Pull    "size,work"
        MOV     r0,#HeapReason_GetAligned
        CLRV
        B       GoodHeapExit        
        
ResultIsWorkPlus4
        STR     size, [work]           ; Store block size
        ADD     addr, work, #4         ; Move to correct return reg & add offset
        Pull    "size,work"
        MOV     r0,#HeapReason_GetAligned
        CLRV
        B       GoodHeapExit

garafailed
        ADRL    R0, ErrorBlock_HeapFail_Alloc     
      [ International
        BL      TranslateError
      ]
 [ debheap
 WRLN " : GetAreaAligned failed"
 ]
garafail_common
        MOV     addr, #0                ; addr := 0 if we couldn't allocate
        Pull    "size,work"             ; RESULTIS 0
        B       NaffHeapExit            ; VSet Exit

garafailed_badhpd
 [ debheap
 STRIM "Invalid heap descriptor"
 ]
        ADRL    R0, ErrorBlock_HeapFail_BadDesc
      [ International
        BL      TranslateError
      ]
        B garafail_common

 [ debheap
garafailed_zero
 STRIM "Can't allocate 0 or less bytes"
 B garafailed
garafailed_align
 STRIM "Alignment not power of 2"
 B garafailed
garafailed_boundary
 STRIM "Boundary not power of 2"
 B garafailed
garafailed_boundary2
 STRIM "Boundary too small"
 B garafailed
 |
garafailed_zero * garafailed
garafailed_align * garafailed
garafailed_boundary * garafailed
garafailed_boundary2 * garafailed
 ]

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; FreeArea. Top level HeapEntry
; ========
;
; Return an area of store to the heap

; In : hpd -> heap descriptor, addr -> block to free

; Out : VClear -> block freed
;       VSet   -> failed to free block, size invalid
;       Rest of universe ok

; The block to be freed is matched against those on the free list and inserted
; in it's correct place, with the list being maintained in ascending address
; order. If possible, the freed block is merged with contigous blocks above
; and below it to give less fragmentation, and if contiguous with main memory,
; is merged with that. If the latter, check to see if there is a block which
; would be made contiguous with main memory by the former's freeing, and if so,
; merge that with main memory too. Phew !

FreeArea ROUT
        Push    "addr, size, work"

 [ debheap
; HpTemp not critical
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT00
 Push  "r0, link"
 STRIM "FreeArea "
 SUB r0, addr, hpd
 SUB r0, r0, #4
 BL PrintOffsetLine
 BL iShowHeap
 Pull "r0, link"
00
 ]
        BL      FindHeapBlock
        BLVC    FreeChunkWithConcatenation

        Pull    "addr, size, work"
        BVC     GoodHeapExit
        B       NaffHeapExit            ; VSet Exit

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; ExtendBlock. Top level HeapEntry
; ===========
;
; Extend or reallocate existing block

; In : hpd -> heap descriptor, addr -> block, size = size to change by

; Out : VClear -> block freed, addr new block pointer
;       VSet   -> failed to extend block
;       Rest of universe ok

ExtendBlock

        Push    "addr, size, work"

 [ debheap
; HpTemp not critical
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT00
 Push  "r0, link"
 DREG size, "ExtendBlock by ",cc
 STRIM " block  at "
 SUB r0, addr, hpd
 SUB r0, r0, #4
 BL PrintOffsetLine
 BL iShowHeap
 Pull "r0, link"
00
 ]
        BL      FindHeapBlock
        BVS     NaffExtension

        ADD     size, size, #3             ; round size as appropriate :
        BICS    size, size, #3             ; round up to nearest 4

        BEQ     GoodExtension              ; get the easy case done.
        BPL     MakeBlockBigger

        RSB     size, size, #0
        LDR     bp, [addr, hpd]          ; get block size
        WritePSRc SVC_mode+I_bit, R14
        SUB     bp, bp, size             ; size of block left
        CMP     bp, #4

 [ debheap
; HpTemp not critical, GE/LT critical
 BLE %FT01
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT01
 WRLN "Freeing part of block"
01
 CMP bp, #4  ; restore GE/Lt
 ]

        MOVLE    HpTemp, #-1               ; if discarding block, then
        STRLE    HpTemp, [stack]           ; make pointer really naff.
        BLE      GoodShrink

        ; If we're only shrinking 4 bytes, only allow the shrink to go ahead
        ; if there's a free block (or hpdbase) after us
        CMP      size, #4
        BGT      DoShrink
        LDR      HpTemp, [hpd, tp]
        CMP      HpTemp, #Nil
        ADDNE    HpTemp, HpTemp, tp        ; Offset of next free block
        LDREQ    HpTemp, hpdbase
        SUB      HpTemp, HpTemp, addr      ; Offset from start of this block
        SUB      HpTemp, HpTemp, size      ; Apply shrink amount to match bp
        CMP      HpTemp, bp
        MOVGT    size, #0                  ; Used block after us. Deny shrink.
        BGT      GoodExtension
        BLT      CorruptExtension          ; Heap corrupt! Next free block is before us
        ; Else there's a free block (or hpdbase) directly after us
DoShrink
        STR      bp, [addr, hpd]           ; update size of block left
        ADD      addr, addr, bp            ; offset of block to free
        STR      size, [addr, hpd]         ; construct block for freeing

GoodShrink
        BL      FreeChunkWithConcatenation ; work still set from block lookup
GoodExtension
        Pull    "addr, size, work"
 [ DebugHeaps
        MOVS    lr, size                        ; work out how much we actually extended by
        BEQ     %FT99                           ; if zero or negative
        BMI     %FT99                           ; then nothing to do
        LDR     HpTemp, [addr, #-4]             ; get new block size
        SUB     HpTemp, HpTemp, #4              ; Exclude size word itself
        ADD     HpTemp, addr, HpTemp            ; end of new block
        SUB     lr, HpTemp, lr                  ; start of new extension
        ORR     bp, hpd, #UsedSpaceDebugMask
98
        STR     bp, [HpTemp, #-4]!              ; store word
        TEQ     HpTemp, lr
        BNE     %BT98
99
 ]
        CLRV
        B        GoodHeapExit

MakeBlockBigger
        LDR      HpTemp, [addr, hpd]       ; get size
        ADD      HpTemp, HpTemp, addr      ; block end
; TMD 01-Mar-89: FindHeapBlock now never returns tp=Nil, only tp=hpdfree,
; so no need for check
        LDR      bp, [tp, hpd]             ; next free
        CMP      bp, #Nil
        ADDNE    bp, bp, tp
        LDREQ    bp, hpdbase

; bp is potential following block
        CMP      HpTemp, bp
        BNE      try_preceding_block

; now get size available, see if fits

        LDR      HpTemp, hpdbase
        CMP      bp, HpTemp
        ADDNE    HpTemp, bp, hpd
        LDRNE    HpTemp, [HpTemp, #fresize]
        LDREQ    HpTemp, hpdend
        SUBEQ    HpTemp, HpTemp, bp
        BICEQ    HpTemp, HpTemp, #3
                                           ; force it to a sensible blocksize
        MRS      lr, CPSR                  ; save EQ/NE state

        CMP      HpTemp, size
        BLT      try_add_preceding_block

        ORR      lr, lr, #I32_bit          ; disable IRQs
        MSR      CPSR_cf, lr

 [ debheap
; HpTemp, EQ/NE critical
 Push "HpTemp,lr"
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT02
 STRIM "Extending block into "
02
 Pull "HpTemp,lr"
 msr CPSR_f, lr
 ]

        LDR      work, [addr, hpd]         ; get size back
        ADD      work, work, size          ; new size
        STR      work, [addr, hpd]         ; block updated

; now see which we're extending into
        BNE      IntoFreeEntry

 [ debheap
 Push HpTemp
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT03
 WRLN "base-end area"
03
 Pull HpTemp
 ]
        ADD      work, work, addr
        STR      work, hpdbase
        B        GoodExtension

IntoFreeEntry

 [ debheap
 Push HpTemp
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT04
 WRLN "free entry"
04
 Pull HpTemp
 ]

        SUB      HpTemp, HpTemp, size      ; new freblk size
        CMP      HpTemp, #4
        BGT      SplitFreeBlockForExtend

; Not enough space for a free block. Increase the grow amount a bit.
        ADDEQ    work, work, #4
        STREQ    work, [addr, hpd]

; free entry just right size : remove from free list
        LDR      HpTemp, [bp, hpd]         ; free link
        CMP      HpTemp, #Nil
        ADDNE    HpTemp, HpTemp, bp        ; offset from heap start
        SUBNE    HpTemp, HpTemp, tp
        STR      HpTemp, [tp, hpd]         ; free list updated
        B        GoodExtension

SplitFreeBlockForExtend
        LDR      work, [tp, hpd]
        ADD      work, work, size
        STR      work, [tp, hpd]           ; prevnode points at right place
        ADD      work, work, tp            ; offset of new free entry
        ADD      work, work, hpd
        STR      HpTemp, [work, #fresize]
        LDR      HpTemp, [bp, hpd]
        CMP      HpTemp, #Nil
        SUBNE    HpTemp, HpTemp, size      ; reduced offset for free link
        STR      HpTemp, [work, #frelink]
        B        GoodExtension

try_preceding_block
; TMD 01-Mar-89: FindHeapBlock now never returns tp=Nil, only tp=hpdfree,
; so no need for check
        CMP      tp, #:INDEX: hpdfree  ; no real preceder?
        BEQ      got_to_reallocate
        ADD      bp, tp, hpd
        LDR      bp, [bp, #fresize]
        ADD      bp, bp, tp            ; end of preceding block
        CMP      addr, bp
        BNE      got_to_reallocate

; now get size available, see if fits

        SUB      bp, bp, tp           ; freblk size
        SUBS     bp, bp, size         ; compare, find free size left
        BLT      got_to_reallocate

 [ debheap
 Push "HpTemp,lr"
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT10
 CMP bp, #0
 BEQ %FT11
 STRIM "Extending block into previous free"
 B   %FT12
11
 STRIM "Previous free perfect fit"
12
 SWI XOS_NewLine
10
 Pull "HpTemp,lr"
 ]

        WritePSRc SVC_mode+I_bit, HpTemp   ; IRQs off

hack_preceder
; bp is new size of preceding block
; tp is prevfree offset
; work is prevprevfree offset
; size is amount block grows by
; addr is block offset
        CMP      bp, #freblksize
        ADDGE    HpTemp, tp, hpd
        STRGE    bp, [HpTemp, #fresize]    ; prevblock shrunk
        BGE      copy_backwards

 ; free freblk: work is still prevprevblk pointer
        LDR      HpTemp, [tp, hpd]
        ADDNE    size, size, bp            ; Increase grow amount by any remainder
        MOVNE    bp, #0                    ; And make sure the block does die
        CMP      HpTemp, #Nil
        ADDNE    HpTemp, HpTemp, tp        ; offset from heap start
        SUBNE    HpTemp, HpTemp, work
        STR      HpTemp, [work, hpd]       ; free list updated

copy_backwards
        ADD      bp, bp, tp
        LDR      HpTemp, [addr, hpd]!      ; current block size
        ADD      size, HpTemp, size
        STR      size, [bp, hpd]!          ; update blocksize

 [ debheap
 Push r0
 LDR r0, hpddebug
 CMP r0, #0
 BEQ %FT06
 DREG HpTemp, "copying -4+",cc
 STRIM " from "
 SUB  R0, addr, hpd
 BL   PrintOffset
 STRIM " to "
 SUB  R0, bp, hpd
 BL   PrintOffsetLine
06
 Pull r0
 ]

; TMD 02-Mar-89: We've finished messing about with the heap structure
; so we can branch outside danger zone and restore IRQ status while doing copy
        B       CopyBackwardsInSafeZone

try_add_preceding_block
    [ {TRUE}
; HpTemp is size of following block
        CMP      tp, #:INDEX: hpdfree  ; no real preceder?
        BEQ      got_to_reallocate
        Push    "work, size"           ; need prevprevblk ptr
        SUB      size, size, HpTemp    ; size still needed
        ADD      HpTemp, tp, hpd
        LDR      HpTemp, [HpTemp, #fresize]
        ADD      HpTemp, HpTemp, tp        ; end of preceding block
        CMP      addr, HpTemp
        BNE      got_to_reallocate2

; now get size available, see if fits

        SUB      HpTemp, HpTemp, tp    ; freblk size
        SUBS     HpTemp, HpTemp, size
        BLT      got_to_reallocate2

 [ debheap
 Push "HpTemp,lr"
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT10
 Pull HpTemp
 CMP HpTemp, #0
 BEQ %FT11
 STRIM "Extending block into previous free and block after"
 B   %FT12
11
 STRIM "Previous free+nextblock perfect fit"
12
 SWI XOS_NewLine
10
 Pull "lr"
 ]

        WritePSRc SVC_mode+I_bit, work ; IRQs off
   ; delink block at bp
        LDR      work, hpdbase
        CMP      bp, work              ; extend into free, or delink block?
        BNE      ext_delink
        LDR      work, hpdend
        SUB      work, work, bp        ; get back real size
        BIC      work, work, #3
        ADD      work, work, bp
        STR      work, hpdbase         ; all free allocated
        B        ext_hack
ext_delink
        LDR      work, [bp, hpd]
        CMP      work, #Nil
        ADDNE    work, work, bp
        SUBNE    work, work, tp
        STR      work, [tp, hpd]       ; block delinked
ext_hack
        MOV      bp, HpTemp
        Pull    "work, size"
; bp is new size of preceding block
; tp is prevfree offset
; work is prevprevfree offset
; size is amount block grows by
; addr is block offset
        B        hack_preceder

got_to_reallocate2
       Pull     "work, size"
  ]
got_to_reallocate
; claim block of new size ; copy data
; Done by recursive SWIs: somewhat inefficient, but simple.

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT05
 WRLN "reallocating block"
05
 ]

        B       ReallocateInSafeZone

CorruptExtension
        ADRL    R0,ErrorBlock_HeapFail_BadLink
      [ International
        BL      TranslateError
      ]

NaffExtension
        Pull    "addr, size, work"
        B       NaffHeapExit


; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; ExtendHeap. Top level HeapEntry
; ==========
;
; Extend or shrink heap

; In : hpd -> heap descriptor, size = size to change by

; Out : VClear -> heap size changed OK
;       VSet   -> failed to change by specified amount
;       size = amount changed by

ExtendHeap       ROUT
        ValidateHpd  ExtendHeap

        CMP      r3, #0
        ADDMI    r3, r3, #3          ; round towards 0
        BIC      R3, R3, #3          ; ensure word amount

        LDR      HpTemp, hpdend
        ADD      HpTemp, HpTemp, R3  ; HpTemp := new size
        LDR      tp, hpdbase
        CMP      tp, HpTemp
        BGT      ExtendHeap_badshrink

        WritePSRc SVC_mode+I_bit, lr
        Push    "R0, R1"
        MOV      R0, hpd             ; Ensure heap will be in valid area
        ADD      R1, hpd, HpTemp
        SWI      XOS_ValidateAddress
        Pull    "R0, R1"
        BCS      ExtendHeap_nafforf

 [ DebugHeaps
        CMP     R3, #0                  ; if shrunk or stayed same
        BLE     %FT15                   ; then nothing to do
        ADD     tp, hpd, HpTemp         ; tp -> end of heap
        SUB     bp, tp, R3              ; bp -> start of new bit
        ORR     lr, hpd, #FreeSpaceDebugMask
10
        STR     lr, [tp, #-4]!          ; store word
        TEQ     tp, bp
        BNE     %BT10
15
 ]

        STR      HpTemp, hpdend      ; uppy date him
        B        GoodHeapExit        ; moved all the size asked for

ExtendHeap_badhpd
        ADRL     R0, ErrorBlock_HeapFail_BadDesc
      [ International
        BL       TranslateError
      ]
        MOV      size, #0
        B        NaffHeapExit

ExtendHeap_nafforf
        ADRL     R0, ErrorBlock_HeapFail_BadExtend
      [ International
        BL      TranslateError
      ]
        MOV      size, #0
        B        NaffHeapExit

ExtendHeap_badshrink
        LDR      HpTemp, hpdend
        STR      tp, hpdend          ; update heap
        SUB      size, HpTemp, tp    ; size managed to change by
        ADRL     R0, ErrorBlock_HeapFail_ExcessiveShrink
      [ International
        BL       TranslateError
      ]
        B        NaffHeapExit        ; and sort of fail

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
; ReadBlockSize. Top level HeapEntry
; =============
;

ReadBlockSize

        Push    "addr, work"
        BL      FindHeapBlock
        LDRVC   size, [addr, hpd]
        Pull   "addr, work"
        BVC     GoodHeapExit
        B       NaffHeapExit

;**************************************************************************
; Common routines for free/extend

FindHeapBlock   ROUT
; Convert addr to address
; Validate heap
; check block is an allocated block
; return tp = free list entry before the block (hpdfree if none)
;      work = free list before that (if exists)
; corrupts HpTemp, bp

        Push    lr

        ValidateHpd findfailed

        SUB     addr, addr, hpd     ; convert to offset
        SUB     addr, addr, #4      ; real block posn

; Find block in heap by chaining down freelist, stepping through blocks

; TMD 01-Mar-89
; no need to check explicitly for null free list, code drops thru OK

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT03
 Push lr
 WRLN "Scanning freelist"
 Pull lr
03
 ]

; step down free list to find appropriate chunk
; get tp = free block before addr
; HpTemp =  "     "   after   "
;   work = block before tp

        MOV     tp, #:INDEX: hpdfree
StepDownFreeList
        LDR     HpTemp, [hpd, tp]     ; link offset
        CMP     HpTemp,#Nil
        BEQ     ListEnded             ; EQ state used!
        ADD     HpTemp, HpTemp, tp
        CMP     HpTemp, addr
        MOVLS   work, tp
        MOVLS   tp, HpTemp
        BLS     StepDownFreeList
ListEnded
        LDREQ   HpTemp, hpdbase      ; if EQ from CMP HpTemp, addr
                                     ; then bad block anyway
        CMP     tp, #:INDEX: hpdfree
        MOVEQ   bp, #hpdsize         ; is this a fudge I see before me?
        BEQ     ScanAllocForAddr
        ADD     bp, tp, #fresize
        LDR     bp, [hpd, bp]
        ADD     bp, tp, bp

ScanAllocForAddr
; bp     -> start of allocated chunk
; HpTemp -> end    "   "        "
; scan to find addr, error if no in here

       Push    work       ; keep prevlink ptr

  [ debheap
; HpTemp critical
 Push "HpTemp, R0, link"
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT02
 STRIM "Scan for addr from "
 MOV   R0, bp
 BL    PrintOffset
 STRIM " to "
 LDR   R0,[stack,#4]  ; HpTemp
 BL    PrintOffsetLine
02
 Pull "HpTemp, r0, link"
 ]
        B       CheckForNullAllocn

ScanAllocForAddrLoop
        CMP     bp, addr
        BEQ     ValidBlock
        LDR     work, [bp, hpd]    ; get size
        ADD     bp, bp, work
CheckForNullAllocn
        CMP     bp, HpTemp
        BLT     ScanAllocForAddrLoop

 [ debheap
 Push lr
 STRIM "Given pointer not a block"
 Pull lr
 ]
       ADRL    R0, ErrorBlock_HeapFail_NotABlock
     [ International
       BL      TranslateError
     |
       SETV
     ]
       Pull   "work, pc"

ValidBlock    ; tp = free link offset, addr = block offset
       CLRV
       Pull   "work, pc"

findfailed_badhpd
 [ debheap
 Push   lr
 STRIM "Invalid heap descriptor"
 Pull   lr
 ]
        ADRL    R0, ErrorBlock_HeapFail_BadDesc
      [ International
        BL      TranslateError
      |
        SETV
      ]
        Pull    PC

;****************************************************************************

FreeChunkWithConcatenation ROUT
; in : addr -> block
;      tp   -> preceding free list entry
; out : block freed, concatenated with any free parts on either side,
;       base reduced if can do
; corrupts HpTemp, bp, size, addr

; TMD 01-Mar-89: FindHeapBlock now never returns tp=Nil, only tp=hpdfree,
; so no need for check, code will get there eventually!

; attempt concatenation with free blocks on both/either side
 [ debheap
 Push "R0, lr"
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT04
 STRIM "concatenation attempt with free ptr "
 MOV   R0,tp
 BL    PrintOffsetLine
04
 Pull  "R0, lr"
 ]

 [ DebugHeaps
        ORR     bp, hpd, #FreeSpaceDebugMask
        LDR     size, [addr, hpd]!
        ADD     HpTemp, addr, size
        SUB     HpTemp, HpTemp, #4      ; HpTemp -> last word of block
10
        STR     bp, [HpTemp], #-4       ; store word, then go back
        TEQ     HpTemp, addr            ; loop until done, but don't overwrite size field
        BNE     %BT10                   ; otherwise we might get an IRQ with a duff heap
        SUB     addr, addr, hpd         ; make addr an offset again
 ]

        LDR     size, [addr, hpd]      ; block size
        ADD     bp, size, addr         ; eob offset
        LDR     HpTemp, [tp, hpd]      ; Nil doesn't matter here!
        ADD     HpTemp, HpTemp, tp     ; offset of free block after ours
        CMP     HpTemp, bp             ; if tp was hpdfree then <> bp
        BNE     NoConcatWithNext       ; so will take branch

 [ debheap
 Push lr
 LDR bp, hpddebug
 CMP bp, #0
 BEQ %FT05
 WRLN "concatenating with block after"
05
 Pull lr
 ]
        ADD    bp, hpd, HpTemp
        LDR    bp, [bp, #fresize]
        ADD    bp, bp, size
        WritePSRc SVC_mode+I_bit, size
        STR    bp, [addr, hpd]       ; enlarge our block
        LDR    bp, [HpTemp, hpd]     ; offset in free list
        CMP    bp, #Nil
        ADDNE  bp, HpTemp, bp        ; offset from heap start
        SUBNE  bp, bp, tp            ; free list offset
        STR    bp, [tp, hpd]         ; free list updated, our block bigger
                                     ; - but not in the free list yet!

NoConcatWithNext  ; tp = free link offset, addr = block offset
                  ; now try for concatenation with previous block
        CMP    tp, #:INDEX: hpdfree  ; are we before any real free blocks?
        BEQ    NoConcatenation       ; yup

        ADD    HpTemp, tp, hpd
        LDR    size, [HpTemp, #fresize]
        ADD    bp, size, tp
        CMP    bp, addr
        BNE    NoConcatenation
 [ debheap
 Push lr
 LDR bp, hpddebug
 CMP bp, #0
 BEQ %FT06
 WRLN "concatenating with block before"
 STRIM "prevfree = "
 Push  R0
 MOV   R0, work
 BL    PrintOffsetLine
 Pull  R0
06
 Pull lr
 ]
        LDR    bp, [addr, hpd]         ; get block size
        ADD    size, bp, size          ; new free block size
        WritePSRc SVC_mode+I_bit, bp
        STR    size, [HpTemp, #fresize]
; now check for butts against base : work is still prevnode to tp
        ADD    HpTemp, size, tp
        LDR    bp, hpdbase
        CMP    bp, HpTemp
        BNE    %FT06                 ; all done : exit keeping IRQs off
        SUB    bp, bp, size
        STR    bp, hpdbase           ; step unused bit back
        MOV    bp, #Nil              ; this MUST have been last free block!
        STR    bp, [work, hpd]
06
        CLRV
        MOV    PC, lr                ; Whew!

NoConcatenation ; check if block butts against base
; tp = previous freelink offset
        LDR     size, [addr, hpd]
        ADD     HpTemp, size, addr
        LDR     bp, hpdbase
        CMP     bp, HpTemp
        BNE     AddToFreeList
        SUB     bp, bp, size
        WritePSRc SVC_mode+I_bit, HpTemp
        STR     bp, hpdbase
        CLRV
        MOV     PC, lr

AddToFreeList  ; block at addr, previous free at tp
 [ debheap
 Push "R0, lr"
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT07
 STRIM "add to free list : free link "
 MOV   R0,tp
 BL    PrintOffset
 STRIM ", block "
 MOV   R0, addr
 BL    PrintOffsetLine
07
 Pull "R0, lr"
 ]
        LDR    size, [addr, hpd]!
        WritePSRc SVC_mode+I_bit, HpTemp
        STR    size, [addr, #fresize]
        SUB    addr, addr, hpd
        LDR    size, [hpd, tp]      ; prevlink
        CMP    size, #Nil
        SUBNE  size, size, addr
        ADDNE  size, size, tp       ; form offset if not eolist
        STR    size, [addr, hpd]
        SUB    size, addr, tp
        STR    size, [tp, hpd]
        CLRV
        MOV    PC, lr

;*****************************************************************************

 [ debheap
;
; ShowHeap. Top level HeapEntry
; ========
;
; Dump the heap pointed to by hpd

ShowHeap
        Push    link
        BL      iShowHeap       ; Needed to fudge link for SVC mode entry
        Pull    link
        B       GoodHeapExit


iShowHeap ROUT ; Internal entry point for debugging heap

        Push    "r0, hpd, addr, size, work, bp, tp, link"

        ValidateHpd showfailed  ; debugging heaps won't work interruptibly

        LDR     tp, hpdfree
        CMP     tp, #Nil
        ADDNE   tp, tp, #:INDEX: hpdfree
        LDR     bp, hpdbase
        MOV     addr, #hpdsize
        LDR     work, hpdend

        SWI     OS_NewLine              ; Initial blurb about hpd contents
        DREG    hpd, "**** Heap map **** : hpd "
        STRIM   "->  free"
        MOV     r0, tp
        BL      PrintOffset
        STRIM   ", base"
        MOV     r0, bp
        BL      PrintOffsetLine
        STRIM   "-> start"
        MOV     r0, addr
        BL      PrintOffset
        STRIM   ",  end"
        MOV     r0, work
        BL      PrintOffsetLine

        SUB     r0, work, bp            ; hpdend-hpdbase
        DREG    r0,"Bytes free: ",cc, Word
        SUB     r0, bp, addr            ; hpdbase-hpdsize
        DREG    r0,", bytes used: ",, Word
        SWI     XOS_NewLine

        CMP     tp, #Nil                ; No free blocks at all ?
        BNE     %FT10
        WRLN    "No Free Blocks"

        CMP     bp, addr                ; Is a block allocated at all ?
        MOVNE   r0, addr ; hpdsize
        BNE     %FT40
        WRLN    "No Used Blocks"
        B       %FT99


10      CMP     tp, addr ; hpdsize       ; Allocated block below first free ?
        BEQ     %FT15

        MOV     r0, addr ; hpdbase
        BL      HexUsedBlk
        SUB     r0, tp, addr ; hpdfree-hpdsize
        DREG    r0
        SWI     XOS_NewLine

; Main loop chaining up free space list

15      ADD     addr, tp, hpd             ; convert to address
        LDR     size, [addr, #fresize]    ; Size of this block
        LDR     addr, [addr, #frelink]    ; offset to next block

        STRIM   "Free Block "
        MOV     r0, tp
        BL      PrintOffset
        DREG    size, ", size "

        ADD     r0, tp, size ; r0 -> eob. Adjacent free blocks don't exist

        CMP     addr, #Nil ; If last block, then must we see if we're = hpdbase
        BEQ     %FT40

; Used block starts at r0, ends at addr+tp - so size = (addr+tp)-r0

        BL      HexUsedBlk
        SUB     r0, addr, r0  ; addr-r0
        ADD     r0, r0, tp    ; used block size
        DREG    r0
        SWI     XOS_NewLine

        ADD     tp, addr, tp  ; step down free list
        B       %BT15         ; And loop


40      CMP     r0, bp      ; Is there any allocated space after this block ?
        BEQ     %FT99
        BL      HexUsedBlk
        SUB     r0, bp, r0  ; hpdbase-sob
        DREG    r0
        SWI     XOS_NewLine

99
        CLRV
        Pull   "r0, hpd, addr, size, work, bp, tp, pc"


showfailed_badhpd
        WRLN    "Invalid heap descriptor : ShowHeap failed"
        Pull    "r0, hpd, addr, size, work, bp, tp, pc"


HexUsedBlk
        Push   "lr"
        STRIM  "Used Block "
        BL      PrintOffset
        STRIM  ", size"
        Pull   "lr"
        MOV     PC, R14

PrintOffset
        Push   "r0, lr"
        DREG    r0
        CMP     R0, #0
        ADDNE   R0, R0, hpd
        DREG    r0," (",cc
        STRIM   ")"
        Pull   "R0, PC"

PrintOffsetLine
        Push   "lr"
        BL      PrintOffset
        SWI     XOS_NewLine
        Pull   "PC"

 ]

HeapCode_end

; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

        END
@


4.7
log
@Merge HAL branch to trunk
Detail:
  This change merges the past 15+ years of HAL branch development back to the trunk.
  This is effectively the end for non-HAL builds of the kernel, as no attempt has been made to maintain it during this merge, and all non-HAL & non-32bit code will soon be removed anyway.
  Rather than list everything that's been added to the HAL branch, it's easier to describe the change in terms of the things that the HAL branch was lacking:
  * Trunk version of Docs/32bit contained updated comments for the SVC stack structure during ErrorV
  * Trunk version of s/HeapMan contained a tweak to try and reduce the number of small free blocks that are created
  * Trunk version of s/Kernel contained a change to only copy 248 bytes of the error string to the error buffer (down from 252 bytes), to take into account the extra 4 bytes needed by the PSR. However this goes against the decision that's been made in the HAL branch that the error buffer should be enlarged to 260 bytes instead (ref: https://www.riscosopen.org/tracker/tickets/201), so the HAL build will retain its current behaviour.
  * Trunk version of s/MsgCode had RMNot32bit error in the list of error messages to count when countmsgusage {TRUE}
  * Trunk version of s/PMF/i2cutils contained support for OS_Memory 5, "read/write value of NVRamWriteSize". Currently the HAL branch doesn't have a use for this (in particular, the correct NVRamWriteSize should be specified by the HAL, so there should be no need for software to change it at runtime), and so this code will remain switched out in the HAL build.
Admin:
  Tested on Raspberry Pi


Version 5.48. Tagged as 'Kernel-5_48'
@
text
@a29 3
              GBLL TubeInfo
TubeInfo      SETL {FALSE}

a238 16
   [ TubeInfo
  LDR  R0, [R12]
  BL   TubeDumpR0
  LDR  R0, [R12, #4]
  BL   TubeDumpR0
  LDR  R0, [R12, #8]
  BL   TubeDumpR0
  LDR  R0, [R12, #24]
  TST  R0, #V_bit
  MOVEQ R0, #"v"
  MOVNE R0, #"V"
  TubeChar R1, R2, "MOV R2, r0"
  TubeChar R0, R1, "MOV R1, #10"
  TubeChar R0, R1, "MOV R1, #13"
    ]

a1985 14
     [ TubeInfo
TubeDumpR0     ROUT
        Push  "R1, R2, lr"
        TubeChar R0, R1, "MOV R1, #10"
        TubeChar R0, R1, "MOV R1, #13"
        MOV    R1, #7
01      MOV    R0, R0, ROR #28
        AND    R2, R0, #&F
        TubeChar R0, R1, "ADD R1, R2, #""0"""
        SUBS   R1, R1, #1
        BPL    %BT01
        Pull  "R1, R2, PC"
     ]

@


4.6
log
@  Minor optimisation to the heap manager for performance enhancement.
Detail:
  When splitting a free block in order to satisfy an allocation request,
    don't split if the remaining free space falls below a specified
    threshold (<= 8 bytes) to avoid creating lots of tiny free blocks,
    but instead gift the extra 8 bytes to the newly allocated block.
    This should stop the worst case heap fragmentation seen with OS_Heap
    heaps (particular the Toolbox's dynamic area).
Admin:
  Tested in Ursula desktop build.


Version 5.44. Tagged as 'Kernel-5_44'
@
text
@d36 5
d51 1
a55 1
work    RN      r4      ; This is the only one we have to save.
d90 1
a90 1
;              /|\                       /|\
d111 1
a111 1
; Block sizes must be forced to a multiple of 8 bytes for subsequent link and
d142 11
d186 1
a186 1
        SWI     XOS_Heap
d221 1
a221 1
        SWI     XOS_Heap
d223 1
a223 1
        MOV     R0, #HeapReason_ExtendBlock
d225 1
a225 1
        B       GoodExtension           ; into danger zone
d240 1
a240 1
        LDR        R12, =HeapReturnedReg_R0
d265 8
d284 1
a284 1
;       r2(addr) -> start of block
d286 1
d298 1
a298 1
        MOV     R11, #IRQsema
d320 1
a320 1
         Push  "R0-R3, lr"
d322 1
a322 1
         LDR    R10, =HeapSavedReg_R0
d330 1
a330 1
         LDMIA  R10, {R0-R3, R10, R11}
d332 1
a332 1
         LDR    R12, =HeapReturnedReg_R0
d336 18
a353 3
         mrs   ,lr, CPSR
         STMIA  R12, {R0-R3, R10, R11, lr}
         Pull  "R0-R3, lr"
d356 3
a358 2
        LDR     R12, =HeapSavedReg_R0
        STMIA   R12, {R0-R4, stack}
d387 2
d407 4
d412 1
a412 8

;HeapInUse
;     $HeapBadAsModuleBRA
;       SetBorder R10, R11, 15, 0, 0
;     $HeapBadAsModuleKET

;        ADR     R0, ErrorBlock_HeapFail_HeapLocked
;        B       NaffHeapExit
d644 2
a645 2
        ADD     size, size, #(freblksize-1)+4   ; Make block size granular
        BIC     size, size, #(freblksize-1)     ; with size field added
d670 5
a674 1
        BNE     SplitFreeBlock
d724 1
d754 1
a754 1
        ADR     R0, ErrorBlock_HeapFail_Alloc
d770 1
a770 1
        ADR     R0, ErrorBlock_HeapFail_BadDesc
d786 292
d1144 1
a1144 1
 DREG size, "ExtendBlock by ",concat
d1156 2
a1157 2
        ADD     size, size, #freblksize-1  ; round size as appropriate :
        BICS    size, size, #freblksize-1  ; round up to nearest 8
d1165 2
a1166 1
        SUBS    bp, bp, size             ; size of block left
d1176 1
a1176 1
 CMP bp, #0  ; restore GE/Lt
d1181 1
d1183 19
a1201 3
        STRGT    bp, [addr, hpd]           ; update size of block left
        ADDGT    addr, addr, bp            ; offset of block to free
        STRGT    size, [addr, hpd]         ; construct block for freeing
d1203 1
d1208 1
a1208 2
        ADD     lr, size, #freblksize-1         ; work out how much we actually extended by
        BICS    lr, lr, #freblksize-1
d1222 1
d1247 1
a1247 1
        BICEQ    HpTemp, HpTemp, #(freblksize-1)
d1249 1
a1249 1
        mrs     ,lr, CPSR                  ; save EQ/NE state
d1255 1
a1255 1
        msr     ,CPSR_cf, lr
d1266 1
a1266 1
 msr ,CPSR_f, lr
d1301 7
a1307 2
        CMP      HpTemp, size
        BNE      SplitFreeBlockForExtend
a1322 1
        SUB      HpTemp, HpTemp, size      ; new freblk size
d1372 4
a1375 4
        CMP      bp, #0
        ADDNE    HpTemp, tp, hpd
        STRNE    bp, [HpTemp, #fresize]    ; prevblock shrunk
        BNE      copy_backwards
d1379 2
d1397 1
a1397 1
 DREG HpTemp, "copying -4+",concat
d1456 1
a1456 1
        BIC      work, work, #(freblksize-1)
d1493 6
d1501 1
a1501 1
        B        NaffHeapExit
d1910 1
a1910 1
        DREG    r0,"Bytes free: ",concat, Word
d1972 1
a1972 1
        GRAB   "r0, hpd, addr, size, work, bp, tp, pc"
d1977 1
a1977 1
        GRAB    "r0, hpd, addr, size, work, bp, tp, pc"
d1993 1
a1993 1
        DREG    r0," (",concat
d1995 1
a1995 1
        GRAB   "R0, PC"
@


4.5
log
@  Bug fixes only.
Detail:
  "Podule" number now displayed again in *ROMModule output - flag
     preservation issue caused it to disappear in 5.23.
  *Eval output no longer misses its trailing space, neither do "Podule" or
    "Extn ROM" in *ROMModules output.
  Heap manager now works again in non-SVC modes.
  Exception dump now contains faked up 26-bit PC+PSR lookalike.
Admin:
  Assembled.
@
text
@d112 10
d617 8
@


4.5.2.1
log
@* Converted to building with ObjAsm (but still a single object file using ORG).
* Added ARM_IMB and ARM_IMBRange SWIs as recommended by ARMv5.
* Some early prototype HAL bits popped in - a lot of source restructuring still
  to come.
* New debug target creates an AIF image with debug information, and translates
  this into an ASCII object file for the 16702B logic analyser.

Version 5.35, 4.79.2.1. Tagged as 'Kernel-5_35-4_79_2_1'
@
text
@d85 1
a85 1
;              /|\                       /|\ 
d301 1
a301 1
         MRS    lr, CPSR
d875 1
a875 1
        MRS      lr, CPSR                  ; save EQ/NE state
d881 1
a881 1
        MSR      CPSR_cf, lr
@


4.5.2.2
log
@Merge Cortex kernel into HAL branch
Detail:
  This is a full merge of the Cortex kernel back into the HAL branch. Since the Cortex kernel is/was just a superset of the HAL branch, at this point in time both branches are identical.
  Main features the HAL branch gains from this merge:
  - ARMv6/ARMv7 support
  - High processor vectors/zero page relocation support
  - objasm 4 warning fixes
  - Improved HAL related functionality:
    - Support for HAL-driven RTCs instead of kernel-driven IIC based ones
    - Support for arbitrary size machine IDs
    - Support for multiple IIC busses
    - Support for any HAL size, instead of hardcoded 64k size
    - Probably some other stuff I've forgotten
  - Probably a few bug fixes here and there
Admin:
  Tested on BB-xM & Iyonix.
  Was successfully flashed to ROM on an Iyonix to test the Cortex branch implementation of the 2010 RTC bug fix.
  IOMD build untested - but has been known to work in the past.


Version 5.35, 4.79.2.123. Tagged as 'Kernel-5_35-4_79_2_123'
@
text
@d214 1
a214 1
        LDR        R12, =ZeroPage+HeapReturnedReg_R0
d263 1
a263 1
        LDR     R11, =ZeroPage+IRQsema
d287 1
a287 1
         LDR    R10, =ZeroPage+HeapSavedReg_R0
d297 1
a297 1
         LDR    R12, =ZeroPage+HeapReturnedReg_R0
d306 2
a307 3
        LDR     R12, =ZeroPage+HeapSavedReg_R0
        STMIA   R12, {R0-R4}
        STR     stack, [R12, #5*4]
@


4.5.2.3
log
@Improve heap manager. Add heap testbed. Add dummy implementation of some OS_ScreenMode reason codes.
Detail:
  s/HeapMan, hdr/KernelWS - Heap manager improvements:
    - Errors generated by interrupted heap operations that are forced to complete by a OS_Heap call from the background are now cached in kernel workspace until the foreground task is resumed. This prevents them from being potentially overwritten by MessageTrans running out of background error buffers.
    - Added new OS_Heap reason code, #7 - Get area aligned. This allows areas of memory to be allocated at specific (power-of-2) alignments, and optionally without crossing a given (power-of-2) boundary. Alignment & boundary calculations are performed using logical addresses.
    - Removed the limitation that all free and allocated blocks must be a multiple of 8 bytes in length. This change was required in order to allow OS_Heap 7 to function correctly. Now the only requirements are that blocks must be multiples of 4 bytes in length, at 4 byte alignment, with a minimum length of 8 bytes. 4 extra padding bytes may still be added to the end of allocations in order to avoid creating 4-byte free blocks.
  s/HeapMan, TestSrc/HeapTest/Makefile, TestSrc/HeapTest/c/testbed, TestSrc/HeapTest/s/asm - Added heap testbed program. Can either use the OS_Heap SWI or directly include a copy of the Kernel's heap manager sources.
  s/vdudecl, s/vduswis - Added dummy implementations of OS_ScreenMode 4, 5 and 6. This prevents the Wimp generating lots of "Unknown OS_ScreenMode reason code" errors when redrawing the screen.
  s/Arthur3, s/Oscli - Moved dotstring closer to where it's used to avoid "ADRL out of range" errors in Tungsten build
Admin:
  Tested in OMAP3 ROM & Tungsten ROM softload.
  Heap testbed successfully performed over 400 million heap ops, so there shouldn't be any serious bugs in the new code (touch wood)


Version 5.35, 4.79.2.128. Tagged as 'Kernel-5_35-4_79_2_128'
@
text
@a35 5
    [ :LNOT: :DEF: HeapTestbed
              GBLL HeapTestbed
HeapTestbed   SETL {FALSE}
    ]

a45 1
work    RN      r4
d50 1
d106 1
a106 1
; Block sizes must be forced to a minimum of 8 bytes for subsequent link and
a126 11
; Call XOS_Heap SWI

        MACRO
        CallXOSHeap
      [ HeapTestbed
        BL      DoCallXOSHeap
      |
        SWI     XOS_Heap
      ]
        MEND

d160 1
a160 1
        CallXOSHeap
d195 1
a195 1
        CallXOSHeap
d197 1
a197 1
        MOVVC   R0, #HeapReason_ExtendBlock
d199 1
a199 1
        BVC     GoodExtension           ; into danger zone
a238 8
        ; Recover the error from our buffer
        LDR       R0,=HeapBackgroundError
        LDR       R10,[R0]
        SWI       XMessageTrans_CopyError
        ; Check that it worked - MessageTrans may be dead
        LDR       R11,[R0]
        TEQ       R10,R11
        LDRNE     R0,=HeapBackgroundError ; Just return our internal buffer if MessageTrans couldn't provide one
d250 1
a250 1
;       r2(addr) -> start of block, or required alignment
a251 1
;       r4(work) =  boundary limitation
d285 1
a285 1
         Push  "R0-R4, lr"
d295 1
a295 1
         LDMIA  R10, {R0-R4, R11}
d302 2
a303 17
         STMIA  R12, {R0-R4, R11, lr}
; Any errors that were generated by the foreground operation may have ended up
; using one of MessageTrans' IRQ buffers. Trouble is, any number of IRQ errors
; could occur between now and when the foreground task gets the error. Avoid
; the error getting clobbered by copying it into a special kernel buffer, and
; then copy it back to a MessageTrans buffer once we're back in the foreground.
         BVC    noheapbackgrounderror
         LDR    R1,=HeapBackgroundError
         MOV    LR,#256
heapbackgrounderrorloop
         LDMIA  R0!,{R2-R4,R12}
         SUBS   LR,LR,#16
         STMIA  R1!,{R2-R4,R12}
         BNE    heapbackgrounderrorloop
         
noheapbackgrounderror
         Pull  "R0-R4, lr"
a336 2
 assert ((.-HeapJumpTable) :SHR: 2) = HeapReason_GetAligned
        B       GetAreaAligned
a354 4
      [ HeapTestbed
        MSR     CPSR_cxsf, lr           ; Fake exit for testbed
        Pull    "r10-r12,pc"
      |
a355 1
      ]
d595 2
a596 2
        ADD     size, size, #3+4                ; Make block size multiple of 4
        BIC     size, size, #3                  ; including header
d613 1
a613 5
        CMP     HpTemp, #freblksize
        BGE     SplitFreeBlock

; Increase allocation size if there wasn't enough space to split the free block
        ADD     size, size, HpTemp
a662 1
        CLRV
d692 1
a692 1
        ADRL    R0, ErrorBlock_HeapFail_Alloc
d708 1
a708 1
        ADRL    R0, ErrorBlock_HeapFail_BadDesc
a723 292
; GetAreaAligned. Top level HeapEntry
; ==============
;
; Allocate an aligned block of memory from the heap

; This is the same as GetArea, except it will only allocate areas with the given
; (power-of-two) alignment.
; Fails if requesting size = 0

; In : hpd -> heap pointer
;      size = size of block required
;      addr = alignment (power of 2)
;      work = boundary (power of 2, 0 for none)

; Out : VClear : addr -> got a block
;       VSet   : addr = 0, couldn't get block
;       Rest of universe ok

GetAreaAligned ROUT
        Push   "size,work"
        ValidateHpd garafailed

 [ debheap
; HpTemp not critical
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT00
 Push  "r0, link"
 MOV r0, size
 DREG r0, "GetAreaAligned "
 MOV r0, addr
 DREG r0, "alignment "
 MOV r0, work
 DREG r0, "boundary "
 BL iShowHeap
 Pull "r0, link"
00
 ]

        CMP     size, #0                        ; Can't deallocate 0, so there!
        BLE     garafailed_zero                 ; And -ve is invalid as well!
     ; note sizes of many megabytes thrown out by looking.

        ADD     size, size, #3                  ; Make block size multiple of 4
        BIC     size, size, #3                  ; excluding header

        SUB     bp, addr, #1                    ; Store alignment-1 in bp
        TST     bp, addr
        BNE     garafailed_align                ; Must be power of 2!
        CMP     bp, #3
        MOVLT   bp, #3                          ; Minimum alignment is 4

        SUB     r0, work, #1                    ; Store boundary-1 in r0
        TST     r0, work
        BNE     garafailed_boundary             ; Must be power of 2!

        ADR     addr, hpdfree-frelink           ; addr:= @@(hpd!free)-frelink

        ; If we have a boundary, it must be >= alignment, and >= size
        CMP     r0, #-1
        BEQ     garaloop
        CMP     r0, bp
        CMPHS   work, size
        BLO     garafailed_boundary2

garaloop
        LDR     tp, [addr, #frelink]        ; tp := addr!fre.link
        CMP     tp, #Nil                    ; Is this the end of the chain ?
        BEQ     garamore                    ;  - so try main blk
        ADD     addr, addr, tp              ; convert offset
        LDR     HpTemp, [addr, #fresize]

; Calculate start and end addresses as if we were to allocate from this block
        ADD     work,addr,#4 ; 4 bytes for storing block size
        ADD     HpTemp,HpTemp,addr ; End of free block
        ADD     work,work,bp
garaloop2
        BIC     work,work,bp ; work = start of user block
        SUB     lr,work,addr
        CMP     lr,#4
        BEQ     garastartok ; Start alignment is exact
        CMP     lr,#freblksize+4
        BGE     garastartok ; Enough space to fit a free block at the start

; We need a free block, but there isn't enough space for it.
; Shift 'work' up by one unit of alignment and try again.

        ADD     work,work,bp,LSL #1
        B       garaloop2

garastartok
; Calculate block end address
        ADD     lr,work,size ; End of user block
        SUBS    lr,HpTemp,lr ; Gap after user block
        BLO     garaloop ; Not big enough

; Check boundary requirement
        CMP     r0,#-1
        BEQ     garaboundaryok
        AND     lr,work,r0 ; Start offset within boundary
        ADD     lr,lr,size
        SUB     lr,lr,#1 ; Last byte of allocation
        CMP     lr,r0
        BLS     garaboundaryok

; This allocation crosses a boundary. Shift 'work' up to be boundary aligned.
        ADD     work,work,r0
        BIC     work,work,r0
        B       garaloop2 ; Loop back round to recheck everything (with small boundary sizes, we may have created a situation where we can't fit an initial free block)

garaboundaryok

; We have a suitable space to allocate from.
        ADD     size,size,#4 ; Correct size to store
        SUB     work,work,#4 ; Correct block start

 [ debheap
 LDR lr, hpddebug
 CMP lr, #0
 BEQ %FT60
 WRLN "Using existing free block"
60
 ]

; Note: bp now being used as scratch

        ADD     bp,work,size ; End of user block
        SUB     bp,HpTemp,bp ; Gap after user block

        WritePSRc SVC_mode+I_bit, lr

; Work out if we need a new free block afterwards
        CMP     bp, #freblksize
        ADDLT   size, size, bp ; Not enough space, so enlarge allocated block
        BLT     %FT10

; Create a new free block that will lie after our allocated block
        SUB     HpTemp, HpTemp, bp
        STR     bp, [HpTemp, #fresize]    ; Write size
        LDR     bp, [addr, #frelink]
        CMP     bp, #Nil
        ADDNE   bp, bp, addr
        SUBNE   bp, bp, HpTemp
        STR     bp, [HpTemp, #frelink]    ; Write next ptr
        SUB     HpTemp, HpTemp, addr
        STR     HpTemp, [addr, #frelink]  ; Fix up link from previous block
10

; Shrink this free block to take up the space preceeding the allocated block.
        SUBS    bp,work,addr
        STRNE   bp, [addr, #fresize]
        BNE     ResultIsWorkPlus4 

; No space for an initial free block. Get rid of it.
        ASSERT  frelink=0 ; otherwise LDR bp,[addr,#frelink]!
        LDR     bp, [addr]
        CMP     bp, #0
        ADDNE   bp, bp, tp
        STR     bp, [addr, -tp]
        B       ResultIsWorkPlus4
 
; Got no more free blocks of length >= size, so try to allocate more heap space
; out of the block described by hpd

garamore
 [ debheap
 LDR work, hpddebug
 CMP work, #0
 BEQ %FT80
 WRLN "Trying to get more from main block"
80
 ]
        LDR     work, hpdbase
        ADD     work, work, hpd
        ADD     tp, work, #4
        ADD     tp, tp, bp
garamoreloop
        BIC     tp, tp, bp            ; tp = pointer to return to user

; Make sure there's enough space for a free block if necessary
        SUB     HpTemp, tp, work      ; HpTemp = tp-(hpd+hpdbase)
        CMP     HpTemp, #4
        BEQ     garamoreok
        CMP     HpTemp, #freblksize+4
        ADDLT   tp, tp, bp, LSL #1 ; Not enough space for free block
        BLT     garamoreloop

garamoreok
; Boundary check
        CMP     r0, #-1
        BEQ     garamoreboundaryok
        AND     HpTemp, tp, r0
        ADD     HpTemp, HpTemp, size
        SUB     HpTemp, HpTemp, #1
        CMP     HpTemp, r0
        BLS     garamoreboundaryok

; Shift 'tp' up to be boundary aligned
        ADD     tp, tp, r0
        BIC     tp, tp, r0
        B       garamoreloop

garamoreboundaryok
        ADD     HpTemp, tp, size      ; New heap end
        SUB     HpTemp, HpTemp, hpd   ; New heap size
        LDR     lr, hpdend
        CMP     HpTemp, lr
        BGT     garafailed

        WritePSRc SVC_mode+I_bit, lr

; Set up the block to return to the user
        ADD     size, size, #4
        STR     size, [tp, #-4]!

; Grow the heap
        STR     HpTemp, hpdbase

; Create preceeding free block if necessary
        SUBS    HpTemp, tp, work
        BEQ     ResultIsTpPlus4

; Write the free block
        STR     HpTemp, [work, #fresize]
        MOV     HpTemp, #Nil
        STR     HpTemp, [work, #frelink]

; Patch up the preceeding block
        SUB     HpTemp, work, addr
        STR     HpTemp, [addr, #frelink]

ResultIsTpPlus4
; Block size is already stored
        ADD     addr, tp, #4
        Pull    "size,work"
        MOV     r0,#HeapReason_GetAligned
        CLRV
        B       GoodHeapExit        
        
ResultIsWorkPlus4
        STR     size, [work]           ; Store block size
        ADD     addr, work, #4         ; Move to correct return reg & add offset
        Pull    "size,work"
        MOV     r0,#HeapReason_GetAligned
        CLRV
        B       GoodHeapExit

garafailed
        ADRL    R0, ErrorBlock_HeapFail_Alloc     
      [ International
        BL      TranslateError
      ]
 [ debheap
 WRLN " : GetAreaAligned failed"
 ]
garafail_common
        MOV     addr, #0                ; addr := 0 if we couldn't allocate
        Pull    "size,work"             ; RESULTIS 0
        B       NaffHeapExit            ; VSet Exit

garafailed_badhpd
 [ debheap
 STRIM "Invalid heap descriptor"
 ]
        ADRL    R0, ErrorBlock_HeapFail_BadDesc
      [ International
        BL      TranslateError
      ]
        B garafail_common

 [ debheap
garafailed_zero
 STRIM "Can't allocate 0 or less bytes"
 B garafailed
garafailed_align
 STRIM "Alignment not power of 2"
 B garafailed
garafailed_boundary
 STRIM "Boundary not power of 2"
 B garafailed
garafailed_boundary2
 STRIM "Boundary too small"
 B garafailed
 |
garafailed_zero * garafailed
garafailed_align * garafailed
garafailed_boundary * garafailed
garafailed_boundary2 * garafailed
 ]

; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
;
d790 1
a790 1
 DREG size, "ExtendBlock by ",cc
d802 2
a803 2
        ADD     size, size, #3             ; round size as appropriate :
        BICS    size, size, #3             ; round up to nearest 4
d811 1
a811 2
        SUB     bp, bp, size             ; size of block left
        CMP     bp, #4
d821 1
a821 1
 CMP bp, #4  ; restore GE/Lt
a825 1
        BLE      GoodShrink
d827 3
a829 20
        ; If we're only shrinking 4 bytes, only allow the shrink to go ahead
        ; if there's a free block (or hpdbase) after us
        CMP      size, #4
        BGT      DoShrink
        LDR      HpTemp, [hpd, tp]
        CMP      HpTemp, #Nil
        ADDNE    HpTemp, HpTemp, tp
        LDREQ    HpTemp, hpdbase
        ADD      HpTemp, HpTemp, hpd       ; Next free block ptr
        SUB      HpTemp, HpTemp, addr      ; Offset from start of this block
        SUB      HpTemp, HpTemp, size      ; Apply shrink amount to match bp
        CMP      HpTemp, bp
        MOVGT    size, #0                  ; Used block after us. Deny shrink.
        BGT      GoodExtension
        BLT      CorruptExtension          ; Heap corrupt!
        ; Else there's a free block (or hpdbase) directly after us
DoShrink
        STR      bp, [addr, hpd]           ; update size of block left
        ADD      addr, addr, bp            ; offset of block to free
        STR      size, [addr, hpd]         ; construct block for freeing
a830 1
GoodShrink
d835 2
a836 1
        MOVS    lr, size                        ; work out how much we actually extended by
a849 1
        CLRV
d874 1
a874 1
        BICEQ    HpTemp, HpTemp, #3
d893 1
a893 1
 msr CPSR_f, lr
d928 2
a929 7
        SUB      HpTemp, HpTemp, size      ; new freblk size
        CMP      HpTemp, #4
        BGT      SplitFreeBlockForExtend

; Not enough space for a free block. Increase the grow amount a bit.
        ADDEQ    work, work, #4
        STREQ    work, [addr, hpd]
d945 1
d995 4
a998 4
        CMP      bp, #freblksize
        ADDGE    HpTemp, tp, hpd
        STRGE    bp, [HpTemp, #fresize]    ; prevblock shrunk
        BGE      copy_backwards
a1001 2
        ADDNE    size, size, bp            ; Increase grow amount by any remainder
        MOVNE    bp, #0                    ; And make sure the block does die
d1018 1
a1018 1
 DREG HpTemp, "copying -4+",cc
d1077 1
a1077 1
        BIC      work, work, #3
a1113 6
CorruptExtension
        ADRL    R0,ErrorBlock_HeapFail_BadLink
      [ International
        BL      TranslateError
      ]

d1116 1
a1116 1
        B       NaffHeapExit
d1525 1
a1525 1
        DREG    r0,"Bytes free: ",cc, Word
d1608 1
a1608 1
        DREG    r0," (",cc
@


4.5.2.4
log
@Fix OS_Heap 4. Fix stack imbalance in system heap code.
Detail:
  s/HeapMan - The code to check if it's safe to shrink a block by 4 bytes assumed 'addr' was the address of the block, when in reality it's just an offset. This was causing the "OK to shrink?" check to always ignore the shrink request on heaps located below the 2G limit, but fail with "heap corrupt" errors in heaps located above the 2G limit.
  s/ArthurSWIs - Fix stack imbalance causing a crash if OS_Heap returns an unexpected error in DoSysHeapOpWithExtension/ClaimSysHeapNode
Admin:
  Tested in Iyonix ROM softload
  Testbed didn't pick up heap shrink bug due to the sanity checks it performs not being vigorous enough.


Version 5.35, 4.79.2.130. Tagged as 'Kernel-5_35-4_79_2_130'
@
text
@d1179 1
a1179 1
        ADDNE    HpTemp, HpTemp, tp        ; Offset of next free block
d1181 1
d1187 1
a1187 1
        BLT      CorruptExtension          ; Heap corrupt! Next free block is before us
@


4.5.2.4.2.1
log
@Merge with HAL branch
Detail:
  Merge the HAL branch into the RPi branch, prior to merging RPi to HAL
  Brief summary of main changes brought in:
  * Added *cache functionality previously provided by ARM module
  * Added "CMOS RAM reset" message on startup when CMOS has been wiped by keypress
  * Renamed HAL Video entries from HAL_Video_XXX to HAL_VideoXXX
  * Dropped mjsHAL macros, GRAB/STASH macros
  * Fixed pseudo-VRAM allocation when machine has exactly 16MB of RAM
  * Added OS_Hardware 5
  * Use OS_SerialOp GetDeviceName for getting serial device name
  * Drop HAL_MonitorLeadID
  * Rework default GraphicsV_IICOp handler
Admin:
  Tested on Raspberry Pi with high processor vectors


Version 5.35, 4.79.2.147.2.23. Tagged as 'Kernel-5_35-4_79_2_147_2_23'
@
text
@d404 8
d1962 1
a1962 1
        Pull   "r0, hpd, addr, size, work, bp, tp, pc"
d1967 1
a1967 1
        Pull    "r0, hpd, addr, size, work, bp, tp, pc"
d1985 1
a1985 1
        Pull   "R0, PC"
@


4.5.2.5
log
@Adoption of *CONFIGURE/STATUS CACHE commands
The kernel already looks after all other aspects of the ARM CPU, so can look after the cache control command too.
 HelpStrs.s:New tokens for help and syntax
 CmdHelp.s:UK help and syntax
 Arthur3.s:Tables updates for *CONFIGURE/STATUS, lined some stuff up, default error text sync'd with Hdr:NewErrors
 MoreComms.s:Parsing and doing of *CACHE
 Utility.s:Hashing table updated for *CACHE
Other minor changes
 hdr/Options:Bring 'MosVer' into the private header
 hdr/RISCOS:aasm aliases for SP removed, MainVars and MosVer made private, added definition of the start of application space
 HeapMan.s:Use of GRAB changed to Pull
 Offset of TutuCMOS changed for more informative PrintSoundCMOS
 PMF/osbyte.s:Use OsBytes header file in place of MainVars

Version 5.35, 4.79.2.151. Tagged as 'Kernel-5_35-4_79_2_151'
@
text
@d1962 1
a1962 1
        Pull   "r0, hpd, addr, size, work, bp, tp, pc"
d1967 1
a1967 1
        Pull    "r0, hpd, addr, size, work, bp, tp, pc"
d1985 1
a1985 1
        Pull   "R0, PC"
@


4.5.2.6
log
@Sort out SetBorder
NewReset.s:
The one remaining use of SetBorder was to denote the user asked for and got a CMOS reset, which in the HAL case emitted a warning because setting the border is potentially complicated/slow.
To solve this, the reset is noted and replaces the normal RISC OS banner with a warning message. The behaviour and text for this comes from the BBC Master, though the escape key is used in place of break since a reset isn't actually needed.
Moved the unused cputable inside its corresponding switch.
Two occurrences of WriteS_Translated would have executed the message in the V=1 case.
KernelWS/Resources:
Flag added to workspace, translation added to messages files.
Heapman.s:
Commented out use of SetBorder removed.
Kernel.s:
SetBorder macro removed.
Middle.s:
Switched out use of SetBorder removed.
Super1.s:
Conditional WriteS_Translated would try to execute the message in the opposite condition case.


Version 5.35, 4.79.2.157. Tagged as 'Kernel-5_35-4_79_2_157'
@
text
@d404 8
@


4.5.2.1.2.1
log
@Add zero page relocation support
Detail:
  A whole mass of changes to add high processor vectors + zero page relocation support to the Cortex branch of the kernel
  At the moment the code can only cope with two ZeroPage locations, &0 and &FFFF0000. But with a bit more tweaking those restrictions can probably be lifted, allowing ZeroPage to be hidden at almost any address (assuming it's fixed at compile time). If I've done my job right, these restrictions should all be enforced by asserts.
  There's a new option, HiProcVecs, in hdr/Options to control whether high processor vectors are used. When enabling it and building a ROM, remember:
  * FPEmulator needs to be built with the FPEAnchor=High option specified in the components file (not FPEAnchorType=High as my FPEmulator commit comments suggested)
  * ShareFS needs unplugging/removing since it can't cope with it yet
  * Iyonix users will need to use the latest ROOL boot sequence, to ensure the softloaded modules are compatible (OMAP, etc. don't really softload much so they're OK with older sequences)
  * However VProtect also needs patching to fix a nasty bug there - http://www.riscosopen.org/tracker/tickets/294
  The only other notable thing I can think of is that the ProcessTransfer code in s/ARM600 & s/VMSAv6 is disabled if high processor vectors are in use (it's fairly safe to say that code is obsolete in HAL builds anyway?)
  Fun challenge for my successor: Try setting ZeroPage to &FFFF00FF (or similar) so its value can be loaded with MVN instead of LDR. Then use positive/negative address offsets to access the contents.
  File changes:
  - hdr/ARMops - Modified ARMop macro to take the ZeroPage pointer as a parameter instead of 'zero'
  - hdr/Copro15ops - Corrected $quick handling in myISB macro
  - hdr/Options - Added ideal setting for us to use for HiProcVecs
  - s/AMBControl/allocate, s/AMBControl/growp, s/AMBControl/mapslot, s/AMBControl/memmap, s/AMBControl/service, s/AMBControl/shrinkp, s/Arthur2, s/Arthur3, s/ArthurSWIs, s/ChangeDyn, s/ExtraSWIs, s/HAL, s/HeapMan, s/Kernel, s/MemInfo, s/Middle, s/ModHand, s/MoreSWIs, s/MsgCode, s/NewIRQs, s/NewReset, s/Oscli, s/PMF/buffer, s/PMF/IIC, s/PMF/i2cutils, s/PMF/key, s/PMF/mouse, s/PMF/osbyte, s/PMF/oseven, s/PMF/osinit, s/PMF/osword, s/PMF/oswrch, s/SWINaming, s/Super1, s/SysComms, s/TickEvents, s/Utility, s/vdu/vdu23, s/vdu/vdudriver, s/vdu/vdugrafl, s/vdu/vdugrafv, s/vdu/vdupalxx, s/vdu/vdupointer, s/vdu/vduswis, s/vdu/vduwrch - Lots of updates to deal with zero page relocation
  - s/ARM600 - UseProcessTransfer option. Zero page relocation support. Deleted pre-HAL ClearPhysRAM code to tidy the file up a bit.
  - s/ARMops - Zero page relocation support. Set CPUFlag_HiProcVecs when high vectors are in use.
  - s/KbdResPC - Disable compilation of dead code
  - s/VMSAv6 - UseProcessTransfer option. Zero page relocation support.
Admin:
  Tested with OMAP & Iyonix ROM softloads, both with high & low zero page.
  High zero page hasn't had extensive testing, but boot sequence + ROM apps seem to work.


Version 5.35, 4.79.2.98.2.48. Tagged as 'Kernel-5_35-4_79_2_98_2_48'
@
text
@d214 1
a214 1
        LDR        R12, =ZeroPage+HeapReturnedReg_R0
d263 1
a263 1
        LDR     R11, =ZeroPage+IRQsema
d287 1
a287 1
         LDR    R10, =ZeroPage+HeapSavedReg_R0
d297 1
a297 1
         LDR    R12, =ZeroPage+HeapReturnedReg_R0
d306 1
a306 1
        LDR     R12, =ZeroPage+HeapSavedReg_R0
@


4.5.2.1.2.2
log
@Fix objasm 4 warnings
Detail:
  s/Arthur3, s/ChangeDyn, s/HAL, s/HeapMan, s/Middle, s/MoreSWIs, s/NewIRQs, s/Utility, s/VMSAv6, s/PMF/key, s/PMF/osbyte, s/PMF/osword, s/vdu/vdudecl, s/vdu/vdudriver, s/vdu/vduplot, s/vdu/vduwrch - Tweaked lots of LDM/STM instructions in order to get rid of the depracation/performance warnings
Admin:
  Tested on rev A2 BB-xM


Version 5.35, 4.79.2.98.2.53. Tagged as 'Kernel-5_35-4_79_2_98_2_53'
@
text
@d307 1
a307 2
        STMIA   R12, {R0-R4}
        STR     stack, [R12, #5*4]
@


4.4
log
@  32-bit Kernel.

Details:
  The Kernel will now compile to produce a pure 32-bit system if No26bitCode is
  set to TRUE.
  If No26bitCode is FALSE, then the Kernel will be a standard 26-bit Kernel,
  although some internal changes have taken place to minimise compile
  switches between the two cases. See Docs.32bit for more technical info.

  The hardest part was the flood-fill...

Other changes:
  Pointer shape changes now take place on the next VSync, rather than actually
  WAITING for the VSync. Turning the Hourglass on shouldn't slow your machine
  down by 5% now :)

  Lots of really crusty pre-IOMD code removed.

Admin:
  Tested in 32 and 26-bit forms in a limited desktop build. Basically, this
  will need to see a lot of use to iron out difficulties. I'd like anyone who
  has a non-frozen project to at least attempt using this Kernel.

Version 5.23. Tagged as 'Kernel-5_23'
@
text
@d208 1
a208 1
; background. Pick up the registers, look at the saved PC to see if error
d258 2
a259 1
        Push    lr                      ; lr is actually SPSR (sneaky)
d301 1
a301 1
         mrs   ,lr, CPSR                ; will be non-zero cause not in user mode
d307 1
a307 1
        STMIA   R12, {R0-R4, stack}     ;This is where the stacked PC (lr) points to (WT)
@


4.3
log
@* Added support for 24LC64 8K EEPROM (untested).
* Integrated Ursula fast service call dispatch code.
* Added Interruptible32bitModes from Ursula.
* Stopped allowing ROM modules (other than the Kernel/UtilityModule) to write
  to the hardware vectors in 26-bit mode.

Version 4.81. Tagged as 'Kernel-4_81'
@
text
@a29 17
                    GBLS HeapBadAsModuleBRA
                    GBLS HeapBadAsModuleKET
HeapBadAsModuleBRA SETS "[ {FALSE}" ; "" for modular testing version
HeapBadAsModuleKET SETS "]"          ; "" for modular testing version

              GBLS RecursiveHeap
RecursiveHeap SETS "XOS_Heap"

     MACRO
$l   jeep $r,$var
   [ Module
$l   ADR  $r, $var
   |
$l   LDR $r, =$var
   ]
     MEND

a32 53
   $HeapBadAsModuleBRA

     GET Hdr:Listopts
     GET Hdr:Macros
     GET Hdr:System
     GET Hdr:ModHand
     GET Hdr:Debug
     GET Hdr:Heap
     GET Hdr:NewErrors

BranchToSWIExit *  0
IRQsema         *  &108

; debug macro: set the border colour

      MACRO
$l    SetBorder  $reg1, $reg2, $red, $green, $blue
  ! 0, "Setborder used"
$l    LDR        $reg1, =VIDC
      LDR        $reg2, =&40000000+ $red + $green *16 + $blue *256
      STR        $reg2, [$reg1]
      MEND

        MACRO
        assert  $condition
 [ :LNOT: ($condition)
 ! 1,"Assert failed: $condition"
 ]
       MEND

        GBLL Module
Module  SETL {TRUE}

     LEADR Module_LoadAddr

HeapTestModule ROUT
           &   0
           &   0
           &   0
           &   0
           &   Title-HeapTestModule
           &   Title-HeapTestModule
           &   0
           &   1024

RecursiveHeap SETS "1024 + (1:SHL:17)"

           &   HeapEntry-HeapTestModule

Title = "HeapTestModule",0

   $HeapBadAsModuleKET

a41 1
TTMMask *       32*1024*1024  ; thirty-two meg mask
a125 43
; check pointer sensible. Exit EQ if OK
; valid RAM checks done elsewhere

        MACRO
$label  CheckPtr $reg,$cond,$xtrabits
$label  TST$cond $reg, #ARM_CC_Mask
       [ "$xtrabits" = ""
        TSTEQ    $reg, #TTMMask    ; check < 32M
       |
        TSTEQ    $reg, #TTMMask + $xtrabits  ; check < 32M, with other bits.
       ]
        MEND

   $HeapBadAsModuleBRA

   [ TubeInfo
DebugTUBE  * &03340000+1*&4000         ; tube in podule #1
; Tube register offsets
 ^ 0
R1STAT # 4
R1DATA # 4
   ]

; routine to stuff a char down the Tube
     MACRO
$l   TubeChar $reg1, $reg2, $chworkt, $stackthere
  !  0, "TubeChar used."
$l
   [ "$stackthere"=""
   Push "$reg1, $reg2"
   ]
     LDR  $reg1, =DebugTUBE
01   LDRB $reg2, [$reg1, #R1STAT]
     TST $reg2, #&40
     BEQ %BT01
     $chworkt
     STRB $reg2, [$reg1, #R1DATA]
   [ "$stackthere"=""
   Pull "$reg1, $reg2"
   ]
   MEND

   $HeapBadAsModuleKET
a131 1
 [ Fix4
d135 2
a136 1
        TEQEQP  PC, #SVC_mode           ; if was clear then clear it now
d148 1
a148 1
        TEQP    PC, #SVC_mode + I_bit   ; disable IRQs before we venture back
d160 1
a160 1
        SWI     $RecursiveHeap
d195 1
a195 1
        SWI     $RecursiveHeap
d198 1
a198 1
        TEQP    PC, #SVC_mode + I_bit   ; disable IRQs before we venture back
d202 1
a202 1
        TEQP    PC, #SVC_mode + I_bit   ; disable IRQs before we venture back
a204 1
 ]
d214 1
a214 4
     $HeapBadAsModuleBRA
     SetBorder R10, R11, 0, 0, 10      ; blue for returning
     $HeapBadAsModuleKET
        jeep       R12, HeapReturnedReg_R0
d235 1
a235 1
        STR       R10, [R12, #HeapReturnedReg_PC-HeapReturnedReg_R0]
d258 1
a258 2
        Push    lr
        MOV     lr, PC             ; hang on to interrupt state
d261 1
a261 1
        TEQP    PC, #SVC_mode+I_bit
a266 1
   [ Interruptible32bitModes
a267 4
   |
        LDR     R10, [R11, #4*7]
        BIC     R10, R10, #ARM_CC_Mask
   ]
a276 10
     $HeapBadAsModuleBRA
     Push "R0, R1, lr"
     MOV   R0, R10
     [ TubeInfo
     BL    TubeDumpR0
     ]
     SetBorder R0, R1, 15, 8, 6
     Pull "R0, R1, lr"
     $HeapBadAsModuleKET

a277 1
     [ Interruptible32bitModes
d281 2
a282 6
         ORR    R10, R10, #I32_bit:OR:SVC26_mode
         STR    R10, [R11, #4*6]               ; return into SVC26 mode with IRQs disabled
     |
         ORR    R10, R10, #SVC_mode+I_bit
         STR    R10, [R11, #4*7]               ; return address zapped
     ]
d286 1
a286 1
         jeep   R10, HeapSavedReg_R0
d290 1
a290 1
;         LDR    R12, [R10, #HeapReturnedReg_PC-HeapSavedReg_R0]
d295 2
a296 2
         SWI    $RecursiveHeap               ; with interrupts off!
         jeep   R12, HeapReturnedReg_R0
d300 1
a300 7
  [ StrongARM
  ;just in case the exact PC address is critical, make sure it is as old way intended,
  ;on old architecture, or on architecture 4...
  ;but, for goodness sake, make sure the PSR bits are stored too! (eg. ADD lr,PC,#8
  ;zaps the PSR bits) (mjs)
         MOV    lr, PC          ;got address (current PC+8) and PSR bits
         ADD    lr, lr, #12     ;now also same position as old code would push on old architecture
a302 5
  |
  ;old way stores PC address and PSR bits directly, may be assuming that address is PC+12 (mjs)
         STMIA  R12, {R0-R3, R10, R11, PC}
         Pull  "R0-R3, lr"
  ]
d305 1
a305 1
        jeep    R12, HeapSavedReg_R0
d309 1
a309 1
        LDR     R12, [R12, #HeapReturnedReg_PC-HeapSavedReg_R0]
d311 1
a311 1
        TEQEQP  PC, lr                  ; restore callers interrupt state
d349 1
a349 4
        MOV     R12, PC
        ORR     R12, R12, #I_bit        ; IRQs off
        TEQP    PC, R12
        MOV     R0, R0
a352 4
     $HeapBadAsModuleBRA
        MOVS   PC, lr
     $HeapBadAsModuleKET

a373 20
     $HeapBadAsModuleBRA

; inline workspace for testing

HeapSavedReg_R0     & 0
HeapSavedReg_R1     & 0
HeapSavedReg_R2     & 0
HeapSavedReg_R3     & 0
HeapSavedReg_R4     & 0
HeapSavedReg_R13    & 0
HeapReturnedReg_R0  & 0
HeapReturnedReg_R1  & 0
HeapReturnedReg_R2  & 0
HeapReturnedReg_R3  & 0
HeapReturnedReg_R4  & 0
HeapReturnedReg_R13 & 0
HeapReturnedReg_PC  & 0               ; also acts as interlock

     $HeapBadAsModuleKET

d380 1
a380 1
        Push   "R0-R2, lr"
d382 2
a383 1
        TEQP    PC, #SVC_mode+I_bit  ; interrupts off for validation
d400 3
a402 2
        Pull   "R0-R2, lr"
        ORRS    PC, lr, #Z_bit       ; success
d405 3
a407 2
        Pull   "R0-R2, lr"
        BICS    PC, lr, #Z_bit       ; NE returned ; fails
a430 5
 [ MEMM_Type <> "ARM600"        ; If on ARM600 these checks are not valid
        CheckPtr hpd                       ; Is either hpd or size bad ?
        CheckPtr size, EQ,  (16*1024*1024) ; If hpd ok, check size < 16M
        BNE     NaffHeapInitialise
 ]
a598 1
 [ Fix2
a601 6
 |
        MOV     tp, addr                    ; tp := addr Keep ptr to prev block
        LDR     addr, [addr, #frelink]      ; addr := addr!fre.link
        CMP     addr, #Nil                  ; Is this the end of the chain ?
        BEQ     garmore                     ;  - so try main blk
 ]
a622 1
 [ Fix2
d625 1
a625 1
        TEQP    PC, #SVC_mode+I_bit
a627 6
 |
        ADDNE   HpTemp, HpTemp, addr      ; convert to address (if not Nil!)
        SUBNE   HpTemp, HpTemp, tp        ; and back to  offset
        TEQP    PC, #SVC_mode+I_bit
        STR     HpTemp, [tp, #frelink]    ; into link of previous free block
 ]
d644 1
a644 1
        TEQP    PC, #SVC_mode+I_bit
d680 1
a680 1
        TEQP    PC, #SVC_mode+I_bit
d808 1
a808 1
        TEQP    PC, #SVC_mode+I_bit
a852 1
 [ Fix2
a856 5
 |
        CMP      tp, #Nil
        LDRNE    bp, [tp, hpd]             ; next free
        CMPNE    bp, #Nil
 ]
d874 1
a874 1
        MOV      lr, PC                    ; save EQ/NE state
d879 2
a880 2
        ORR      lr, lr, #I_bit            ; disable IRQs
        TEQP     PC, lr
d891 1
a891 1
 TEQP  PC, lr
a951 2
 [ {TRUE}
 [ Fix2
a954 4
 |
        CMP      tp, #Nil              ; no free list?
        CMPNE    tp, #:INDEX: hpdfree  ; or no real preceder?
 ]
d985 1
a985 1
        TEQP     PC, #SVC_mode+I_bit       ; IRQs off
a1026 1
 [ Fix4
a1029 1
 |
a1030 12
        ADD      bp, bp, #4                ; new block pointer
        STR      bp, [stack]               ; return to user

; copy wackbords: HpTemp-4 bytes from addr+4 to bp, in appropriate order!
cpe_prev
        SUBS     HpTemp, HpTemp, #4
        LDRGT    work, [addr, #4]!
        STRGT    work, [bp], #4
        BGT      cpe_prev
        B        GoodExtension
 ]
    ]
d1068 1
a1068 1
        TEQP     PC, #SVC_mode+I_bit   ; IRQs off
a1109 1
 [ Fix4
a1110 50
 |
        TEQP     PC, #SVC_mode+I_bit       ; no interrupts during this
        LDR      work, [addr, hpd]!        ; get block size, set block addr
        ADD      size, size, work
        SUB      size, size, #4            ; block size to claim
        ADD      addr, addr, #4
        MOV      bp, addr                  ; address to copy from
        Push     addr                      ; save for later freeing

        MOV      R0, #HeapReason_Get
        SWI      $RecursiveHeap
        Pull     addr, VS
        BVS      NaffExtension

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT06
 DREG work, "got new block : copying "
06
 ]

        STR      addr, [stack, #4]

; claimed : copy work-4 bytes from bp to addr
CopyForExtension
        SUBS     work, work, #4
        LDRGT    HpTemp, [bp],#4
        STRGT    HpTemp, [addr],#4
        BGT      CopyForExtension

; free the old block!

 [ debheap
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT08
 WRLN "freeing old block"
08
 ]

; recursive SWI to free old block; we have invalidated any held information

        MOV      R0, #HeapReason_Free
        Pull     addr                  ; heap block addr
        SWI      $RecursiveHeap

        MOV      R0, #HeapReason_ExtendBlock
        B        GoodExtension
 ]
d1143 1
a1143 1
        TEQP     PC, #SVC_mode+I_bit
a1180 4
 [ Fix3
 |
        Pull     lr
 ]
a1226 1
 [ Fix2
a1230 20
 |
        LDR     tp, hpdfree          ; first find bounding free blocks
        CMP     tp, #Nil             ; no free?
  [ debheap
; HpTemp not critical
; EQ critical
 BNE %FT01
 LDR HpTemp, hpddebug
 CMP HpTemp, #0
 BEQ %FT01
 Push  "link"
 WRLN "No free list - scan all blocks"
 Pull "link"
 CMP R0,R0 ; restore EQ
01
 ]
        MOVEQ   bp, #hpdsize         ; load block limits to look through
        LDREQ   HpTemp, hpdbase
        BEQ     ScanAllocForAddr
 ]
a1261 1
 [ Fix2
a1263 5
 |
        ADD     tp, tp, #fresize
        LDR     bp, [hpd,tp]
        SUB     tp, tp, #fresize
 ]
d1307 2
d1310 1
a1310 2
       Pull   "work, lr"
       ORRS    PC, lr, #V_bit
d1313 2
a1314 2
       Pull   "work, lr"
       BICS    PC, lr, #V_bit
d1325 2
d1328 1
a1328 2
        Pull    lr
        ORRS    PC, lr, #V_bit
a1338 1
 [ Fix2
a1340 5
 |
        CMP     tp, #Nil
        MOVEQ   tp, #:INDEX: hpdfree
        BEQ     NoConcatenation
 ]
d1386 1
a1386 1
        TEQP   PC, #SVC_mode+I_bit
d1421 1
a1421 1
        TEQP   PC, #SVC_mode+I_bit
d1427 1
a1427 1
        ORRNES PC, lr, #I_bit        ; all done : exit keeping IRQs off
d1432 3
a1434 1
        ORRS   PC, lr, #I_bit        ; Whew!
d1444 1
a1444 1
        TEQP    PC, #SVC_mode+I_bit
d1446 2
a1447 1
        ORRS    PC, lr, #I_bit
d1465 1
a1465 1
        TEQP   PC, #SVC_mode+I_bit
d1475 2
a1476 1
        ORRS   PC, lr, #I_bit
d1584 2
a1585 1
        GRABS  "r0, hpd, addr, size, work, bp, tp, pc"
d1590 1
a1590 1
        GRABS    "r0, hpd, addr, size, work, bp, tp, pc"
d1599 1
a1599 1
        MOVS    PC, R14
d1608 1
a1608 1
        GRABS  "R0, PC"
d1629 1
a1629 1
        Pull  "R1, R2, PC", ,^
a1634 4

        $HeapBadAsModuleBRA
        InsertDebugRoutines
        $HeapBadAsModuleKET
@


4.2
log
@Kernel merged
@
text
@d386 3
d391 1
d412 7
d421 1
@


4.2.2.1
log
@ 1 Simplify source by removing various long-standing compile flags
   and pre-Medusa h/w support

 2 Fix bug with Pages_Unsafe/Pages_Safe page moving for StrongARM
   (interrupt hole) - also better performance for StrongARM

 3 Improve perfromance of physical memory clear for StrongARM
   (make sure it uses burst write for STM)

 4 Suspend Chocolate task switching for StrongARM if SALDMIBbroken
   is TRUE
@
text
@d246 1
d319 1
d481 1
d483 1
d593 5
a597 1

d636 1
d638 1
d705 1
d707 1
d715 1
d717 1
d766 1
d770 6
d797 1
d803 6
d872 1
d874 1
d888 1
d890 1
d1034 1
d1039 5
d1139 2
d1144 4
d1220 1
d1224 4
d1229 9
d1239 1
d1304 1
a1304 1

d1317 1
d1319 50
d1427 1
d1429 1
d1435 1
d1437 1
d1439 4
d1450 1
d1452 1
d1489 1
d1494 20
d1545 1
d1548 5
d1594 1
d1596 1
d1611 1
d1613 1
d1626 1
d1629 5
@


4.2.2.2
log
@Various speed ups
Memory map changes:
remove shadow ROM
move UNDEF stack, SoftCAM and MMU tables above 64M
expand RMA limit to 15M from 11M
expand SysHeap limit to 3M-32k from 2M-8k
expand SVC stack to 32k from 8k
partially protect kernel workspace from user access
protect SVC stack from user access
@
text
@a725 10
  [ mjsSysHeapNodesTrace
        Push    "r0-r2"
        AND     r0,r1,#&FF00000
        CMP     r0,#&1C00000
        MOVEQ   r0,#0
        LDREQ   r1,[r0,#mjsSHNT_ohc_total]
        ADDEQ   r1,r1,#1
        STREQ   r1,[r0,#mjsSHNT_ohc_total]
        Pull    "r0-r2"
  ]
a843 1
  [ InternationaliseCommonSilentErrors
a844 1
  ]
a890 10
  [ mjsSysHeapNodesTrace
        Push    "r0-r2"
        AND     r0,r1,#&FF00000
        CMP     r0,#&1C00000
        MOVEQ   r0,#0
        LDREQ   r1,[r0,#mjsSHNT_ohf_total]
        ADDEQ   r1,r1,#1
        STREQ   r1,[r0,#mjsSHNT_ohf_total]
        Pull    "r0-r2"
  ]
a927 10
  [ mjsSysHeapNodesTrace
        Push    "r0-r2"
        AND     r0,r1,#&FF00000
        CMP     r0,#&1C00000
        MOVEQ   r0,#0
        LDREQ   r1,[r0,#mjsSHNT_ohx_total]
        ADDEQ   r1,r1,#1
        STREQ   r1,[r0,#mjsSHNT_ohx_total]
        Pull    "r0-r2"
  ]
@


4.2.2.3
log
@added support for Sparse dynamic areas
fixed performance disaster caused by naff API for Shrinkable areas
implemented clamps for dynamic areas max size
configured kernel to not own or create RAMFS area (needs new RAMFS)
AMBControl now uses system heap for space, not RMA
AMBControl enables Lazy task swapping if running on rev T or better SA
kernel now assumes there could be code above 64M
SWIS for limited 32 bit user code support implemented
Long command lines implemented (1k instead of 256)
Fast service call distribution implemented (uses Ursula module format)
*fx,*key etc now allow missing space before first parameter
*configure is reinstated (bug fix)
@
text
@a383 3
   [ Interruptible32bitModes
        LDR     R10, [R11, #4*8]        ; Get LR from IRQ stack
   |
a385 1
   ]
a405 7
     [ Interruptible32bitModes
         STR    R10, [R11, #4*8]               ; return address zapped
         LDR    R10, [R11, #4*6]               ; get stored SPSR
         BIC    R10, R10, #&FF
         ORR    R10, R10, #I32_bit:OR:SVC26_mode
         STR    R10, [R11, #4*6]               ; return into SVC26 mode with IRQs disabled
     |
a407 1
     ]
@


4.2.2.3.2.1
log
@Changed compile switches, to build Ursula kernel for RPC and A7000(+),
switches now set as follows:
  ARM67Support      TRUE  (for 610,710,7500,7500FE)
  ARMSASupport      TRUE  (for StrongARM)
  ARMSASupport_RevS FALSE (for StrongARMs before rev S)
  IOMD1Support      TRUE  (for old machines)
  IOMD2Support      FALSE (They killed Phoebe!)
Version set to 4.00 (RISC OS 4)
This is the same as my last commit to the Ursula branch
@
text
@d437 1
d446 5
@


4.2.2.4
log
@Phoebe aware version of kernel
Source currently builds for Phoebe only. Flipping source switches will
build for Risc PC and/or A7000(+) as well (or instead). Not tested
much on older platforms.
Known issues remaining:
 - on Phoebe, kernel does not always set up the video (new VCO)
   properly. It appears that anything via the display manager is ok,
   old modes are ok before a monitor definition is seen, but mode
   changes via applications in the desktop always/often (?) aren't.
   Most likely area for investigation is whether kernel catches all
   mode change routes for ensuring it programs the new VCO.
 - on Phoebe, kernel does not yet have the hooks to support multiple
   CPU(s) (to park the slaves and allow them to be used later). I
   have a technical note on this, which should be archived as part of
   the Ursula burial work.
 - on older platforms, the areas that need checking most are CMOS
   power on reset (when in ROM) and mode changes by all routes (since
   these areas are bent by Phoebe support)
Note that kernel currently builds for rev S or better StrongARM. The
switch ARMSASupport_RevS should be set false if building for Risc PC.
@
text
@d437 1
d446 5
@


4.1
log
@Initial revision
@
text
@d25 1
d322 1
a322 1
; Here's the bit that gets returned to if the heap op was done in the 
d424 1
d427 11
d440 1
d444 1
a444 1
        STMIA   R12, {R0-R4, stack}
d490 1
a490 1
        MOVNV   R0, R0
d508 1
a508 1
; Errors 
d1197 1
a1197 1
        
d1842 1
a1842 1
        
d1856 1
a1856 1
        SUB     r0, addr, r0  ; addr-r0 
@


4.1.7.1
log
@NCOS 1.06 Imported from Zip drive
@
text
@@


4.1.5.1
log
@Import from SrcFiler
@
text
@@


4.1.3.1
log
@Import from cleaned 370 CD
@
text
@a24 1

d321 1
a321 1
; Here's the bit that gets returned to if the heap op was done in the
a422 1

a424 11
  [ StrongARM
  ;just in case the exact PC address is critical, make sure it is as old way intended,
  ;on old architecture, or on architecture 4...
  ;but, for goodness sake, make sure the PSR bits are stored too! (eg. ADD lr,PC,#8
  ;zaps the PSR bits) (mjs)
         MOV    lr, PC          ;got address (current PC+8) and PSR bits
         ADD    lr, lr, #12     ;now also same position as old code would push on old architecture
         STMIA  R12, {R0-R3, R10, R11, lr}
         Pull  "R0-R3, lr"
  |
  ;old way stores PC address and PSR bits directly, may be assuming that address is PC+12 (mjs)
a426 1
  ]
d430 1
a430 1
        STMIA   R12, {R0-R4, stack}     ;This is where the stacked PC (lr) points to (WT)
d476 1
a476 1
        MOV     R0, R0
d494 1
a494 1
; Errors
d1183 1
a1183 1

d1828 1
a1828 1

d1842 1
a1842 1
        SUB     r0, addr, r0  ; addr-r0
@


4.1.1.1
log
@Import from cleaned 360 CD
@
text
@@
