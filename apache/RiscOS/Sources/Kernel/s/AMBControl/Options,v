head	4.3;
access;
symbols
	Kernel-6_15:4.3
	Kernel-6_14:4.3
	Kernel-6_01-3:4.3
	Kernel-6_13:4.3
	Kernel-6_12:4.3
	Kernel-6_11:4.3
	Kernel-6_10:4.3
	Kernel-6_09:4.3
	Kernel-6_08-4_129_2_10:4.3
	Kernel-6_08-4_129_2_9:4.3
	Kernel-6_08:4.3
	Kernel-6_07:4.3
	Kernel-6_06:4.3
	Kernel-6_05-4_129_2_8:4.3
	Kernel-6_05:4.3
	Kernel-6_04:4.3
	Kernel-6_03:4.3
	Kernel-6_01-2:4.3
	Kernel-6_01-4_146_2_1:4.3
	Kernel-6_02:4.3
	Kernel-6_01-1:4.3
	Kernel-6_01:4.3
	Kernel-6_00:4.3
	Kernel-5_99:4.3
	Kernel-5_98:4.3
	Kernel-5_97-4_129_2_7:4.3
	Kernel-5_97:4.3
	Kernel-5_96:4.3
	Kernel-5_95:4.3
	Kernel-5_94:4.3
	Kernel-5_93:4.3
	Kernel-5_92:4.3
	Kernel-5_91:4.3
	Kernel-5_90:4.3
	Kernel-5_89-4_129_2_6:4.3
	Kernel-5_89:4.3
	Kernel-5_88-4_129_2_5:4.3
	Kernel-5_88-4_129_2_4:4.3
	Kernel-5_88:4.3
	Kernel-5_87:4.3
	Kernel-5_86-4_129_2_3:4.3
	Kernel-5_86-4_129_2_2:4.3
	Kernel-5_86-4_129_2_1:4.3
	Kernel-5_86:4.3
	SMP:4.3.0.2
	SMP_bp:4.3
	Kernel-5_85:4.3
	Kernel-5_54-1:4.2
	Kernel-5_84:4.3
	Kernel-5_83:4.3
	Kernel-5_82:4.3
	Kernel-5_81:4.3
	Kernel-5_80:4.3
	Kernel-5_79:4.3
	Kernel-5_78:4.3
	Kernel-5_77:4.3
	Kernel-5_76:4.3
	Kernel-5_75:4.3
	Kernel-5_74:4.3
	Kernel-5_73:4.3
	Kernel-5_72:4.3
	Kernel-5_71:4.3
	Kernel-5_70:4.3
	Kernel-5_69:4.3
	Kernel-5_68:4.3
	Kernel-5_67:4.3
	Kernel-5_66:4.3
	Kernel-5_65:4.2
	Kernel-5_64:4.2
	Kernel-5_63:4.2
	Kernel-5_62:4.2
	Kernel-5_61:4.2
	Kernel-5_60:4.2
	Kernel-5_59:4.2
	Kernel-5_58:4.2
	Kernel-5_57:4.2
	Kernel-5_56:4.2
	Kernel-5_55:4.2
	Kernel-5_54:4.2
	Kernel-5_53:4.2
	Kernel-5_52:4.2
	Kernel-5_51:4.2
	Kernel-5_50:4.2
	Kernel-5_49:4.2
	HAL_merge:4.1.3.1.8.3
	Kernel-5_48:4.2
	Kernel-5_35-4_79_2_327:4.1.3.1.8.3
	Kernel-5_35-4_79_2_326:4.1.3.1.8.3
	Kernel-5_35-4_79_2_325:4.1.3.1.8.3
	Kernel-5_35-4_79_2_324:4.1.3.1.8.3
	Kernel-5_35-4_79_2_323:4.1.3.1.8.3
	Kernel-5_35-4_79_2_322:4.1.3.1.8.3
	Kernel-5_35-4_79_2_321:4.1.3.1.8.3
	Kernel-5_35-4_79_2_320:4.1.3.1.8.3
	Kernel-5_35-4_79_2_319:4.1.3.1.8.3
	Kernel-5_35-4_79_2_318:4.1.3.1.8.3
	Kernel-5_35-4_79_2_317:4.1.3.1.8.3
	Kernel-5_35-4_79_2_316:4.1.3.1.8.3
	Kernel-5_35-4_79_2_315:4.1.3.1.8.3
	Kernel-5_35-4_79_2_314:4.1.3.1.8.3
	Kernel-5_35-4_79_2_313:4.1.3.1.8.3
	Kernel-5_35-4_79_2_312:4.1.3.1.8.3
	Kernel-5_35-4_79_2_311:4.1.3.1.8.3
	Kernel-5_35-4_79_2_310:4.1.3.1.8.3
	Kernel-5_35-4_79_2_309:4.1.3.1.8.3
	Kernel-5_35-4_79_2_308:4.1.3.1.8.3
	Kernel-5_35-4_79_2_307:4.1.3.1.8.3
	Kernel-5_35-4_79_2_306:4.1.3.1.8.3
	Kernel-5_35-4_79_2_305:4.1.3.1.8.3
	Kernel-5_35-4_79_2_304:4.1.3.1.8.3
	Kernel-5_35-4_79_2_303:4.1.3.1.8.3
	Kernel-5_35-4_79_2_302:4.1.3.1.8.3
	Kernel-5_35-4_79_2_301:4.1.3.1.8.3
	Kernel-5_35-4_79_2_300:4.1.3.1.8.3
	Kernel-5_35-4_79_2_299:4.1.3.1.8.3
	Kernel-5_35-4_79_2_298:4.1.3.1.8.3
	Kernel-5_35-4_79_2_297:4.1.3.1.8.3
	Kernel-5_35-4_79_2_296:4.1.3.1.8.3
	Kernel-5_35-4_79_2_295:4.1.3.1.8.3
	Kernel-5_35-4_79_2_294:4.1.3.1.8.3
	Kernel-5_35-4_79_2_293:4.1.3.1.8.3
	Kernel-5_35-4_79_2_292:4.1.3.1.8.3
	Kernel-5_35-4_79_2_291:4.1.3.1.8.3
	Kernel-5_35-4_79_2_290:4.1.3.1.8.3
	Kernel-5_35-4_79_2_289:4.1.3.1.8.3
	Kernel-5_35-4_79_2_288:4.1.3.1.8.3
	Kernel-5_35-4_79_2_287:4.1.3.1.8.3
	Kernel-5_35-4_79_2_286:4.1.3.1.8.3
	Kernel-5_35-4_79_2_285:4.1.3.1.8.3
	Kernel-5_35-4_79_2_284:4.1.3.1.8.3
	Kernel-5_35-4_79_2_283:4.1.3.1.8.3
	Kernel-5_35-4_79_2_282:4.1.3.1.8.3
	Kernel-5_35-4_79_2_281:4.1.3.1.8.3
	Kernel-5_35-4_79_2_280:4.1.3.1.8.3
	Kernel-5_35-4_79_2_279:4.1.3.1.8.3
	Kernel-5_35-4_79_2_278:4.1.3.1.8.3
	Kernel-5_35-4_79_2_277:4.1.3.1.8.3
	Kernel-5_35-4_79_2_276:4.1.3.1.8.3
	Kernel-5_35-4_79_2_275:4.1.3.1.8.3
	Kernel-5_35-4_79_2_274:4.1.3.1.8.3
	Kernel-5_35-4_79_2_273:4.1.3.1.8.3
	Kernel-5_35-4_79_2_272:4.1.3.1.8.3
	Kernel-5_35-4_79_2_271:4.1.3.1.8.3
	Kernel-5_35-4_79_2_270:4.1.3.1.8.3
	Kernel-5_35-4_79_2_269:4.1.3.1.8.3
	Kernel-5_35-4_79_2_268:4.1.3.1.8.3
	Kernel-5_35-4_79_2_267:4.1.3.1.8.3
	Kernel-5_35-4_79_2_266:4.1.3.1.8.3
	Kernel-5_35-4_79_2_265:4.1.3.1.8.3
	Kernel-5_35-4_79_2_264:4.1.3.1.8.3
	Kernel-5_35-4_79_2_263:4.1.3.1.8.3
	Kernel-5_35-4_79_2_262:4.1.3.1.8.3
	Kernel-5_35-4_79_2_261:4.1.3.1.8.3
	Kernel-5_35-4_79_2_260:4.1.3.1.8.3
	Kernel-5_35-4_79_2_259:4.1.3.1.8.3
	Kernel-5_35-4_79_2_258:4.1.3.1.8.3
	Kernel-5_35-4_79_2_257:4.1.3.1.8.3
	Kernel-5_35-4_79_2_256:4.1.3.1.8.3
	Kernel-5_35-4_79_2_255:4.1.3.1.8.3
	Kernel-5_35-4_79_2_254:4.1.3.1.8.3
	Kernel-5_35-4_79_2_253:4.1.3.1.8.3
	Kernel-5_35-4_79_2_252:4.1.3.1.8.3
	Kernel-5_35-4_79_2_251:4.1.3.1.8.3
	Kernel-5_35-4_79_2_250:4.1.3.1.8.3
	Kernel-5_35-4_79_2_249:4.1.3.1.8.3
	Kernel-5_35-4_79_2_248:4.1.3.1.8.3
	Kernel-5_35-4_79_2_247:4.1.3.1.8.3
	Kernel-5_35-4_79_2_246:4.1.3.1.8.3
	Kernel-5_35-4_79_2_245:4.1.3.1.8.3
	Kernel-5_35-4_79_2_244:4.1.3.1.8.3
	Kernel-5_35-4_79_2_243:4.1.3.1.8.3
	Kernel-5_35-4_79_2_242:4.1.3.1.8.3
	Kernel-5_35-4_79_2_241:4.1.3.1.8.3
	Kernel-5_35-4_79_2_240:4.1.3.1.8.3
	Kernel-5_35-4_79_2_239:4.1.3.1.8.3
	Kernel-5_35-4_79_2_238:4.1.3.1.8.3
	Kernel-5_35-4_79_2_237:4.1.3.1.8.3
	Kernel-5_35-4_79_2_236:4.1.3.1.8.3
	Kernel-5_35-4_79_2_235:4.1.3.1.8.3
	Kernel-5_35-4_79_2_234:4.1.3.1.8.3
	Kernel-5_35-4_79_2_233:4.1.3.1.8.3
	Kernel-5_35-4_79_2_232:4.1.3.1.8.3
	Kernel-5_35-4_79_2_231:4.1.3.1.8.3
	Kernel-5_35-4_79_2_230:4.1.3.1.8.3
	Kernel-5_35-4_79_2_229:4.1.3.1.8.3
	Kernel-5_35-4_79_2_228:4.1.3.1.8.3
	Kernel-5_35-4_79_2_227:4.1.3.1.8.3
	Kernel-5_35-4_79_2_226:4.1.3.1.8.3
	Kernel-5_35-4_79_2_225:4.1.3.1.8.3
	Kernel-5_35-4_79_2_224:4.1.3.1.8.3
	Kernel-5_35-4_79_2_223:4.1.3.1.8.3
	Kernel-5_35-4_79_2_222:4.1.3.1.8.3
	Kernel-5_35-4_79_2_221:4.1.3.1.8.3
	Kernel-5_35-4_79_2_220:4.1.3.1.8.3
	Kernel-5_35-4_79_2_219:4.1.3.1.8.3
	Kernel-5_35-4_79_2_218:4.1.3.1.8.3
	Kernel-5_35-4_79_2_217:4.1.3.1.8.3
	Kernel-5_35-4_79_2_216:4.1.3.1.8.3
	Kernel-5_35-4_79_2_215:4.1.3.1.8.3
	Kernel-5_35-4_79_2_214:4.1.3.1.8.3
	Kernel-5_35-4_79_2_213:4.1.3.1.8.3
	Kernel-5_35-4_79_2_212:4.1.3.1.8.3
	Kernel-5_35-4_79_2_211:4.1.3.1.8.3
	Kernel-5_35-4_79_2_210:4.1.3.1.8.3
	Kernel-5_35-4_79_2_209:4.1.3.1.8.3
	Kernel-5_35-4_79_2_208:4.1.3.1.8.3
	Kernel-5_35-4_79_2_207:4.1.3.1.8.3
	Kernel-5_35-4_79_2_206:4.1.3.1.8.3
	Kernel-5_35-4_79_2_205:4.1.3.1.8.3
	Kernel-5_35-4_79_2_204:4.1.3.1.8.3
	Kernel-5_35-4_79_2_203:4.1.3.1.8.3
	Kernel-5_35-4_79_2_202:4.1.3.1.8.3
	Kernel-5_35-4_79_2_201:4.1.3.1.8.3
	Kernel-5_35-4_79_2_200:4.1.3.1.8.3
	Kernel-5_35-4_79_2_199:4.1.3.1.8.3
	Kernel-5_35-4_79_2_198:4.1.3.1.8.3
	Kernel-5_35-4_79_2_197:4.1.3.1.8.3
	Kernel-5_35-4_79_2_196:4.1.3.1.8.3
	Kernel-5_35-4_79_2_195:4.1.3.1.8.3
	Kernel-5_35-4_79_2_194:4.1.3.1.8.3
	Kernel-5_35-4_79_2_193:4.1.3.1.8.3
	Kernel-5_35-4_79_2_192:4.1.3.1.8.3
	Kernel-5_35-4_79_2_191:4.1.3.1.8.3
	Kernel-5_35-4_79_2_190:4.1.3.1.8.3
	Kernel-5_35-4_79_2_189:4.1.3.1.8.3
	Kernel-5_35-4_79_2_188:4.1.3.1.8.3
	Kernel-5_35-4_79_2_187:4.1.3.1.8.3
	Kernel-5_35-4_79_2_186:4.1.3.1.8.3
	Kernel-5_35-4_79_2_185:4.1.3.1.8.3
	Kernel-5_35-4_79_2_184:4.1.3.1.8.3
	Kernel-5_35-4_79_2_183:4.1.3.1.8.3
	Kernel-5_35-4_79_2_182:4.1.3.1.8.3
	Kernel-5_35-4_79_2_181:4.1.3.1.8.3
	Kernel-5_35-4_79_2_180:4.1.3.1.8.3
	Kernel-5_35-4_79_2_179:4.1.3.1.8.3
	Kernel-5_35-4_79_2_178:4.1.3.1.8.3
	Kernel-5_35-4_79_2_177:4.1.3.1.8.3
	Kernel-5_35-4_79_2_176:4.1.3.1.8.3
	Kernel-5_35-4_79_2_175:4.1.3.1.8.3
	Kernel-5_35-4_79_2_174:4.1.3.1.8.3
	Kernel-5_35-4_79_2_173:4.1.3.1.8.3
	Kernel-5_35-4_79_2_172:4.1.3.1.8.3
	Kernel-5_35-4_79_2_171:4.1.3.1.8.3
	Kernel-5_35-4_79_2_170:4.1.3.1.8.3
	Kernel-5_35-4_79_2_169:4.1.3.1.8.3
	Kernel-5_35-4_79_2_168:4.1.3.1.8.3
	Kernel-5_35-4_79_2_167:4.1.3.1.8.3
	Kernel-5_35-4_79_2_166:4.1.3.1.8.3
	Kernel-5_35-4_79_2_165:4.1.3.1.8.3
	RPi_merge:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_23:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_22:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_21:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_20:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_19:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_18:4.1.3.1.8.3
	Kernel-5_35-4_79_2_164:4.1.3.1.8.3
	Kernel-5_35-4_79_2_163:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_17:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_16:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_15:4.1.3.1.8.3
	Kernel-5_35-4_79_2_162:4.1.3.1.8.3
	Kernel-5_35-4_79_2_161:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_14:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_13:4.1.3.1.8.3
	Kernel-5_35-4_79_2_160:4.1.3.1.8.3
	Kernel-5_35-4_79_2_159:4.1.3.1.8.3
	Kernel-5_35-4_79_2_158:4.1.3.1.8.3
	Kernel-5_35-4_79_2_157:4.1.3.1.8.3
	Kernel-5_35-4_79_2_156:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_12:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_11:4.1.3.1.8.3
	Kernel-5_35-4_79_2_155:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_10:4.1.3.1.8.3
	Kernel-5_35-4_79_2_154:4.1.3.1.8.3
	Kernel-5_35-4_79_2_153:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_9:4.1.3.1.8.3
	Kernel-5_35-4_79_2_152:4.1.3.1.8.3
	Kernel-5_35-4_79_2_151:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_8:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_7:4.1.3.1.8.3
	Kernel-5_35-4_79_2_150:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_6:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_5:4.1.3.1.8.3
	Kernel-5_35-4_79_2_149:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_4:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_3:4.1.3.1.8.3
	Kernel-5_35-4_79_2_148:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_2:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147_2_1:4.1.3.1.8.3
	RPi:4.1.3.1.8.3.0.6
	RPi_bp:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_52_2_1:4.1.3.1.8.3
	alees_Kernel_dev:4.1.3.1.8.3.0.4
	alees_Kernel_dev_bp:4.1.3.1.8.3
	Kernel-5_35-4_79_2_147:4.1.3.1.8.3
	Kernel-5_35-4_79_2_146:4.1.3.1.8.3
	Kernel-5_35-4_79_2_145:4.1.3.1.8.3
	Kernel-5_35-4_79_2_144:4.1.3.1.8.3
	Kernel-5_35-4_79_2_143:4.1.3.1.8.3
	Kernel-5_35-4_79_2_142:4.1.3.1.8.3
	Kernel-5_35-4_79_2_141:4.1.3.1.8.3
	Kernel-5_35-4_79_2_140:4.1.3.1.8.3
	Kernel-5_35-4_79_2_139:4.1.3.1.8.3
	Kernel-5_35-4_79_2_138:4.1.3.1.8.3
	Kernel-5_35-4_79_2_137:4.1.3.1.8.3
	Kernel-5_35-4_79_2_136:4.1.3.1.8.3
	Kernel-5_35-4_79_2_135:4.1.3.1.8.3
	Kernel-5_35-4_79_2_134:4.1.3.1.8.3
	Kernel-5_35-4_79_2_133:4.1.3.1.8.3
	Kernel-5_35-4_79_2_132:4.1.3.1.8.3
	Kernel-5_35-4_79_2_131:4.1.3.1.8.3
	Kernel-5_35-4_79_2_130:4.1.3.1.8.3
	Kernel-5_35-4_79_2_129:4.1.3.1.8.3
	Kernel-5_35-4_79_2_128:4.1.3.1.8.3
	Kernel-5_35-4_79_2_127:4.1.3.1.8.3
	Kernel-5_35-4_79_2_126:4.1.3.1.8.3
	Kernel-5_35-4_79_2_125:4.1.3.1.8.3
	Kernel-5_35-4_79_2_124:4.1.3.1.8.3
	Kernel-5_35-4_79_2_123:4.1.3.1.8.3
	Cortex_merge:4.1.3.1.8.3
	Kernel-5_35-4_79_2_122:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_54:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_53:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_52:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_51:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_50:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_49:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_48:4.1.3.1.8.3
	Kernel-5_35-4_79_2_121:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_47:4.1.3.1.8.3
	Kernel-5_35-4_79_2_120:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_46:4.1.3.1.8.3
	Kernel-5_35-4_79_2_119:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_45:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_44:4.1.3.1.8.3
	Kernel-5_35-4_79_2_118:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_43:4.1.3.1.8.3
	Kernel-5_35-4_79_2_117:4.1.3.1.8.3
	Kernel-5_35-4_79_2_116:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_42:4.1.3.1.8.3
	Kernel-5_35-4_79_2_115:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_41:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_40:4.1.3.1.8.3
	Kernel-5_35-4_79_2_114:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_39:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_38:4.1.3.1.8.3
	Kernel-5_35-4_79_2_113:4.1.3.1.8.3
	Kernel-5_35-4_79_2_112:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_37:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_36:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_35:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_34:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_33:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_32:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_31:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_30:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_29:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_28:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_27:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_26:4.1.3.1.8.3
	Kernel-5_35-4_79_2_111:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_25:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_24:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_23:4.1.3.1.8.3
	Kernel-5_35-4_79_2_110:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_22:4.1.3.1.8.3
	Kernel-5_35-4_79_2_109:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_21:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_20:4.1.3.1.8.3
	Kernel-5_35-4_79_2_108:4.1.3.1.8.3
	Kernel-5_35-4_79_2_107:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_19:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_18:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_17:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_16:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_15:4.1.3.1.8.3
	Kernel-5_35-4_79_2_106:4.1.3.1.8.3
	Kernel-5_35-4_79_2_105:4.1.3.1.8.3
	Kernel-5_35-4_79_2_104:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_14:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_13:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_12:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_11:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_10:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_9:4.1.3.1.8.3
	Kernel-5_35-4_79_2_103:4.1.3.1.8.3
	Kernel-5_35-4_79_2_102:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_8:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_7:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_6:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_5:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_4:4.1.3.1.8.3
	Kernel-5_35-4_79_2_101:4.1.3.1.8.3
	Kernel-5_35-4_79_2_100:4.1.3.1.8.3
	Kernel-5_35-4_79_2_99:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_3:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_2:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98_2_1:4.1.3.1.8.3
	Cortex:4.1.3.1.8.3.0.2
	Cortex_bp:4.1.3.1.8.3
	Kernel-5_35-4_79_2_98:4.1.3.1.8.3
	Kernel-5_35-4_79_2_97:4.1.3.1.8.3
	Kernel-5_35-4_79_2_96:4.1.3.1.8.3
	Kernel-5_35-4_79_2_95:4.1.3.1.8.3
	Kernel-5_35-4_79_2_94:4.1.3.1.8.3
	Kernel-5_35-4_79_2_93:4.1.3.1.8.3
	Kernel-5_35-4_79_2_92:4.1.3.1.8.3
	Kernel-5_35-4_79_2_91:4.1.3.1.8.3
	Kernel-5_35-4_79_2_90:4.1.3.1.8.3
	Kernel-5_35-4_79_2_89:4.1.3.1.8.3
	Kernel-5_35-4_79_2_88:4.1.3.1.8.3
	Kernel-5_35-4_79_2_87:4.1.3.1.8.3
	Kernel-5_35-4_79_2_86:4.1.3.1.8.3
	Kernel-5_35-4_79_2_85:4.1.3.1.8.3
	Kernel-5_35-4_79_2_84:4.1.3.1.8.3
	Kernel-5_35-4_79_2_83:4.1.3.1.8.3
	Kernel-5_35-4_79_2_82:4.1.3.1.8.3
	Kernel-5_35-4_79_2_81:4.1.3.1.8.3
	Kernel-5_35-4_79_2_80:4.1.3.1.8.3
	Kernel-5_35-4_79_2_79:4.1.3.1.8.3
	Kernel-5_35-4_79_2_78:4.1.3.1.8.3
	Kernel-5_35-4_79_2_77:4.1.3.1.8.3
	RO_5_07:4.1.3.1.8.3
	Kernel-5_35-4_79_2_76:4.1.3.1.8.3
	Kernel-5_35-4_79_2_75:4.1.3.1.8.3
	Kernel-5_35-4_79_2_74:4.1.3.1.8.3
	Kernel-5_35-4_79_2_73:4.1.3.1.8.3
	Kernel-5_35-4_79_2_72:4.1.3.1.8.3
	Kernel-5_35-4_79_2_71:4.1.3.1.8.3
	Kernel-5_35-4_79_2_70:4.1.3.1.8.3
	Kernel-5_35-4_79_2_69:4.1.3.1.8.3
	Kernel-5_35-4_79_2_68:4.1.3.1.8.3
	Kernel-5_35-4_79_2_67:4.1.3.1.8.3
	Kernel-5_35-4_79_2_66:4.1.3.1.8.3
	Kernel-5_35-4_79_2_65:4.1.3.1.8.3
	Kernel-5_35-4_79_2_64:4.1.3.1.8.3
	Kernel-5_35-4_79_2_63:4.1.3.1.8.3
	Kernel-5_35-4_79_2_62:4.1.3.1.8.3
	Kernel-5_35-4_79_2_61:4.1.3.1.8.3
	Kernel-5_35-4_79_2_59:4.1.3.1.8.3
	Kernel-5_35-4_79_2_58:4.1.3.1.8.3
	Kernel-5_35-4_79_2_57:4.1.3.1.8.3
	Kernel-5_35-4_79_2_56:4.1.3.1.8.3
	Kernel-5_35-4_79_2_55:4.1.3.1.8.3
	Kernel-5_35-4_79_2_54:4.1.3.1.8.3
	Kernel-5_35-4_79_2_53:4.1.3.1.8.3
	Kernel-5_35-4_79_2_52:4.1.3.1.8.3
	Kernel-5_35-4_79_2_51:4.1.3.1.8.3
	Kernel-5_35-4_79_2_50:4.1.3.1.8.2
	Kernel-5_35-4_79_2_49:4.1.3.1.8.2
	Kernel-5_35-4_79_2_48:4.1.3.1.8.2
	Kernel-5_47:4.1.3.1
	Kernel-5_46-4_90_2_1:4.1.3.1
	nbingham_Kernel_FastNC_dev_bp:4.1.3.1
	nbingham_Kernel_FastNC_dev:4.1.3.1.0.12
	Kernel-5_46:4.1.3.1
	Kernel-5_45:4.1.3.1
	Kernel-5_35-4_79_2_47:4.1.3.1.8.2
	Kernel-5_35-4_79_2_46:4.1.3.1.8.2
	Kernel-5_35-4_79_2_45:4.1.3.1.8.2
	Kernel-5_35-4_79_2_44:4.1.3.1.8.2
	Kernel-5_35-4_79_2_25_2_2:4.1.3.1.8.2
	Kernel-5_35-4_79_2_43:4.1.3.1.8.2
	Kernel-5_35-4_79_2_42:4.1.3.1.8.2
	Kernel-5_35-4_79_2_41:4.1.3.1.8.2
	Kernel-5_35-4_79_2_40:4.1.3.1.8.2
	Kernel-5_35-4_79_2_39:4.1.3.1.8.2
	Kernel-5_35-4_79_2_38:4.1.3.1.8.2
	Kernel-5_35-4_79_2_37:4.1.3.1.8.2
	Kernel-5_35-4_79_2_36:4.1.3.1.8.2
	Kernel-5_35-4_79_2_35:4.1.3.1.8.2
	Kernel-5_35-4_79_2_34:4.1.3.1.8.2
	Kernel-5_35-4_79_2_33:4.1.3.1.8.2
	Kernel-5_35-4_79_2_32:4.1.3.1.8.2
	Kernel-5_44:4.1.3.1
	Kernel-5_35-4_79_2_25_2_1:4.1.3.1.8.2
	Kernel-5_43:4.1.3.1
	Kernel-5_35-4_79_2_31:4.1.3.1.8.2
	Kernel-5_35-4_79_2_30:4.1.3.1.8.2
	Kernel-5_35-4_79_2_29:4.1.3.1.8.2
	Kernel-5_35-4_79_2_28:4.1.3.1.8.2
	Kernel-5_35-4_79_2_27:4.1.3.1.8.2
	Kernel-5_35-4_79_2_26:4.1.3.1.8.2
	Kernel-5_42:4.1.3.1
	Kernel-5_41:4.1.3.1
	Kernel-5_40:4.1.3.1
	Kernel-5_35-4_79_2_25:4.1.3.1.8.2
	Kernel-5_35-4_79_2_24:4.1.3.1.8.2
	Kernel-5_35-4_79_2_23:4.1.3.1.8.2
	Kernel-5_35-4_79_2_22:4.1.3.1.8.2
	Kernel-5_35-4_79_2_21:4.1.3.1.8.2
	Kernel-5_35-4_79_2_20:4.1.3.1.8.2
	Kernel-5_35-4_79_2_19:4.1.3.1.8.2
	Kernel-5_35-4_79_2_18:4.1.3.1.8.2
	Kernel-5_35-4_79_2_17:4.1.3.1.8.2
	Kernel-5_35-4_79_2_16:4.1.3.1.8.2
	Kernel-5_35-4_79_2_15:4.1.3.1.8.2
	Kernel-5_35-4_79_2_14:4.1.3.1.8.2
	Kernel-5_39:4.1.3.1
	Kernel-5_13-4_52_2_1:4.1.3.1
	Bethany:4.1.3.1.0.10
	Kernel-5_38:4.1.3.1
	Kernel-5_35-4_79_2_13:4.1.3.1.8.2
	Kernel-5_35-4_79_2_12:4.1.3.1.8.2
	Kernel-5_35-4_79_2_11:4.1.3.1.8.1
	Kernel-5_37:4.1.3.1
	Kernel-5_35-4_79_2_10:4.1.3.1
	Kernel-5_35-4_79_2_9:4.1.3.1
	Kernel-5_36:4.1.3.1
	Kernel-5_35-4_79_2_8:4.1.3.1
	Kernel-5_35-4_79_2_7:4.1.3.1
	Kernel-5_35-4_79_2_6:4.1.3.1
	Kernel-5_35-4_79_2_5:4.1.3.1
	Kernel-5_35-4_79_2_4:4.1.3.1
	Kernel-5_35-4_79_2_3:4.1.3.1
	Kernel-5_35-4_79_2_2:4.1.3.1
	dellis_autobuild_BaseSW:4.1.3.1
	Kernel-5_35-4_79_2_1:4.1.3.1
	HAL:4.1.3.1.0.8
	Kernel-5_35:4.1.3.1
	Kernel-5_34:4.1.3.1
	Kernel-5_33:4.1.3.1
	Kernel-5_32:4.1.3.1
	Kernel-5_31:4.1.3.1
	Kernel-5_30:4.1.3.1
	Kernel-5_29:4.1.3.1
	Kernel-5_28:4.1.3.1
	Kernel-5_27:4.1.3.1
	Kernel-5_26:4.1.3.1
	Kernel-5_25:4.1.3.1
	Kernel-5_24:4.1.3.1
	Kernel-5_23:4.1.3.1
	Kernel-5_22:4.1.3.1
	sbrodie_sedwards_16Mar2000:4.1.3.1
	Kernel-5_21:4.1.3.1
	Kernel-5_20:4.1.3.1
	Kernel-5_19:4.1.3.1
	Kernel-5_18:4.1.3.1
	Kernel-5_17:4.1.3.1
	Kernel-5_16:4.1.3.1
	Kernel-5_15:4.1.3.1
	Kernel-5_14:4.1.3.1
	Kernel-5_13:4.1.3.1
	Kernel-5_12:4.1.3.1
	Kernel-5_11:4.1.3.1
	Kernel-5_10:4.1.3.1
	Kernel-5_09:4.1.3.1
	Kernel-5_08:4.1.3.1
	Kernel-5_07:4.1.3.1
	Kernel-5_06:4.1.3.1
	Kernel-5_05:4.1.3.1
	Kernel-5_04:4.1.3.1
	Kernel-5_03:4.1.3.1
	Kernel-5_02:4.1.3.1
	Kernel-5_01:4.1.3.1
	Kernel-5_00:4.1.3.1
	Kernel-4_99:4.1.3.1
	Kernel-4_98:4.1.3.1
	Kernel-4_97:4.1.3.1
	Kernel-4_96:4.1.3.1
	Kernel-4_95:4.1.3.1
	Kernel-4_94:4.1.3.1
	Kernel-4_93:4.1.3.1
	Kernel-4_92:4.1.3.1
	Kernel-4_91:4.1.3.1
	Kernel-4_90:4.1.3.1
	dcotton_autobuild_BaseSW:4.1.3.1
	Kernel-4_89:4.1.3.1
	Kernel-4_88:4.1.3.1
	Kernel-4_87:4.1.3.1
	Kernel-4_86:4.1.3.1
	Kernel-4_85:4.1.3.1
	sbrodie_UrsulaRiscPC_Kernel_19Aug99:4.1.3.1.2.3
	Kernel-4_84:4.1.3.1
	sbrodie_UrsulaRiscPC_Kernel_18Aug99:4.1.3.1.2.3
	Ursula_RiscPC_bp:4.1.3.1.2.3
	Kernel-4_83:4.1.3.1
	Kernel-4_82:4.1.3.1
	Kernel-4_81:4.1.3.1
	Kernel-4_80:4.1.3.1
	Kernel-4_79:4.1.3.1
	Kernel-4_78:4.1.3.1
	Kernel-4_77:4.1.3.1
	Kernel-4_76:4.1.3.1
	Kernel-4_75:4.1.3.1
	Kernel-4_74:4.1.3.1
	Kernel-4_73:4.1.3.1
	Kernel-4_72:4.1.3.1
	Kernel-4_71:4.1.3.1
	Kernel-4_70:4.1.3.1
	Kernel-4_69:4.1.3.1
	Kernel-4_68:4.1.3.1
	mstphens_UrsulaRiscPCBuild_20Nov98:4.1.3.1.2.3
	Ursula_RiscPC:4.1.3.1.2.3.0.2
	Kernel-4_67:4.1.3.1
	Kernel-4_66:4.1.3.1
	Kernel-4_65:4.1.3.1
	Ursula_merge:4.1.3.1
	Kernel-4_64:4.1.3.1
	mstphens_Kernel-3_81:4.1.3.1.2.3
	rthornb_UrsulaBuild-19Aug1998:4.1.3.1.2.3
	UrsulaBuild_FinalSoftload:4.1.3.1.2.3
	rthornb_UrsulaBuild-12Aug1998:4.1.3.1.2.3
	aglover_UrsulaBuild-05Aug1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-29Jul1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-22Jul1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-15Jul1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-07Jul1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-17Jun1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-03Jun1998:4.1.3.1.2.3
	rthornb_UrsulaBuild-27May1998:4.1.3.1.2.3
	mstphens_Kernel-3_80:4.1.3.1.2.3
	rthornb_UrsulaBuild-21May1998:4.1.3.1.2.3
	rthornb_UrsulaBuild_01May1998:4.1.3.1.2.3
	afrost_NC2_Generic:4.1.3.1
	Daytona:4.1.3.1.0.6
	Daytona_bp:4.1.3.1
	Ursula_bp:4.1.3.1
	Ursula:4.1.3.1.0.2
	RO_3_71:4.1.3.1
	MergeFiles:4.1.3.1
	RO_3_70:4.1.3.1
	StrongARM:4.1.3;
locks; strict;
comment	@# @;


4.3
date	2016.12.13.16.42.53;	author jlee;	state Exp;
branches;
next	4.2;
commitid	aGog9bB8f4QKlQxz;

4.2
date	2016.06.30.20.08.12;	author jlee;	state Exp;
branches;
next	4.1;
commitid	IWoXxARWeuLDOwcz;

4.1
date	96.11.06.02.01.37;	author nturton;	state Exp;
branches
	4.1.3.1;
next	;

4.1.3.1
date	96.11.06.02.01.37;	author nturton;	state Exp;
branches
	4.1.3.1.2.1
	4.1.3.1.8.1;
next	;

4.1.3.1.2.1
date	97.05.21.09.30.24;	author mstphens;	state Exp;
branches;
next	4.1.3.1.2.2;

4.1.3.1.2.2
date	97.09.09.13.33.49;	author mstphens;	state Exp;
branches;
next	4.1.3.1.2.3;

4.1.3.1.2.3
date	97.10.21.15.31.29;	author mstphens;	state Exp;
branches;
next	;

4.1.3.1.8.1
date	2000.10.20.15.48.04;	author mstephen;	state Exp;
branches;
next	4.1.3.1.8.2;

4.1.3.1.8.2
date	2000.11.10.14.41.16;	author mstephen;	state Exp;
branches;
next	4.1.3.1.8.3;

4.1.3.1.8.3
date	2002.11.30.00.31.10;	author bavison;	state Exp;
branches;
next	;


desc
@@


4.3
log
@Reimplement AMBControl ontop of the PMP system
Detail:
  With this set of changes, each AMB node is now the owner of a fake DANode which is linked to a PMP.
  From a user's perspective the behaviour of AMBControl is the same as before, but rewriting it to use PMPs internally offers the following (potential) benefits:
  * Reduction in the amount of code which messes with the CAM & page tables, simplifying future work/maintenance. Some of the AMB ops (grow, shrink) now just call through to OS_ChangeDynamicArea. However all of the old AMB routines were well-optimised, so to avoid a big performance hit for common operations not all of them have been removed (e.g. mapslot / mapsome). Maybe one day these optimal routines will be made available for use by regular PMP DAs.
  * Removal of the slow Service_MemoryMoved / Service_PagesSafe handlers that had to do page list fixup after the core kernel had reclaimed/moved pages. Since everything is a PMP, the kernel will now deal with this on behalf of AMB.
  * Removal of a couple of other slow code paths (e.g. Do_AMB_MakeUnsparse calls from OS_ChangeDynamicArea)
  * Potential for more flexible mapping of application space in future, e.g. sparse allocation of memory to the wimp slot
  * Simpler transition to an ASID-based task swapping scheme on ARMv6+?
  Other changes of note:
  * AMB_LazyMapIn switch has been fixed up to work correctly (i.e. turning it off now disables lazy task swapping and all associated code instead of producing a build error)
  * The DANode for the current app should be accessed via the GetAppSpaceDANode macro. This will either return the current AMB DANode, or AppSpaceDANode (if e.g. pre-Wimp). However be aware that AppSpaceDANode retains the legacy behaviour of having a base + size relative to &0, while the AMB DANodes (identifiable via the PMP flag) are sane and have their base + size relative to &8000.
  * Mostly-useless DebugAborts switch removed
  * AMBPhysBin (page number -> phys addr lookup table) removed. Didn't seem to give any tangible performance benefit, and was imposing hidden restrictions on memory usage (all phys RAM fragments in PhysRamTable must be multiple of 512k). And if it really was a good optimisation, surely it should have been applied to all areas of the kernel, not just AMB!
  Other potential future improvements:
  * Turn the fake DANodes into real dynamic areas, reducing the amount of special code needed in some places, but allow the DAs to be hidden from OS_DynamicArea 3 so that apps/users won't get too confused
  * Add a generic abort trapping system to PMPs/DAs (lazy task swapping abort handler is still a special case)
  File changes:
  - s/ARM600, s/VMSAv6, s/ExtraSWIs - Remove DebugAborts
  - s/ArthurSWIs - Remove AMB service call handler dispatch
  - s/ChangeDyn - AMB_LazyMapIn switch fixes. Add alternate internal entry points for some PMP ops to allow the DANode to be specified (used by AMB)
  - s/Exceptions - Remove DebugAborts, AMB_LazyMapIn switch fixes
  - s/Kernel - Define GetAppSpaceDANode macro, AMB_LazyMapIn switch fix
  - s/MemInfo - AMB_LazyMapIn switch fixes
  - s/AMBControl/AMB - Update GETs
  - s/AMBControl/Memory - Remove block size quantisation, AMB_BlockResize (page list blocks are now allocated by PMP code)
  - s/AMBControl/Options - Remove PhysBin definitions, AMBMIRegWords (moved to Workspace file), AMB_LimpidFreePool switch. Add AMB_Debug switch.
  - s/AMBControl/Workspace - Update AMBNode to contain an embedded DANode. Move AMBMIRegWords here from Options file.
  - s/AMBControl/allocate - Fake DA node initialisation
  - s/AMBControl/deallocate - Add debug output
  - s/AMBControl/growp, growshrink, mapslot, mapsome, shrinkp - Rewrite to use PMP ops where possible, add debug output
  - s/AMBControl/main - Remove PhysBin initialisation. Update the enumerate/mjs_info call.
  - s/AMBControl/memmap - Low-level memory mapping routines updated or rewritten as appropriate.
  - s/AMBControl/readinfo - Update to cope with DANode
  - s/AMBControl/service - Remove old service call handlers
  - s/AMBControl/handler - DA handler for responding to PMP calls from OS_ChangeDynamicArea; just calls through to growpages/shrinkpages as appropriate.
Admin:
  Tested on pretty much everything currently supported


Version 5.66. Tagged as 'Kernel-5_66'
@
text
@; Copyright 1996 Acorn Computers Ltd
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;

; > s.Options

AMBMagicNodeID     * &4E424D41        ;"AMBN"

AMBInitialMaxNodes * 256


ApplicationStart  * (32*1024)

AbsMaxAppSize     * AplWorkMaxSize                   ;application space limit for RISC OS
AbsMaxAppPages    * (AbsMaxAppSize:SHR:Log2PageSize) ;and same limit expressed in Pages

;whether to check handles given to AMBControl - not very useful when in kernel
;
                    GBLL    ValidateAMBHandles
ValidateAMBHandles  SETL    {FALSE}


;performance enhancements originally introduced for Ursula OS
;
; ChocolateAMB       - if {FALSE}, disables all AMBControl crazy chocolate flavour enhancements
;
; AMB_LazyMapIn      - if {TRUE}, individual pages of a swapped-in task are only mapped in when
;                      necessary (happens via abort mechanism). This typically makes the swapping
;                      cost much lower and much less sensitive to large slot size. The worst case
;                      swapping cost is still good (abort mechanism cost is very small).
;                      Probably only worth supporting this on ARMs with simple instruction restart
;                      after abort (originally StrongARM revT or later for Ursula)
;
; AMB_ChocTrace      - if {TRUE}, keep trace info for some enhanced code calls and data (probably development only)

                    GBLL    AMB_LazyMapIn
                    GBLL    AMB_ChocTrace
                    GBLL    AMB_Debug

AMB_LazyMapIn       SETL    {TRUE}  :LAND: ChocolateAMB

AMB_ChocTrace       SETL    {FALSE} :LAND: ChocolateAMB   ;development only

AMB_Debug           SETL    {FALSE}

       END
@


4.2
log
@Merge HAL branch to trunk
Detail:
  This change merges the past 15+ years of HAL branch development back to the trunk.
  This is effectively the end for non-HAL builds of the kernel, as no attempt has been made to maintain it during this merge, and all non-HAL & non-32bit code will soon be removed anyway.
  Rather than list everything that's been added to the HAL branch, it's easier to describe the change in terms of the things that the HAL branch was lacking:
  * Trunk version of Docs/32bit contained updated comments for the SVC stack structure during ErrorV
  * Trunk version of s/HeapMan contained a tweak to try and reduce the number of small free blocks that are created
  * Trunk version of s/Kernel contained a change to only copy 248 bytes of the error string to the error buffer (down from 252 bytes), to take into account the extra 4 bytes needed by the PSR. However this goes against the decision that's been made in the HAL branch that the error buffer should be enlarged to 260 bytes instead (ref: https://www.riscosopen.org/tracker/tickets/201), so the HAL build will retain its current behaviour.
  * Trunk version of s/MsgCode had RMNot32bit error in the list of error messages to count when countmsgusage {TRUE}
  * Trunk version of s/PMF/i2cutils contained support for OS_Memory 5, "read/write value of NVRamWriteSize". Currently the HAL branch doesn't have a use for this (in particular, the correct NVRamWriteSize should be specified by the HAL, so there should be no need for software to change it at runtime), and so this code will remain switched out in the HAL build.
Admin:
  Tested on Raspberry Pi


Version 5.48. Tagged as 'Kernel-5_48'
@
text
@a20 11
AMBGrowMaxNodes    * 64               ;not used now AMBControl is in kernel


;Bin pages by physical address, for quick mapping from page number to
;physical address. Bin entry holds physical address of first page in bin.
;Bin size must be no bigger than minimum physical RAM fragment to be found
;in machine. eg. 512k size gives 128 pages in a bin, so shift of 7 and
;mask of &7F. Max practical bin size is 1M (mask must be immediate constant).
;
AMBPhysBinShift    * 7
AMBPhysBinMask     * &7F
a27 6
  [ ChocolateAMB
AMBMIRegWords      * (AbsMaxAppPages+31) :SHR: 5     ;no. of words for AMBMappedInRegister
                                                     ;convenient to set this at fixed max size
                                                     ;(only 896 bytes for 28Mb AppSpace)
  ]

a44 6
; AMB_LimpidFreePool - if {TRUE}, the cache(s) can be assumed to be clear with respect to the FreePool
;                      when AMBControl fetches pages from it. This allows AMBControl to avoid any
;                      cache clean/flush for moving pages out of the FreePool. This assumption is
;                      valid if either: FreePool pages are uncacheable; or FreePool pages are
;                      never used in situ; or FreePool pages are flushed after use in situ.
;
a47 1
                    GBLL    AMB_LimpidFreePool
d49 1
a51 2
AMB_LimpidFreePool  SETL    {TRUE}  :LAND: ChocolateAMB   ;allowed because FreePool is currently marked uncacheable
                                                          ;current implementation assumes uncacheability as criterion
d55 2
@


4.1
log
@Initial revision
@
text
@d16 2
d21 1
a21 1
AMBGrowMaxNodes    * 64
a34 2
PageSize          * (4*1024)
Log2PageSize      * 12             ;for shifts
d36 14
a49 1
AbsMaxAppSize     * (28*1024*1024) ;28 Mb application space limit for RISC OS
d51 10
a60 1
;maximum logical space size cleaned by range strategy
d62 7
a68 1
AMB_ARMA_CleanRange_thresh * 256*1024
d70 3
d74 3
a76 2
                GBLL    ValidateAMBHandles     ; whether to check handles given to AppMAMBan
ValidateAMBHandles  SETL    {FALSE}
d78 1
@


4.1.3.1
log
@Import from cleaned 370 CD
@
text
@@


4.1.3.1.8.1
log
@more use of ARMops in page manipulation, change register usage of ARmops
tested by kernel boot to star prompt only

Version 5.35, 4.79.2.11. Tagged as 'Kernel-5_35-4_79_2_11'
@
text
@d33 3
@


4.1.3.1.8.2
log
@reintroduce Ursula AMBControl, recoded with generic ARMop style, not debugged yet

Version 5.35, 4.79.2.12. Tagged as 'Kernel-5_35-4_79_2_12'
@
text
@a15 2
; > s.Options

d19 1
a19 1
AMBGrowMaxNodes    * 64               ;not used now AMBControl is in kernel
d33 1
d35 3
a37 2
AbsMaxAppSize     * (28*1024*1024)                   ;28 Mb application space limit for RISC OS
AbsMaxAppPages    * (AbsMaxAppSize:SHR:Log2PageSize) ;and same limit expressed in Pages
a38 5
  [ ChocolateAMB
AMBMIRegWords      * (AbsMaxAppPages+31) :SHR: 5     ;no. of words for AMBMappedInRegister
                                                     ;convenient to set this at fixed max size
                                                     ;(only 896 bytes for 28Mb AppSpace)
  ]
d40 1
a40 3
;whether to check handles given to AMBControl - not very useful when in kernel
;
                    GBLL    ValidateAMBHandles
a42 29

;performance enhancements originally introduced for Ursula OS 
;
; ChocolateAMB       - if {FALSE}, disables all AMBControl crazy chocolate flavour enhancements
;
; AMB_LazyMapIn      - if {TRUE}, individual pages of a swapped-in task are only mapped in when
;                      necessary (happens via abort mechanism). This typically makes the swapping
;                      cost much lower and much less sensitive to large slot size. The worst case
;                      swapping cost is still good (abort mechanism cost is very small).
;                      Probably only worth supporting this on ARMs with simple instruction restart
;                      after abort (originally StrongARM revT or later for Ursula)
;
; AMB_LimpidFreePool - if {TRUE}, the cache(s) can be assumed to be clear with respect to the FreePool
;                      when AMBControl fetches pages from it. This allows AMBControl to avoid any
;                      cache clean/flush for moving pages out of the FreePool. This assumption is
;                      valid if either: FreePool pages are uncacheable; or FreePool pages are
;                      never used in situ; or FreePool pages are flushed after use in situ.
;
; AMB_ChocTrace      - if {TRUE}, keep trace info for some enhanced code calls and data (probably development only)

                    GBLL    AMB_LazyMapIn
                    GBLL    AMB_LimpidFreePool
                    GBLL    AMB_ChocTrace

AMB_LazyMapIn       SETL    {TRUE}  :LAND: ChocolateAMB
AMB_LimpidFreePool  SETL    {TRUE}  :LAND: ChocolateAMB   ;allowed because FreePool is currently marked uncacheable
                                                          ;current implementation assumes uncacheability as criterion

AMB_ChocTrace       SETL    {FALSE} :LAND: ChocolateAMB   ;development only
@


4.1.3.1.8.3
log
@  Commit of kernel as featured in release 5.00.
Detail:
  Lots of changes since last version, at least the following:
  * Updated OS timestamp, removed alpha status
  * Negative INKEY OS version changed to &AA
  * GraphicsV is now alocated vector number &2A
  * ROM moved up to &FC000000
  * Max application slot increased to 512 Mbytes (for now)
  * Max size of RMA increased to 256 Mbytes
  * RMA is now first-created dynamic area (so it gets lowest address after
    top of application slot)
  * OS_Memory 10 reimplemeted
  * New OS_ReadSysInfo 6 values 18-22 added
  * OS_ReadSysInfo 8 gains flag bit to indicate soft power-off
  * Misc internal top-bit-set-address fixes
  * *ChangeDynamicArea can take sizes in megabytes or gigabytes
  * Magic word "&off" in R0 passed to OS_Reset powers down if possible
  * Added acceleration: block copy; CLS; text window scroll up; rectangle
    fill
  * Disabled LED flashing in page mode (liable to crash)
  * Masked sprite plot and VDU 5 text avoids reading the screen if possible
  * Framestore made USR mode accessible
  * Fix for VDU 5,127 bug - now relies on font definitions being in extreme
    quarters of memory, rather than bottom half
  * Allocated 64-bit OS_Convert... SWIs
  * IIC errors use allocated error numbers
  * Looks for Dallas RTC before Philips RTC because we're using a Philips
    NVRAM device with the same ID
  * Fix to bug that meant the oscillator in the Dallas RTC wasn't enabled
  * Default mouse type (USB) changed to allocated number
  * Ram disc max size increased to 128 Mbytes (Ursula merge) and made
    cacheable for StrongARMs (not XScale)
  * Branch through zero handler now works in USR mode, by use of a
    trampoline in the system stack to allow PC-relative register storage
  * Address exception handler changed to not use 0 as workspace
  * OS_Memory 13 extended to allow specification of cacheability and access
    privileges
  * Added OS_Memory 16 to return important memory addresses
  * RISCOS_MapInIO() takes cacheable flag in bit 3, access permissions in
    bits 10 and 11, doubly-mapped flag in bit 20, and access permissions
    specified flag in bit 21
  * Bug fix in last version for application abort handlers didn't quite
    work; register shuffle required
  * "Module is not 32-bit compatible" error now reports the module name
  * Default configured language changed from 10 to 11 (now Desktop again)

Version 5.35, 4.79.2.51. Tagged as 'Kernel-5_35-4_79_2_51'
@
text
@d36 1
a36 1
AbsMaxAppSize     * AplWorkMaxSize                   ;application space limit for RISC OS
d51 1
a51 1
;performance enhancements originally introduced for Ursula OS
@


4.1.3.1.2.1
log
@Added following enhancements:

 - Chocolate screen mapping (section mapped and cached), StrongARM only
   Phoebe h/w (IOMD 2) will have register to assist this, but code currently
   relies on data abort mechanism to keep screen up to date wrt write-back
   data cache.

 - Chocolate AMBControl task switching (lazy page mapping), StrongARM only
   Improves task swapping speed. There appears to be a StrongAEM silicon
   bug rev 2 and 3) which means that LDMIB rn, {regs includind rn} cannot
   be reliably restarted after a data abort. This stuffs Chocolate AMBControl
   (awaiting response from Digital).

Both enhancements need more work to complete for Phoebe. Chocolate AMBControl
may well have to be made dormant because of silicon bug.

Note that this kernel *will* cause problems with task switching on StrongARM,
unless Chocolate task switching is disabled via !Flavour application.
@
text
@a15 2
; > s.Options

d19 1
a19 1
AMBGrowMaxNodes    * 64               ;not used now AMBControl is in kernel
d36 1
a36 8
AbsMaxAppSize     * (28*1024*1024)                   ;28 Mb application space limit for RISC OS
AbsMaxAppPages    * (AbsMaxAppSize:SHR:Log2PageSize) ;and same limit expressed in Pages

  [ ChocolateAMB
AMBMIRegWords      * (AbsMaxAppPages+31) :SHR: 5     ;no. of words for AMBMappedInRegister
                                                     ;convenient to set this at fixed max size
                                                     ;(only 896 bytes for 28Mb AppSpace)
  ]
d40 2
a41 9
;Cleaning a sufficiently small space by range will be quicker, because of the fixed
;memory reading cost for a full DC clean. A sufficiently large space will be better handled
;by full clean, because of the huge number of clean/flush line instructions for the range
;case. We use a threshold to switch between the two schemes. The value of the threshold
;depends on memory speed, core speed etc. but is not particularly critical.
;
AMB_ARMA_CleanRange_thresh        * 256*1024 ;must be whole no. pages
;
AMB_ARMA_CleanSparseRange_thresh  * 256*1024 ;must be whole no. pages
d43 1
a43 3
;whether to check handles given to AMBControl - not very useful when in kernel
;
                    GBLL    ValidateAMBHandles
a45 32

;performance enhancements introduced for Ursula OS
;
; ChocolateAMB       - if {FALSE}, disables all AMBControl crazy chocolate flavour enhancements
;                      (defined in kernel GetAll, since other parts of kernel need hooks if true)
;
; AMB_LazyMapIn      - if {TRUE}, individual pages of a swapped-in task are only mapped in when
;                      necessary (happens via abort mechanism). This typically makes the swapping
;                      cost much lower and much less sensitive to large slot size. The worst case
;                      swapping cost is still good (abort mechanism cost is very small).
;
; AMB_StickyLastNode - if {TRUE}, the last deallocated node (the node itself, not the AppSpace
;                      pages) is retained, with page list. If the next allocate occurs
;                      without any intervening FreePool mangling, the page list is reused to save
;                      work. This is handy especially because the FreePool L2PT area is uncached.
;
; AMB_LimpidFreePool - if {TRUE}, the FreePool is normally assumed to be crystal clear (pages inactive),
;                      so that cache flushing is not required on mapping out from the FreePool. This
;                      requires a call to AMBControl from the Wimp to maintain FreePool status, if
;                      Wimp_ClaimFreeMemory is still supported.
;
; AMB_ChocTrace      - if {TRUE}, keep trace info for some enhanced code calls and data (probably development only)

                    GBLL    AMB_LazyMapIn
                    GBLL    AMB_StickyLastNode
                    GBLL    AMB_LimpidFreePool
                    GBLL    AMB_ChocTrace

AMB_LazyMapIn       SETL    {TRUE}  :LAND: ChocolateAMB
AMB_StickyLastNode  SETL    {FALSE} :LAND: ChocolateAMB   ;NOT implemented yet
AMB_LimpidFreePool  SETL    {FALSE} :LAND: ChocolateAMB   ;NOT implemented yet
AMB_ChocTrace       SETL    {TRUE}  :LAND: ChocolateAMB
@


4.1.3.1.2.2
log
@ 1 Simplify source by removing various long-standing compile flags
   and pre-Medusa h/w support

 2 Fix bug with Pages_Unsafe/Pages_Safe page moving for StrongARM
   (interrupt hole) - also better performance for StrongARM

 3 Improve perfromance of physical memory clear for StrongARM
   (make sure it uses burst write for STM)

 4 Suspend Chocolate task switching for StrongARM if SALDMIBbroken
   is TRUE
@
text
@d80 4
a83 6
; AMB_LimpidFreePool - if {TRUE}, the cache(s) can be assumed to be clear with respect to the FreePool
;                      when AMBControl fetches pages from it. This allows AMBControl to avoid any
;                      cache clean/flush for moving pages out of the FreePool. This assumption is
;                      valid if either: FreePool pages are uncacheable; or FreePool pages are
;                      never used in situ; or FreePool pages are flushed after use in situ (eg. by
;                      Wimp_ClaimFreeMemory).
d94 2
a95 4
AMB_ChocTrace       SETL    {FALSE} :LAND: ChocolateAMB   ;development only

AMB_LimpidFreePool  SETL    {TRUE}  :LAND: ChocolateAMB   ;allowed because FreePool is currently marked uncacheable
                                                          ;current implementation assumes uncacheability as criterion
@


4.1.3.1.2.3
log
@1) Fixes and tidy ups:
   - mapping of Cur/Sys/Sound area done more elegantly, and soft CAM info
     is now consistent with it
   - cached screen cleaning on VSync performed *after* VSync events
   - comments at top of ARM600 modernised
   - Pages_Unsafe/Safe code fixed to work properly on StrongARM with
     pages that are involved in interrupts (there is no fix for ARM8,
     since that is unlikely to be needed - an ASSERT checks use of ARM8
   - OS_DynamicArea code souped up, to be much more efficient for large
     numbers of dynamic areas (see comments near top of ChangeDyn)
   - cached screen is now suspended on h/w scroll (avoids possible cache
     incoherency)
2) API changes:
   - new OS_Memory reason code (10) allows Wimp to inform kernel of
     Wimp_ClaimFreeMemory, and can control VRAM rescue (see below)
   - new OS_ReadSysInfo reason code (6) allows reading of kernel values
     (reserved for Acorn use, eg. for SoftLoad, ROMPatch)
   - new OS_DynamicArea reason codes (6 and 7) allow for more efficient
     monitoring of dynamic areas by TaskManager (reserved for Acorn use)
3) Changes for Phoebe:
   - kernel runs a VRAM rescue process, which ensures that any VRAM not
     used for the screen is reclaimed if necessary and sinks to the bottom
     of the Free Pool. This is important for Phoebe, where VRAM is slower
     than SDRAM, but does no harm on other platforms.
   - logical copy of physical RAM is removed from memory map. This frees
     up 256M of address space that will later be used for PCI on Phoebe,
     but should do no harm on other platforms (this space is marked
     private in PRMs, so 3rd parties should not use it).
@
text
@d47 1
a47 1
;StrongARM - maximum logical space size cleaned by range strategy
d65 1
a65 2
;performance enhancements introduced for Ursula OS (AMB_LazyMapIn is for StrongARM only - others
;should work on any ARM)
d75 5
d84 2
a85 1
;                      never used in situ; or FreePool pages are flushed after use in situ.
d90 1
d95 3
a99 2

AMB_ChocTrace       SETL    {FALSE} :LAND: ChocolateAMB   ;development only
@
