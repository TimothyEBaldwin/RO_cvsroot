head	4.38;
access;
symbols
	RISC_OSLib-5_97:4.38
	RISC_OSLib-5_96:4.37
	RISC_OSLib-5_95:4.36
	RISC_OSLib-5_94:4.35
	RISC_OSLib-5_93:4.35
	RISC_OSLib-5_92:4.34
	RISC_OSLib-5_91:4.33
	RISC_OSLib-5_90:4.32
	RISC_OSLib-5_89:4.32
	RISC_OSLib-5_88:4.31
	RISC_OSLib-5_87:4.28
	RISC_OSLib-5_86-1:4.28
	RISC_OSLib-5_86:4.28
	RISC_OSLib-5_85:4.28
	RISC_OSLib-5_84:4.28
	RISC_OSLib-5_83-2:4.28
	RISC_OSLib-5_83-1:4.27
	RISC_OSLib-5_83:4.28
	RISC_OSLib-5_82:4.27
	RISC_OSLib-5_81:4.27
	RISC_OSLib-5_75-2:4.26
	RISC_OSLib-5_80:4.27
	RISC_OSLib-5_79:4.27
	RISC_OSLib-5_78:4.26
	RISC_OSLib-5_75-1:4.26
	RISC_OSLib-5_77:4.26
	RISC_OSLib-5_76:4.26
	RISC_OSLib-5_75:4.26
	RISC_OSLib-5_74:4.26
	RISC_OSLib-5_73:4.26
	RISC_OSLib-5_72:4.26
	RISC_OSLib-5_71:4.26
	RISC_OSLib-5_70:4.26
	RISC_OSLib-5_69:4.25
	RISC_OSLib-5_68:4.25
	RISC_OSLib-5_67:4.25
	RISC_OSLib-5_66:4.24
	RISC_OSLib-5_65:4.24
	RISC_OSLib-5_64:4.23
	RISC_OSLib-5_63:4.22
	RISC_OSLib-5_62:4.22
	RISC_OSLib-5_61:4.22
	RISC_OSLib-5_60:4.22
	RISC_OSLib-5_59:4.21
	RISC_OSLib-5_58:4.21
	RISC_OSLib-5_57:4.21
	RISC_OSLib-5_56:4.21
	RISC_OSLib-5_55:4.20
	RISC_OSLib-5_54:4.20
	RISC_OSLib-5_53:4.19
	RISC_OSLib-5_52:4.19
	RISC_OSLib-5_51:4.19
	RO_5_07:4.18
	RISC_OSLib-5_50:4.18
	RISC_OSLib-5_49:4.18
	RISC_OSLib-5_46-4_64_2_1:4.16
	NoInlineAsm:4.16.0.2
	RISC_OSLib-5_48:4.18
	RISC_OSLib-5_47:4.16
	RISC_OSLib-5_46:4.16
	RISC_OSLib-5_45:4.15
	RISC_OSLib-5_44:4.15
	RISC_OSLib-5_43:4.14
	RISC_OSLib-5_42:4.14
	RISC_OSLib-5_41:4.14
	RISC_OSLib-5_40:4.13
	RISC_OSLib-5_39:4.13
	RISC_OSLib-5_38:4.13
	RISC_OSLib-5_37:4.13
	RISC_OSLib-5_36:4.13
	RISC_OSLib-5_35:4.13
	RISC_OSLib-5_34:4.12
	RISC_OSLib-5_33-4_50_2_1:4.12
	sbrodie_dev:4.12.0.2
	sbrodie_dev_bp:4.12
	RISC_OSLib-5_33:4.12
	RISC_OSLib-5_32:4.12
	RISC_OSLib-5_31:4.12
	RISC_OSLib-5_30:4.12
	RISC_OSLib-5_29:4.12
	RISC_OSLib-5_28:4.12
	RISC_OSLib-5_27:4.12
	RISC_OSLib-5_26:4.12
	RISC_OSLib-5_25:4.12
	RISC_OSLib-5_24:4.12
	RISC_OSLib-5_01-4_16_2_5:4.5
	RISC_OSLib-5_23:4.12
	RISC_OSLib-5_22:4.12
	RISC_OSLib-5_21:4.11
	RISC_OSLib-5_20:4.10
	RISC_OSLib-5_19:4.10
	RISC_OSLib-5_18:4.10
	RISC_OSLib-5_17:4.9
	RISC_OSLib-5_16:4.9
	RISC_OSLib-5_15:4.9
	dellis_autobuild_BaseSW:4.8
	RISC_OSLib-5_14:4.8
	RISC_OSLib-5_13:4.8
	RISC_OSLib-5_12:4.8
	RISC_OSLib-5_01-4_16_2_4:4.5
	RISC_OSLib-5_11:4.8
	RISC_OSLib-5_01-4_16_2_3:4.5
	RISC_OSLib-5_01-4_16_2_2:4.5
	RISC_OSLib-5_10:4.8
	RISC_OSLib-5_01-4_16_2_1:4.5
	Bethany:4.5.0.4
	RISC_OSLib-5_09:4.8
	RISC_OSLib-5_08:4.8
	RISC_OSLib-5_07:4.7
	RISC_OSLib-5_06:4.6
	RISC_OSLib-4_97-4_12_2_8:4.5.2.10
	RISC_OSLib-5_05:4.5
	RISC_OSLib-5_04:4.5
	sbrodie_sedwards_16Mar2000:4.5
	RISC_OSLib-5_03:4.5
	RISC_OSLib-5_02:4.5
	RISC_OSLib-4_97-4_12_2_7:4.5.2.9
	RISC_OSLib-5_01:4.5
	RISC_OSLib-5_00:4.5
	RISC_OSLib-4_99:4.5
	RISC_OSLib-4_98:4.5
	RISC_OSLib-4_97-4_12_2_6:4.5.2.8
	RISC_OSLib-4_97-4_12_2_5:4.5.2.6
	RISC_OSLib-4_97-4_12_2_4:4.5.2.5
	RISC_OSLib-4_97-4_12_2_3:4.5.2.4
	RISC_OSLib-4_97-4_12_2_2:4.5.2.2
	sbrodie_RISC_OSLib-4_97-4_12_2_1:4.5.2.1
	kbracey_32bit:4.5.0.2
	kbracey_32bit_bp:4.5
	dcotton_autobuild_BaseSW:4.12
	RISC_OSLib-4_97:4.5
	RISC_OSLib-4_96:4.5
	RISC_OSLib-4_95:4.5
	RISC_OSLib-4_94:4.5
	RISC_OSLib-4_93:4.5
	RISC_OSLib-4_92:4.5
	mstphens_UrsulaRiscPCBuild_20Nov98:4.3
	Ursula_RiscPC:4.3.0.6
	sforrest_daytona_appflash-0_31:4.3
	RISC_OSLib-4_91:4.5
	RISC_OSLib-4_90:4.5
	RISC_OSLib-4_89:4.5
	Ursula_merge:4.3
	RISC_OSLib-4_88:4.4
	RISC_OSLib-4_87:4.4
	blaughto_daytona_appflash-0_30:4.3
	rmanby_clib-4_86:4.3
	rthornb_UrsulaBuild-19Aug1998:4.3
	UrsulaBuild_FinalSoftload:4.3
	rthornb_UrsulaBuild-12Aug1998:4.3
	aglover_UrsulaBuild-05Aug1998:4.3
	rthornb_UrsulaBuild-29Jul1998:4.3
	rthornb_UrsulaBuild-22Jul1998:4.3
	rthornb_UrsulaBuild-15Jul1998:4.3
	rthornb_UrsulaBuild-07Jul1998:4.3
	rthornb_UrsulaBuild-17Jun1998:4.3
	rthornb_UrsulaBuild-03Jun1998:4.3
	rthornb_UrsulaBuild-27May1998:4.3
	rthornb_UrsulaBuild-21May1998:4.3
	rthornb_UrsulaBuild_01May1998:4.3
	afrost_NC2_Generic:4.1.7.1
	Spinner_B20_2:4.1.7.1
	Spinner_19_3:4.1.7.1
	Spinner_B18:4.1.7.1
	Spinner_B17:4.1.7.1
	Spinner_B15:4.1.7.1
	Spinner_B14:4.1.7.1
	Spinner_B13:4.1.7.1
	Spinner_B12:4.1.7.1
	Spinner_B10:4.1.7.1
	Daytona:4.3.0.4
	Daytona_bp:4.3
	Ursula:4.3.0.2
	Ursula_bp:4.3
	Spinner_B7:4.1.7.1
	RO_3_71:4.1.3.2
	ARTtmp_merge:4.1.7.1
	Spin_3Apr97:4.1.7.1
	ARTtmp:4.1.7.1.0.2
	Spin_merge:4.1.7.1
	MergeFiles:4.1.3.1
	RO_3_70:4.1.3.1
	NC_1_06:4.1.7.1
	Spinner:4.1.7
	Spin_xx:4.1.5
	NC_xx:4.1.5.1
	RO_3_60:4.1.1.1
	StrongARM:4.1.3
	Black:4.1.1;
locks; strict;
comment	@# @;


4.38
date	2018.06.11.00.05.10;	author jlee;	state Exp;
branches;
next	4.37;
commitid	B7wQuIyWYAjnjNFA;

4.37
date	2018.06.10.22.59.58;	author jlee;	state Exp;
branches;
next	4.36;
commitid	Gm9P7LGkgxxZWMFA;

4.36
date	2018.04.14.16.06.04;	author jlee;	state Exp;
branches;
next	4.35;
commitid	afB85cupMVhCuqyA;

4.35
date	2017.09.03.22.22.21;	author jlee;	state Exp;
branches;
next	4.34;
commitid	o2klppFenR57KN5A;

4.34
date	2016.05.28.18.56.02;	author jlee;	state Exp;
branches;
next	4.33;
commitid	iLtWPZpTlif3uh8z;

4.33
date	2016.05.24.22.50.25;	author jlee;	state Exp;
branches;
next	4.32;
commitid	RYaH5CsBb1WpUM7z;

4.32
date	2016.05.08.17.28.46;	author jlee;	state Exp;
branches;
next	4.31;
commitid	EXWpQR82F1tYDH5z;

4.31
date	2016.03.01.14.45.15;	author bavison;	state Exp;
branches;
next	4.30;
commitid	gU659thg4gc5UWWy;

4.30
date	2016.03.01.08.55.45;	author rsprowson;	state Exp;
branches;
next	4.29;
commitid	RUx4qff1QOxdZUWy;

4.29
date	2016.02.29.10.24.14;	author bavison;	state Exp;
branches;
next	4.28;
commitid	4Cb775DX43yNvNWy;

4.28
date	2015.01.16.00.44.43;	author jlee;	state Exp;
branches;
next	4.27;
commitid	AU0zG3zSgj29sb6y;

4.27
date	2014.01.20.21.32.30;	author jlee;	state Exp;
branches;
next	4.26;
commitid	Gyv6odvmqENCXTlx;

4.26
date	2012.06.26.23.25.26;	author jlee;	state Exp;
branches;
next	4.25;
commitid	jkPFvMf2hJLi0haw;

4.25
date	2012.02.16.22.42.22;	author jlee;	state Exp;
branches;
next	4.24;
commitid	dDPxGaAkFdvBYqTv;

4.24
date	2011.11.26.13.04.57;	author rsprowson;	state Exp;
branches;
next	4.23;
commitid	oqcep4Kpl6STpQIv;

4.23
date	2011.10.28.14.23.38;	author bavison;	state Exp;
branches;
next	4.22;
commitid	hIG6j26y6NoxM7Fv;

4.22
date	2011.08.06.20.05.14;	author jlee;	state Exp;
branches;
next	4.21;
commitid	D9pXqV2mtIAhluuv;

4.21
date	2009.11.28.21.52.16;	author jlee;	state Exp;
branches;
next	4.20;

4.20
date	2009.05.31.17.58.56;	author pnaulls;	state Exp;
branches;
next	4.19;

4.19
date	2004.10.27.17.29.20;	author bavison;	state Exp;
branches;
next	4.18;

4.18
date	2003.12.02.16.51.31;	author bavison;	state Exp;
branches;
next	4.17;

4.17
date	2003.11.03.18.53.02;	author bavison;	state Exp;
branches;
next	4.16;

4.16
date	2003.04.15.16.50.28;	author kbracey;	state Exp;
branches;
next	4.15;

4.15
date	2002.11.15.15.00.31;	author kbracey;	state Exp;
branches;
next	4.14;

4.14
date	2002.05.22.10.45.27;	author kbracey;	state Exp;
branches;
next	4.13;

4.13
date	2002.01.29.16.03.36;	author kbracey;	state Exp;
branches;
next	4.12;

4.12
date	2000.11.20.17.27.37;	author dellis;	state Exp;
branches;
next	4.11;

4.11
date	2000.11.08.15.26.24;	author kbracey;	state Exp;
branches;
next	4.10;

4.10
date	2000.10.09.10.12.36;	author sbrodie;	state Exp;
branches;
next	4.9;

4.9
date	2000.10.02.10.46.57;	author kbracey;	state Exp;
branches;
next	4.8;

4.8
date	2000.05.16.13.09.20;	author kbracey;	state Exp;
branches;
next	4.7;

4.7
date	2000.05.10.16.48.47;	author kbracey;	state Exp;
branches;
next	4.6;

4.6
date	2000.05.09.14.09.38;	author kbracey;	state Exp;
branches;
next	4.5;

4.5
date	98.10.01.09.14.27;	author kbracey;	state Exp;
branches
	4.5.2.1;
next	4.4;

4.4
date	98.08.27.15.07.28;	author smiddle;	state Exp;
branches;
next	4.3;

4.3
date	97.05.01.17.27.17;	author kbracey;	state Exp;
branches;
next	4.2;

4.2
date	97.01.21.16.51.50;	author nturton;	state Exp;
branches;
next	4.1;

4.1
date	96.11.05.09.25.03;	author nturton;	state Exp;
branches
	4.1.1.1
	4.1.3.1
	4.1.5.1
	4.1.7.1;
next	;

4.5.2.1
date	99.11.08.15.51.32;	author sbrodie;	state Exp;
branches;
next	4.5.2.2;

4.5.2.2
date	99.11.09.11.02.37;	author sbrodie;	state Exp;
branches;
next	4.5.2.3;

4.5.2.3
date	99.11.09.16.21.22;	author sbrodie;	state Exp;
branches;
next	4.5.2.4;

4.5.2.4
date	99.11.10.14.02.28;	author kbracey;	state Exp;
branches;
next	4.5.2.5;

4.5.2.5
date	99.11.10.16.59.07;	author kbracey;	state Exp;
branches;
next	4.5.2.6;

4.5.2.6
date	99.11.22.13.27.48;	author sbrodie;	state Exp;
branches;
next	4.5.2.7;

4.5.2.7
date	99.11.22.17.14.18;	author sbrodie;	state Exp;
branches;
next	4.5.2.8;

4.5.2.8
date	99.11.23.13.42.46;	author sbrodie;	state Exp;
branches;
next	4.5.2.9;

4.5.2.9
date	2000.01.14.11.02.19;	author kbracey;	state Exp;
branches;
next	4.5.2.10;

4.5.2.10
date	2000.05.09.13.58.52;	author kbracey;	state Exp;
branches;
next	;

4.1.1.1
date	96.11.05.09.25.03;	author nturton;	state Exp;
branches;
next	;

4.1.3.1
date	96.11.05.19.53.05;	author nturton;	state Exp;
branches
	4.1.3.1.2.1;
next	4.1.3.2;

4.1.3.2
date	97.05.01.14.22.09;	author kbracey;	state Exp;
branches;
next	;

4.1.3.1.2.1
date	97.04.29.20.33.43;	author kbracey;	state Exp;
branches;
next	;

4.1.5.1
date	96.11.21.11.29.17;	author nturton;	state Exp;
branches;
next	;

4.1.7.1
date	96.11.29.19.48.47;	author nturton;	state Exp;
branches;
next	;


desc
@@


4.38
log
@Fix to CopyError change
Detail:
  kernel/s/k_body - CPSR_f is the correct field for the NZCV flags, not _c
Admin:
  Untested


Version 5.97. Tagged as 'RISC_OSLib-5_97'
@
text
@; Copyright 1996 Acorn Computers Ltd
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;
; -*- Mode: Assembler -*-
;* Body of shared library kernel for Arthur/Brazil
;* Lastedit: 13 Dec 90 14:39:20 by Harry Meekings *
;
; Copyright (C) Acorn Computers Ltd., 1988.
;
; 23-Sep-94 AMcC  __rt_ symbols defined and exported (compatible with cc vsn 5 etc)
;

        GET     h_stack.s
        GET     h_workspc.s
        GET     h_common.s
        GET     Hdr:OSMisc

        EXPORT  |_kernel_exit|
        EXPORT  |_kernel_setreturncode|
        EXPORT  |_kernel_exittraphandler|
        EXPORT  |_kernel_unwind|
        EXPORT  |_kernel_procname|
        EXPORT  |_kernel_language|

        EXPORT  |_kernel_command_string|
        EXPORT  |_kernel_hostos|
        EXPORT  |_kernel_swi|
        EXPORT  |_kernel_swi_c|
        EXPORT  |_kernel_osbyte|
        EXPORT  |_kernel_osrdch|
        EXPORT  |_kernel_oswrch|
        EXPORT  |_kernel_osbget|
        EXPORT  |_kernel_osbput|
        EXPORT  |_kernel_osgbpb|
        EXPORT  |_kernel_osword|
        EXPORT  |_kernel_osfind|
        EXPORT  |_kernel_osfile|
        EXPORT  |_kernel_osargs|
        EXPORT  |_kernel_oscli|
        EXPORT  |_kernel_last_oserror|
        EXPORT  |_kernel_peek_last_oserror|
        EXPORT  |_kernel_system|
        EXPORT  |_kernel_getenv|
        EXPORT  |_kernel_setenv|

        EXPORT  |_kernel_register_allocs|
        EXPORT  |_kernel_register_slotextend|
        EXPORT  |_kernel_alloc|
        EXPORT  |__rt_allocauto|
        EXPORT  |__rt_freeauto|

        EXPORT  |_kernel_current_stack_chunk|
        EXPORT  |_kernel_stkovf_split_0frame|
        EXPORT  |_kernel_stkovf_split|
        EXPORT  |_kernel_stkovf_copyargs|
        EXPORT  |_kernel_stkovf_copy0args|

        EXPORT  |_kernel_udiv|
        EXPORT  |_kernel_urem|
        EXPORT  |_kernel_udiv10|
        EXPORT  |_kernel_sdiv|
        EXPORT  |_kernel_srem|
        EXPORT  |_kernel_sdiv10|

        EXPORT  |_kernel_escape_seen|
        EXPORT  |_kernel_init|
        EXPORT  |_kernel_client_is_module|
 [ ModeMayBeNonUser
        EXPORT  |_kernel_entermodule|
        EXPORT  |_kernel_moduleinit|
        EXPORT  |_kernel_irqs_on|
        EXPORT  |_kernel_irqs_off|
 ]
        EXPORT  |_kernel_irqs_disabled|
        EXPORT  |_kernel_processor_mode|
        EXPORT  |_kernel_RMAalloc|
        EXPORT  |_kernel_RMAfree|
        EXPORT  |_kernel_RMAextend|

        EXPORT  |_kernel_fpavailable|

        EXPORT  |_kernel_call_client|
        EXPORT  |_kernel_raise_error|

        EXPORT  |__rt_sdiv|
        EXPORT  |__rt_udiv|
        EXPORT  |__rt_udiv10|
        EXPORT  |__rt_sdiv10|

        EXPORT  |x$divide|
        EXPORT  |x$udivide|
        EXPORT  |x$remainder|
        EXPORT  |x$uremainder|

        EXPORT  |__counter|
 [ {CONFIG}<>26
        EXPORT  |AcquireMutex|
 ]

PSRBits         *       &FC000003
PSRZBit         *       &40000000
PSRVBit         *       &10000000

PSRIBit         *       &08000000
PSRFBit         *       &04000000
PSRMode         *       &00000003
PSRUSRMode      *       &00000000
PSRSVCMode      *       &00000003
PSRPrivileged   *       &00000003

PSR32IBit       *       &00000080
PSR32FBit       *       &00000040
PSR32Mode       *       &0000001F
PSR32USRMode    *       &00000010
PSR32SVCMode    *       &00000013
PSR32UNDMode    *       &0000001B
PSR32Privileged *       &0000000F


; A RTS$$Data area
                ^       0
lang_size       #       4
lang_codeBase   #       4
lang_codeLimit  #       4
lang_name       #       4
lang_Init       #       4
lang_Finalise   #       4
lang_Trap       #       4
lang_UncaughtTrap #     4
lang_Event      #       4
lang_UnhandledEvent #   4
lang_FastEvent  #       4
lang_Unwind     #       4
lang_ProcName   #       4

; a _kernel_unwindblock
                ^       0
uwb_r4          #       4
uwb_r5          #       4
uwb_r6          #       4
uwb_r7          #       4
uwb_r8          #       4
uwb_r9          #       4
uwb_fp          #       4
uwb_sp          #       4
uwb_pc          #       4
uwb_sl          #       4
uwb_f4          #       3*4
uwb_f5          #       3*4
uwb_f6          #       3*4
uwb_f7          #       3*4
uwb_size        #       0


        GET     Hdr:Wimp
 [ DDE
        GET     Hdr:DDEUtils
 ]
        GET     Hdr:Machine.<Machine>


        MACRO
        CallClient $r
        ; Always called with v6 = the kernel static base.
        ; If shared library, used to worry about calling standard change.
        MOV     lr, pc
        MOV     pc, $r
        MEND


|_kernel_call_client|
 [ :LNOT:(SharedLibrary :LAND: {CONFIG}=26)
        MOV     pc, a4
   |
  ; If we're 26-bit and a shared library, we need to cope with APCS-32
  ; clients not preserving flags
        FunctionEntry
        MOV     lr, pc
        MOV     pc, a4
        Return
 ]


 [ ModeMayBeNonUser
|_kernel_moduleinit|
; Preserve r9 (== v6) across this call
        ADD     sl, r1, #SC_SLOffset

        LoadStaticBase ip, r1
        LDMIB   r0, {r1-r2}
        MOV     r0, #0
        STMIA   ip, {r0-r2}
        ADR     r0, |_kernel_RMAalloc|
        STR     r0, [ip, #O_allocProc]  ; default alloc proc
        ADR     r0, |_kernel_RMAfree|
        STR     r0, [ip, #O_freeProc]   ; and no dealloc proc
        LDR     pc, [sp], #4
 ]

|_kernel_irqs_disabled|
 [ {CONFIG} = 26
        AND     a1, lr, #PSRIBit
 |
        MRS     a1, CPSR
        AND     a1, a1, #PSR32IBit
 ]
        Return  ,LinkNotStacked

 [ ModeMayBeNonUser
|_kernel_RMAalloc|
        FunctionEntry
|_kernel_RMAalloc_from_extend|
        MOVS    r3, a1
        Return  ,,EQ
        MOV     r0, #Module_Claim
        SWI     Module
        MOVVS   a1, #0
        MOVVC   a1, r2
        Return

|_kernel_RMAextend|
        FunctionEntry
        CMP     a1, #0
        MOVEQ   a1, a2
        BEQ     |_kernel_RMAalloc_from_extend|
        CMP     a2, #0
        BEQ     |_kernel_RMAfree_from_extend|
        LDR     r3, [a1, #-4]
        SUB     r3, r3, #4              ; Correct to useable size
        SUB     r3, a2, r3
        MOV     r2, a1
        MOV     r0, #Module_Extend
        SWI     Module
        MOVVS   a1, #0
        MOVVC   a1, r2
        Return

|_kernel_RMAfree|
        FunctionEntry
|_kernel_RMAfree_from_extend|
        MOVS    r2, a1
        MOVNE   r0, #Module_Free
        SWINE   Module
        MOV     a1, #0
        Return

  |

|_kernel_RMAalloc|
|_kernel_RMAextend|
|_kernel_RMAfree|
        MOV     a1, #0
        Return  ,LinkNotStacked

 ]

; Don't corrupt a1-a4 in these two routines, please.
; __counter relies on it, for one.
|_kernel_irqs_on|
 [ {CONFIG}=26
        BICS    pc, lr, #PSRIBit        ; 32-bit OK - in {CONFIG}=26
 |
   [ NoARMv6
|_kernel_irqs_on_NoARMv6|
        MRS     ip, CPSR
        BIC     ip, ip, #PSR32IBit
        MSR     CPSR_c, ip
        Return  ,LinkNotStacked
   ]
   [ SupportARMv6 :LAND: (:LNOT: NoARMv6 :LOR: SHARED_C_LIBRARY)
|_kernel_irqs_on_SupportARMv6|
        CPSIE   i
        Return  ,LinkNotStacked
   ]
 ]

|_kernel_irqs_off|
 [ {CONFIG}=26
        ORRS    pc, lr, #PSRIBit
 |
   [ NoARMv6
|_kernel_irqs_off_NoARMv6|
        MRS     ip, CPSR
        ORR     ip, ip, #PSR32IBit
        MSR     CPSR_c, ip
        Return  ,LinkNotStacked
   ]
   [ SupportARMv6 :LAND: (:LNOT: NoARMv6 :LOR: SHARED_C_LIBRARY)
|_kernel_irqs_off_SupportARMv6|
        CPSID   i
        Return  ,LinkNotStacked
   ]
 ]

|_kernel_processor_mode|
      [ {CONFIG}=26
        AND     a1, lr, #3      ; the question is anyway about the caller's
        MOVS    pc, lr          ; state, not ours - the answers are probably
                                ; the same.
      |
        MRS     a1, CPSR
        AND     a1, a1, #PSR32Mode
        MOV     pc, lr
      ]

|_kernel_client_is_module|
        LoadStaticBase a1, ip
      [ {CONFIG}=26
        TST     r14, #PSRPrivileged
      |
        MRS     ip, CPSR
        TST     ip, #PSR32Privileged
      ]
        MOVNE   a1, #0
        LDREQ   a1, [a1, #O_moduleDataWord]
        Return  ,LinkNotStacked

 [ ModeMayBeNonUser
|_kernel_entermodule|
        ; user entry to a module.  Need to allocate a stack in application
        ; workspace.
        ; r0 points to a kernel init block
        ; (for old stubs) r12 is the module's private word pointer.
        ; (for new stubs) r12 is -1
        ;                r8 is the module's private word pointer
        ;                r6 is the requested root stack size
        MOV     r9, r0
        SWI     GetEnv
        MOV     r4, r1
        MOV     r1, #Application_Base
        CMPS    r12, #0
        MOVLT   r12, r8
        MOVGE   r6, #OldRootStackSize
        STR     r6, [r1, #SC_size]
        LDR     r12, [r12]
        LDMIB   r12, {r2, r3}           ; relocation offsets
        ADD     r5, r1, #SC_SLOffset+SL_Lib_Offset
        STMIA   r5, {r2, r3}            ; transfer to user stack chunk
        ADD     r2, r1, r6
        MOV     r3, #1                  ; 'is a module' flag
        MOV     r0, r9
 ]

|_kernel_init|
        ; r0 points to a kernel init block.
        ; r1 = base of root stack chunk
        ; r2 = top of root stack chunk (= initial sp)
        ; r3 = 0 if ordinary application, 1 if module
        ; r4 = end of workspace (= heap limit).
        ; Always in user mode.
        MOV     sp, r2
        ADD     sl, r1, #SC_SLOffset
        MOV     fp, #0                  ; mark base of stack
        STR     fp, [r1, #SC_next]
        STR     fp, [r1, #SC_prev]
        STR     fp, [r1, #SC_deallocate]
        LDR     r5, =IsAStackChunk
        STR     r5, [r1, #SC_mark]

        LoadStaticBase v6, ip
        STR     r1, [v6, #O_heapBase]
        STR     r1, [v6, #O_rootStackChunk]
        LDMIA   r0, {r0-r2}
        CMP     r3, #0                  ; if module, imagebase (in RMA) isn't
        MOVNE   r0, #Application_Base   ; interesting
        STMIA   v6, {r0-r2}

        ; Copy the argument string (in SWI mode), so we can access it
        ; (assumed in page 0), while all user access to page 0 is disabled
        MOV     r6, sp                  ; (sp may be different in SWI mode)
        SWI     EnterSVC
        SWI     GetEnv
        MOV     r1, r0
01      LDRB    r5, [r1], #+1
 [ DDE
        CMP     r5, #' '                ; I seem to be getting LF terminated
        BCS     %B01                    ; commands. I don't know why.
 |
        CMP     r5, #0
        BNE     %B01
 ]
        SUB     r1, r1, r0
        ADD     r1, r1, #3
        BIC     r1, r1, #3
02      SUBS    r1, r1, #4
        LDR     r5, [r0, r1]
        STR     r5, [r6, #-4]!
        BNE     %B02
        WritePSRc 0, r5                  ; back to user mode
 [ DDE
        SWI     XDDEUtils_GetCLSize
        MOVVS   r0, #0
        CMP     r0, #0
        BEQ     %F04
        ADD     r0, r0, #3
        BIC     r0, r0, #3
        SUB     r1, r6, r0
        MOV     r0, r1
03      LDRB    r2, [r6], #+1
        CMP     r2, #' '
        MOVCC   r2, #' '
        STRB    r2, [r0], #+1
        BCS     %B03
        SWI     XDDEUtils_GetCl
        MOV     r6, r1
04
 ]
        STR     r6, [v6, #O_ArgString]

        ADRL    r0, |_kernel_malloc|
        STR     r0, [v6, #O_allocProc]  ; default alloc proc
        ADRL    r0, |_kernel_free|
        STR     r0, [v6, #O_freeProc]   ; and no dealloc proc

        ; set up a small stack chunk for use in performing stack extension.
        ; We needn't bother with most of the fields in the description of
        ; this chunk - they won't ever be used.  We must set mark (to be
        ; not IsAStackChunk) and SL_xxx_Offset. Also prev.
        STR     sp, [v6, #O_extendChunk]
      [ {CONFIG}<>26
        MOV     r0, #OSPlatformFeatures_ReadCodeFeatures
        SWI     XOS_PlatformFeatures
        MOVVS   r0, #0
        ; _swp_available is used as a bitfield:
        ; bit 0 => SWP available
        ; bit 1 => LDREX/STREX available
        ; bit 2 => LDREX[B|D|H]/STREX[B|D|H] available
        ; This is a simple manipulation of the PlatformFeatures return flags
        ASSERT  CPUFlag_NoSWP                 = 1:SHL:11
        ASSERT  CPUFlag_LoadStoreEx           = 1:SHL:12
        ASSERT  CPUFlag_LoadStoreClearExSizes = 1:SHL:13
        EOR     r0, r0, #CPUFlag_NoSWP
        MOV     r1, #7
        AND     r1, r1, r0, LSR #11
        STR     r1, [v6, #O__swp_available]
      |
        BL      CheckIfSwpAvailable
      ]
        MOV     r0, #1
        STR     r0, [v6, #O_extendChunkNotInUse]
        ADD     r0, sl, #SL_Lib_Offset
        LDMIA   r0, {r1, r2}
        ADD     r0, sp, #SC_SLOffset+SL_Lib_Offset
        STMIA   r0, {r1, r2}
        STR     sp, [sp, #SC_mark]
        STR     fp, [sp, #SC_prev]      ; 0 to mark end of chain
        MOV     r0, #ExtendStackSize
        STR     r0, [sp, #SC_size]
        ADD     sp, sp, #ExtendStackSize
        STR     sp, [v6, #O_heapTop]    ; save updated value for heap base
        STR     r4, [v6, #O_heapLimit]
        MOV     sp, r6

        MOV     r0, #1
        STRB    r0, [v6, #O_callbackInactive]
        STR     fp, [v6, #O_hadEscape]
        STR     r3, [v6, #O_moduleDataWord]
        STRB    fp, [v6, #O_escapeSeen]

        ; Determine whether FP is available (to decide whether fp regs need
        ; saving over _kernel_system)
        ; The SWI will fail if it isn't
        SWI     FPE_Version
        MOVVC   r0, #&70000     ; IVO, DVZ, OFL cause a trap
        WFSVC   r0
        MOVVC   r0, #1
        MOVVS   r0, #0
        STRB    r0, [v6, #O_fpPresent]

        ; Check where the stacks are
        ASSERT  O_svcStack = O_undStack + 4
        MOV     r0, #6
        ADR     r1, RSI6_List
        ADD     r2, v6, #O_undStack
        SWI     XOS_ReadSysInfo
        LDRVS   r0, =&01E02000
        LDRVS   r1, =&01C02000
        STMVSIA r2, {r0, r1}

        ADD     r4, v6, #O_IIHandlerInData
        ADR     r5, IIHandlerInDataInitValue
        BL      CopyHandler
        ADD     r4, v6, #O_PAHandlerInData
        ADR     r5, PAHandlerInDataInitValue
        BL      CopyHandler
        ADD     r4, v6, #O_DAHandlerInData
        ADR     r5, DAHandlerInDataInitValue
        BL      CopyHandler
        ADD     r4, v6, #O_AEHandlerInData
        ADR     r5, AEHandlerInDataInitValue
        BL      CopyHandler

 [ StrongARM   ;CopyHandler does some dynamic code
        MOV     r0, #1
        ASSERT  O_IIHandlerInData < O_PAHandlerInData
        ASSERT  O_PAHandlerInData < O_DAHandlerInData
        ASSERT  O_DAHandlerInData < O_AEHandlerInData
        ADD     r1, v6, #O_IIHandlerInData
        ADD     r2, v6, #O_AEHandlerInData + 16
        SWI     XOS_SynchroniseCodeAreas
 ]

        MOV     r0, #0
        BL      InstallHandlers

        MOV     r0, #0
        SWI     XWimp_ReadSysInfo
        MOVVS   r0, #0                  ; error - presumably Wimp not present
        CMP     r0, #0
        MOVNE   r0, #1
        STRB    r0, [v6, #O_underDesktop]

        LDREQ   r1, [v6, #O_heapLimit]
        MOVNE   r0, #Env_ApplicationSpace
        MOVNE   r1, #0
        SWINE   ChangeEnv
        STR     r1, [v6, #O_knownSlotSize]
        STR     r1, [v6, #O_initSlotSize]

        MOV     v1, #0
        LDMIB   v6, {v2, v3}
CallInitProcs Keep
        CMP     v2, v3
        BGE     EndInitProcs
        LDR     v4, [v2, #lang_size]
        CMP     v4, #lang_Init
        BLE     NoInitProc
        LDR     a1, [v2, #lang_Init]
        CMP     a1, #0
        BEQ     NoInitProc
        CallClient a1
        CMP     a1, #0
        MOVNE   v1, a1
NoInitProc
        ADD     v2, v2, v4
        B       CallInitProcs
EndInitProcs
        CMP     v1, #0
        BEQ     NoMainProgram
        CallClient v1

NoMainProgram
        BL      Finalise
        ADR     r0, E_NoMainProgram
        BL      |_kernel_copyerror|
FatalError Keep
        SWI     GenerateError

 [ {CONFIG}=26
; v6 = static base
; sp -> extendChunk, which we will use as workspace
; assumed entered in USR mode with SVC stack empty
CheckIfSwpAvailable
        STMIA   sp!, {r0-r12,r14}      ; error handler might corrupt anything
        MOV     r0, #0                 ; start off assuming error will happen
        STR     r0, [v6, #O__swp_available]

        MOV     r0, #6
        MOV     r1, #0
        MOV     r2, #0
        MOV     r3, #0
        SWI     XOS_ChangeEnvironment           ; read existing error handler
        STMIA   sp!, {r1-r3}
        MOV     r0, #6
        ADR     r1, %FT01
        MOV     r2, sp
        MOV     r3, sp
        SWI     XOS_ChangeEnvironment           ; set temp error handler

        SWP     r0, r0, [sp]                    ; try a SWP

        MOV     r0, #1
        STR     r0, [v6, #O__swp_available]     ; note we were successful
        B       %FT02
01
        MOV     sp, r0                          ; put back sp after error
02
        MOV     r0, #6
        LDMDB   sp!, {r1-r3}
        SWI     XOS_ChangeEnvironment           ; restore error handler
        LDMDB   sp!, {r0-r12,pc}
 ]

;StrongARM - there is dynamic code here, but this is sorted in _kernel_init, after
;all calls to CopyHandler
CopyHandler
        LDMIA   r5!, {r6, r7}                   ; first 2 instructions
        STMIA   r4!, {r6, r7}
        LDR     r6, =&E51FF004                  ; LDR PC,<nextword>
        STR     r6, [r4], #4
        STR     r5, [r4]                        ; address of main handler
        MOV     pc, r14

        LTORG

RSI6_List
        DCD     OSRSI6_UNDSTK, OSRSI6_SVCSTK, -1

|Sys$RCLimit|
        DCB     "Sys$$RCLimit", 0
        ALIGN

|_kernel_exit|
 [ ModeMayBeNonUser
        [ {CONFIG} = 26
        TST     r14, #3
        |
        MRS     ip, CPSR
        TST     ip, #PSR32Privileged
        ]
        BEQ     |_kernel_user_exit|
        MOV     ip, sp
        SUB     sp, sp, #4*12              ; set up an unwind block
        STR     sl, [sp, #-4]!
        STMFD   sp!, {a1, r3-r9, fp, ip, r14}  ; r3 to reserve an extra word
        BL      |_kernel_exittraphandler|
01      ADD     a1, sp, #8
        ADD     a2, sp, #4
        BL      |_kernel_unwind|
        CMP     a1, #0
        BNE     %B01
        MOV     r0, #1                  ; get base address of RMA
        SWI     XOS_ReadDynamicArea
        MOVVC   r14, r0
        MOVVS   r14, #&01800000         ; default to fixed base if SWI fails
        LDR     a1, [sp], #4
        CMP     a1, r14
        ADRCC   a1, E_Exit
        BLCC    |_kernel_copyerror|     ; BL<cond> 32-bit OK
        [ {CONFIG}=26
        LDMIB   sp, {r4-r9, fp, sp, pc}^
        |
      [ {FALSE} ; this instruction is now deprecated
        LDMIB   sp, {r4-r9, fp, sp, pc}
      |
        LDMIB   sp, {r4-r9, fp, ip, lr}
        MOV     sp, ip
        MOV     pc, lr
      ]
        ]

        ALIGN

        ErrorBlock Exit, "Exit called", C49

|_kernel_user_exit|
 ]
        LoadStaticBase v6, ip
; the work of finalisation gets done in the Exit handler.
; Due to a bug in the RISC OS kernel where the PC value in the error block
; is incorrectly written if OS_Exit is called with a return value outside
; the range 0 .. Sys$RCLimit we perform the check ourselves and call
; GenerateError directly
        LDR     r2, [v6, #O_returnCode]
        CMP     r2, #0
        SWIEQ   Exit
        ADR     r0, |Sys$RCLimit|
        ADD     r1, v6, #O_returnCodeLimit
        MOV     r2, #4
        MOV     r3, #0
        MOV     r4, #0
        SWI     XOS_ReadVarVal
        MOVVS   r3, #&100
        BVS     KernelExit1
        MOV     r3, #0
KernelExit2
        LDRB    r0, [r1], #1
        SUB     r0, r0, #'0'
        CMP     r0, #10
        BCS     KernelExit1
        ADD     r3, r3, r3, LSL #2
        ADD     r3, r0, r3, LSL #1
        B       KernelExit2
KernelExit1
        ADR     r0, E_BadReturnCode
        BL      |_kernel_copyerror|
        LDR     r2, [v6, #O_returnCode]
        CMP     r2, #0
        ADDLTS  r2, r2, r3
        CMPNE   r2, r3
        LDR     r1, ABEXString
        SWICC   Exit
        STR     r0, [sp, #-4]!
        BL      Finalise
        LDR     r0, [sp],  #4
        SWI     GenerateError

; Generate an external error. Re-init the stack to the root stack chunk.
; The stack contents are not needed since this is an external error.
; In some cases we must re-init the stack (eg. stack overflow).
; The only case where it might may a difference is under a debugger in which
; case tough luck, you don't get a backtrace.
|_kernel_raise_error|
        TEQ     r0, #0
        Return  ,LinkNotStacked, EQ
 [ ModeMayBeNonUser
        [ {CONFIG}=26
        TST     r14, #3
        |
        MRS     ip, CPSR
        TST     ip, #PSR32Privileged
        ]
        BNE     |_kernel_exit|
 ]
        LoadStaticBase v6, ip
        LDR     sl, [v6, #O_rootStackChunk]
        LDR     sp, [sl, #SC_size]
        ADD     sp, sl, sp
        ADD     sl, sl, #SC_SLOffset
        MOV     fp, #0
        STR     a1, [sp, #-4]!
        BL      Finalise
        LDR     a1, [sp], #4
        SWI     GenerateError

Finalise
        STR     lr, [sp, #-4]!
        LDMIB   v6, {v2, v3}
CallFinaliseProcs
        CMP     v2, v3
        BGE     EndFinaliseProcs
        LDR     v4, [v2, #lang_size]
        CMP     v4, #lang_Finalise
        BLE     NoFinaliseProc
        LDR     v1, [v2, #lang_Finalise]
        CMP     v1, #0
        BEQ     NoFinaliseProc
        CallClient v1
NoFinaliseProc
        ADD     v2, v2, v4
        B       CallFinaliseProcs
EndFinaliseProcs
 [ SharedLibrary
        ; Then do finalisation for the shared library (if we are one)
        ; Not CallClient here, because change of calling standards is
        ; inappropriate.
        LDR     v2, =|RTSK$$Data$$Base|
        LDR     v3, =|RTSK$$Data$$Limit|
CallFinaliseProcs_SL
        CMP     v2, v3
        BGE     EndFinaliseProcs_SL
        LDR     v4, [v2, #lang_size]
        CMP     v4, #lang_Finalise
        BLE     NoFinaliseProc_SL
        ; Before doing a shared library module finalisation we must check it
        ; was initialised by the client. Do this by comparing the language
        ; names.
        STMDB   sp!, {v1, v2, v3}
        LDR     v1, [v2, #lang_name]
        LDMIB   v6, {v2, v3}
CheckClientInit
        CMP     v2, v3
        LDMGEIA sp!, {v1, v2, v3}
        BGE     NoFinaliseProc_SL ; No client init found so can't finalise
        MOV     a1, v1
        LDR     a2, [v2, #lang_name]
CompareClientAndLibraryNames
        LDRB    a3, [a1], #1
        LDRB    a4, [a2], #1
        CMP     a3, a4
        LDRNE   a1, [v2, #lang_size]
        ADDNE   v2, v2, a1
        BNE     CheckClientInit
        CMP     a3, #0
        BNE     CompareClientAndLibraryNames
        LDMIA   sp!, {v1, v2, v3}
        LDR     v1, [v2, #lang_Finalise]
        CMP     v1, #0
        MOVNE   lr, pc
        MOVNE   pc, v1
NoFinaliseProc_SL
        ADD     v2, v2, v4
        B       CallFinaliseProcs_SL
EndFinaliseProcs_SL
 ]
        LDR     lr, [sp], #4
        B       RestoreOSHandlers


|_kernel_setreturncode|
        LoadStaticBase ip, a2
        STR     a1, [ip, #O_returnCode]
        Return  ,LinkNotStacked

|_kernel_fpavailable|
        LoadStaticBase ip, a1
        LDRB    a1, [ip, #O_fpPresent]
        Return  ,LinkNotStacked

ABEXString
        =       "ABEX"

        ErrorBlock BadReturnCode, "Return code too large", C50
        ErrorBlock NoMainProgram, "No main program", C51

        LTORG

 ;*-------------------------------------------------------------------*
 ;* Abort Handlers                                                    *
 ;*-------------------------------------------------------------------*

; The handlers called by the OS are in my static data, written there on
; startup, because that's the only way they can find out where the static data
; is.  They don't do much, other than save some registers and load r12 with
; the static base.  They are all the same length, and all immediately precede
; the real handler; when they are installed, a branch to the real handler is
; tacked on the end.

IIHandlerInDataInitValue
        STMFD   r13!, {r0-r4, r12, r14, pc}
        SUB     r12, pc, #O_IIHandlerInData+12

; Now the bits of the abort handlers which get executed from the code.
; r12 is the address of my static data; the user's values of r0 and r12 are
; on the SVC stack.  (SVC mode, interrupts disabled).

IIHandler Keep
        SUB     r14, r14, #4
        STR     r14, [r12, #O_registerDump + 15 * 4]

        LDR     r14, [r12, #O_oldAbortHandlers + 0]
        STR     r14, [r13, #28]
        B       Aborted


PAHandlerInDataInitValue
        STMFD   r13!, {r0-r4, r12, r14, pc}
        SUB     r12, pc, #O_PAHandlerInData+12
PAHandler Keep
        SUB     r14, r14, #4
        STR     r14, [r12, #O_registerDump + 15 * 4]

        LDR     r14, [r12, #O_oldAbortHandlers + 4]
        STR     r14, [r13, #28]
        B       Aborted

DAHandlerInDataInitValue
        STMFD   r13!, {r0-r4, r12, r14, pc}
        SUB     r12, pc, #O_DAHandlerInData+12
DAHandler Keep
        SUB     r14, r14, #8
        STR     r14, [r12, #O_registerDump + 15 * 4]

        LDR     r14, [r12, #O_oldAbortHandlers + 8]
        STR     r14, [r13, #28]
        B       Aborted2

AEHandlerInDataInitValue
        STMFD   r13!, {r0-r4, r12, r14, pc}
        SUB     r12, pc, #O_AEHandlerInData+12
AEHandler Keep
        SUB     r14, r14, #8
        STR     r14, [r12, #O_registerDump + 15 * 4]

        LDR     r14, [r12, #O_oldAbortHandlers + 12]
        STR     r14, [r13, #28]
;       B       Aborted2

Aborted2 Keep
; Abort which may be in the FP emulator, and if so should be reported
; as occurring at the instruction being emulated.
; Try the FPEmulator_Abort SWI

        LDR     r2, [sp, #24]
        ADD     r2, r2, #8              ; original r14
        LDR     r1, [sp, #20]           ; original r12
      [ {CONFIG}=26
        BIC     r2, r2, #PSRBits
      |
        TEQ     pc, pc
        BICNE   r2, r2, #PSRBits
        MRSEQ   r3, CPSR
        BICEQ   r0, r3, #PSR32Mode
        ORREQ   r0, r0, #PSR32SVCMode
        MSREQ   CPSR_c, r0              ; if in 32-bit mode, probably ABT
        STREQ   lr, [sp, #-4]!          ; so switch to SVC to preserve R14_svc
      ]
        MOV     r0, #-2                 ; current context
        SWI     XFPEmulator_Abort       ; WILL NOT ERROR ON SOME OLD FPEs - acts as
                                        ; if FPEmulator_Version, hence returning a
                                        ; small number
      [ {CONFIG}<>26
        TEQ     pc, pc
        LDREQ   lr, [sp], #4            ; get back R14_svc
        MSREQ   CPSR_c, r3              ; back to original mode
       [ StrongARM_MSR_bug
        NOP                             ; avoid StrongARM bug
       ]
      ]
        BVS     NoFPEAbortSWI           ; in case someone really does error
        TEQ     r0, #0                  ; check for real "not FP abort" return
        LDMEQFD sp, {r0-r2}
        BEQ     Aborted                 ; not in FPEmulator
        CMP     r0, #&01000000          ; check for a bogus result
        BLO     NoFPEAbortSWI
        B       FPEFault

NoFPEAbortSWI
; If in user mode, can't be in FPE
      [ {CONFIG}=26
        LDR     r1, [sp, #24]
        TST     r1, #PSRPrivileged
      |
        TEQ     pc, pc
        LDRNE   r1, [sp, #24]
        ANDNE   r1, r1, #PSRMode        ; obtain aborter's mode from R14
        MRSEQ   r1, SPSR                ; obtain aborter's mode from SPSR
        TST     r1, #PSR32Privileged
      ]
        LDMEQFD sp, {r0-r4}
        BEQ     Aborted

; Otherwise, find out where the FPE module is
      [ {CONFIG} <> 26
        TST     r2, #2_11100
      ]
        STMFD   sp!, {r0 - r6}
      [ {CONFIG} = 26
        BIC     r6, r14, #PSRBits
      |
        BICEQ   r6, r14, #PSRBits       ; 32-bit OK (26-bit cond)
        MOVNE   r6, r14
      ]
        MOV     r0, #18
        ADR     r1, FPEName
        SWI     Module
        LDMVSFD sp!, {r0 - r6}
        BVS     Aborted
; (r3 = code base of FPE; word before is length of FPE code)
        CMP     r6, r3
        LDRGE   r4, [r3, #-4]
        ADDGE   r3, r3, r4
        CMPGE   r3, r6
        LDMFD   sp!, {r0 - r6}
        BLT     Aborted

; It was a storage fault in the FP emulator.
; We assume FPEmulator 4.00 or later - r0
; will point to a full register save. The format differs slightly
; depending on whether the FPEmulator is 32-bit or not. If we're
; in a 32-bit mode, we know the FPEmulator will be. If not, check
; to see if the saved r12 is in the UND stack.
FPEFault
        ADD     r14, r12, #O_registerDump
        LDMIA   r0!, {r1-r4}            ; copy R0-R15
        STMIA   r14!, {r1-r4}
        LDMIA   r0!, {r1-r4}
        STMIA   r14!, {r1-r4}
        LDMIA   r0!, {r1-r4}
        STMIA   r14!, {r1-r4}
        LDMIA   r0!, {r1-r4}
        SUB     r4, r4, #4              ; adjust PC back 4
        STMIA   r14!, {r1-r4}
      [ {CONFIG}<>26
        TEQ     pc, pc
        BEQ     FPEFault_32on32
      ]
        LDR     r3, [r12, #O_undStack]
        MOV     r2, r1, LSR #20         ; we're on a 26-bit system
        TEQ     r2, r3, LSR #20         ; is the stack frame in the UND stack?
        BEQ     FPEFault_32on26
FPEFault_26on26
        B       FPEFault_Continue

FPEFault_32on26
        LDR     r2, [r0, #-72]          ; get the SPSR
        AND     r2, r2, #PSRBits
        BIC     r4, r4, #PSRBits
        ORR     r4, r4, r2
        STR     r4, [r14, #-4]          ; merge it with pc in register dump
      [ {CONFIG}<>26
        B       FPEFault_Continue

FPEFault_32on32
        LDR     r2, [r0, #-72]          ; get the SPSR
        STR     r2, [r14]               ; store it in the register dump
      ]

FPEFault_Continue
        LDMFD   r13!, {r0-r4, r12, r14, pc}

        ErrorBlock  PrefetchAbort,      "Prefetch Abort", C60
        ErrorBlock  DataAbort,          "Data Abort", C61
        ErrorBlock  AddressException,   "Address Exception", C53
        ErrorBlock  IllegalInstruction, "Illegal Instruction", C54
FPEName =       "FPEmulator",0
        ALIGN

Aborted Keep
        ADD     r14, r12, #O_registerDump
  [ SASTMhatbroken
        STMIA   r14!, {r0-r12}
        STMIA   r14, {r13,r14}^
        NOP
        SUB     r14, r14, #13*4
  |
        STMIA   r14, {r0-r14}^
        NOP
  ]

        LDR     r0, [r13, #20]
        STR     r0, [r14, #r12*4]

        TEQ     pc, pc
        MOVNE   r3, pc
        ANDNE   r3, r3, #PSRBits
        MRSEQ   r3, CPSR
        LDRNE   r0, [sp, #24]
        ANDNE   r0, r0, #PSRMode        ; obtain aborter's mode from R14
        MRSEQ   r0, SPSR                ; obtain aborter's mode from SPSR
        STREQ   r0, [r14, #16*4]        ; store aborter's SPSR if in 32-bit mode
        TST     r0, #PSR32Privileged
        BEQ     NotPrivileged
        LDR     r0, [r14, #r14*4]       ; if abort in a privileged mode, save
        STR     r0, [r14, #pc*4]        ; PC as user R14
        LDR     r0, [r12, #O_svcStack]  ; switch to SVC mode and look at R13_svc
        ADD     r4, r14, #10 * 4        ; reg ptr into unbanked register
        TEQ     pc, pc
        MSREQ   CPSR_c, #PSR32SVCMode+PSR32IBit+PSR32FBit
        TEQNEP  pc, #PSRSVCMode+PSRIBit+PSRFBit
        MOV     r1, r0, LSR #20         ; r0 = stack top
        MOV     r1, r1, LSL #20         ; r1 = stack base
        SUB     r2, r0, #12             ; r2 = stack top - 12
        CMP     r13, r1                 ; r1 <= r13 <= r2?
        CMPHS   r2, r13
        LDMHSDB r0, {r0-r2}             ; Pull R10-R12 off of top of SVC stack
        STMHSIA r4, {r0-r2}             ; if there were at least 3 words on it
        TEQ     pc, pc
        MSREQ   CPSR_cxs, r3
        TEQNEP  pc, r3
        NOP
NotPrivileged
        LDMFD   r13!, {r0-r4, r12, r14, pc}

AbortFindHandler Keep
; We can only call an abort handler if we had a stack at the
; time of the abort.  If not, we have to say 'uncaught trap'.
; There is a problem as soon as interrupts are enabled, that an event may
; arrive and trash the register dump.  If there's a stack, this is solved
; by copying the dump onto it.  Otherwise, we protect ourselves while
; constructing the error by pretending there's a callback going on.
; Entry may be in SWI mode (faults) or user mode (stack overflow,
; divide by zero).
; r0 is the address of an error block describing the fault.
; r12 is the address of our static data.

        MOV     v6, r12
        BL      CopyErrorV6OK
        LDRB    r2, [v6, #O_inTrapHandler]
        CMP     r2, #0
        BNE     RecursiveTrap
        LDRB    r2, [v6, #O_unwinding]
        CMP     r2, #0
        BNE     duh_abort
        MOV     r2, #1
        STRB    r2, [v6, #O_inTrapHandler]

        ADD     r11, v6, #O_registerDump+17*4
        LDR     r10, [v6, #O_registerDump+sl*4]
        LDR     r1, [v6, #O_heapBase]
        LDR     r2, [v6, #O_heapLimit]

        LDR     r12, [v6, #O_registerDump+sp*4]
        ; Stack pointer and stack limit must both be word aligned
        ; Frame pointer might not be (bottom bit used as flag), so don't check for that (_kernel_unwind will check it before using it anyway)
        TST     r10, #3
        TSTEQ   r12, #3
        BNE     Trap_NoStackForHandler
        CMP     r12, r1
        CMPHI   r2, r12
        ADDHI   r1, r12, #256
        CMPHI   r1, r10
        BLS     Trap_NoStackForHandler
        LDR     r3, =IsAStackChunk
        LDR     r4, [r10, #SC_mark-SC_SLOffset]
        EOR     r4, r4, r3
        BICS    r4, r4, #&80000000 ; a chunk marked 'handling extension' will do
        BNE     Trap_NoStackForHandler
        LDR     v1,  [v6, #O_registerDump+fp*4]

        ; At this point, r12 is the user mode stack pointer and r11 points just past
        ; the 17th entry of the register dump.
        LDMDB   r11!, {a1-a4, v2-v5, lr}
        STMDB   r12!, {a1-a4, v2-v5, lr}
        LDMDB   r11!, {a1-a4, v2-v5}
        STMDB   r12!, {a1-a4, v2-v5}
        ; Some agony here about preventing an event handler running
        ; (on the user stack) while the registers describing the stack
        ; (sp & sl) haven't both been updated.
 [ ModeMayBeNonUser
        MOV     a1, #0
        MRS     a1, CPSR
        TST     a1, #2_11100
        BEQ     %FT01                                   ; 26-bit mode
     [ {CONFIG}=26
        MSR     CPSR_c, #PSR32IBit + PSRUSRMode         ; USR26, I set
     |
        MSR     CPSR_c, #PSR32IBit + PSR32USRMode       ; USR32, I set
     ]
        MSR     CPSR_f, #PSRVBit                        ; set V for calling IntOn.
        B       %FT02
01      LDR     a1, [v6, #O_registerDump+pc*4]
        TST     a1, #PSRIBit
        ORREQ   a1, a1, #PSRVBit
        BICNE   a1, a1, #PSRVBit
        TEQP    a1, #0
02
   |
     [ No32bitCode
        TEQP    pc, #PSRIBit:OR:PSRVBit                 ; user mode
     |
        MRS     a1, CPSR
        ORR     a1, a1, #PSR32IBit                      ; may not need this
        ORR     a1, a1, #PSRVBit
      [ {CONFIG}=26
        BIC     a1, a1, #PSR32Privileged                ; into USR26 mode
      |
        BIC     a1, a1, #PSR32Mode                      ; into USR32 mode
      ]
        MSR     CPSR_cf, a1                             ; switch to user mode
     ]
 ]

        NOP
        MOV     sp, r12
        MOV     sl, r10
        MOV     fp, v1
        SWIVS   IntOn

        LDR     v1, [v6, #O_errorNumber]
        MOV     r0, sp
        MOV     v2, #lang_Trap
        BL      FindAndCallHandlers

        MOV     r0, sp
        MOV     v2, #lang_UncaughtTrap
        BL      FindAndCallHandlers

        BL      RestoreOSHandlers
        MOV     v5, sp
        ADD     fp, v6, #O_errorNumber
        ADR     ip, E_UncaughtTrap
        B       FatalErrorX

Trap_NoStackForHandler
        ADR     ip, E_NoStackForTrapHandler
        B       FatalErrorY

        ErrorBlock NoStackForTrapHandler, "No stack for trap handler", C55

RecursiveTrap Keep
        ADR     ip, E_RecursiveTrap
FatalErrorY
        ; Pointer to error block in ip. (beware, RestoreOSHandlers
        ; corrupts r0-r8).
        MOV     fp, r0
        MOV     r0, #0
        STRB    r0, [v6, #O_callbackInactive]
        WritePSRc 0, lr
        BL      RestoreOSHandlers
        ADD     v5, v6, #O_registerDump
FatalErrorX
 [ SharedLibrary
        LDR     a1, [v5, #pc*4]
        ADD     a2, v6, #O_pc_hex_buff
        BL      HexOut
        MOV     a1, v5
        ADD     a2, v6, #O_reg_hex_buff
        BL      HexOut
        MOV     r0, ip
  [ :DEF:DEFAULT_TEXT
        ADD     r0, r0, #4
10      LDRB    r2, [r0], #1
        CMP     r2, #0
        BNE     %B10
        ADD     r0, r0, #3
        BIC     r0, r0, #3
  ]
        SavePSR v4
        SWI     EnterSVC
        BLVC    open_messagefile        ; BL<cond> 32-bit OK
        RestPSR v4
        MOV     r0, r0
        ; We just trample all over the start of our workspace.
        ; Fine, as we've removed handlers and are about to go pop.
        ADD     r2, v6, #O_FatalErrorBuffer
        MOV     r3, #256
        ADD     r4, fp, #4
        ADD     r5, v6, #O_pc_hex_buff
        ADD     r6, v6, #O_reg_hex_buff
        MOV     r7, #0
        SWI     XMessageTrans_ErrorLookup
 |
        MOV     r0, ip
        BL      |_kernel_copyerror|
        MOV     a4, r0
        ADD     a2, v6, #O_FatalErrorBuffer
        BL      CopyError2
        SUB     a2, a2, #1
        ADR     a4, str1
        BL      CopyErrorString
        SUB     a2, a2, #1
        ADD     a4, fp, #4
        BL      CopyErrorString
        SUB     a2, a2, #1
        ADR     a4, str2
        BL      CopyErrorString
        SUB     a2, a2, #1
        LDR     a1, [v5, #pc*4]
        BL      HexOut
        MOV     a4, a2
        [ :DEF:DEFAULT_TEXT
        ADR     a1, str3
        ADR     a2, str3tok
        |
        ADR     a1, str3tok
        ]
        BL      |_kernel_getmessage|
        MOV     a2, a4
        MOV     a4, r0
        BL      CopyErrorString
        SUB     a2, a2, #1
        MOV     a1, v5
        BL      HexOut
        MOV     a1, #0
        STRB    a1, [a2]
        ADD     r0, v6, #O_FatalErrorBuffer
 ]
        B       FatalError

str1    = ": ", 0
str2    = ", pc = ", 0
 [ :DEF:DEFAULT_TEXT
str3    = ": registers at ", 0
 ]
str3tok = "C56", 0
        ALIGN

; a1 = Hex value to convert
; a2 = Buffer
HexOut  MOV     a4, #8
01      MOV     a1, a1, ROR #28
        AND     a3, a1, #15
        CMP     a3, #10
        ADDLT   a3, a3, #"0"
        ADDGE   a3, a3, #"A"-10
        STRB    a3, [a2], #+1
        SUBS    a4, a4, #1
        BNE     %B01
 [ SharedLibrary
        STRB    a4, [a2]
 ]
        Return  ,LinkNotStacked


|_kernel_exittraphandler|
        LoadStaticBase ip, a1
        MOV     a1, #0
        STRB    a1, [ip, #O_inTrapHandler]
        MOV     a1, #1
        STRB    a1, [ip, #O_callbackInactive]
        Return  ,LinkNotStacked

FindAndCallHandlers Keep
        ; Finds a handler of type offset v2 in a language description,
        ; responsible for the current pc value.  If one (non-zero) is found,
        ; calls it, and resumes the program if it so requests.
        ; Otherwise, unwinds the stack and repeats the operation.
        ; r0 addresses the register dump
        ; v1 is the first argument for the handler (fault / event code)
        ; v2 is the handler offset
        ; v6 is my static data base

        ; set up an initial unwind block.  For our purposes, we don't care
        ; about the values of callee-save registers (ARM or FP).
        STMFD   sp!, {r0, r14}
        MOV     v3, fp
        MOV     v4, sp
        LDR     v5, [r0, #pc*4]
        MOV     ip, sl
        MOV     r1, v5
        SUB     sp, sp, #uwb_size+4
        ADD     v4, sp, #uwb_fp+4
        STMIA   v4, {v3, v4, v5, ip}
FCH_NextFrame
        [ {CONFIG}=26
        BIC     r1, r1, #PSRBits
        |
        MRS     v4, CPSR
        TST     v4, #2_11100
        BICEQ   r1, r1, #PSRBits
        ]
        LDMIB   v6, {v4, v5}
FCH_NextLanguage Keep
        ; find to which language the current pc corresponds (between which
        ; language's code bounds it lies).
        CMP     v4, v5
        BGE     FCH_NoHandlerFound

        LDMIA   v4, {r0, r2, r3}
        CMP     r1, r2
        CMPGE   r3, r1
        ADDLT   v4, v4, r0
        BLT     FCH_NextLanguage

        ; If the language has a handler procedure of the right type, call it
        ; (it may not have one either by not having a large enough area, or
        ;  a zero entry).
        CMP     r0, v2
        BLE     FCH_Unwind
        LDR     r2, [v4, v2]
        CMP     r2, #0
        BEQ     FCH_Unwind

        ; arguments for the handler are
        ;   fault or event code
        ;   pointer to dumped registers
        ; return value is non-zero to resume; otherwise, search continues
        LDR     a1, =|RTSK$$Data$$Limit|
        CMP     v5, a1
        MOV     a1, v1
        LDR     a2, [sp, #uwb_size+4]
        BNE     FCH_CallClient
        MOV     lr, pc
        MOV     pc, r2
        B       FCH_ClientCalled
FCH_CallClient
        CallClient r2
FCH_ClientCalled
        CMP     v2, #lang_Event  ; event handlers are only allowed to pass escape
        BNE     FCH_NotEvent
        CMP     v1, #-1
        BNE     FCH_Exit
FCH_NotEvent
        CMP     a1, #0
        BEQ     FCH_Unwind
        ; if resuming after a trap, clear the 'in trap handler' status
FCH_Exit
        SUBS    r0, v2, #lang_Trap
        SUBNES  r0, v2, #lang_UncaughtTrap
        STREQB  r0, [v6, #O_inTrapHandler]
        LDR     r0, [sp, #uwb_size+4]
        B       ReloadUserState

FCH_NoHandlerFound Keep
        ; pc is not within a known code area in the image.  Perhaps it is
        ; within a library area (if the image uses a shared library).
 [ SharedLibrary
        LDR     r0, =|RTSK$$Data$$Limit|
        CMP     v5, r0
        MOVNE   v5, r0
        LDRNE   v4, =|RTSK$$Data$$Base|
        BNE     FCH_NextLanguage
 ]
FCH_Unwind  Keep
        ADD     a1, sp, #4
        MOV     a2, sp
        BL      |_kernel_unwind|
        CMP     a1, #0
        LDRGT   r1, [sp, #uwb_pc+4]
        BGT     FCH_NextFrame

        ADD     sp, sp, #uwb_size+4+4
        [ {CONFIG}=26
        LDMFD   sp!, {pc}^
        |
        LDR     pc, [sp], #4
        ]

        ErrorBlock UncaughtTrap, "Uncaught trap", C57
        ErrorBlock RecursiveTrap, "Trap while in trap handler", C58

RestoreOSHandlers Keep
        ; (there may not be a valid sp)
        STR     lr, [v6, #O_lk_RestoreOSHandlers]
        BL      InstallCallersHandlers
        LDRB    r1, [v6, #O_underDesktop]
        CMP     r1, #0
        LDRNE   r1, [v6, #O_knownSlotSize]
        LDRNE   r0, [v6, #O_initSlotSize]
        CMPNE   r1, r0
        LDR     lr, [v6, #O_lk_RestoreOSHandlers]
        BNE     SetWimpSlot
        Return  ,LinkNotStacked

SetWimpSlot_Save_r4r5
        STMFD   sp!, {r4, r5}
SetWimpSlot  Keep
        ; Set the wimp slot to r0 - ApplicationBase.
        ; Destroys r4, r5
        ; May need to set MemoryLimit temporarily to the slot size,
        ; in order that Wimp_SlotSize not refuse.
        ; (Note that preservation of r4 is required anyway because of
        ;  fault in Wimp_SlotSize which corrupts it).
        ; Returns the slot size set.
        MOV     r4, r0
        MOV     r0, #Env_MemoryLimit
        MOV     r1, #0
        SWI     ChangeEnv
        MOV     r5, r1                          ; r5 = current memory limit
        MOV     r0, #Env_ApplicationSpace
        MOV     r1, #0
        SWI     ChangeEnv
        CMP     r1, r5                          ; is memory limit=application space?
        BNE     SetWimpSlot_DoFudge             ; if not, make it so.
        SUB     r0, r4, #Application_Base
        MOV     r1, #-1
        SWI     XWimp_SlotSize                  ; change slot size
        Return  ,LinkNotStacked

SetWimpSlot_DoFudge
        MOV     r0, #Env_MemoryLimit
        SWI     ChangeEnv
        SUB     r0, r4, #Application_Base
        MOV     r1, #-1
        SWI     XWimp_SlotSize                  ; change slot size
        MOV     r4, r0
        MOV     r0, #Env_MemoryLimit
        MOV     r1, r5
        SWI     ChangeEnv
        MOV     r0, r4
        Return  ,LinkNotStacked

; Our own exit handler, which restores our parent's environment then exits.
; Just in case a C program manages to (call something which) does a SWI Exit.
; Necessary otherwise because of Obey.
; The register state prevailing when exit was called is completely undefined;
; all we can rely on is that r12 addresses our static data.  The stack
; description may be junk so we reset the stack to its base.
ExitHandler Keep
        MOV     v6, r12
        LDR     sl, [v6, #O_rootStackChunk]
        LDR     sp, [sl, #SC_size]
        ADD     sp, sl, sp
        ADD     sl, sl, #SC_SLOffset
        MOV     fp, #0
  ; so the user can get to hear about faults in his atexit procs, unset
  ;  inTrapHandler.  This is safe (will terminate) because all finalisation
  ; is one-shot.
        STRB    fp, [v6, #O_inTrapHandler]
        STMFD   sp!, {r0-r2}
        BL      Finalise
        LDMIA   sp!, {r0-r2}
        SWI     Exit

UpCallHandler
        TEQ     r0, #256
        MOVNE   pc, r14
; Entered in SWI mode.  A new application is starting (not started by system,
; for which there's a different UpCall handler).  It has the same MemoryLimit
; as this application, so is free to overwrite it.  We'd better close ourselves
; down.
; The register state is undefined, except that r13 must be the SWI stack
; pointer.
        STMFD   sp!, {r0-r3, v1-v6, sl, fp, lr}
        MOV     v6, r12
        WritePSRc PSRUSRMode, r0
        LDR     sl, [v6, #O_rootStackChunk]
        LDR     sp, [sl, #SC_size]
        ADD     sp, sl, sp
        ADD     sl, sl, #SC_SLOffset
        MOV     fp, #0
        BL      Finalise
        SWI     EnterSVC
        LDMFD   sp!, {r0-r3, v1-v6, sl, fp, pc}

InstallHandlers Keep
        ; r0 is zero for the initial call (previous values for the handlers
        ; to be saved).
        ; If non-zero, it is the value memoryLimit should be set to.
        STR     r0, [sp, #-4]!
        MOV     r8, r0
        MOV     r0, #0
        MOV     r1, #0
        MOV     r2, #0
        MOV     r3, #0
        ADD     r4, v6, #O_IIHandlerInData
        ADD     r5, v6, #O_PAHandlerInData
        ADD     r6, v6, #O_DAHandlerInData
        ADD     r7, v6, #O_AEHandlerInData
        SWI     SetEnv
        CMP     r8, #0
        ADDEQ   r8, v6, #O_oldAbortHandlers
        STMEQIA r8!, {r4-r7}

        MOV     r0, #Env_ExitHandler
        ADR     r1, ExitHandler
        MOV     r2, v6
        SWI     ChangeEnv
        STMEQIA r8!, {r1, r2}

        MOV     r0, #Env_MemoryLimit
        LDR     r1, [sp], #4
        SWI     ChangeEnv
        STREQ   r1, [r8], #4

        MOV     r0, #Env_ErrorHandler
        ADR     r1, ErrorHandler
        MOV     r2, v6
        ADD     r3, v6, #O_errorBuffer
        SWI     ChangeEnv
        STMEQIA r8!, {r1, r2, r3}

        ; callback, escape and event handlers must be updated atomically
        SWI     IntOff

        MOV     r0, #Env_CallBackHandler
        ADR     r1, CallBackHandler
        MOV     r2, v6
        ADD     r3, v6, #O_registerDump
        SWI     ChangeEnv
        STMEQIA r8!, {r1, r2, r3}

        MOV     r0, #Env_EscapeHandler
        ADR     r1, EscapeHandler
        MOV     r2, v6
        SWI     ChangeEnv
        STMEQIA r8!, {r1, r2}

        MOV     r0, #Env_EventHandler
        ADR     r1, EventHandler
        MOV     r2, v6
        SWI     ChangeEnv
        STMEQIA r8!, {r1, r2}

        SWI     IntOn

        MOV     r0, #Env_UpCallHandler
        ADR     r1, UpCallHandler
        MOV     r2, v6
        SWI     ChangeEnv
        STMEQIA r8!, {r1, r2}

        Return  ,LinkNotStacked


InstallCallersHandlers Keep
        ADD     r8, v6, #O_oldAbortHandlers
        MOV     r0, #0
        MOV     r1, #0
        MOV     r2, #0
        MOV     r3, #0
        LDMIA   r8!, {r4-r7}
        SWI     SetEnv

        MOV     r0, #Env_ExitHandler
        LDMIA   r8!, {r1, r2}
        SWI     ChangeEnv

        MOV     r0, #Env_MemoryLimit
        LDR     r1, [r8], #4
        SWI     ChangeEnv
        MOV     r4, r1

        MOV     r0, #Env_ErrorHandler
        LDMIA   r8!, {r1, r2, r3}
        SWI     ChangeEnv

        ; callback, escape and event handlers must be updated atomically
        SWI     IntOff

        MOV     r0, #Env_CallBackHandler
        LDMIA   r8!, {r1, r2, r3}
        SWI     ChangeEnv

        MOV     r0, #Env_EscapeHandler
        LDMIA   r8!, {r1, r2}
        SWI     ChangeEnv

        MOV     r0, #Env_EventHandler
        LDMIA   r8!, {r1, r2}
        SWI     ChangeEnv

        SWI     IntOn

        MOV     r0, #Env_UpCallHandler
        LDMIA   r8!, {r1, r2}
        SWI     ChangeEnv

        Return  ,LinkNotStacked



 ;*-------------------------------------------------------------------*
 ;* Error handler                                                     *
 ;*-------------------------------------------------------------------*

ErrorHandler Keep
; Now Brazil compatibility is discarded and all SWI calls in the library
; are X-bit set (other than _kernel_swi if non-X bit set has been explicitly
; asked for), any error is treated as fatal here.
;
; Entry with static data base in r0.  User mode, interrupts on
; Since it would be nice to preserve as much as possible for the FP fault case
; we switch back to SWI mode to save the registers.
        SWI     EnterSVC

        LDR     r14, [r0, #O_errorNumber]
        TEQ     r14, #Error_IllegalInstruction
        TEQNE   r14, #Error_PrefetchAbort
        TEQNE   r14, #Error_DataAbort
        TEQNE   r14, #Error_AddressException
  [ SASTMhatbroken
        ADDNE   r14, r0, #O_registerDump
        STMNEIA r14!, {r0-r12}
        STMNEIA r14, {r13,r14}^
        NOP
        SUBNE   r14, r14, #13*4
  |
        STMNEIA r14, {r0-r14}^
  ]

        MOV     r12, r0
        ADD     r0, r0, #O_errorNumber
        BEQ     AbortFindHandler

        LDMDA   r0, {r1, r2}            ; r1 is error pc, r2 error number
        MOV     r14, #0
        STR     r14, [r12, #O_registerDump+16*4]        ; zero PSR
        MRS     r14, CPSR
        TST     r14, #2_11100
        BICEQ   r1, r1, #&fc000003      ; Sanitize PC value
        CMP     r2, #Error_BranchThroughZero
        MOVEQ   r1, #0
        STR     r1, [r12, #O_registerDump+pc*4]
        B       AbortFindHandler

 ;*-------------------------------------------------------------------*
 ;* Escape and event handling                                         *
 ;*-------------------------------------------------------------------*

|_kernel_escape_seen|
      [ No32bitCode
        MOV     a4, r14
        LoadStaticBase a3, ip
        MOV     a2, #0
        TST     r14, #PSRSVCMode
        SWIEQ   EnterSVC
        TEQP    pc, #PSRIBit+PSRSVCMode  ; interrupts off, for atomic read and update
        LDRB    a1, [a3, #O_escapeSeen]
        STRB    a2, [a3, #O_escapeSeen]
        MOVS    pc, a4
      |
        LoadStaticBase a3
      [ SupportARMK :LAND: NoARMK
        LDR     a4, [a3, #O__swp_available]
        TST     a4, #4 ; CPU supports LDREXB?
      ]
        MOV     a2, #0
        ADD     a3, a3, #O_escapeSeen :AND: :NOT: &FF
        ADD     a3, a3, #O_escapeSeen :AND: &FF         ; Yuckeroo
      [ SupportARMK
       [ NoARMK
        SWPEQB  a1, a2, [a3]
        BEQ     %FT02
       ]
01      LDREXB  a1, [a3]
        STREXB  a4, a2, [a3]
        TEQ     a4, #1
        BEQ     %BT01
02
      |
        SWPB    a1, a2, [a3]
      ]
        Return  "", LinkNotStacked
      ]

EventHandler Keep
        TEQ     r0, #4
        MOVEQ   pc, lr
        STMFD   r13!, {r11, r14}
        STR     r0, [r12, #O_eventCode]
        ADD     r11, r12, #O_eventRegisters
      [ {FALSE} ; this instruction is now deprecated
        STMIA   r11, {r0-r10, r13}
      |
        STMIA   r11, {r0-r10}
        STR     r13, [r11, #11*4]
      ]

        STMDB   r11, {r13}^
        MOV     v6, r12
        MOV     v2, r11
        LDMIB   r12, {v4, v5}
02      CMP     v4, v5
        BGE     EndFastEventHandlers
        LDR     v1, [v4]
        CMP     v1, #lang_FastEvent
        LDRGT   r1, [v4, #lang_FastEvent]
        CMPGT   r1, #0
        BLE     %F01
        MOV     a1, v2
        MOV     v1, r12
        MOV     fp, #0                          ; nb fp is NOT r13
        ; SL not set up - handlers must not have stack checking on,
        ; and may not require relocation of data references.
        MOV     r14, pc
        MOV     pc, r1
        MOV     r12, v1
01      ADD     v4, v4, v1
        B       %B02
EndFastEventHandlers
        ; If callback is possible (not already in a callback), set r12 to 1 to
        ; request it.
        LDRB    r12, [v6, #O_callbackInactive]

        ADD     v6, v6, #O_eventRegisters
        LDMIA   v6, {r0-r10}
        LDMFD   r13!, {r11, pc}


EscapeHandler Keep
        TSTS    r11, #&40
        BNE     haveEscape
        STR     r0, [r13, #-4]!
        MOV     r0, #0
        STRB    r0, [r12, #O_hadEscape]
        LDR     r0, [r13], #4
        MOV     pc, r14         ; ignore flag going away

haveEscape
        ; In Arthur, it is NEVER safe to call a handler now: we always have to
        ; wait for CallBack.
        STR     r0, [r13, #-4]!
        MOV     r0, #-1
        STRB    r0, [r12, #O_hadEscape]
        LDRB    r0, [r12, #O_eventCode]
        STRB    r0, [r12, #O_escapeSeen]
        STR     r0, [r12, #O_eventCode]
        LDRB    r11, [r12, #O_callbackInactive]
        CMP     r11, #0
        MOVNE   r12, #1
        LDR     r0, [r13], #4
        MOV     pc, r14

; Callback handler - entered in either SWI or IRQ mode, interrupts disabled,
; just before OS return to user mode with interrupts on.
CallBackHandler Keep
        ; Set 'in callback' to prevent callback being reentered before it finishes
        ; when we enable interrupts later on.
        MOV     r0, #0
        STRB    r0, [r12, #O_callbackInactive]

        MRS     r0, CPSR
        TST     r0, #2_11100

        MOV     v6, r12                 ; get SB into our standard place
        ; Copy the register set from our static callback buffer, onto the stack
        ; (If we appear to have a valid stack pointer).  Otherwise, we just
        ; ignore the event.
        ADD     r11, v6, #O_registerDump+16*4
        LDR     r10, [v6, #O_registerDump+sl*4]
        LDR     r1, [v6, #O_heapBase]
        LDR     r2, [v6, #O_heapLimit]
        LDR     r3, =IsAStackChunk

        ; if in a 26-bit mode - mark PSR in register dump as invalid.
        MOVEQ   r12, #-1
        STREQ   r12, [r11]

        LDR     r12, [v6, #O_registerDump+sp*4]
        LDR     v5, [v6, #O_registerDump+fp*4]
        CMP     r12, r1
        CMPHI   r2, r12         ; sp within heap and ...
        CMPHI   r10, r1
        CMPHI   r2, r10         ; sl within heap and ...
        CMPHI   r12, r10        ; sp > sl and ...
        BLS     Event_BadStack
        TST     r10, #3         ; sl word aligned
        TSTEQ   r12, #3         ; sp word aligned
        LDREQ   r4, [r10, #SC_mark-SC_SLOffset]
        CMPEQ   r4, r3          ; sl points at stack chunk
        BEQ     Event_StackOK
Event_BadStack
        MOV     r12, #-1
        B       Event_NoStackForHandler

Event_StackOK

        LDMDA   r11!, {r0-r7, r14}
        STMDB   r12!, {r0-r7, r14}
        LDMDA   r11!, {r0-r7}
        STMDB   r12!, {r0-r7}

Event_NoStackForHandler
        WritePSRc PSRIBit+PSRSVCMode, r1; we want the testing for an escape and
        MOV     r1, #1                  ; allowing callbacks to be indivisible
        LDRB    r0, [v6, #O_hadEscape]  ; (otherwise an escape may be lost).
        STRB    r1, [v6, #O_callbackInactive]
        MOV     r1, #0
        STRB    r1, [v6, #O_hadEscape]
        LDR     v1, [v6, #O_eventCode]
        TEQ     r0, #0                  ; if hadEscape = 0
        CMPEQ   v1, #-1                 ; and it's an escape event
        BEQ     %FT02                   ; then the escape's gone.
        CMP     r0, #0
        BEQ     %FT01
        MOV     r0, #126                ; acknowledge escape
        SWI     Byte
        MOV     v1, #-1                 ; escape overrides everything else
01
        [ {CONFIG}=26
        TEQP    pc, #PSRIBit            ; to user mode, with interrupts off
        NOP
        |
        WritePSRc PSRIBit+PSRUSRMode, r0
        ]

        CMP     r12, #0
        BGE     CallEventHandlers
02
        ADD     r0, v6, #O_registerDump
        B       ReloadUserState

CallEventHandlers
        MOV     sp, r12
        ASSERT  sl = r10
        MOV     fp, v5
        SWI     IntOn
        MOV     r0, sp
        MOV     v2, #lang_Event
        BL      FindAndCallHandlers

        MOV     r0, sp
        MOV     v2, #lang_UnhandledEvent
        BL      FindAndCallHandlers

        MOV     r0, sp
ReloadUserState
        ; Here we must unset the 'callback active' flag and restore our state
        ; from the callback buffer atomically. 3u ARMs unsupported now
        ; User r13, r14 must be reloaded from user mode.
        SWI     EnterSVC
        [ {CONFIG}=26
        TEQP    pc, #PSRIBit+PSRSVCMode
        NOP
        |
        LDR     r1, [r0, #16*4]
        CMP     r1, #-1
        MSRNE   CPSR_c, #PSR32IBit+PSR32SVCMode
        MSREQ   CPSR_c, #PSR32IBit+PSRSVCMode
        MSRNE   SPSR_cxsf, r1
        ]
        ADD     r14, r0, #pc*4
        LDMDB   r14, {r0-r14}^
        NOP
        LDMIA   r14, {pc}^

        LTORG

 ;*-------------------------------------------------------------------*
 ;* Debugging support                                                 *
 ;*-------------------------------------------------------------------*

FindHandler Keep
        ; find to which language the r1 corresponds (between which
        ; language's code bounds it lies).
        LDMIB   v6, {v4, v5}
01      CMP     v4, v5
        BHS     FH_NoHandlerFound
        LDMIA   v4, {r0, r2, r3}
        CMP     r1, r2
        CMPHS   r3, r1
        ADDLO   v4, v4, r0
        BLO     %B01

        ; If the language has a handler procedure of the right type, return
        ; it in r2 (otherwise 0)
        CMP     r0, v2
        LDRGT   r2, [v4, v2]
        MOVLE   r2, #0
        Return  ,LinkNotStacked

FH_NoHandlerFound
 [ SharedLibrary
        LDR     r0, =|RTSK$$Data$$Limit|
        CMP     v5, r0
        MOVNE   v5, r0
        LDRNE   v4, =|RTSK$$Data$$Base|
        BNE     %B01
 ]
        MOV     r2, #0
        Return  ,LinkNotStacked

; char *_kernel_language(int pc);
|_kernel_language|
        FunctionEntry "v2, v4-v6"
        LoadStaticBase v6, ip
        MOV     v2, #lang_name
        RemovePSRFromReg a1, lr, r1
        BL      FindHandler
        MOV     a1, r2
        Return  "v2, v4-v6"

; char *_kernel_procname(int pc);
|_kernel_procname|
        FunctionEntry "v2, v4-v6"
        LoadStaticBase v6, ip
        MOV     v2, #lang_ProcName
        RemovePSRFromReg a1, lr, r1
        BL      FindHandler
        CMP     r2, #0
        MOVEQ   a1, #0
        Return  "v2, v4-v6",,EQ

        MOV     a1, r1
 [ {CONFIG}=26
        MOV     lr, pc
        MOV     pc, r2          ; can't tail-call as may be APCS-32
        Return  "v2, v4-v6"
 |
        LDMFD   sp!, {v2, v4-v6, r14}
        MOV     pc, r2
 ]

; int _kernel_unwind(_kernel_unwindblock *inout, char **language);
|_kernel_unwind|
        FunctionEntry "a1, a2, v2, v4-v6"
        LoadStaticBase v6, ip
        LDR     r1, [a1, #uwb_pc]
        RemovePSRFromReg r1, lr
        MOV     v2, #lang_Unwind
        BL      FindHandler
        CMP     r2, #0
        BEQ     call_default_unwind_handler

 [ {CONFIG}=26                   
        LDMFD   sp!, {a1, a2}
        MOV     lr, pc
        MOV     pc, r2          ; can't tail-call as may be APCS-32
        Return  "v2, v4-v6"
 |
        LDMFD   sp!, {a1, a2, v2, v4-v6, r14}
        MOV     pc, r2
 ]

call_default_unwind_handler
        LDMFD   sp!, {a1, a2, v2, v4-v6, r14}
default_unwind_handler Keep
        STMFD   sp!, {v1-v6, r14}
        LoadStaticBase v6
        MOV     v2, #1
        STRB    v2, [v6, #O_unwinding]
        LDR     a4, [a1, #uwb_fp]
        BICS    a4, a4, #ChunkChange
        MOVEQ   v5, #0
        BEQ     duh_exit

        ; a minimal sensibleness check on the FP's value
        ; (bottom bit used to mark stack extension, masked out above).

        TST     a4, #&00000002
        BNE     duh_corrupt

        LDR     a3, [a4, #frame_entrypc]
        RemovePSRFromReg a3, v1

        TST     a3, #3                  ; If low bits of PC set...
        BNE     duh_corrupt             ; ...then either stack corrupt or was in Thumb mode (and if Thumb, the STM check below will fail anyway)

        STMFD   sp!, {a1-a2}
        MOV     a1, #0
        SWI     XOS_PlatformFeatures
        MOVVS   a1, #0
        TST     a1, #8                  ; Is it PC+8 or PC+12?
        ADDNE   a3, a3, #4
        LDMFD   sp!, {a1-a2}

        LDR     v1, [a3, #-12]

        ; check that the save mask instruction is indeed the right sort of STM
        ; If not, return indicating stack corruption.
        MOV     ip, v1, LSR #16
        EOR     ip, ip, #&e900
        EORS    ip, ip, #&002d          ; STMFD sp!, ... (sp = r13)
        BNE     duh_corrupt

        ; update register values in the unwindblock which the save mask says
        ; were saved in this frame.
        MOV     ip, #1
        ADD     v2, a4, #frame_prevfp
        MOV     v3, #v6
        ADD     v4, a1, #uwb_r4-r4*4
01      TST     v1, ip, ASL v3
        LDRNE   r14, [v2, #-4]!
        STRNE   r14, [v4, v3, ASL #2]
        SUB     v3, v3, #1
        CMP     v3, #v1
        BGE     %B01

        ; skip over saved arguments
16      TST     v1, ip, ASL v3
        SUBNE   v2, v2, #4
        SUBS    v3, v3, #1
        BGE     %B16

        ; now look for floating point stores immediately after the savemask
        ; instruction, updating values in the saveblock if they are there.
        SUB     a3, a3, #8
        LDR     v1, [a3]                ; check for SUB fp, ip, #n
        LDR     v4, =&e24cb             ; (assumes fp=r11, ip=r12)
        CMP     v4, v1, LSR #12
        ADDEQ   a3, a3, #4              ; skip over it

        ; first look for SFM F4,<count>,[sp,#-count*12]!
        LDR     v4, =&ed2d4200          ; assume sp = r13 if SFM
        LDR     v1, [a3]
        LDR     r14, =&004080ff         ; ignore count + offset
        BIC     r14, v1, r14
        CMP     r14, v4
        BNE     UnwindNotSFM            ; it's not SFM

        LDRB    v3, [v6, #O_fpPresent]
        TEQ     v3, #0
        BEQ     UnwindEndFP             ; can only unwind this if FP present
        AND     v3, v1, #&FF            ; v3 = offset
        AND     v4, v1, #&8000          ; v4 = bottom bit of count
        TST     v1, #&400000
        ORRNE   v4, v4, #&10000         ; add in top bit
        MOVS    v4, v4, LSR #15
        MOVEQ   v4, #4                  ; v4 = count
        ADD     v4, v4, v4, LSL #1      ; v4 = count * 3
        TEQ     v4, v3
        BNE     UnwindEndFP             ; count didn't match offset

        ADD     v3, a1, #uwb_f4         ; v3 -> uwb_f4
        SUB     v2, v2, v4, LSL #2      ; pull v2 down to base of stored FP regs
15      LFM     f0, 1, [v2], #12
        SUBS    v4, v4, #3
        STFE    f0, [v3], #12
        BNE     %B15
        B       UnwindEndFP

        ; or alternatively multiple STFE Fn,[sp,#-12]!
UnwindNotSFM
        LDR     v4, =&ed6c0103
02      LDR     v1, [a3], #+4
        BIC     r14, v1, #&17000        ; sp = r12 or r13
        CMP     r14, v4
        BNE     UnwindEndFP
        MOV     v1, v1, LSR #10
        AND     v1, v1, #&1c
        ADD     v1, v1, v1, ASL #1
        ADD     v1, a1, v1
        LDR     r14, [v2, #-4]!
        STR     r14, [v1, #uwb_f4-r4*4*3+8]
        LDR     r14, [v2, #-4]!
        STR     r14, [v1, #uwb_f4-r4*4*3+4]
        LDR     r14, [v2, #-4]!
        STR     r14, [v1, #uwb_f4-r4*4*3]
        B       %B02

UnwindEndFP
        LDMDB   a4, {a3, a4, v1}        ; saved fp, sp, link
        ; if the new fp is in a different stack chunk, must amend sl
        ; in the unwind block.
        TST     a3, #ChunkChange
        BIC     a3, a3, #ChunkChange
        LDR     v3, [a1, #uwb_sl]
        LDRNE   v3, [v3, #SC_prev-SC_SLOffset]
        ADDNE   v3, v3, #SC_SLOffset
        ADD     ip, a1, #uwb_fp
        STMIA   ip, {a3, a4, v1, v3}
        MOV     v3, a2
        RemovePSRFromReg v1, v2, r1
        MOV     v2, #lang_name
        BL      FindHandler
        STR     r2, [v3]
        MOV     v5, #1
duh_exit
        MOV     a1, #0
        STRB    a1, [v6, #O_unwinding]
        MOV     a1, v5
        Return  "v1-v6"

duh_abort
        LDR     r12, [v6, #O_registerDump+r12*4]  ; abort handling trampled this.
        MOV     r14, #0
        MRS     r14, CPSR
        TST     r14, #2_11100
        LDRNE   r14, [v6, #O_registerDump+16*4]
        MSRNE   CPSR_c, r14
        LDREQ   r14, [v6, #O_registerDump+pc*4]
        TEQEQP  r14, #0                 ; Back to the mode and interrupt
                                        ; status before we got the abort
        NOP
duh_corrupt
        MOV     v5, #-1
        B       duh_exit


 ;*-------------------------------------------------------------------*
 ;* SWI interfaces                                                    *
 ;*-------------------------------------------------------------------*


|_kernel_hostos|
        EnterLeafProcContainingSWI
        MOV     r0, #0
        MOV     r1, #1
        SWI     Byte
        MOV     a1, r1
        ExitLeafProcContainingSWI

; Abort handlers assume that lr is preserved
|_kernel_swi_c|
        FunctionEntry "a3, a4, v1-v6", makeframe
        BIC     r12, a1, #&80000000
        TST     a1, #&80000000          ; non-X bit requested?
        ORREQ   r12, r12, #X
        LDMIA   r1, {r0-r9}
        SWI     XOS_CallASWIR12
        LDMFD   sp!, {ip, lr}
        STMIA   ip, {r0 - r9}
        MOV     ip, #0
        MOVCS   ip, #1
        MOVVS   ip, #0
        STR     ip, [lr]
        MOVVC   a1, #0
        BLVS    CopyError               ; BL<cond> 32-bit OK
        Return  "v1-v6", fpbased

; Abort handlers assume that lr is preserved
|_kernel_swi|
        FunctionEntry "a3, v1-v6"
        BIC     r12, a1, #&80000000
        TST     a1, #&80000000
        ORREQ   r12, r12, #X
        LDMIA   r1, {r0-r9}
        SWI     XOS_CallASWIR12
        LDR     ip, [sp]
        STMIA   ip, {r0-r9}
        MOVVC   a1, #0
        BLVS    CopyError               ; BL<cond> 32-bit OK
        Return  "a3, v1-v6"


|_kernel_command_string|
        LoadStaticBase a1
        LDR     a1, [a1, #O_ArgString]
        Return  ,LinkNotStacked

|_kernel_osbyte|
        FunctionEntry "v6"
        SWI     Byte
        BVS     ErrorExitV6Stacked
        AND     a1, a2, #&ff
        ORR     a1, a1, a3, ASL #8
        MOV     a1, a1, ASL #16
        ADC     a1, a1, #0
        MOV     a1, a1, ROR #16
        Return  "v6"

|_kernel_osrdch|
        FunctionEntry "v6"
        SWI     ReadC
        BVS     ErrorExitV6Stacked
        Return  "v6",,CC
        CMPS    a1, #27         ; escape
        MOVEQ   a1, #-27
        MOVNE   a1, #-1         ; other error, EOF etc
        Return  "v6"

|_kernel_oswrch|
        FunctionEntry "v6"
        SWI     XOS_WriteC
        Return  "v6",,VC
ErrorExitV6Stacked
        BL      CopyError
        MOV     a1, #-2
        Return  "v6"

|_kernel_osbget|
        FunctionEntry "v6"
        MOV     r1, a1
        SWI     BGet
        BVS     ErrorExitV6Stacked
        MOVCS   a1, #-1
        Return  "v6"

|_kernel_osbput|
        FunctionEntry "v6"
        SWI     BPut
        Return  "v6",,VC
        BVS     ErrorExitV6Stacked

|_kernel_osgbpb|
; typedef struct {
;         void * dataptr;
;         int nbytes, fileptr;
;         int buf_len;
;         char * wild_fld;
; } _kernel_osgbpb_block;
; int _kernel_osgbpb(int op, unsigned handle, _kernel_osgbpb_block *inout);
        FunctionEntry "r4, r5, r6, r7, v6"
        MOV     r7, a3
        LDMIA   a3, {r2 - r6}
        SWI     Multiple
        STMIA   r7, {r2 - r6}
        BLVS    CopyError               ; BL<cond> 32-bit OK
        MOVCS   a1, #-1                 ; CopyError preserves C and V
        MOVVS   a1, #-2
        Return  "r4, r5, r6, r7, v6"

|_kernel_osword|
        FunctionEntry "v6"
        SWI     Word
        BVS     ErrorExitV6Stacked
        MOV     a1, r1
        Return  "v6"

|_kernel_osfind|
        FunctionEntry "v6"
        SWI     XOS_Find
        Return  "v6",,VC
        BVS     ErrorExitV6Stacked

|_kernel_osfile|
; typedef struct {
;         int load, exec;
;         int start, end;
; } _kernel_osfile_block;
; int _kernel_osfile(int op, const char *name, _kernel_osfile_block *inout);
        FunctionEntry "r4-r6,v6"
        MOV     r6, a3
        LDMIA   a3, {r2 - r5}
        SWI     XOS_File
        STMIA   r6, {r2 - r5}
        BLVS    CopyError               ; BL<cond> 32-bit OK
        MOVVS   a1, #-2
        Return  "r4-r6,v6"

|_kernel_osargs|
        FunctionEntry "v6"
        MOV     ip, a1
        ORR     ip, ip, a2
        SWI     Args
        BVS     ErrorExitV6Stacked
        CMP     ip, #0
        MOVNE   a1, r2
        Return  "v6"

|_kernel_oscli|
        FunctionEntry "v6"
        SWI     CLI
        BVS     ErrorExitV6Stacked
        MOV     a1, #1      ; return 1 if OK
        Return  "v6"

|_kernel_last_oserror|
        LoadStaticBase ip, a1
        LDR     a1, [ip, #O_errorBuffer]
        CMP     a1, #0
        ADDNE   a1, ip, #O_errorNumber
        MOVNE   a2, #0
        STRNE   a2, [ip, #O_errorBuffer]
        Return  ,LinkNotStacked

|_kernel_peek_last_oserror|
        LoadStaticBase ip, a1
        LDR     a1, [ip, #O_errorBuffer]
        TEQ     a1, #0
        ADDNE   a1, ip, #O_errorNumber
        Return  ,LinkNotStacked

|_kernel_system|
; Execute the string a1 as a command;  if a2 is zero, as a subprogram,
; otherwise a replacement.
;
        STMFD   sp!, {v1-v6, r14}
        LoadStaticBase  v6, ip
        LDRB    v5, [v6, #O_fpPresent]
        CMPS    v5, #0
        SFMNEFD f4, 4, [sp]!
        RFSNE   v5
        STMFD   sp!, {a1, v5}

        LDR     v5, [v6, #O_heapLimit]
        LDR     v4, [v6, #O_heapTop]
        LDR     v3, [v6, #O_imageBase]
        ; if the heap has been extended, copying the image is futile at best
        ; (and maybe harmful if it has a hole)
        LDR     v2, [v6, #O_initSlotSize]
        CMP     v5, v2
        MOVGT   v4, v5                  ; so pretend top = limit.

; Calculate len of image and size of gap.  We will not bother copying at all if gap
; is too small (but can't fault, because the command may not be an application)
        SUB     r0, v4, v3              ; Len = heapTop - imageBase
        ADD     r0, r0, #15
        BIC     v2, r0, #15             ; rounded Len, multiple of 16
        SUB     r14, v5, v3             ; heapLimit - imageBase
        SUB     r14, r14, v2            ; Gap = (heapLimit -imageBase) - Len
        ; if gap is too small, don't bother with copy.  1024 is an arbitrary
        ; small number, but what this is mainly aiming to avoid is the
        ; (otherwise possible) case of v6 < 0.
        CMP     r14, #1024
        MOVLT   r14, #0
      [ {FALSE} ; this instruction is now deprecated
        STMFD   sp!, {a2, v2-v5, r14, r15}   ; save them away
      |
        SUB     sp, sp, #4
        STMFD   sp!, {a2, v2-v5, r14}        ; save them away
      ]
                                        ;subr/chain, len, base, top, limit, gap
                                        ; hole for memoryLimit

        BL      InstallCallersHandlers  ; sets r4 to current memoryLimit
        STR     r4, [sp, #24]
        ADD     r14, sp, #16
        LDMIA   r14, {v5, r14}          ; recover limit, gap

        LDRB    r0, [v6, #O_underDesktop]  ; if under desktop, find what the
        CMP     r0, #0                     ; Wimp slot size currently is, so we
        MOVNE   r0, #Env_ApplicationSpace  ; can reset it later on
        MOV     r1, #0
        SWINE   ChangeEnv

        STR     r1, [sp, #-4]!          ; remember slot size
        ; All registers must be preserved whose values are wanted afterwards.
        ; v1 to v6 are already on the stack.
        ADD     ip, sp, r14
        ADD     r5, v6, #O_languageEnvSave
        STMIA   r5, {sl, fp, ip}        ; save ptr to moved stack
        ADD     v6, v6, r14             ; now points to the to be copied data
        ; Be careful with stack usage from here on out - anything we push now
        ; might get lost or overwritten. Once s_Exit restores sp everything
        ; will be OK again.

; The following loop copies the image up memory. It avoids overwriting
; itself by jumping to its copied copy as soon as it has copied itself,
; unless, of course, it's running in the shared C library...
; The image is copied in DECREASING address order.
CopyUp  CMP     r14, #0
        BEQ     CopyUpDone
        LDR     v2, [sp, #8]            ; image base
        LDR     v3, [sp, #12]           ; Len
        ADD     r1, v3, v2              ; imageBase + Len = initial src
        RemovePSRFromReg pc, v4, v4     ; where to copy down to before jumping
        CMP     v4, v5                  ; copy code > limit?
        ADDHI   v4, v3, #16             ; yes => in shared lib so fake v4
        MOVHI   v2, #0                  ; and don't jump to non-copied code
        MOVLS   v2, r14                 ; else jump to copied code
01      LDMDB   r1!, {r0,r2-r4}
        STMDB   v5!, {r0,r2-r4}
        CMP     r1, v4                  ; r1 < %B01 ?
        BHI     %B01                    ; no, so keep going...
  [ StrongARM
    ;in case we are jumping to code we have just copied here (ie not shared Clib)...
    CMP   v2, #0
    MOVNE r0, #0 ; Inefficient, but this is only for static lib version (also danger here with the call to SetWimpSlot_Save_r4r5?)
    SWINE XOS_SynchroniseCodeAreas
  ]
        ADD     r0, pc, v2              ; ... go to moved image
        MOV     pc, r0                  ; and continue copying up...
01      LDMDB   r1!, {r0,r2-r4}
        STMDB   v5!, {r0,r2-r4}
        CMP     r1, v3                  ; src > imageBase ?
        BHI     %B01                    ; yes, so continue

  ;StrongARM - no need to synchronise for rest of copied code here, since we will not
  ;be executing it (we have to synchronise later, after copying down)

CopyUpDone
        ; ip is the relocated sp.
        LDR     r0, [ip, #4]           ; chain/subr
        CMP     r0, #0
        BNE     %FT01

        MOV     r0, #Env_MemoryLimit
        LDR     r1, [v6, #O_imageBase]
        ADD     r1, r1, r14
        SWI     ChangeEnv

        MOV     r0, #Env_ErrorHandler
        ADR     r1, s_ErrHandler
        MOV     r2, v6
        ADD     r3, v6, #O_errorBuffer
        SWI     ChangeEnv

        MOV     r0, #Env_ExitHandler
        ADR     r1, s_ExitHandler
        MOV     r2, v6
        SWI     ChangeEnv

        MOV     r0, #Env_UpCallHandler  ; We don't really want one of these, ...
        ADR     r1, s_UpCallHandler     ; but RISCOS rules say we must have it
        MOV     r2, v6
        SWI     ChangeEnv

01      LDR     r0, [ip, #32]           ; the CLI string to execute
        ADD     r0, r0, r14             ; ... suitably relocated...

        SWI     OS_CLI                  ; force non-X variant
        B       s_Exit

s_UpCallHandler
        MOV     pc, r14

s_ErrHandler
        MOV     v6, r0
        MOV     r0, #-2
        B       s_Exit2

s_ExitHandler
        MOV     v6, r12
s_Exit
        MOV     r0, #0
s_Exit2
        ADD     r5, v6, #O_languageEnvSave
      [ {FALSE} ; this instruction is now deprecated
        LDMIA   r5, {sl, fp, sp}
      |
        LDMIA   r5, {sl, fp}
        LDR     sp, [r5, #2*4]
      ]
        LDMFD   sp!, {a2, a3, v1-v5}    ; slotsize,
                                        ;subr/chain, Len, Base, Top, Limit, Gap
        STR     r0, [sp, #4]            ; ... over prev saved r0...
        CMP     a3, #0
        SWINE   Exit
        MOVS    a1, a2
        BEQ     %FT01
        BL      SetWimpSlot_Save_r4r5   ; set slot size back to value before CLI
        LDMFD   sp!, {r4, r5}

01
  [ StrongARM
        STR     v2, [sp, #-4]!          ; remember base for later
  ]
        SUB     sp, sp, v5              ; and relocate sp...
        SUB     v6, v6, v5              ; ...and the static data ptr

; The following loop copies the image down memory. It avoids overwriting
; itself by jumping to its copied copy as soon as it has copied itself,
; unless of course, this code is running in the shared C library...
; The image is copied in ASCENDING address order.
        CMP     v5, #0
        BEQ     CopyDnDone
CopyDn
        SUB     r0, v4, v1              ; limit - L = init src
        RemovePSRFromReg pc, v3, v3     ; == BIC v3, pc, #&FC000003 in 26bit
        ADD     v3, v3, #%F02-.-4       ; where to copy to before jumping
        CMP     v3, v4                  ; copy code > limit?
        SUBHI   v3, v4, #16             ; yes => in shared lib so fake v3
        MOVHI   v1, #0                  ; and don't jump to not copied code...
        MOVLS   v1, v5                  ; else jump...
01      LDMIA   r0!, {r1-r3,ip}
        STMIA   v2!, {r1-r3,ip}
        CMP     r0, v3                  ; copied the copy code?
        BLO     %B01                    ; no, so continue...
  [ StrongARM
    ;in case we are jumping to code we have just copied here (ie not shared Clib)...
    MOV   r1, r0
    CMP   v1, #0
    MOVNE r0, #0 ; Inefficient, but this is only for static lib version
    SWINE XOS_SynchroniseCodeAreas
    MOV   r0, r1
  ]
        SUB     ip, pc, v1              ; yes => copied this far ...
        MOV     pc, ip                  ; ... so branch to copied copy loop
01      LDMIA   r0!, {r1-r3,ip}
        STMIA   v2!, {r1-r3,ip}
        CMP     r0, v4                  ; finished copying?
        BLO     %B01                    ; no, so continue...
02
CopyDnDone
  [ StrongARM
    ;you've guessed it
    MOV    r0, #1
    LDR    r1, [sp], #4
    MOV    r2, v2
    CMP    r1, r2
    SWINE  XOS_SynchroniseCodeAreas
  ]
        LDR     r0, [sp], #4            ; old memoryLimit
        BL      InstallHandlers

        LDMFD   sp!, {a1, v5}
        LDRB    v4, [v6, #O_fpPresent]
        CMPS    v4, #0
        WFSNE   v5
        LFMNEFD f4, 4, [sp]!
        Return  "v1-v6"

CopyError  Keep ; a1 is the address of an error block (may be ours)
                ; we want to copy its contents into our error block,
                ; so _kernel_last_oserror works.
        ; This routine MUST preserve the C and V flags across the call.
        ; The BICS only affects N and Z (C not changed as barrel shifter not used)
        LoadStaticBase v6, a2
CopyErrorV6OK
        MOV     a4, a1
        ADD     a2, v6, #O_errorNumber
CopyError2
        STR     pc, [a2, #-4]           ; mark as valid
        LDR     a3, [a4], #4
        STR     a3, [a2], #4
CopyErrorString
01      LDRB    a3, [a4], #+1
        STRB    a3, [a2], #+1
        BICS    a3, a3, #&1F            ; replaces CMP a3, #' '
        BNE     %B01                    ; replaces BCS %B01
        ; We're probably here because a SWI returned an error. This probably
        ; also means that the kernel has set the callback postponement flag -
        ; a flag designed to prevent global error buffers being clobbered by
        ; callbacks. However we've just copied the error into our own private 
        ; buffer, so there's no need for the kernel to postpone callbacks. In
        ; fact, postponing callbacks can be harmful, potentially preventing the
        ; user from quitting a malfunctioning app, due to both CLib's Escape
        ; handler and Alt-Break being reliant on callbacks. So if we're in user
        ; mode, do a dummy SWI to clear the postponement flag.
 [ {CONFIG} = 26
        TST     lr, #PSRIBit+PSRPrivileged
        SWIEQ   XOS_IntOn
        MOVS    pc, lr
 |
        MRS     a3, CPSR
        TST     a3, #PSR32IBit+PSR32Privileged
        SWIEQ   XOS_IntOn
        MSR     CPSR_f, a3
        MOV     pc, lr
 ]

|_kernel_getenv|
; _kernel_oserror *_kernel_getenv(const char *name, char *buffer, unsigned size);
        FunctionEntry "v1,v2,v6", frame
        LoadStaticBase v6, ip
        SUB     r2, r2, #1
        MOV     r3, #0
        MOV     r4, #3
        SWI     XOS_ReadVarVal
        MOVVC   a1, #0
        STRVCB  a1, [r1, r2]
        BLVS    CopyError               ; BL<cond> 32-bit OK
        Return  "v1,v2,v6", "fpbased"

|_kernel_setenv|
; _kernel_oserror *_kernel_setenv(const char *name, const char *value);
        FunctionEntry "v1,v6"
        LoadStaticBase v6, ip
        ; Apparently, we need to say how long the value string is as well
        ; as terminating it.
        TEQ     a2, #0
        MOV     a3, #-1
01      ADDNE   a3, a3, #1
        LDRNEB  ip, [a2, a3]
        CMPNE   ip, #0
        BNE     %B01
        MOV     r3, #0
        MOV     r4, #0
        SWI     XOS_SetVarVal
        MOVVC   a1, #0
        BLVS    CopyError               ; BL<cond> 32-bit OK
        Return  "v1,v6"

 ;*-------------------------------------------------------------------*
 ;* Storage management                                                *
 ;*-------------------------------------------------------------------*

|_kernel_register_allocs|
; void _kernel_register_allocs(allocproc *malloc, freeproc *free);
        LoadStaticBase ip, a3
        ADD     ip, ip, #O_allocProc
        STMIA   ip, {a1, a2}
        Return  ,LinkNotStacked


|_kernel_register_slotextend|
        LoadStaticBase ip, a3
        MOVS    a2, a1
        LDR     a1, [ip, #O_heapExtender]
        STRNE   a2, [ip, #O_heapExtender]
        Return  ,LinkNotStacked

|_kernel_alloc|
; unsigned _kernel_alloc(unsigned minwords, void **block);
;  Tries to allocate a block of sensible size >= minwords.  Failing that,
;  it allocates the largest possible block of sensible size.  If it can't do
;  that, it returns zero.
;  *block is returned a pointer to the start of the allocated block
;  (NULL if none has been allocated).
        LoadStaticBase ip, a3

        CMP     r0, #2048
        MOVLT   r0, #2048

        ADD     ip, ip, #O_heapTop
        LDMIA   ip, {r2, r3}

        SUB     r3, r3, r0, ASL #2      ; room for a block of this size?
        CMP     r3, r2                  ; if so, ...
        BGE     alloc_return_block

        ; There's not going to be room for the amount required.  See if
        ; we can extend our workspace.
        LDRB    r3, [ip, #O_underDesktop-O_heapTop]
        CMP     r3, #0
 [ SharedLibrary
; See if we are allowed to extend the wimp-slot - depends on the stub vintage
; if running under the shared library. If not shared, we can do it provided
; we're running under the desktop.
        LDRNEB  r3, [ip, #O_kallocExtendsWS-O_heapTop]
        CMPNE   r3, #0
 ]
        BEQ     alloc_cant_extend       ; not under desktop or old stubs

        STMFD   sp!, {r0, r1, lr}

        LDR     r3, [ip, #O_heapExtender-O_heapTop]
        CMP     r3, #0
        BEQ     alloc_no_extender
        LDR     r0, [sp], #-4           ; ask for the amount we were asked for
        MOV     r0, r0, ASL #2          ; (since what we are given may well
                                        ;  not be contiguous with what we had
                                        ;  before).
        ; Set to a silly value, guaranteed not to be equal to initSlotSize, to ensure
        ; reset on exit.
        STR     r3, [ip, #O_knownSlotSize-O_heapTop]
        MOV     r1, sp
        MOV     lr, pc
        MOV     pc, r3
        LoadStaticBase ip, a3           ; restore our static base
        ADD     ip, ip, #O_heapTop
        LDR     r1, [sp], #+4           ; base of area acquired
        CMP     r0, #0                  ; size (should be 0 or big enough)
        BEQ     alloc_cant_extend_0

        LDMIA   ip, {r2, lr}
        CMP     lr, r1
        SUBNE   r3, lr, r2              ; if not contiguous with old area, amount free
        ADD     lr, r1, r0              ; adjust heapLimit
        MOVNE   r0, r2                  ; if not contiguous, remember old heapTop
        MOVNE   r2, r1                  ; and adjust
        STMIA   ip, {r2, lr}
        CMPNE   r3, #0                  ; if contiguous, or old area had no free space,
        BEQ     alloc_cant_extend_0     ; return from new area

        ADD     sp, sp, #4              ; otherwise, return block from top of old area
        LDMFD   sp!, {r1, lr}           ; first (malloc will try again and get from
        STR     r0, [r1]                ; new area).
        MOV     r0, r3, ASR #2
        Return  ,LinkNotStacked

alloc_no_extender
        ; if current slotsize = heap limit, try to extend the heap by the
        ; amount required (or perhaps by just enough to allow allocation
        ; of the amount required)
        ADD     lr, r2, r0, ASL #2      ; heaptop if request could be granted
        MOV     r0, #Env_ApplicationSpace ; find current slotsize
        MOV     r1, #0
        SWI     ChangeEnv
        LDR     r0, [ip, #O_knownSlotSize-O_heapTop]
        CMP     r1, r0
        BNE     alloc_cant_extend_0

        ; If the extension will be contiguous with the current heap top,
        ; then we need just enough to allow the requested allocation.
        LDMIA   ip, {r2, r3}
        CMP     r3, r0
        BEQ     alloc_extend_slot
        ; Otherwise, we must extend by the amount requested.  If there's still
        ; some space left in the previous area, give that back first.
        CMP     r2, r3
        BNE     alloc_cant_extend_0
        STR     r0, [ip, #O_heapTop-O_heapTop]
        LDR     r2, [sp]
        ADD     lr, r0, r2, ASL #2
alloc_extend_slot
        ; lr holds the slot size we want.  r1 is the current memory limit.
        ; Now if memory limit is not slot size, we must reset memory limit
        ; temporarily over the call to Wimp_SlotSize (or it will refuse).
        MOV     r0, lr
        BL      SetWimpSlot_Save_r4r5
        LDMFD   sp!, {r4, r5}
        ADD     r0, r0, #Application_Base
        STR     r0, [ip, #O_knownSlotSize-O_heapTop]
        STR     r0, [ip, #O_heapLimit-O_heapTop]

alloc_cant_extend_0
        LDMFD   sp!, {r0, r1, lr}
alloc_cant_extend
        LDMIA   ip, {r2, r3}

        SUB     r3, r3, r0, ASL #2      ; room for a block of this size?
        CMP     r3, r2                  ; if so, ...

alloc_return_block
        STRGE   r2, [r1]                ; return it above the previous heapTop
        ADDGE   r2, r2, r0, ASL #2      ; and update heapTop
        STRGE   r2, [ip]
        Return  ,LinkNotStacked, GE

        ADD     r0, r0, r3, ASR #2      ; otherwise, return whatever is free
        SUB     r0, r0, r2, ASR #2
        CMP     r0, #0
        BGT     alloc_return_block

        STR     r0, [r1]                ; (if none, returned block is NULL,
        Return  ,LinkNotStacked         ; and don't update heapTop)


|_kernel_malloc|
; void * _kernel_malloc(int numbytes);
;  Allocates numbytes bytes (rounded up to number of words), and returns
;  the block allocated.  If it can't, returns NULL.
;  Normally, this will be replaced by the real malloc very early in the
;  startup procedure.
        LoadStaticBase ip, a2

        ADD     ip, ip, #O_heapTop
        LDMIA   ip, {r2, r3}

        SUB     r3, r3, r0              ; room for a block of this size?
        CMP     r3, r2                  ; if so, ...
        ADDGE   r3, r2, r0
        MOVGE   r0, r2                  ; return it above heapTop
        STRGE   r3, [ip]
        MOVLT   r0, #0
        Return  ,LinkNotStacked

|_kernel_free|
; void free(void *);
;  Frees the argument block.
;  Normally, this will be replaced by the real free very early in the
;  startup procedure.
;  I don't think there's much point in providing a real procedure for this;
;  if I do, it complicates malloc and alloc above.
        Return  ,LinkNotStacked

; In future these could be sophisticated allocators that associate
; allocated blocks with stack chunks, allowing longjmp() et al to
; clear them up. But for now, this suffices for C99's VLAs.
|__rt_allocauto|
        FunctionEntry
        LoadStaticBase ip, a2
        MOV     lr, pc
        LDR     pc, [ip, #O_allocProc]
        TEQ     a1, #0
        Return  ,,NE
        LoadStaticBase ip, a1
        LDR     lr, [sp], #4
        ADD     ip, ip, #O_registerDump
      [ {FALSE} ; this instruction is now deprecated
        STMIA   ip, {a1 - r14}
      |
        STMIA   ip, {a1 - r12}
        STR     r13, [ip, #13*4]
        STR     r14, [ip, #14*4]
      ]
        ADR     r0, E_StackOverflow
        BL      |_kernel_copyerror|
        SWI     GenerateError

|__rt_freeauto|
        LoadStaticBase ip, a2
        LDR     pc, [ip, #O_freeProc]


 ;*-------------------------------------------------------------------*
 ;* Stack chunk handling                                              *
 ;*-------------------------------------------------------------------*

|_kernel_current_stack_chunk|
        SUB     a1, sl, #SC_SLOffset
        Return  ,LinkNotStacked

 ;*-------------------------------------------------------------------*
 ;* Stack overflow handling                                           *
 ;*-------------------------------------------------------------------*

|_kernel_stkovf_split_0frame|
; Run out of stack.
; Before doing anything else, we need to acquire some work registers
; as only ip is free.
; We can save things on the stack a distance below fp which allows the
; largest possible list of saved work registers (r0-r3, r4-r9 inclusive,
; plus fp, sp, lr = 13 regs in total) plus a minimal stack
; frame for return from StkOvfExit (a further 4 words, giving 17 in total)
; plus 4 extended floating point registers (a further 3*4 words)
        MOV     ip, sp
|_kernel_stkovf_split|
        SUB     ip, sp, ip              ; size required
        SUB     sp, fp, #29*4
        STMFD   sp!, {a1, a2, v1-v6, lr}; to save a1-a2, v1-v6
 [ 0 = 1
        LoadStaticAddress disable_stack_extension, a1, lr
        LDR     a1, [a1]
        CMP     a1, #0
        BNE     StackOverflowFault
 ]
        ADD     v4, ip, #SC_SLOffset    ; required size + safety margin
        SUBS    v1, fp, #30*4           ; save area ptr, clear V flag
        BL      GetStackChunk
        BVS     StackOverflowFault
; Get here with v2 pointing to a big enough chunk of size v3
; (Not yet marked as a stack chunk)
        ADD     sl, v2, #SC_SLOffset    ; make the new sl
        ADD     sp, v2, v3              ; and initial sp
        LDR     a1, =IsAStackChunk
        STR     a1, [sl, #SC_mark-SC_SLOffset]
; v1 is save area in old frame... will be temp sp in old frame
        ADD     a1, v1, #4*4            ; temp fp in old frame
        LDMDA   fp, {v3-v6}             ; old fp, sp,lr, pc

        STMFD   sp!,{a1-a2}
        MOV     a1,#0
        SWI     XOS_PlatformFeatures
        MOVVS   a1,#0
        TST     a1,#8                   ; Stores PC+8 or PC+12?
        ADREQ   v6, StkOvfPseudoEntry+12
        ADRNE   v6, StkOvfPseudoEntry+8
        LDMFD   sp!,{a1-a2}

        STMDA   a1, {v3-v6}             ; new return frame in old chunk...
        ADR     lr, StackOverflowExit
        MOV     a2, sp                  ; saved sp in old frame = NEW sp
                                        ; (otherwise exit call is fatal)
        STMDB   fp, {a1, a2, lr}        ; pervert old frame to return here...
        [ {CONFIG}=26
        LDMDA   v1, {a1, a2, v1-v6, pc}^
        |
        LDMDA   v1, {a1, a2, v1-v6, pc}
        ]

|_kernel_stkovf_copy0args|
; Run out of stack.
; Before doing anything else, we need to acquire some work registers
; (IP is free in the StkOvf case, but not in the StkOvfN case).
; We can save things on the stack a distance below FP which allows the
; largest possible list of saved work registers (R0-R3, R4-9 inclusive,
; plus FP, SP, LR, entry PC, = 14 regs in total) plus 4 extended floating
; point registers, a further 3*4 words
        MOV     ip, #0                  ; STKOVF not STKOVFN
|_kernel_stkovf_copyargs|
; the (probable) write below sp here is inevitable - there are no registers
; free.  The only way to make this safe against events is to pervert sl
; temporarily.
        ADD     sl, sl, #4
        STR     lr, [fp, #-26*4]        ; save LR
        SUB     lr, fp, #26*4           ; & use as temp SP
        STMFD   lr!, {a1, a2, v1-v6}    ; to save A1-A2, V1-V6
       [ 0 = 1
        LoadStaticAddress disable_stack_extension, a1, lr
        LDR     a1, [a1]
        CMP     a1, #0
        BNE     StackOverflowFault
       ]
        SUB     v4, fp, sp              ; needed frame size
        ADD     v4, v4, #SC_SLOffset    ; + safety margin
        MOV     sp, lr                  ; got an SP now...
        SUB     sl, sl, #4
        ; We do not drop SL here : the code that gets called to acquire a new
        ; stack chunk had better not check for stack overflow (and also had
        ; better not use more than the minimum that may be available).
        SUBS    v1, fp, #26*4           ; save area ptr, clear V flag
        BL      GetStackChunk
        BVS     StackOverflowFault      ; out of stack

; Get here with V2 pointing to a big enough chunk of size V3
        ADD     sl, v2, #SC_SLOffset    ; make the new SL
        ADD     sp, v2, v3              ; and initial SP
        LDR     a1, =IsAStackChunk
        STR     a1, [sl, #SC_mark-SC_SLOffset]
; Copy over 5th and higher arguments, which are expected on the stack...
        CMP     ip, #0
        BLE     DoneArgumentCopy
01      LDR     v5, [fp, ip, ASL #2]    ; copy args in high->low
        STR     v5, [sp, #-4]!          ; address order
        SUBS    ip, ip, #1
        BNE     %B01
DoneArgumentCopy
; Now create a call frame in the new stack chunk by copying
; over stuff saved in the frame in the old stack chunk to the
; new, perverting LR so that, on return, control comes back to
; this code and perverting SP and FP to give us a save area
; containing none of the V registers.
        MOV     v1, fp                  ; old chunk's frame pointer
        SUB     ip, v4, #SC_SLOffset    ; needed frame size, no margin
        LDMDA   v1!, {a1, a2, v2-v6}    ; 1st 7 of possible 14 saved regs
        ADR     v5, StackOverflowExit
        MOV     v4, sp                  ; SP in NEW chunk
        ORR     v3, fp, #ChunkChange    ; new FP in old chunk
        SUB     fp, sp, #4              ; FP in new chunk
        STMFD   sp!, {a1, a2, v2-v6}    ; 1st 7 copied frame regs
        LDMDA   v1!, {a1, a2, v2-v6}    ; and the 2nd 7 regs
        STMFD   sp!, {a1, a2, v2-v6}    ; copied to the new frame

; Now adjust the PC value saved in the old chunk to say "no registers"
        MOV     a1,#0
        SWI     XOS_PlatformFeatures
        MOVVS   a1,#0
        TST     a1,#8                   ; PC+8 or PC+12?
        ADREQ   v2, StkOvfPseudoEntry+12
        ADRNE   v2, StkOvfPseudoEntry+8

        STR     v2, [v1, #26*4]
; Set the SP to be FP - requiredFrameSize and return by reloading regs
; from where they were saved in the old chunk on entry to STKOVF/N
        SUB     sp, fp, ip
        [ {CONFIG}=26
        LDMDA   v1, {a1, a2, v1-v6, pc}^
        |
        LDMDA   v1, {a1, a2, v1-v6, pc}
        ]

StkOvfPseudoEntry
        STMFD   sp!, {fp, ip, lr, pc}   ; A register save mask

StackOverflowExit Keep
; We return here when returning from the procedure which caused the
; stack to be extended. FP is in the old chunk SP and SL are still
; in the new one.

        ; We need to move sp and sl back into the old chunk.  Since this happens
        ; in two operations, we need precautions against events while we're
        ; doing it.
        ADD     sl, sl, #4              ; (an invalid stack-chunk handle)
        SUB     sp, fp, #3*4            ; get a sensible sp in the old chunk
        STMFD   sp!, {a1-a2, v1-v4}     ; Save some work regs
        MOV     v4, r14                 ; Remember if register permute needed
; Now see if the new chunk has a next chunk and deallocate it if it has.
        SUB     v1, sl, #4
        LDR     v2, [v1, #SC_next-SC_SLOffset]
        LDR     sl, [v1, #SC_prev-SC_SLOffset]
        LDR     a1, [sl, #SC_mark]      ; make not a stack chunk (before making
        EOR     a1, a1, #&40000000      ; sl a proper stackchunk handle).
        STR     a1, [sl, #SC_mark]
        ADD     sl, sl, #SC_SLOffset
        SUB     sp, sp, #4
DeallocateChunkLoop
        CMP     v2, #0                  ; is there a next next chunk?
        BEQ     DoneDeallocateChunks    ; No! - do nothing
        LDR     v3, [v2, #SC_next]      ; next chunk
        MOV     a1, v2
        LDR     ip, [v2,#SC_deallocate] ; deallocate proc for this chunk
        CMPS    ip, #0                  ; is there a proc?
        MOVEQ   v1, v2                  ; no deallocate proc: try next chunk
        BEQ     DeallocateChunkLoopSkip ; go around next chunk
        MOV     lr, pc
        MOV     pc, ip                  ; there was, so call it...
        MOV     a2, #0
        STR     a2, [v1, #SC_next-SC_SLOffset] ; and unhook next chunk
DeallocateChunkLoopSkip
        MOV     v2, v3
        B       DeallocateChunkLoop
DoneDeallocateChunks
; Clear the chunk change bit, and return to caller by reloading the saved work
; regs and the frame regs that were adjusted at the time the stack was extended
        LDR     a1, =IsAStackChunk
        STR     a1, [sl, #SC_mark-SC_SLOffset]
        BIC     fp, fp, #ChunkChange
; Return
        Return  "a1-a2, v1-v4", fpbased

GetStackChunk Keep
; Naughty procedure with non-standard argument conventions.
; On entry, V1 = save area ptr in case of error return; V4 = needed size;
; On exit, V1, and V4 are preserved, V2 points to the newly inserted chunk
; and V3 is the chunk's size. In case of error, V is set.
StkOvfGetChunk
      [ {CONFIG}=26
        TST     r14, #PSRSVCMode        ; in SWI mode, stack overflow is fatal
        ORRNES  pc, r14, #PSRVBit       ; (could have been detected earlier,
                                        ; but deferral to now is simpler).
      |
        MRS     v2, CPSR
        MOVS    v2, v2, LSL #28
        TEQHI   v2, #&F0000000          ; allow stack extension in SYS mode
        MSRNE   CPSR_f, #V_bit          ; maintain NE
        MOVNE   pc, lr
      ]
; Check that the current chunk really is a stack chunk...
        STMFD   sp!, {a3, a4, ip, lr}   ; save args not saved before
        LDR     v2, =IsAStackChunk      ; magic constant...
        LDR     v3, [sl, #SC_mark-SC_SLOffset]
        CMP     v2, v3                  ; matches magic in chunk?
        BNE     StkOvfError             ; No! - die horribly
        EOR     v3, v3, #&80000000      ; make not a stack chunk, so recursive
        STR     v3, [sl, #SC_mark-SC_SLOffset] ; extension faults
; We have a chunk, see if there's a usable next chunk...
        SUB     v2, sl, #SC_SLOffset
02      LDR     v2, [v2, #SC_next]
        CMP     v2, #0
        BEQ     StkOvfGetNewChunk       ; No! - so make one
        LDR     v3, [v2, #SC_size]
        CMP     v4, v3                  ; is it big enough?
        BGT     %B02                    ; No! so try next chunk
; unlink the usable chunk from the chain...
        LDR     a1, [v2, #SC_prev]      ; previous chunk
        LDR     a2, [v2, #SC_next]      ; next chunk
        STR     a2, [a1, #SC_next]      ; prev->next = next
        CMPS    a2, #0                  ; next == NULL ?
        STRNE   a1, [a2, #SC_prev]      ; next->prev = prev
        B       StkOvfInsertChunk
StkOvfGetNewChunk Keep
        ; Now we swap to the special extension chunk (to give a reasonable
        ; stack size to malloc).
        LoadStaticBase v2, ip
03      MOV     a1, #0
        ADD     a2, v2, #O_extendChunkNotInUse
      [ {CONFIG}=26
        LDR     lr, [v2, #O__swp_available]
        TEQ     lr, #0
        SWPNE   a1, a1, [a2]
        BLEQ    Arm2Swp
      |
       [ SupportARMv6
        [ NoARMv6
        LDR     lr, [v2, #O__swp_available]
        TST     lr, #2 ; CPU supports LDREX?
        SWPEQ   a1, a1, [a2]
        BEQ     %FT02
        ]
        MOV     lr, #0
01      LDREXB  a1, [a2]
        STREXB  a3, lr, [a2]
        TEQ     a3, #1
        BEQ     %BT01
02
       |
        SWP     a1, a1, [a2]
       ]
      ]
        TEQ     a1, #0
        BLEQ    Sleep                     ; preserves Z
        BEQ     %BT03
        LDR     a2, [v2, #O_extendChunk]
        LDR     a3, [a2, #SC_size]
        ADD     a3, a2, a3                ; new sp
      [ {FALSE} ; this instruction is now deprecated
        STMFD   a3!, {sl, fp, sp}         ; save old stack description
      |
        STR     sp, [a3, #-4]!
        STMFD   a3!, {sl, fp}             ; save old stack description
      ]
        MOV     sp, a3
        ADD     sl, a2, #SC_SLOffset
        MOV     fp, #0

        MOV     a1, #RootStackSize; new chunk is at least this big
        CMP     a1, v4            ; but may be bigger if he wants a huge frame
        MOVLT   a1, v4
        LDR     ip, [v2, #O_allocProc]
        CMPS    ip, #0
        BEQ     %F01                    ; (restore stack chunk, then error)
        LDR     lr, [v2, #O_freeProc]
        STMFD   sp!, {a1, lr}           ; chunk size in bytes, dealloc proc
        MOV     lr, pc
        MOV     pc, ip
        MOV     lr, v2
        MOVS    v2, a1
        LDMFD   sp!, {v3, ip}           ; size in bytes, dealloc
01
      [ {FALSE} ; this instruction is now deprecated
        LDMFD   sp, {sl, fp, sp}        ; back to old chunk
      |
        LDMFD   sp!, {sl, fp}           ; back to old chunk
        LDR     sp, [sp]
      ]
        MOV     a1, #1
        STR     a1, [lr, #O_extendChunkNotInUse]
        BEQ     StkOvfError
        STR     v3, [v2, #SC_size]
        STR     ip, [v2, #SC_deallocate]
        LDR     a1, [sl, #SL_Lib_Offset]
        STR     a1, [v2, #SL_Lib_Offset+SC_SLOffset]
        LDR     a1, [sl, #SL_Client_Offset]
        STR     a1, [v2, #SL_Client_Offset+SC_SLOffset]
; and re-link it in its proper place...
StkOvfInsertChunk
        SUB     a1, sl, #SC_SLOffset    ; chunk needing extension...
        LDR     a2, =IsAStackChunk
        STR     a2, [a1, #SC_mark]      ; remark as stack chunk
        LDR     a2, [a1, #SC_next]      ; its next chunk
        STR     a2, [v2, #SC_next]      ; this->next = next
        STR     v2, [a1, #SC_next]      ; prev->next = this
        STR     a1, [v2, #SC_prev]      ; this->prev = prev
        CMPS    a2, #0
        STRNE   v2, [a2, #SC_prev]      ; next->prev = this
        STR     pc, [v2, #SC_mark]      ; Not a stack chunk (for safe non-atomic
                                        ; update of sp and sl).
        Return  "a3, a4, ip"            ; restore extra saved regs
StkOvfError
        [ {CONFIG}=26
        LDMFD   sp!, {a3, a4, ip, lr}
        ORRS    pc, lr, #PSRVBit        ; return with V set
        |
        MSR     CPSR_f, #V_bit
        LDMFD   sp!, {a3, a4, ip, pc}
        ]

StackOverflowFault Keep
        LoadStaticBase ip, a1
        MOV     sp, v1
        LDMDA   v1, {a1, a2, v1-v6, lr}
        ADD     ip, ip, #O_registerDump
      [ {FALSE} ; this instruction is now deprecated
        STMIA   ip, {a1 - r14}
      |
        STMIA   ip, {a1 - r12}
        STR     r13, [ip, #13*4]
        STR     r14, [ip, #14*4]
      ]
        ADR     r0, E_StackOverflow
        BL      |_kernel_copyerror|
        SWI     GenerateError

        LTORG
        ErrorBlock StackOverflow, "Stack overflow", C45

 [ {CONFIG}=26
Arm2Swp ; like SWP a1,a1,[a2] but corrupts a3, lr and flags
        SWI     IntOff
        LDR     a3, [a2]
        STR     a1, [a2]
        SWI     IntOn
        MOV     a1, a3
        MOV     pc, lr
 |
AcquireMutex
        FunctionEntry
        MOV     a2, a1
  [ SupportARMv6
   [ NoARMv6
        LoadStaticBase a4, ip
        LDR     a1, [a4, #O__swp_available]
        TST     a1, #2 ; does CPU support LDREX?
        BEQ     %FT03
   ]
        MOV     a3, #0
  ]
        B       %FT02
  [ SupportARMv6
01      MOV     a1, #6
        SWI     XOS_UpCall
02      LDREX   a1, [a2]
        STREX   a4, a3, [a2]
        TEQ     a4, #1
        BEQ     %BT02
        TEQ     a1, #0
        BEQ     %BT01
        Return
  ]
  [ NoARMv6
01      MOV     a1, #6
        SWI     XOS_UpCall
02
03      MOV     a1, #0
        SWP     a1, a1, [a2]
        TEQ     a1, #0
        BEQ     %BT01
        Return
  ]
 ]

Sleep
; a2 -> pollword
; must exit with Z set
        MOV     a1, #6
        SWI     XOS_UpCall
        CMP     a1, a1
        MOV     pc, lr

 ;*-------------------------------------------------------------------*
 ;* Arithmetic                                                        *
 ;*-------------------------------------------------------------------*

|__rt_udiv|
|_kernel_udiv|
|x$udivide|
; Unsigned divide of a2 by a1: returns quotient in a1, remainder in a2
; Destroys a3 and ip
      [ NoARMVE
|_kernel_udiv_NoARMVE|
        MOV     a3, #0
        RSBS    ip, a1, a2, LSR #3
        BCC     u_sh2
        RSBS    ip, a1, a2, LSR #8
        BCC     u_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&FF000000
        RSBS    ip, a1, a2, LSR #4
        BCC     u_sh3
        RSBS    ip, a1, a2, LSR #8
        BCC     u_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&00FF0000
        RSBS    ip, a1, a2, LSR #8
        MOVCS   a1, a1, LSL #8
        ORRCS   a3, a3, #&0000FF00
        RSBS    ip, a1, a2, LSR #4
        BCC     u_sh3
        RSBS    ip, a1, #0
        BCS     dividebyzero
u_loop  MOVCS   a1, a1, LSR #8
u_sh7   RSBS    ip, a1, a2, LSR #7
        SUBCS   a2, a2, a1, LSL #7
        ADC     a3, a3, a3
u_sh6   RSBS    ip, a1, a2, LSR #6
        SUBCS   a2, a2, a1, LSL #6
        ADC     a3, a3, a3
u_sh5   RSBS    ip, a1, a2, LSR #5
        SUBCS   a2, a2, a1, LSL #5
        ADC     a3, a3, a3
u_sh4   RSBS    ip, a1, a2, LSR #4
        SUBCS   a2, a2, a1, LSL #4
        ADC     a3, a3, a3
u_sh3   RSBS    ip, a1, a2, LSR #3
        SUBCS   a2, a2, a1, LSL #3
        ADC     a3, a3, a3
u_sh2   RSBS    ip, a1, a2, LSR #2
        SUBCS   a2, a2, a1, LSL #2
        ADC     a3, a3, a3
u_sh1   RSBS    ip, a1, a2, LSR #1
        SUBCS   a2, a2, a1, LSL #1
        ADC     a3, a3, a3
u_sh0   RSBS    ip, a1, a2
        SUBCS   a2, a2, a1
        ADCS    a3, a3, a3
        BCS     u_loop
        MOV     a1, a3
        Return  ,LinkNotStacked
      ]
      [ SupportARMVE :LAND: (:LNOT: NoARMVE :LOR: SHARED_C_LIBRARY)
|_kernel_udiv_SupportARMVE|
; Long delay on UDIV result makes it faster to divide and then check for error
        UDIV    a3, a2, a1
        TEQ     a1, #0
        BEQ     dividebyzero
        MLS     a2, a3, a1, a2
        MOV     a1, a3
        Return  ,LinkNotStacked
      ]

; Unsigned remainder of a2 by a1: returns remainder in a1
; Could be faster (at expense in size) by duplicating code for udiv,
; but removing the code to generate a quotient.  As it is, a sensible
; codegenerator will call udiv directly and use the result in a2

|_kernel_urem|
|x$uremainder|
        FunctionEntry
        BL      |_kernel_udiv|
        MOV     a1, a2
        Return

; Fast unsigned divide by 10: dividend in a1
; Returns quotient in a1, remainder in a2

|__rt_udiv10|
|_kernel_udiv10|
      [ NoARMM
|_kernel_udiv10_NoARMM|
        SUB     a2, a1, #10
        SUB     a1, a1, a1, LSR #2
        ADD     a1, a1, a1, LSR #4
        ADD     a1, a1, a1, LSR #8
        ADD     a1, a1, a1, LSR #16
        MOV     a1, a1, LSR #3
        ADD     a3, a1, a1, LSL #2
        SUBS    a2, a2, a3, LSL #1
        ADDPL   a1, a1, #1
        ADDMI   a2, a2, #10
        Return  ,LinkNotStacked
      ]
      [ SupportARMM :LAND: (:LNOT: NoARMM :LOR: SHARED_C_LIBRARY)
|_kernel_udiv10_SupportARMM|
; For small numbers, UDIV would be faster than this, but not enough to make it
; worth dynamically switching between algorithms.
        LDR     a2, =&CCCCCCCD ; (8^32) / 10
        UMULL   ip, a3, a2, a1
        MOV     a3, a3, LSR #3 ; Accurate division by 10
        SUB     a2, a1, a3, LSL #1
        MOV     a1, a3
        SUB     a2, a2, a3, LSL #3
        Return  ,LinkNotStacked
      ]


|__rt_sdiv|
|_kernel_sdiv|
|x$divide|
; Signed divide of a2 by a1: returns quotient in a1, remainder in a2
; Quotient is truncated (rounded towards zero).
; Sign of remainder = sign of dividend.
; Destroys a3, a4 and ip
      [ NoARMVE
|_kernel_sdiv_NoARMVE|
; Negates dividend and divisor, then does an unsigned divide; signs
; get sorted out again at the end.

        ANDS    a3, a1, #&80000000
        RSBMI   a1, a1, #0
        EORS    a4, a3, a2, ASR #32
        RSBCS   a2, a2, #0
        RSBS    ip, a1, a2, LSR #3
        BCC     s_sh2
        RSBS    ip, a1, a2, LSR #8
        BCC     s_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&FF000000
        RSBS    ip, a1, a2, LSR #4
        BCC     s_sh3
        RSBS    ip, a1, a2, LSR #8
        BCC     s_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&00FF0000
        RSBS    ip, a1, a2, LSR #8
        MOVCS   a1, a1, LSL #8
        ORRCS   a3, a3, #&0000FF00
        RSBS    ip, a1, a2, LSR #4
        BCC     s_sh3
        RSBS    ip, a1, #0
        BCS     dividebyzero
s_loop  MOVCS   a1, a1, LSR #8
s_sh7   RSBS    ip, a1, a2, LSR #7
        SUBCS   a2, a2, a1, LSL #7
        ADC     a3, a3, a3
s_sh6   RSBS    ip, a1, a2, LSR #6
        SUBCS   a2, a2, a1, LSL #6
        ADC     a3, a3, a3
s_sh5   RSBS    ip, a1, a2, LSR #5
        SUBCS   a2, a2, a1, LSL #5
        ADC     a3, a3, a3
s_sh4   RSBS    ip, a1, a2, LSR #4
        SUBCS   a2, a2, a1, LSL #4
        ADC     a3, a3, a3
s_sh3   RSBS    ip, a1, a2, LSR #3
        SUBCS   a2, a2, a1, LSL #3
        ADC     a3, a3, a3
s_sh2   RSBS    ip, a1, a2, LSR #2
        SUBCS   a2, a2, a1, LSL #2
        ADC     a3, a3, a3
s_sh1   RSBS    ip, a1, a2, LSR #1
        SUBCS   a2, a2, a1, LSL #1
        ADC     a3, a3, a3
s_sh0   RSBS    ip, a1, a2
        SUBCS   a2, a2, a1
        ADCS    a3, a3, a3
        BCS     s_loop
        EORS    a1, a3, a4, ASR #31
        ADD     a1, a1, a4, LSR #31
        RSBCS   a2, a2, #0
        Return  ,LinkNotStacked
      ]
      [ SupportARMVE :LAND: (:LNOT: NoARMVE :LOR: SHARED_C_LIBRARY)
|_kernel_sdiv_SupportARMVE|
        SDIV    a3, a2, a1
        TEQ     a1, #0
        BEQ     dividebyzero
        MLS     a2, a3, a1, a2
        MOV     a1, a3
        Return  ,LinkNotStacked
      ]

; Signed remainder of a2 by a1: returns remainder in a1

|_kernel_srem|
|x$remainder|
        FunctionEntry
        BL      |_kernel_sdiv|
        MOV     a1, a2
        Return

; Fast signed divide by 10: dividend in a1
; Returns quotient in a1, remainder in a2
; Quotient is truncated (rounded towards zero).

|__rt_sdiv10|
|_kernel_sdiv10|
      [ NoARMM
|_kernel_sdiv10_NoARMM|
        MOVS    a4, a1
        RSBMI   a1, a1, #0
        SUB     a2, a1, #10
        SUB     a1, a1, a1, LSR #2
        ADD     a1, a1, a1, LSR #4
        ADD     a1, a1, a1, LSR #8
        ADD     a1, a1, a1, LSR #16
        MOV     a1, a1, LSR #3
        ADD     a3, a1, a1, LSL #2
        SUBS    a2, a2, a3, LSL #1
        ADDPL   a1, a1, #1
        ADDMI   a2, a2, #10
        MOVS    a4, a4
        RSBMI   a1, a1, #0
        RSBMI   a2, a2, #0
        Return  ,LinkNotStacked
      ]
      [ SupportARMM :LAND: (:LNOT: NoARMM :LOR: SHARED_C_LIBRARY)
|_kernel_sdiv10_SupportARMM|
; Using SMULL here would be tricky due to the need to round towards zero
        MOVS    a4, a1
        LDR     a2, =&CCCCCCCD ; (8^32) / 10
        RSBMI   a1, a1, #0
        UMULL   ip, a3, a2, a1
        MOV     a3, a3, LSR #3 ; Accurate division by 10
        SUB     a2, a1, a3, LSL #1
        MOV     a1, a3
        SUB     a2, a2, a3, LSL #3
        RSBMI   a1, a1, #0
        RSBMI   a2, a2, #0
        Return  ,LinkNotStacked
      ]

        RoutineVariant _kernel_udiv, ARMVE, UDIV_SDIV, MLS
        RoutineVariant _kernel_udiv10, ARMM, UMULL_UMLAL
        RoutineVariant _kernel_sdiv, ARMVE, UDIV_SDIV, MLS
        RoutineVariant _kernel_sdiv10, ARMM, UMULL_UMLAL
      [ {CONFIG}=26
        EXPORT  |_kernel_irqs_on$variant|
        EXPORT  |_kernel_irqs_off$variant|
|_kernel_irqs_on$variant| * |_kernel_irqs_on|
|_kernel_irqs_off$variant| * |_kernel_irqs_off|
      |
        RoutineVariant _kernel_irqs_on, ARMv6, SRS_RFE_CPS
        RoutineVariant _kernel_irqs_off, ARMv6, SRS_RFE_CPS
      ]

        EXPORT  __rt_div0
__rt_div0
dividebyzero
        ; Dump all registers, then enter the abort code.
        ; We need to discover whether we were doing a divide (in which case,
        ; r14 is a valid link), or a remainder (in which case, we must retrieve
        ; the link from the stack).
        LoadStaticBase ip, a3
        ADD     ip, ip, #O_registerDump
      [ {FALSE} ; this instruction is now deprecated
        STMIA   ip, {r0-r13}
      |
        STMIA   ip, {r0-r12}
        STR     r13, [ip, #13*4]
      ]
        RemovePSRFromReg r14, r1, r0            ; == BIC r0, r14, #PSRBits  IFF 26bit
        SUBS    r1, pc, r0
        ADRGE   r1, |_kernel_udiv|
        CMPGE   r0, r1
        LDRGE   r14, [sp], #4
        STR     r14, [ip, #r14*4]
        ADR     r0, E_DivideByZero
10
        SUB     r14, r14, #4
        STR     r14, [ip, #pc*4]

        BL      |_kernel_copyerror|

        SWI     EnterSVC
        LDR     r14, [ip, #pc * 4]
        LDMIB   ip, {r1-r14}^
        NOP
        STMDB   sp!, {r10, r11, r12}
        STR     r14, [sp, #-4]!
        SWI     GenerateError

        EXPORT  |_kernel_fault|
|_kernel_fault|
        ; r0 points to an error block;
        ; original r0 is on the stack.
        ; r14 is the place to pretend the fault happened
        STMFD   sp!, {r1, ip}
        LoadStaticBase ip, r1
        ADD     ip, ip, #O_registerDump
      [ {FALSE} ; this instruction is now deprecated
        STMIA   ip, {r0-r14}
      |
        STMIA   ip, {r0-r12}
        STR     r13, [ip, #13*4]
        STR     r14, [ip, #14*4]
      ]
        LDMFD   sp!, {r1, r2, r3}
        STR     r3, [ip]
        STR     r2, [ip, #ip*4]
        STR     r1, [ip, #r1*4]
        B       %B10

        ErrorBlock DivideByZero, "Divide by zero", C06

; --- International message lookup routines ----------------------------

        EXPORT  |_kernel_copyerror|
        EXPORT  |_kernel_getmessage|
        EXPORT  |_kernel_getmessage_def|
        EXPORT  |_kernel_getmessage2|

        [ SharedLibrary   ; Only works with module for the moment

        GET     Hdr:MsgTrans

n_module_claim      EQU  6
n_module_lookupname EQU 18

; Lookup an error message
;
; On entry:
;   R0 = Pointer to "international" error block.
;        +--------------------+
;        | Default error no.  | - Default error no and str are used if message file
;        +--------------------+   cannot be opened or an error occurs trying to read
;        | Default error str. |   the message file.
;        +--------------------+
;        | Pad. to word align |
;        +--------------------+
;        | Error no.          | - Real error numbers (may be same as default)
;        +--------------------+
;        | Error message tag  |   Message tag in message file
;        +--------------------+
; Return:
;   R0 = Pointer to selected error block (default or from message file)
;
|_kernel_copyerror|
        FunctionEntry "r1-r7,r12"
        BL      open_messagefile
        MOV     r2, #0
        ADR     r4, module_name
        MOV     r5, #0
        MOV     r6, #0
        MOV     r7, #0
        SWI     XMessageTrans_ErrorLookup
        Return  "r1-r7,r12"

; Try to get a message from the message file
;
; On entry:
;   R0 = Message to use if failed to get message from message file
;   R1 = Message tag
;
; Return:
;   R0 = Message
;
      [ :DEF:DEFAULT_TEXT
|_kernel_getmessage|
      ]
|_kernel_getmessage_def|
        FunctionEntry "r0-r7,r12"
        BL      open_messagefile
        MOV     r0, r1
        LDR     r1, [sp, #4]
        MOV     r2, #0
        MOV     r4, #0
        MOV     r5, #0
        MOV     r6, #0
        MOV     r7, #0
        SWI     XMessageTrans_Lookup
        STRVC   r2, [sp]
        Return  "r0-r7,r12"

      [ :LNOT::DEF:DEFAULT_TEXT
; On entry:
;   R0 = Message tag
;
; Return:
;   R0 = Message
;
|_kernel_getmessage|
        FunctionEntry "r1"
        MOV     r1, r0
        BL      |_kernel_getmessage_def|
        Return  "r1"
      ]

; On entry:
; [ DEFAULT_TEXT
;   R0 = Message to use if failed to get message from message file
;   R1 = Message tag
;   R2 = Destination buffer
;   R3 = Size of buffer
; |
;   R0 = Message tag
;   R1 = Destination buffer
;   R2 = Size of buffer
; ]
;
; Return:
;   R0 = Message
;
|_kernel_getmessage2|
        FunctionEntry "r0-r7"
        BL      open_messagefile
        MOV     r0, r1
      [ :DEF:DEFAULT_TEXT
        LDR     r1, [sp, #4]
      |
        MOV     r3, r2
        LDR     r2, [sp, #4]
        LDR     r1, [sp]
      ]
        MOV     r4, #0
        MOV     r5, #0
        MOV     r6, #0
        MOV     r7, #0
        SWI     XMessageTrans_Lookup
        STRVC   r2, [sp]
        Return  "r0-r7"


message_filename
        DCB     "SharedCLibrary:Messages", 0
        ALIGN

module_name
        DCB     "SharedCLibrary", 0
        ALIGN

; Try to open the message file.
;
open_messagefile
        FunctionEntry "r0,r2-r5"
        MOV     r0, #6
        MOV     r1, #0
        MOV     r2, #OSRSI6_CLibWord
        SWI     XOS_ReadSysInfo
        MOVVS   r2, #0
        MOVS    r5, r2
        LDREQ   r5, =Legacy_CLibWord
        LDR     r1, [r5]
        CMP     r1, #0
        Return  "r0,r2-r5",,NE
        MOV     r0, #Module_Claim
        MOV     r3, #Module_WorkSpace
        SWI     XOS_Module
        Return  "r0,r2-r5",,VS                  ; NB R1 = 0
        SavePSR r1
        SWI     XOS_EnterOS
        STR     r2, [r5]
        RestPSR r1
        MOV     r0, r2
        ADR     r1, message_filename
        MOV     r2, #0
        SWI     XMessageTrans_OpenFile
        MOVVC   r1, r0
        Return  "r0,r2-r5",,VC
        MOV     r0, #Module_Free
        LDR     r2, [r5]
        SWI     XOS_Module
        MOV     r1, #0
        Return  "r0,r2-r5"

        |

|_kernel_copyerror|
        Return  ,LinkNotStacked

|_kernel_getmessage|
|_kernel_getmessage_def|
|_kernel_getmessage2|
        Return  ,LinkNotStacked

        ]

|__counter|
        MOV     ip, lr
 [ {CONFIG}=26
        MOV     a4, pc
 |
        MRS     a4, CPSR
 ]
        MOV     a1, #6
        MOV     a2, #0
        MOV     a3, #OSRSI6_CLibCounter
        SWI     XOS_ReadSysInfo
        MOVVS   a3, #0
        CMP     a3, #0
        LDREQ   a3, =Legacy_CLibCounter
        SWI     EnterSVC
        MOV     a2, ip
        BL      |_kernel_irqs_off|      ; Disable IRQs round update.
        LDRB    a1, [a3]
        ADD     ip, a1, #1
        STRB    ip, [a3]
 [ {CONFIG}=26
        TEQP    pc, a4                  ; Restore mode and IRQs
 |
        MSR     CPSR_c, a4              ; Restore mode and IRQs
 ]
        Return  ,LinkNotStacked,,a2


        END
@


4.37
log
@Try and avoid blocking callbacks
Detail:
  The kernel has a 'callback postponement flag' which will be set whenever an X SWI, called from user mode, returns a pointer to an error (and the error block looks like it's in RAM).
  Although this flag will help prevent the error buffer from being overwritten by any errors generated by callbacks, it will also have the effect of blocking Alt-Break and CLib's Escape handler, due to them both being reliant on callbacks.
  Since the flag may persist for a long time, it can be dangerous to leave the OS in this state (the flag can only be cleared by a SWI call from user mode - which may never happen if the program is stuck in a bad state).
  So to combat this, CLib will now make some effort to try and avoid leaving the postponement flag in situations where it shouldn't be needed.
  File changes:
  - c/armsys:
    - Change _sys_flen to return 0 for TTY streams, since calling OS_Args for them isn't going to generate any useful result (previously it was generating an error, causing the postponement flag to be left set on entry to main())
    - Be extra vigilant when entering main() to make sure the callback postponement flag isn't set, just in case other checks don't resolve it
  - kernel/s/k_body:
    - Change CopyError to attempt to clear the callback postponement flag if we suspect it's set. We've just copied the error to our own buffer, so it should be our job to worry about preventing that buffer being prematurely overwritten, not the kernel's.
Admin:
  Tested on BB-xM
  'while (1) {}' (and similar variants) now multitasks in task windows and is no longer unkillable
  Fixes issue reported on forums:
  https://www.riscosopen.org/forum/forums/4/topics/11542#posts-79767


Version 5.96. Tagged as 'RISC_OSLib-5_96'
@
text
@d2532 1
a2532 1
        MSR     CPSR_c, a3
@


4.36
log
@Make abort handling more robust
Detail:
  kernel/s/k_body - Update AbortFindHandler to check that SP & SL are both word aligned, especially because the code will attempt to load from SL to check for the stack chunk magic marker.
Admin:
  Tested on BB-xM
  Avoids some "abort while in abort handler" type scenarios if an abort occurs while SP/SL are invalid


Version 5.95. Tagged as 'RISC_OSLib-5_95'
@
text
@d2515 18
d2534 1
@


4.35
log
@Eliminate some global OS_SynchroniseCodeAreas calls
Detail:
  kernel/s/k_body - Eliminate a couple of global OS_SynchroniseCodeAreas calls in _kernel_init and _kernel_system
  s/initmodule - Eliminate a global OS_SynchroniseCodeAreas call in _Shared_Lib_Module_SWI_Code
Admin:
  Tested on iMx6
  Improves performance with SMP ROMs, where global D-cache clean isn't really possible


Version 5.93. Tagged as 'RISC_OSLib-5_93'
@
text
@d1075 5
@


4.34
log
@Remove ARM2 NOPs
Detail:
  kernel/s/k_body, s/initmodule - Remove NOPs from after PSR manipulation macros; the macros now fully take care of ARM2 & StrongARM compatibility for us
Admin:
  Tested PlingSystem build on (ARM3) RISC OS 3.1
  Requires HdrSrc-2_63 for ARM2 compatibility


Version 5.92. Tagged as 'RISC_OSLib-5_92'
@
text
@d505 7
a511 3
   ;r0,lr are free to use here
   MOV   r0, #0
   SWI   XOS_SynchroniseCodeAreas
d2332 3
d2357 1
a2357 1
    MOVNE r0, #0
d2433 5
a2437 1
01      SUB     sp, sp, v5              ; and relocate sp...
d2462 1
a2462 1
    MOVNE r0, #0
d2476 5
a2480 2
    MOV    r0, #0
    SWI    XOS_SynchroniseCodeAreas
@


4.33
log
@When multiple CPU architectures are supported, allow dynamically linked clients to be given optimal versions of routines where possible
Detail:
  This set of changes adds support for representing architecture-specific variants of routines within the export tables which the shared C library uses to fill in the client's stubs.
  This allows builds of the module which target multiple architectures (e.g. IOMD, Raspberry Pi, or softloads) to offer the most optimal versions of routines to clients wherever multiple variants exist.
  If only one architecture is supported, only one version of each routine will be built, and no variant tables will be generated.
  Currently routine selection for staticly linked clients isn't supported - staticly linked targets will only use the most backwards-compatible version of the routines, as before. Also not all routines are catered for yet (e.g. _ll_udiv)
  File changes:
  - s/h_common - New file containing macros used during variant table construction
  - Makefile - Set SHARED_C_LIBRARY to {TRUE} for SCL builds of assembler code, as per the SHARED_C_LIBRARY #define
  - kernel/s/k_body, s/longlong - For routines which have multiple variants available for the target architectures, build all variants, and generate variant table entries using the new RoutineVariant macro. This has required some reordering of the different variants to make sure that when both versions are built, the most backwards-compatible one will be first (and thus will be called by staticly linked clients)
  - s/h_modmacro - "Entry" macro (when building SCL export tables) changed to use DCD instead of B, to allow byte-aligned symbols to be represented (low bits of symbol address is now used as 'is a variant table' flag)
  - s/initmodule - Client stub initialisation rewritten to take into account the B -> DCD change, and to detect and evaluate variant entries
  - clib/s/cl_entries, kernel/s/k_entries, kernel/s/k_entries2 - Update library entry tables to reference the variant forms of routines where relevant
Admin:
  Tested on Raspberry Pi 1, 2, 3 (ROM), RISC OS 3.1 & StrongARM 3.7 (softload 26bit build)
  Requires Kernel-5_35-4_79_2_325


Version 5.91. Tagged as 'RISC_OSLib-5_91'
@
text
@a401 1
        NOP
a417 2
 |
        NOP
a1161 1
        NOP
a1459 1
        NOP
@


4.32
log
@Prefer CPS over MSR for PSR manipulation. Use UDIV/SDIV for general-purpose division, and UMULL for /10.
Detail:
  s/k_body:
  - _kernel_irqs_off and _kernel_irqs_on now use CPS for disabling/enabling IRQs as opposed to MSR. Apart from being shorter code sequences, it's generally a faster instruction.
  - __rt_udiv and __rt_sdiv (and aliases) now use the UDIV and SDIV instructions if building for ARMv7VE
  - __rt_udiv10 and __rt_sdiv10 (and aliases) now use UMULL to multiply by 1/10 when building for targets with long multiply support, as this is faster than the old method. UDIV/SDIV can be fast too, but only for small numbers, making UMULL the best for the general case.
Admin:
  Tested on Cortex-A15
  Prototyping of division routines on assorted CPUs shows that UDIV/SDIV is generally between 20% and 400% faster than the old routine (Cortex-A7, Cortex-A53), or up to 1300% faster on Cortex-A15 (the CPU does not like the old routine!)
  Division by 10 is now about 20% faster across all appropriate CPUs


Version 5.89. Tagged as 'RISC_OSLib-5_89'
@
text
@d26 1
d275 1
d279 4
a282 1
   |
d284 1
a285 1
        Return  ,LinkNotStacked
d293 1
d297 4
a300 1
   |
d302 1
a303 1
        Return  ,LinkNotStacked
d3153 1
d3201 4
a3204 1
      |
d3211 1
a3212 2
        Return  ,LinkNotStacked

d3232 1
d3243 4
a3246 1
      |
d3255 1
a3256 1
        Return  ,LinkNotStacked
d3267 1
d3323 4
a3326 1
      |
d3332 1
a3333 1
        Return  ,LinkNotStacked
d3351 1
d3367 4
a3370 1
      |
d3382 15
a3397 1
        Return  ,LinkNotStacked
@


4.31
log
@  Better fix
Detail:
  AcquireMutex doesn't have the same functionality as Arm2Swp, best not to
  make people think they might do. Also add an extra literal pool because
  otherwise some instructions don't reach when doing APCS-32 softload builds.

Retagged as 'RISC_OSLib-5_88'
@
text
@d273 1
d277 3
d284 1
a284 1
      [ {CONFIG}=26
d286 2
a287 1
      |
d291 3
d295 1
a295 1
      ]
d3143 1
a3143 1

d3191 8
d3219 1
d3230 10
d3250 1
d3306 7
d3330 1
d3346 13
@


4.30
log
@Build fix
26 bit CLib (in PlingSystem) was missing AcquireMutex label.
Retagged as RISC_OSLib-5_88.
@
text
@d106 1
d108 1
d3070 1
a3073 1
AcquireMutex
@


4.29
log
@  Support for ARMv8
Detail:
  The SWP and SWPB instructions have finally been removed in ARMv8, after
  having been deprecated for a very long time. This version adds alternative
  versions of code that used to use them with ones that use LDREX/STREX and
  LDREXB/STREXB instead. Soft-loadable C libraries will choose between
  implementations at runtime using OS_PlatformFeatures; ROM builds only
  include the appropriate version for the target hardware.
Admin:
  Tested on Raspberry Pi 3.

Version 5.88. Tagged as 'RISC_OSLib-5_88'
@
text
@d3071 1
d3120 1
a3120 1
        SWI     &20033 ; XOS_UpCall
@


4.28
log
@Escape some dollars
Detail:
  kernel/s/k_body, s/initmodule - Escape some dollars contained in strings to avoid warnings from objasm
Admin:
  Resulting binary unchanged


Version 5.83. Retagged as 'RISC_OSLib-5_83'
@
text
@d26 1
d106 1
d416 15
a430 2
        MOV     r0, #1
        STR     r0, [v6, #O__swp_available]
d1633 4
d1640 11
d1652 1
d2967 14
d2982 1
d3078 35
@


4.27
log
@Fix 32bitification error
Detail:
  kernel/s/k_body - At CopyUpDone in _kernel_system(), a big block of conditional code was converted to unconditional as part of the 32bit conversion process. However one line for setting up the error handler remained conditional, potentially preventing the correct error buffer pointer being set when about to start the child task.
Admin:
  Tested on BB-xM


Version 5.79. Tagged as 'RISC_OSLib-5_79'
@
text
@d576 1
a576 1
        DCB     "Sys$RCLimit", 0
@


4.26
log
@Improve sanity checks in default_unwind_handler
Detail:
  kernel/s/k_body - Now ignores unaligned PC values, as they either indicate stack corruption or Thumb use (which the unwind handler doesn't support anyway)
Admin:
  Tested on Raspberry Pi with high processor vectors


Version 5.70. Tagged as 'RISC_OSLib-5_70'
@
text
@d2332 1
a2332 1
        ADDEQ   r3, v6, #O_errorBuffer
@


4.25
log
@Protect against StrongARM MSR bug & ARM2 "banked register after mode change" bug
Detail:
  kernel/s/k_body - NOP in Aborted2 is only needed if we're targeting StrongARM
  s/longlong - Make ReadCPUArch StrongARM & ARM2 safe
Admin:
  Tested in IOMD ROM softload


Version 5.67. Tagged as 'RISC_OSLib-5_67'
@
text
@d1907 1
a1907 1
        ; (bottom bit used to mark stack extension).
d1915 3
d1925 1
@


4.24
log
@Review use of StrongARM switch.
Was being used to conditionalise things which aren't really StrongARM related, now should be read as "support split I+D caches" switch.

Version 5.65. Tagged as 'RISC_OSLib-5_65'
@
text
@d165 2
d862 1
d864 1
@


4.23
log
@  File handling improvements
Detail:
  * Added 64-bit file pointer API support, following the LFS spec v1.5
    (see Docs directory). Internally, now uses 64-bit file pointers
    exclusively. For now, the backend still limits you to 4GB-1 files, but
    clients of the C library won't need recompiling again to support larger
    files than this once they use the new API.
  * Fixed a large number of warnings produced in compilation, assembly and
    linking, many of them new and resulting from the improved checks in the
    latest toolchain.
  * Increased the maximum stream buffer size from 16MB to 1GB.
  * Added Hdr:SDFS and Hdr:SDIO to the list of headers used to build swis.h
    if they are present.
Admin:
  Verified that the new 64-bit file pointer buffering code works using a
  ROM build (since the toolchain makes extensive use of reading, writing
  and seeking internally).

Version 5.64. Tagged as 'RISC_OSLib-5_64'
@
text
@d1910 1
a1910 1
        [ StrongARM
d1915 1
a1915 1
        TST     a1, #8
a1917 1
        ]
d2725 1
a2725 1
        [ StrongARM
d2730 1
a2730 1
        TST     a1,#8
d2734 1
a2734 3
        |
        ADR     v6, StkOvfPseudoEntry+12
        ]
d2808 1
a2809 1
        [ StrongARM
d2813 1
a2813 1
        TST     a1,#8
d2816 1
a2816 3
        |
        ADR     v2, StkOvfPseudoEntry+12
        ]
@


4.22
log
@Update to work with zero page relocation
Detail:
  clib/s/cl_stub, kernel/s/k_body, s/initmodule - Use OS_ReadSysInfo 6 to look up CLibWord/RISCOSLibWord/CLibCounter location each time it's needed instead of using hardcoded addresses. SWI overhead shouldn't be too bad since the zero page areas are rarely used.
  rlib/c/menu - Fix null pointer access when attempting to clear a submenu pointer via menu_submenu(...,...,NULL)
  s/h_workspc - Remove old local definitions of CLibCounter, RISCOSLibWorkSpace and CLibWorkSpace. Use Hdr:PublicWS instead.
Admin:
  Tested on rev A2 BB-xM


Version 5.60. Tagged as 'RISC_OSLib-5_60'
@
text
@d201 1
a201 1
        LDMFD   sp!, {pc}
d588 1
a588 1
        STMFD   sp!, {sl}
d600 1
a600 1
        LDMFD   sp!, {a1}
d607 1
d609 5
d657 1
a657 1
        STMDB   sp!, {r0}
d659 1
a659 1
        LDMIA   sp!, {r0}
d685 1
a685 1
        STMFD   sp!, {a1}
d687 1
a687 1
        LDMFD   sp!, {a1}
d691 1
a691 1
        STMFD   sp!, {lr}
d750 1
a750 1
        LDMFD   sp!, {lr}
d1335 1
a1335 1
        LDMFD   sp!, {pc}
d1423 1
a1423 1
        STMFD   sp!, {r0-r3, v1-v6, fp, sl, lr}
d1434 1
a1434 1
        LDMFD   sp!, {r0-r3, v1-v6, fp, sl, pc}
d1440 1
a1440 1
        STMFD   sp!, {r0}
d1462 1
a1462 1
        LDMFD   sp!, {r1}
d1464 1
a1464 1
        STMEQIA r8!, {r1}
d1520 1
a1520 1
        LDMIA   r8!, {r1}
d1627 1
d1629 4
d1668 1
a1668 1
        STMFD   r13!, {r0}
d1671 1
a1671 1
        LDMFD   r13!, {r0}
d1677 1
a1677 1
        STMFD   r13!, {r0}
d1686 1
a1686 1
        LDMFD   r13!, {r0}
d2249 1
d2251 4
d2269 1
a2269 1
        STMFD   sp!, {r1}               ; remember slot size
d2274 1
a2274 1
        STMIA   r5, {fp, ip, sl}        ; save ptr to moved stack
d2358 6
a2363 1
        LDMIA   r5, {fp, sp, sl}
d2416 1
a2416 1
        LDMFD   sp!, {r0}               ; old memoryLimit
d2437 2
a2438 2
        LDMIA   a4!, {a3}
        STMIA   a2!, {a3}
d2665 1
d2667 5
d2941 1
d2943 4
d2965 1
d2967 4
d3008 1
d3010 5
d3234 1
d3236 4
d3244 1
a3244 1
        LDMGEFD sp!, {r14}
d3258 1
a3258 1
        STMDB   sp!, {r14}
d3269 1
d3271 5
@


4.21
log
@Improve safety & reliability of callback handling in SharedCLibrary
Detail:
  CallBackHandler in kernel.s.k_body now ensures that the stored 'sp' and 'sl' values are word-aligned before attempting to read from 'sl' to verify that it points to a stack chunk. This avoids an exception being triggered in certain situations when alignment exceptions are turned on and a piece of hand-written assembler is using the sl register to store data.
Admin:
  Further checks should be added to check that 'fp' is valid before calling _kernel_unwind, as _kernel_unwind currently only performs minimal checks that are not always sufficient.
  Tested on rev C2 beagleboard with KinoAmp pre-release.


Version 5.56. Tagged as 'RISC_OSLib-5_56'
@
text
@d571 1
a571 1
        DCD     15, 16, -1
d3360 8
a3367 2
        MOV     r5, #0
        LDR     r1, [r5, #CLibWorkSpace]
d3376 1
a3376 1
        STR     r2, [r5, #CLibWorkSpace]
d3385 1
a3385 1
        LDR     r2, [r5, #CLibWorkSpace]
d3403 1
a3403 1
        MOV     a3, lr
d3405 1
a3405 1
        MOV     a2, pc
d3407 1
a3407 1
        MRS     a2, CPSR
d3409 7
d3417 1
a3417 1
        LDR     a4, =CLibCounter
d3419 1
a3419 1
        LDRB    a1, [a4]
d3421 1
a3421 1
        STRB    ip, [a4]
d3423 1
a3423 1
        TEQP    pc, a2                  ; Restore mode and IRQs
d3425 1
a3425 1
        MSR     CPSR_c, a2              ; Restore mode and IRQs
d3427 1
a3427 1
        Return  ,LinkNotStacked,,a3
@


4.20
log
@Normalise C and assembler include paths
Detail:
 This changes all the C and assembler includes to be a canoncial Unix format.
 Also match include paths to previous commit for EditIntern/DrawIntern/VerIntern
 Finally, also include some minor type fixes (NULL vs 0)
Admin:
 May be some other paths elsewhere in the source I'm not immediately able to fix.  Will address any issues ASAP, since this is a huge change.

Version 5.54. Not tagged
@
text
@d1711 4
a1714 2
        LDR     r4, [r10, #SC_mark-SC_SLOffset]
        CMP     r4, r3          ; sl points at stack chunk
d1869 1
a1869 1
 [ {CONFIG}=26
@


4.19
log
@  Bugfix and system mode support.
Detail:
  * Fixed signed pointer comparison: most top-bit-set pointers passed to
    _kernel_raise_error() were being translated into "Exit called"
  * Stack extension is now permitted in SYS mode; includes support in longjmp()
Admin:
  Verified that stack extension works.

Version 5.51. Tagged as 'RISC_OSLib-5_51'
@
text
@d24 2
a25 2
        GET     s.h_stack
        GET     s.h_workspc
@


4.18
log
@  Changes for Customer W; also suitable for building on an Iyonix.
Detail:
  * No longer uses aasm to build h.swis.
  * (Only) compatible with new C compilers: assumes const static data is
    placed in separate read-only areas, and suitable command-line switch
    is used to ensure that library static data is never placed in a zero-
    init area.
  * Stack extension code now thread-safe.
  * Heap thread-safety code (in clib) now uses SWP instruction test results
    from stack extension code (in kernel) - as a side effect, the exported
    symbol _swp_available now exists, if you need to use it elsewhere.
  * Slightly closer to having top-bit-set heap addresses working.
Admin:
  Tested in a Tungsten build, and with Customer W's test suite.

Version 5.48. Tagged as 'RISC_OSLib-5_48'
@
text
@d602 2
a603 2
        ADRLT   a1, E_Exit
        BLLT    |_kernel_copyerror|     ; BL<cond> 32-bit OK
d2864 2
a2865 1
        TST     v2, #PSR32Privileged
@


4.17
log
@  Ansilib improvements, and a bugfix to system()
Detail:
  * _kernel_irqs_disabled() is included in ansilib build, now needed for
    ARM 2 SWP replacement in c.alloc
  * _kernel_entrypoint() for ansilib now initialises relocation offsets in
    root stack chunk, necessary if linking with -zm object code
  * system() implementation now calls DDEUtils_FlushCL if starting a
    short command line - necessary in case previous system() call was a
    long command line directed at a DDE-unaware application
Admin:
  Ansilib changes tested, DDE change not expected to cause problems.

Version 5.47. Not tagged
@
text
@d411 8
d523 35
d2670 2
a2671 2
; plus fp, sp, lr, entry pc, = 14 regs in total) plus a minimal stack
; frame for return from StkOvfExit (a further 4 words, giving 18 in total)
d2895 13
d2922 2
a2923 2
        LDR     v2, [v2, #O_freeProc]
        STMFD   sp!, {a1, v2}           ; chunk size in bytes, dealloc proc
d2926 1
d2931 2
d2974 18
@


4.16
log
@* __assert2() added to support for C99 assert(), which displays
  function name.
* _Exit() added.
* Lots of new <math.h> functions (acosh, asinh, atanh, exp2, expm1,
  ilogb, log1p, log2, logb, scalbn, scalbln, cbrt, erf, erfc,
  lgamma, tgamma, nexttoward, fmaf). Float and long double forms
  of every function added; long double forms are included as another
  library object in the stubs rather than the shared library, as they
  just branch to the double form.
* Subnormal/NaN/infinity cases in various <math.h> functions improved.
* Added <tgmath.h>.
* Headers brought into line with CC 5.54.
* RMEnsures added to C library initialisation to try to load minimum
  CallASWI, FPEmulator, CLib. No errors reported if load fails.
* A few pointless inter-file dependencies removed to reduce minimum
  size of included ANSILib.

Version 5.46. Tagged as 'RISC_OSLib-5_46'
@
text
@d82 1
a83 1
 ]
d202 1
a202 1

d213 1
@


4.15
log
@ROM build fixed for 64-bit stuff.
PCI added to swis.h
alloc.c updated to handle bigger slots (new code merged from ARM libraries)
Various 32-bit fixes for backtracing, and general trap handling.
Polite "Application is not 32-bit compatible" message.
Headers <stdint.h> and <inttypes.h> fixed to work in non-C99 mode.
txt changed to do new-style Delete behaviour

Version 5.44. Tagged as 'RISC_OSLib-5_44'
@
text
@d3153 1
d3201 1
d3203 2
a3207 1
      [ :DEF:DEFAULT_TEXT
a3208 3
      |
        LDR     r1, [sp]
      ]
d3218 14
d3309 1
@


4.14
log
@* Added two new library chunks, 4 and 5, which contain extensions to the kernel
  and C library respectively. These have no static data associated with them,
  just being extensions of the stub tables. The reason for this is to minimise
  wasted space in programs that don't use the C99 facilities; o.stubs is now
  a library split into 3 pieces - basic kernel and CLib, extra kernel and extra
  CLib; only the bits a program needs get included.

* Previous extensions to the C library stubs revoked - they now stop at _swix;
  all the new C99 functions now live in chunk 4. Anyone using those new
  functions should relink with new stubs and ensure this C library version.

* printf/scanf now support 64-bit types through "ll" and "j" length modifiers.

* Run-time support for VLAs (__rt_allocauto and __rt_freeauto) added. No
  attempt is currently made to clear up on longjmp or to cope with someone
  changing the kernel allocator while a VLA is active. These would be a
  future enhancement.

* Added complete 64-bit run-time support (48 functions) to kernel library;
  these functions are compatible with the ones used by the ARM ADS. Many of
  the simpler functions will not normally be used by the compiler, as it
  will generate inline code. There is scope for improvement by switching
  in MULL and CLZ-using forms of multiply and divide when possible.

* llabs and lldiv added to C library.

* Header files corrected in a few areas, and changed to match the C compiler.
  <stdint.h> and <stdbool.h> now require the compiler to be in C99 mode
  (as detected using __STDC_VERSION__).


Version 5.41. Tagged as 'RISC_OSLib-5_41'
@
text
@d111 1
d118 1
d789 2
d796 5
d803 11
a813 5
        LDR     r1, [sp, #20]           ; original r12
        ADD     r2, r2, #8              ; original r14
        SWI     XFPEmulator_Abort
        BVS     NoFPEAbortSWI
        TEQ     r0, #0
d816 2
d897 1
a897 1
        LDR     r2, [r1, #-72]          ; get the SPSR
d926 8
a933 8
        MOV     r3, pc
        AND     r3, r3, #PSRBits
        MRS     r3, CPSR
        TST     r3, #2_11100
        LDREQ   r0, [sp, #24]
        ANDEQ   r0, r0, #PSRMode        ; obtain aborter's mode from R14
        MRSNE   r0, SPSR                ; obtain aborter's mode from SPSR
        STRNE   r0, [r14, #16*4]        ; store aborter's SPSR if in 32-bit mode
d939 1
d941 9
a949 9
        MSREQ   CPSR_c, #PSR32SVCMode
        TEQNEP  pc, #PSRSVCMode
        NOP
        SUB     r12, r0, sp
        CMP     r12, #3 * 4
        BLT     NotPrivileged
        LDMDB   r0, {r0-r2}             ; Pull R10-R12 off of top of SVC stack
        ADD     r4, r14, #10 * 4        ; if there were at least 3 words on it
        STMIA   r4, {r0-r2}
d987 4
a990 4
        CMPGT   r2, r12
        ADDGT   r1, r12, #256
        CMPGT   r1, r10
        BLE     Trap_NoStackForHandler
d1662 5
a1666 5
        CMPGT   r2, r12         ; sp within heap and ...
        CMPGT   r10, r1
        CMPGT   r2, r10         ; sl within heap and ...
        CMPGT   r12, r10        ; sp > sl and ...
        BLE     Event_BadStack
a1750 1
IsClientHandler  EQU &80000000
d1756 1
a1756 1
        BGE     FH_NoHandlerFound
d1759 3
a1761 3
        CMPGE   r3, r1
        ADDLT   v4, v4, r0
        BLT     %B01
a1767 5
        ; If the handler is within the shared library, we must mark it.
        CMP     r2, #0
        LDRNE   r0, =|RTSK$$Data$$Limit|
        CMPNE   v5, r0
        ORRNE   r2, r2, #IsClientHandler
d1788 1
a1788 1
        BIC     a1, r2, #IsClientHandler
d1803 3
a1805 5
        TST     r2, #IsClientHandler
        LDMEQFD sp!, {v2, v4-v6, r14}
        MOVEQ   pc, r2

        CallClient r2
d1807 4
d1823 1
a1823 5

        TST     r2, #IsClientHandler
        LDMEQFD sp!, {a1, a2, v2, v4-v6, r14}
        MOVEQ   pc, r2

d1825 2
a1826 1
        CallClient r2
d1828 4
a1960 1
        BIC     r2, r2, #IsClientHandler
d2226 3
a2228 3
        ADDGT   v4, v3, #16             ; yes => in shared lib so fake v4
        MOVGT   v2, #0                  ; and don't jump to non-copied code
        MOVLE   v2, r14                 ; else jump to copied code
d2232 1
a2232 1
        BGT     %B01                    ; no, so keep going...
d2244 1
a2244 1
        BGT     %B01                    ; yes, so continue
d2321 3
a2323 3
        SUBGT   v3, v4, #16             ; yes => in shared lib so fake v3
        MOVGT   v1, #0                  ; and don't jump to not copied code...
        MOVLE   v1, v5                  ; else jump...
d2327 1
a2327 1
        BLT     %B01                    ; no, so continue...
d2341 1
a2341 1
        BLT     %B01                    ; no, so continue...
d3273 2
d3276 1
@


4.13
log
@Abort and error handling massively overhauled:
  Aborts now give standard error messages (Abort on Data Transfer at... etc)
  *ShowRegs now filled in after aborts
  assert(), abort(), "free failed" and standard signal handlers now use Wimp
    error boxes if in the desktop
  Postmortem button on error boxes to view the postmortem

Also, x$multiply, x$divide, __rt_sdiv, x$remainder, x$udivide, __rt_udiv and
x$uremainder optimised.

Version 5.35. Tagged as 'RISC_OSLib-5_35'
@
text
@d58 2
d2571 23
d3087 2
@


4.12
log
@  Improved abort handling
Detail:
  * One check for 26-bit mode wan't being made, leading to the runtime reporting
    'Uncaught trap:' when a trap should have been catching the abort.  This
    prevented signal handlers from trapping some aborts.
  * When an abort was occuring in SVC mode, the stack wasn't being flattened,
    resulting in all sorts of nasty things when you tried to carry on from a
    signal handler (probably the main reason why you ever see 'No stack for trap
    handler'). SVC and undefined stacks are now flattened.  Further work should
    be done to restore the state of the OS after an abort, but this probably
    requires a new OS call to tidy itself up adequately.
Admin:
  Built 26-bit versions of the library with new 32-bit compatible entry points and checked abort handling with both sharedclibrary and ansilib.

Version 5.22. Tagged as 'RISC_OSLib-5_22'
@
text
@d50 1
d92 2
d97 5
d730 1
a730 1
        STMFD   r13!, {r0, r12}
d739 4
a742 1
        ADR     r0, E_IllegalInstruction
d745 1
d747 1
a747 1
        STMFD   r13!, {r0, r12}
d751 4
a754 1
        ADR     r0, E_PrefetchAbort
d758 1
a758 1
        STMFD   r13!, {r0, r12}
d762 4
a765 1
        ADR     r0, E_DataAbort
d769 1
a769 1
        STMFD   r13!, {r0, r12}
d773 4
a776 1
        ADR     r0, E_AddressException
d783 2
a784 1
        STMFD   sp!, {r0-r2, r14}
d786 1
a786 1
        BIC     r14, r14, #PSRBits
d788 2
a789 4
        MOV     r0, #0
        MRS     r0, CPSR
        TST     r0, #2_11100
        BICEQ   r14, r14, #PSRBits
d793 1
a793 1
        ADD     r2, r14, #8             ; original r14
d797 1
a797 1
        LDMEQFD sp!, {r0-r2, r14}
a798 2
        STR     r0, [sp, #20]           ; update r12 in stack
        LDMFD   sp!, {r0-r2, r14}
d804 1
a804 1
        LDR     r1, [sp, #12]
d807 4
a810 6
        MOV     r2, #0
        MRS     r2, CPSR
        TST     r2, #2_11100
        LDREQ   r1, [sp, #12]
        ANDEQ   r1, r1, #3              ; obtain aborter's mode from R14
        MRSNE   r1, SPSR                ; obtain aborter's mode from SPSR
d813 1
a813 1
        LDMEQFD sp!, {r0-r2, r14}
d820 1
a820 2
        LDMFD   sp!, {r0-r2, r14}
        STMFD   sp!, {r0 - r6, r14}
d830 1
a830 1
        LDMVSFD sp!, {r0 - r6, r14}
d837 1
a837 1
        LDMFD   sp!, {r0 - r6, r14}
d841 1
a841 1
; We assume FPEmulator 4.00 or later - r12 in the register dump
a846 2
        LDR     r1, [r13, #4]           ; r1 -> FPE stack frame
        ADD     r13, r13, #8            ; pop the saved values of r0 and r12
d848 9
a856 5
        LDMIA   r1!, {r2-r9}            ; copy R0-R15
        STMIA   r14!, {r2-r9}
        LDMIA   r1!, {r2-r9}
        SUB     r9, r9, #4
        STMIA   r14!, {r2-r9}
d858 2
a859 4
        MOV     r2, #0
        MRS     r2, CPSR
        TST     r2, #2_11100
        BNE     FPEFault_32on32
d866 1
a866 2
        MOV     sp, r1                  ; pull the SVC stack up
        B       AbortFindHandler
d869 1
a869 1
        LDR     r2, [r1, #-72]          ; get the SPSR
d871 5
a875 4
        BIC     r9, r9, #PSRBits
        ORR     r9, r9, r2
        STR     r9, [r14, #-4]          ; merge it with pc in register dump
        B       FPEFault_32
d880 1
d882 2
a883 8
FPEFault_32
        MRS     r2, CPSR
        BIC     r3, r2, #PSR32Mode
        ORR     r3, r3, #PSR32IBit + PSR32UNDMode
        MSR     CPSR_c, r3
        MOV     sp, r1                  ; pull the UND stack up
        MSR     CPSR_c, r2
        B       AbortFindHandler
a892 7
; entry here in SVC26, SVC32, ABT32 or UND32 mode
; r0 a pointer to an error block describing the abort.
; all user registers except r0, r12 are as at the time of the abort.
; r0 & r12 are on the stack.
; First, save all user registers in registerDump.
        STMFD   r13!, {r14}         ; remember the abort pc
        BL      |_kernel_copyerror|
a893 1

d895 4
a898 4
	STMIB	r14!, {r1-r12}
	STMIB	r14, {r13,r14}^
	NOP
	SUB	r14, r14, #12*4
d900 2
a901 1
        STMIB   r14, {r1-r14}^
d904 2
a905 1
        LDMFD   r13!, {r1, r2, r3}      ; abort PC, R0, R12
d907 29
a935 33
        MOV     r6, r14                 ; switch it to a non-banked register
        MOV     r4, #0
        MRS     r4, CPSR
        TST     r4, #2_11100
        ANDEQ   r5, r1, #3              ; obtain aborter's mode from R14
        MRSNE   r5, SPSR                ; obtain aborter's mode from SPSR
        STRNE   r5, [r14, #16*4]        ; store aborter's SPSR if in 32-bit mode
        BICNE   r4, r4, #PSR32Mode
        ORRNE   r4, r4, #PSR32SVCMode
        MSRNE   CPSR_c, r4              ; switch to SVC32 (already in SVC26 if 26bit)
        TST     r5, #PSR32Privileged
        LDRNE   r1, [r6, #lr*4]         ; if aborted in a privileged mode, save
        STR     r1, [r6, #pc*4]         ; PC as user R14
        STR     r2, [r6, #r0*4]
        STREQ   r3, [r6, #r12*4]
        BEQ     AbortFlattenStacks
        LDR     r4, [r12, #O_svcStack]
        SUB     r1, r4, sp
        CMP     r1, #3 * 4
        BCC     AbortFlattenStacks
        LDMEA   r4, {r1, r2, r3}
        ADD     r4, r6, #10 * 4
        STMIA   r4, {r1, r2, r3}

; should really fall through to error handler and let the OS clean up,
; but this is a lot better than it was!
AbortFlattenStacks
        MRS     r4, CPSR                ; MRS and MSR here will be NOPs on
        ORR     r1, r4, #PSR32UNDMode   ; ARM2/3, so we'll end up setting
        MSR     CPSR_c, r1              ; R13_svc twice; just make sure
        LDR     sp, [r12, #O_undStack]  ; we set the real value last.
        MSR     CPSR_c, r4
        LDR     sp, [r12, #O_svcStack]
a1495 1
        ADD     r14, r0, #O_registerDump
d1497 5
d1503 5
a1507 4
	STMIA	r14!, {r0-r12}
	STMIA	r14, {r13,r14}^
	NOP
	SUB	r14, r14, #13*4
d1509 1
a1509 1
        STMIA   r14, {r0-r14}^
d1514 2
d1592 6
a1597 1
        MOVEQ   pc, r14         ; ignore flag going away
d1599 1
d1605 1
d1669 3
d1674 1
a1674 1
        MOV     r0, #&7e
d1687 1
a1687 1

d2136 7
d2880 1
d2882 1
d2942 1
d2966 1
d2968 1
d3033 1
@


4.11
log
@WimpSlot extension code failed on a 32-bit system.
Second attempt at getting 32-bit overlay manager to work.

Version 5.21. Tagged as 'RISC_OSLib-5_21'
@
text
@d918 1
a918 1
        BEQ     AbortFindHandler
d922 1
a922 1
        BCC     AbortFindHandler
d927 10
d1186 4
@


4.10
log
@  Fixed _kernel_setenv.
Detail:
  _kernel_setenv(varname, NULL) should delete the variables.  It now does.
Admin:
  Tested in module.

Version 5.18. Tagged as 'RISC_OSLib-5_18'
@
text
@d1284 1
a1284 1
        MOV     r5, r1
d1288 2
a1289 3
        CMP     r1, r5
        MOVNE   r0, #Env_MemoryLimit
        SWINE   ChangeEnv
d1292 1
a1292 6
        SWI     XWimp_SlotSize
        MOVNE   r4, r0
        MOVNE   r0, #Env_MemoryLimit
        MOVNE   r1, r5
        SWINE   ChangeEnv
        MOVNE   r0, r4
d1295 12
@


4.9
log
@* Trailing garbage no longer appears after some perror() calls.
* Correction to static base location in modulewrap - was affecting some
  DSL 4000 video software.

Version 5.15. Tagged as 'RISC_OSLib-5_15'
@
text
@d2338 5
a2342 4
        MOV     a3, #0
01      LDRB    ip, [a2, a3]
        CMP     ip, #0
        ADDNE   a3, a3, #1
@


4.8
log
@C library would fail on new Kernels due to an incorrect call to
OS_ReadSysInfo 6.

Version 5.08. Tagged as 'RISC_OSLib-5_08'
@
text
@d3061 1
d3126 35
d3200 1
@


4.7
log
@tmpnam() would cause system crashes in version 5.06

Version 5.07. Tagged as 'RISC_OSLib-5_07'
@
text
@d515 1
a515 1
        DCD     15, 16
@


4.6
log
@32-bit work merged from kbracey_32bit branch.

Version 5.06. Tagged as 'RISC_OSLib-5_06'
@
text
@d248 2
d284 1
a284 1
        TST     r14, #PSRSVCMode
d3169 6
a3174 1
        FunctionEntry "r0"
d3176 1
a3176 1
        LDR     r0, =CLibCounter
d3178 9
a3186 8
        LDRB    lr, [r0]
        STR     lr, [sp]
        ADD     lr, lr, #1
        STRB    lr, [r0]
        BL      |_kernel_irqs_on|
        WritePSRc PSRUSRMode, r0
        NOP
        Return  "r0"
@


4.5
log
@Ursula branch merged.
StrongARMfudge flag removed.
StrongARM compatibility set according to AMBKernel flag in Hdr:RISCOS
strftime %U and %W specifiers fixed for week 0.

Version 4.89. Tagged as 'RISC_OSLib-4_89'
@
text
@a25 1
        GET     s.h_StrongA
d99 1
d101 2
d104 8
a112 1
OSBase          *       &1800000
d149 1
a149 4
Wimp_ReadSysInfo EQU X+&400f2
Wimp_SlotSize    EQU X+&400ec
; Not needed anymore since behaviour under debugger is now identical
;Debugger_BeingDebugged EQU X+&41d41
d151 1
a151 2
DDEUtils_GetCLSize EQU X+&42583
DDEUtils_GetCL     EQU X+&42584
a154 5
        NOOP
        MOV     r0, r0
        MEND

        MACRO
d157 1
a157 2
        ; If shared library, need to worry about calling standard change.
 [ (:LNOT:SharedLibrary)
a159 12
   |
        LDRB    ip, [v6, #O_APCS_A_Client]
        CMP     ip, #0
        MOVNE   r12, sp
        MOVNE   r13, sl
        MOVNE   r10, fp
        MOV     lr, pc
        MOV     pc, $r
        MOVNE   fp, r10
        MOVNE   sl, r13
        MOVNE   sp, r12
 ]
d164 1
a164 1
 [ (:LNOT:SharedLibrary)
d167 3
a169 8
        STMFD   sp!, {v6, lr}
        LoadStaticBase v6
        LDRB    ip, [v6, #O_APCS_A_Client]
        CMP     ip, #0
        MOVNE   r12, sp
movne_sla_sl
        MOVNE   r13, sl
        MOVNE   r10, fp
d172 1
a172 5
        MOVNE   fp, r10
movne_sl_sla
        MOVNE   sl, r13
        MOVNE   sp, r12
        LDMFD   sp!, {v6, pc}^
d189 1
a189 1
        LDMFD   sp!, {pc}^
d193 7
a199 2
        ANDS    a1, r14, #PSRIBit
        MOVS    pc, r14
d202 2
a203 1
        STMFD   sp!, {r14}
d205 3
a207 3
        LDMEQFD sp!, {pc}^
        MOVNE   r0, #Module_Claim
        SWINE   Module
d210 1
a210 1
        LDMFD   sp!, {pc}^
d213 1
d216 1
a216 1
        BEQ     |_kernel_RMAalloc|
d218 1
a218 2
        BEQ     |_kernel_RMAfree|
        STMFD   sp!, {r14}
d227 1
a227 1
        LDMFD   sp!, {pc}^
d230 2
a231 1
        STMFD   sp!, {r14}
d236 1
a236 1
        LDMFD   sp!, {pc}^
d244 1
a244 1
        MOVS    pc, r14
d249 8
a256 1
        BICS    pc, r14, #PSRIBit
d259 8
a266 1
        ORRS    pc, r14, #PSRIBit
d269 3
a271 2
        AND     a1, r14, #3     ; the question is anyway about the caller's
        MOVS    pc, r14         ; state, not ours - the answers are probably
d273 5
a277 1

d281 1
d283 4
d289 1
a289 1
        MOVS    pc, r14
d362 1
a362 1
        TEQP    pc, #0                  ; back to user mode
d364 2
a365 2
        NOOP
        SWI     DDEUtils_GetCLSize
d378 1
a378 1
        SWI     DDEUtils_GetCL
d382 1
a382 1
        NOOP
d425 10
d458 1
a458 1
        SWI     Wimp_ReadSysInfo
d464 1
a467 1
        LDREQ   r1, [v6, #O_heapLimit]
d503 1
a503 1
        LDMIA   r5!, {r6, r7}
d505 9
a513 7
        SUB     r6, r5, r4
        SUB     r6, r6, #8
        MOV     r6, r6, ASR #2
        BIC     r6, r6, #&ff000000
        ORR     r6, r6, #&ea000000
        STR     r6, [r4]
        MOVS    pc, r14
d521 1
d523 4
d545 2
a546 1
        BLLT    |_kernel_copyerror|
d548 3
d605 1
a605 1
        MOVEQS  pc, lr
d607 1
d609 4
d693 1
a693 1
        MOVS    pc, r14
d698 1
a698 1
        MOVS    pc, r14
d706 2
d759 23
d783 13
a795 1
        TST     r14, #3
d797 1
d799 4
d804 1
d806 4
d824 8
a831 6
; Where to find the user context differs between Brazil and Arthur.
;  on Arthur, r13 points to the base of a full register save (r13 needs
;  resetting to above this point).
;  on Brazil r13 points to the word above a full register save.
; NB - is the pc value right??
        ADD     r13, r13, #8    ; pop the saved values of r0 and r12
d833 1
a833 2
        MOV     r1, r13
        LDMIA   r1!, {r2-r9}
d836 1
d838 33
a870 2
        ADD     r13, r13, #16*4
        MOV     r1, r9
a879 2
SVC_StackSize EQU 8192

d881 2
a882 2
; entry here in SVC mode,  r0 a pointer to an error block describing
; the abort.
d899 17
a915 6
        LDMFD   r13!, {r1, r2, r3}
        TST     r1, #3
        LDRNE   r1, [r14, #lr * 4]
        STR     r1, [r14, #pc*4]
        STR     r2, [r14, #r0*4]
        STREQ   r3, [r14, #r12*4]
d917 1
a917 3
        MOV     r4, sp, LSR #20
        MOV     r4, r4, LSL #20
        ADD     r4, r4, #SVC_StackSize
d922 1
a922 1
        ADD     r4, r14, #10 * 4
d948 1
a948 1
        ADD     r11, v6, #O_registerDump+16*4
a952 50
 [ SharedLibrary
        ; Shared Library, with the possibility that the fault occurred
        ; when APCS_A was in force.  In order to sort this mess out, it
        ; is necessary that sl at the time of the fault was a valid
        ; stackchunk handle.  In the non-shared case, this may not be true -
        ; it won't be within Fortran code, for example.
        ; Also, in non-user C code it won't be a full handle (no mark etc).
        ; But I know that in that case, we have APCS_U.
;        LDR     r3, [v6, #O_registerDump+pc*4]
;        TST     r3, #PSRSVCMode
;        MOVNE   r2, #-1         ; but then, the stack is not within the heap
;        BNE     Trap_IsAPCSR

        LDR     r3, =IsAStackChunk
        CMP     r10, r1         ; within the heap?
        CMPGE   r2, r10
        BLT     Trap_NotAPCSR

        LDR     r4, [r10, #SC_mark-SC_SLOffset]
        EOR     r4, r4, r3
        BICS    r4, r4, #&80000000 ; a chunk marked 'handling extension' will do
        BNE     Trap_NotAPCSR

Trap_IsAPCSR
        LDR     v1,  [v6, #O_registerDump+fp*4]
        LDR     r12, [v6, #O_registerDump+sp*4]
        B       Trap_CallingStandardKnown

Trap_NotAPCSR
        LDR     r10, [v6, #O_registerDump+r13*4]
        CMP     r10, r1
        CMPGE   r2, r10
        BLT     Trap_NoStackForHandler

        LDR     r4, [r10, #SC_mark-SC_SLOffset]
        EOR     r4, r4, r3
        BICS    r4, r4, #&80000000 ; a chunk marked 'handling extension' will do
        BNE     Trap_NoStackForHandler
        LDR     v1,  [v6, #O_registerDump+r10*4]
        LDR     r12, [v6, #O_registerDump+r12*4]

Trap_CallingStandardKnown
        ; We require that sp+256 > sl and sp < heaptop.
        ADD     r1, r12, #256
        CMP     r1, r10
        CMPCS   r2, r12
        BCC     Trap_NoStackForHandler

     |

a964 1
 ]
d966 4
a969 2
        LDMDB   r11!, {a1-a4, v2-v5}
        STMDB   r12!, {a1-a4, v2-v5}
d976 12
a987 1
        LDR     a1, [v6, #O_registerDump+pc*4]
d992 1
d994 1
d996 11
d1009 1
a1009 1
        NOOP
d1044 2
a1045 2
        TEQP    pc, #0
        NOOP
d1065 1
a1065 1
        MOV     v4, pc
d1067 2
a1068 2
        BLVC    open_messagefile
        TEQP    pc, v4
d1070 3
a1072 1
        ADD     r2, v6, #O_fastEventStack
d1083 1
a1083 1
        ADD     a2, v6, #O_fastEventStack
d1113 1
a1113 1
        ADD     r0, v6, #O_fastEventStack
d1139 1
a1139 1
        MOVS    pc, r14
d1148 1
a1148 1
        MOVS    pc, r14
d1160 1
a1160 1
        ; set up an intial unwind block.  For our purposes, we don't care
d1172 1
d1174 1
d1205 5
a1209 3
        MOVEQ   lr, pc
        MOVEQ   pc, r2
        BEQ     FCH_ClientCalled
d1246 1
d1248 3
d1266 1
a1266 1
        MOVS    pc, lr
d1291 1
a1291 1
        SWI     Wimp_SlotSize
d1297 1
a1297 1
        MOVS    pc, r14
d1323 1
a1323 1
        CMP     r0, #256
a1331 2
        TEQP    pc, #0
        NOOP
d1333 2
d1342 1
a1342 2
        LDMFD   sp!, {r0-r3, v1-v6, fp, sl, lr}
        MOVS    pc, lr
d1411 1
a1411 1
        MOVS    pc, r14
d1457 1
a1457 1
        MOVS    pc, r14
d1488 5
a1492 1
        BIC     r1, r1, #&0c000003      ; Sanitize PC value
d1503 1
d1508 1
a1508 1
        SWINE   EnterSVC
d1513 8
d1524 1
a1524 1
        MOVEQS  pc, lr
a1554 1
        CMP     r12, #0
d1586 3
d1599 3
a1601 83
 [ SharedLibrary
        ; Shared Library, with the possibility that the event occurred
        ; when APCS_A was in force.  In order to sort this mess out, it
        ; is necessary that sl at the time of the fault was a valid
        ; stackchunk handle.  In the non-shared case, this may not be true -
        ; it won't be within Fortran code, for example.
        ; There is a complicating factor, namely that the event may have
        ; happened during APCS change.  This has the forms
        ;   200 -> 300   mov[ne]  fp, fp_a
        ;                mov[ne]  sl, sl_a
        ;                mov[ne]  sp, sp_a
        ;
        ;   300 -> 200   mov[ne]  sp_a, sp
        ;                mov[ne]  sl_a, sl
        ;                mov[ne]  fp_a, fp
        ;
        ; This code cares about the values of fp, sp and sl, so possible
        ; problems are:
        ;    after either  mov sl_x, sl_y  we appear to be in APCS_R, but
        ;    sp_r holds the value of SL.  In both cases, fp_r holds the
        ;    value of FP.
        ;
        MOV     r12, #-1
        CMP     r10, r1
        CMPGE   r2, r10
        BLT     Event_NotAPCSR

        LDR     r4, [r10, #SC_mark-SC_SLOffset]
        CMP     r4, r3
        BNE     Event_NotAPCSR
        LDR     v5, [v6, #O_registerDump+fp*4]
        LDR     r0, [v6, #O_registerDump+pc*4]
        BIC     r14, r0, #PSRBits
        LDR     r14, [r14, #-4]
        LDR     r12, movne_sl_sla
        EORS    r12, r12, r14
        BNE     %F01
        TST     r0, #PSRZBit
        BNE     IsntExecutedSLChange

01      BICS    r12, r12, #&F0000000    ; lose the condition mask
        BEQ     IsExecutedSLChange

        LDR     r12, movne_sla_sl
        EORS    r12, r12, r14
        BNE     %F02
        TST     r0, #PSRZBit
        BNE     IsntExecutedSLChange

02      BICS    r12, r12, #&F0000000
        BEQ     IsExecutedSLChange

IsntExecutedSLChange
        LDR     r12, [v6, #O_registerDump+r13*4]
        B       Event_CallingStandardKnown

IsExecutedSLChange
        LDR     r12, [v6, #O_registerDump+r12*4]
        B       Event_CallingStandardKnown

Event_NotAPCSR
        LDR     r10, [v6, #O_registerDump+r13*4]
        CMP     r10, r1
        CMPGE   r2, r10
        BLT     Event_NoStackForHandler

        LDR     r4, [r10, #SC_mark-SC_SLOffset]
        CMP     r4, r3
        BNE     Event_NoStackForHandler
        LDR     r12, [v6, #O_registerDump+r12*4]
        LDR     v5, [v6, #O_registerDump+r10*4]

;  Now  r12  is the SP value in the interrupted code
;       v5          FP
;       r10         SL

Event_CallingStandardKnown
        CMP     r12, r10
        CMPGT   r2, r12
        MOVLE   r12, #-1
        BLE     Event_NoStackForHandler

     |
a1618 1
 ]
d1620 3
a1622 3
        LDMDB   r11!, {r0-r7}
        STMDB   r12!, {r0-r7}
        LDMDB   r11!, {r0-r7}
d1626 1
a1626 1
        TEQP    pc, #PSRIBit+PSRSVCMode ; we want the testing for an escape and
d1634 11
a1644 3
        MOVNE   r0, #&7e
        SWINE   Byte
        MOVNE   v1, #-1                 ; escape overrides everything else
a1645 2
        TEQP    pc, #PSRIBit           ; to user mode, with interrupts off
        NOOP
a1652 1
        ; now find a handler
d1654 1
a1654 1
        MOV     sl, r10
d1671 1
d1673 8
a1680 1
        NOOP
d1683 1
a1683 1
        NOOP
d1715 1
a1715 1
        MOVS    pc, r14
d1726 1
a1726 1
        MOVS    pc, r14
d1730 1
a1730 1
        STMFD   sp!, {v2, v4-v6, r14}
d1733 1
a1733 1
        BIC     r1, a1, #PSRBits
d1736 1
a1736 1
        LDMFD   sp!, {v2, v4-v6, pc}^
d1740 1
a1740 1
        STMFD   sp!, {v2, v4-v6, r14}
d1743 1
a1743 1
        BIC     r1, a1, #PSRBits
d1747 1
a1747 1
        LDMEQFD sp!, {v2, v4-v6, pc}^
d1755 1
a1755 1
        LDMFD   sp!, {v2, v4-v6, pc}^
d1759 1
a1759 1
        STMFD   sp!, {a1, a2, v2, v4-v6, r14}
d1762 1
a1762 1
        BIC     r1, r1, #PSRBits
d1775 1
a1775 1
        LDMFD   sp!, {v2, v4-v6, pc}^
d1785 1
a1785 1
        BICS    a4, a4, #APCSChange+ChunkChange
d1790 1
a1790 1
        ; (top bits used to mark stack extension & APCS change).
d1792 1
a1792 1
        TST     a4, #&3c000003
d1796 1
a1796 1
        BIC     a3, a3, #PSRBits
d1803 1
a1803 2
        LDREQ   v1, [a3, #-12]
        LDRNE   v1, [a3, #-8]
d1805 1
a1805 1
        |
a1806 1
        ]
d1812 1
a1812 2
        EOR     ip, ip, #&002c
        BICS    ip, ip, #1              ; STMFD sp!, ... (sp = r12 or r13)
d1828 6
d1837 36
d1875 1
a1875 1
        BIC     r14, v1, #&7000
d1883 1
a1883 1
        STR     r14, [v1, #uwb_r4-r4*4*3+8]
d1885 1
a1885 1
        STR     r14, [v1, #uwb_r4-r4*4*3+4]
d1887 1
a1887 1
        STR     r14, [v1, #uwb_r4-r4*4*3]
d1895 1
a1895 1
        BIC     a3, a3, #ChunkChange+APCSChange
d1902 1
a1902 1
        BIC     r1, v1, #PSRBits
d1912 1
a1912 1
        LDMFD   sp!, {v1-v6, pc}^
d1916 7
a1922 2
        LDR     r14, [v6, #O_registerDump+pc*4]
        TEQP    r14, #PSRBits           ; Back to the mode and interrupt
d1924 1
a1924 1
        NOOP
d1943 1
d1945 1
a1945 4
  [ StrongARM
        MOV     ip, sp
        STMFD   sp!, {a3, a4, v1-v6, fp, ip, r14, pc}
        SUB     fp, ip, #4
a1956 1
        BLVS    CopyError
d1958 2
a1959 34
        LDMDB   fp, {v1-v6, fp, sp, pc}^
  |
        ; Set up a proper frame here, so if an error happens (and not X)
        ; a sensible traceback can be given.
        MOV     ip, sp
        STMFD   sp!, {a3, a4, v1-v6, fp, ip, r14, pc}
        SUB     fp, ip, #4
        ; be kind to fault handler if there is an error.
        ADR     a4, AfterSWI-4
        SUB     a4, a4, sp
        MOV     a4, a4, LSR #2
        BIC     a4, a4, #&ff000000
        ADD     a4, a4, #&ea000000      ; B always
        TST     a1, #&80000000          ; non-X bit requested?
        ORR     a1, a1, #&EF000000      ; SWI + Always
        ORREQ   a1, a1, #X
        STMFD   sp!, {a1, a4}
        LDMIA   a2, {r0 - r9}
        MOV     pc, sp
AfterSWI
        ADD     sp, sp, #8
        LDMFD   sp!, {ip, lr}
        STMIA   ip, {r0 - r9}
        MOV     ip, #0
        MOVCS   ip, #1
        MOVVS   ip, #0
        STR     ip, [lr]
        BLVS    CopyError
        MOVVC   a1, #0
        LDMDB   fp, {v1-v6, fp, sp, pc}^
  ]

swi_ret_inst
        MOV     pc, ip
d1961 1
d1963 1
a1963 2
  [ StrongARM
        STMDB   sp!, {a3, v1-v6, lr}
a1970 1
        BLVS    CopyError
d1972 2
a1973 17
        LDMIA   sp!, {a3, v1-v6, pc}^
  |
        STMDB   sp!, {a3, v1-v6, lr}
        LDR     a4, swi_ret_inst
        TST     a1, #&80000000
        ORR     a1, a1, #&ef000000
        ORREQ   a1, a1, #X
        STMDB   sp!, {a1, a4}
        LDMIA   a2, {r0-r9}
        MOV     ip, pc
        MOV     pc, sp
        LDR     ip, [sp, #8]!
        STMIA   ip, {r0-r9}
        BLVS    CopyError
        MOVVC   a1, #0
        LDMIA   sp!, {a3, v1-v6, pc}^
  ]
d1979 1
a1979 1
        MOVS    pc, r14
d1982 1
a1982 1
        STMFD   sp!, {v6, r14}
d1990 1
a1990 1
        LDMFD   sp!, {v6, pc}^
d1993 1
a1993 1
        STMFD   sp!, {v6, r14}
d1996 1
a1996 1
        LDMCCFD sp!, {v6, pc}^
d2000 1
a2000 1
        LDMFD   sp!, {v6, pc}^
d2003 3
a2005 2
        STMFD   sp!, {v6, r14}
        SWI     WriteC
d2007 3
a2009 3
        BLVS    CopyError
        MOVVS   a1, #-2
        LDMFD   sp!, {v6, pc}^
d2012 1
a2012 1
        STMFD   sp!, {v6, r14}
d2017 1
a2017 1
        LDMFD   sp!, {v6, pc}^
d2020 1
a2020 1
        STMFD   sp!, {v6, r14}
d2022 1
a2022 1
        LDMVCFD sp!, {v6, pc}^
d2033 1
a2033 1
        STMFD   sp!, {r4, r5, r6, r7, v6, r14}
d2038 2
a2039 2
        BLVS    CopyError
        MOVCS   a1, #-1
d2041 1
a2041 1
        LDMFD   sp!, {r4, r5, r6, r7, v6, pc}^
d2044 1
a2044 1
        STMFD   sp!, {v6, r14}
d2048 1
a2048 1
        LDMFD   sp!, {v6, pc}^
d2051 3
a2053 3
        STMFD   sp!, {v6, r14}
        SWI     Open
        LDMVCFD sp!, {v6, pc}^
d2062 1
a2062 1
        STMFD   sp!, {r4, r5, r6, v6, r14}
d2065 1
a2065 1
        SWI     File
d2067 1
a2067 1
        BLVS    CopyError
d2069 1
a2069 1
        LDMFD   sp!, {r4, r5, r6, v6, pc}^
d2072 1
a2072 1
        STMFD   sp!, {v6, r14}
d2079 1
a2079 1
        LDMFD   sp!, {v6, pc}^
d2082 1
a2082 1
        STMFD   sp!, {v6, r14}
d2086 1
a2086 1
        LDMFD   sp!, {v6, pc}^
d2095 1
a2095 1
        MOVS    pc, r14
d2105 1
a2105 4
        STFNEE  f7, [sp, #-12]!
        STFNEE  f6, [sp, #-12]!
        STFNEE  f5, [sp, #-12]!
        STFNEE  f4, [sp, #-12]!
d2162 1
a2162 1
        BIC     v4, pc, #&FC000003      ; where to copy down to before jumping
d2191 1
d2193 8
a2200 8
        MOVEQ   r0, #Env_MemoryLimit
        LDREQ   r1, [v6, #O_imageBase]
        ADDEQ   r1, r1, r14
        SWIEQ   ChangeEnv

        MOVEQ   r0, #Env_ErrorHandler
        ADREQ   r1, s_ErrHandler
        MOVEQ   r2, v6
d2202 1
a2202 1
        SWIEQ   ChangeEnv
d2204 9
a2212 9
        MOVEQ   r0, #Env_ExitHandler
        ADREQ   r1, s_ExitHandler
        MOVEQ   r2, v6
        SWIEQ   ChangeEnv

        MOVEQ   r0, #Env_UpCallHandler  ; We don't really want one of these, ...
        ADREQ   r1, s_UpCallHandler     ; but RISCOS rules say we must have it
        MOVEQ   r2, v6
        SWIEQ   ChangeEnv
d2214 1
a2214 1
        LDR     r0, [ip, #32]           ; the CLI string to execute
d2217 1
a2217 1
        SWI     CLI:AND::NOT:X          ; force non-X variant
d2241 3
a2243 2
        BLNE    SetWimpSlot_Save_r4r5   ; set slot size back to value before CLI
        LDMNEFD sp!, {r4, r5}
d2245 1
a2245 1
        SUB     sp, sp, v5              ; and relocate sp...
d2256 1
a2256 1
        BIC     v3, pc, #&FC000003
d2294 2
a2295 5
        LDFNEE  f4, [sp], #12
        LDFNEE  f5, [sp], #12
        LDFNEE  f6, [sp], #12
        LDFNEE  f7, [sp], #12
        LDMFD   sp!, {v1-v6, pc}^
d2300 2
d2313 3
a2315 3
        CMP     a3, #' '
        BCS     %B01
        MOVS    pc, r14
d2319 1
a2319 3
        MOV     ip, sp
        STMFD   sp!, {v1, v2, v6, fp, ip, r14, pc}
        SUB     fp, ip, #4
d2321 1
d2324 1
a2324 2
        SWI     X:OR:ReadVarVal
        BLVS    CopyError
d2327 2
a2328 1
        LDMDB   fp, {v1, v2, v6, fp, sp, pc}^
d2332 1
a2332 1
        STMFD   sp!, {v1, v6, r14}
d2343 1
a2343 2
        SWI     X:OR:SetVarVal
        BLVS    CopyError
d2345 2
a2346 1
        LDMFD   sp!, {v1, v6, pc}^
d2357 1
a2357 1
        MOVS    pc, r14
d2365 1
a2365 1
        MOVS    pc, r14
d2434 1
a2434 1
        MOVS    pc, r14
d2483 1
a2483 1
        MOVGES  pc, r14
d2491 1
a2491 1
        MOVS    pc, r14                 ; and don't update heapTop)
d2511 1
a2511 1
        MOVS    pc, r14
d2520 1
a2520 1
        MOVS    pc, r14
d2528 1
a2528 1
        MOVS    pc, r14
d2584 1
d2586 3
d2645 1
a2645 1
        ADR     v5, StackOverflowExit   ; return address...
d2667 1
d2669 3
d2680 1
a2680 10
; The Z flag is set (through magic in the compatibility stubs) if stack
; extension happened in APCS_A, in which case we must permute the
; stack-description registers here and permute them back at the end.
; We do not do the expected ..EQ operations here, in order to keep the
; event handler happy - APCS change expected to be unconditional or NE.
        MOV     r14, pc
        TST     r14, #PSRZBit
        MOVNE   fp, r10
        MOVNE   sl, r13
        MOVNE   sp, r12
d2686 1
a2686 1
        STMFD   sp!, {a1, v1-v4}        ; Save some work regs
d2703 3
a2705 1
        CMPS    ip, #0                  ; if there is one...
d2707 4
a2710 4
        MOVNE   pc, ip                  ; then call it...
        MOVNE   a2, #0
        STRNE   a2, [v1, #SC_next-SC_SLOffset] ; and unhook next chunk
        MOVEQ   v1, v2                  ; no deallocate proc: try next chunk
d2719 2
a2720 7
; Return, changing APCS if necessary
        TST     v4, #PSRZBit
        LDMDB   fp, {a1, v1-v4, fp, sp, lr}
        MOVNE   r12, sp
        MOVNE   r13, sl
        MOVNE   r10, fp
        MOVS    pc, r14
d2728 1
d2732 6
d2807 1
a2807 1
        LDMFD   sp!, {a3, a4, ip, pc}^  ; restore extra saved regs
d2809 1
d2812 4
d2835 50
a2884 1
; Destroys a3, a4 and ip
a2885 62
        MOVS    a3, a1
        BEQ     dividebyzero
        MOV     a4, #0
        MOV     ip, #&80000000
        CMP     a2, ip
        MOVLO   ip, a2
u_loop
        CMP     ip, a3, ASL #0
        BLS     u_shifted0mod8
        CMP     ip, a3, ASL #1
        BLS     u_shifted1mod8
        CMP     ip, a3, ASL #2
        BLS     u_shifted2mod8
        CMP     ip, a3, ASL #3
        BLS     u_shifted3mod8
        CMP     ip, a3, ASL #4
        BLS     u_shifted4mod8
        CMP     ip, a3, ASL #5
        BLS     u_shifted5mod8
        CMP     ip, a3, ASL #6
        BLS     u_shifted6mod8
        CMP     ip, a3, ASL #7
        MOVHI   a3, a3, ASL #8
        BHI     u_loop
u_loop2
u_shifted7mod8
        CMP     a2, a3, ASL #7
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #7
u_shifted6mod8
        CMP     a2, a3, ASL #6
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #6
u_shifted5mod8
        CMP     a2, a3, ASL #5
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #5
u_shifted4mod8
        CMP     a2, a3, ASL #4
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #4
u_shifted3mod8
        CMP     a2, a3, ASL #3
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #3
u_shifted2mod8
        CMP     a2, a3, ASL #2
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #2
u_shifted1mod8
        CMP     a2, a3, ASL #1
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #1
u_shifted0mod8
        CMP     a2, a3, ASL #0
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #0
        CMP     a1, a3, LSR #1
        MOVLS   a3, a3, LSR #8
        BLS     u_loop2
        MOV     a1, a4
        MOVS    pc, r14
a2890 2
; Unfortunately, udiv doesn't preserve any (but the callee-save) registers,
; so we need to stack our link over the call.
d2893 1
a2893 1
        STMFD   sp!, {r14}
d2896 1
a2896 1
        LDMFD   sp!, {pc}^
a2899 7
;
; Calculate x / 10 as (x * 2**32/10) / 2**32.
; That is, we calculate the most significant word of the double-length
; product. In fact, we calculate an approximation which may be 1 off
; because we've ignored a carry from the least significant word we didn't
; calculate. We correct for this by insisting that the remainder < 10
; and by incrementing the quotient if it isn't.
d2903 2
a2904 3
        MOV     a2, a1
        MOV     a1, a1, LSR #1
        ADD     a1, a1, a1, LSR #1
d2909 5
a2913 6
        ADD     a3, a1, a1, ASL #2
        SUB     a2, a2, a3, ASL #1
        CMP     a2, #10
        ADDGE   a1, a1, #1
        SUBGE   a2, a2, #10
        MOVS    pc, r14
d2923 54
a2976 75
; Code mostly as for udiv, except that the justification part is slightly
; simplified by knowledge that the dividend is in the range [0..#x80000000]
; (one register may be gained thereby).

        MOVS    ip, a1
        BEQ     dividebyzero
        RSBMI   a1, a1, #0              ; absolute value of divisor
        EOR     ip, ip, a2
        ANDS    a4, a2, #&80000000
        ORR     ip, a4, ip, LSR #1
        ; ip bit 31  sign of dividend (= sign of remainder)
        ;    bit 30  sign of dividend EOR sign of divisor (= sign of quotient)
        RSBNE   a2, a2, #0              ; absolute value of dividend

        MOV     a3, a1
        MOV     a4, #0
s_loop
        CMP     a2, a3, ASL #0
        BLS     s_shifted0mod8
        CMP     a2, a3, ASL #1
        BLS     s_shifted1mod8
        CMP     a2, a3, ASL #2
        BLS     s_shifted2mod8
        CMP     a2, a3, ASL #3
        BLS     s_shifted3mod8
        CMP     a2, a3, ASL #4
        BLS     s_shifted4mod8
        CMP     a2, a3, ASL #5
        BLS     s_shifted5mod8
        CMP     a2, a3, ASL #6
        BLS     s_shifted6mod8
        CMP     a2, a3, ASL #7
        MOVHI   a3, a3, ASL #8
        BHI     s_loop
s_loop2
        CMP     a2, a3, ASL #7
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #7
        CMP     a2, a3, ASL #6
s_shifted6mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #6
        CMP     a2, a3, ASL #5
s_shifted5mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #5
        CMP     a2, a3, ASL #4
s_shifted4mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #4
        CMP     a2, a3, ASL #3
s_shifted3mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #3
        CMP     a2, a3, ASL #2
s_shifted2mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #2
        CMP     a2, a3, ASL #1
s_shifted1mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #1
        CMP     a2, a3, ASL #0
s_shifted0mod8
        ADC     a4, a4, a4
        SUBHS   a2, a2, a3, ASL #0
        CMP     a1, a3, LSR #1
        MOVLS   a3, a3, LSR #8
        BLS     s_loop2
        MOV     a1, a4
        TST     ip, #&40000000
        RSBNE   a1, a1, #0
        TST     ip, #&80000000
        RSBNE   a2, a2, #0
        MOVS    pc, r14
d2981 1
a2981 1
        STMFD   sp!, {r14}
d2984 1
a2984 1
        LDMFD   sp!, {pc}^
d2994 2
a2995 3
        MOV     a2, a1
        MOV     a1, a1, LSR #1
        ADD     a1, a1, a1, LSR #1
d3000 5
a3004 6
        ADD     a3, a1, a1, ASL #2
        SUB     a2, a2, a3, ASL #1
        CMP     a2, #10
        ADDGE   a1, a1, #1
        SUBGE   a2, a2, #10
        CMP     a4, #0
d3007 1
a3007 1
        MOVS    pc, r14
d3017 1
a3017 1
        BIC     r0, r14, #PSRBits
d3033 1
a3033 1
        NOOP
a3037 10
        [ 0 = 1
        ADD     ip, ip, #pc*4
        LDMIA   ip, {r14}^
        SUB     ip, ip, #pc*4-4
        LDMIA   ip, {r1-r13}
        TEQP    pc, #0
        NOOP
        SWI     GenerateError
        ]

d3062 1
a3062 9
XMessageTrans_OpenFile    EQU &61501
XMessageTrans_Lookup      EQU &61502
XMessageTrans_CloseFile   EQU &61504
XMessageTrans_ErrorLookup EQU &61506

MessageTrans_OpenFile     EQU &41501
MessageTrans_Lookup       EQU &41502
MessageTrans_CloseFile    EQU &41504
MessageTrans_ErrorLookup  EQU &41506
d3086 1
a3086 1
        STMDB   sp!, {r1-r7, r12, lr}
d3094 1
a3094 1
        LDMIA   sp!, {r1-r7, r12, pc}^
d3106 1
a3106 1
        STMDB   sp!, {r0-r7, r12, lr}
d3121 1
a3121 1
        LDMIA   sp!, {r0-r7, r12, pc}^
d3134 1
a3134 1
        STMDB   sp!, {r0, r2-r5, lr}
d3138 1
a3138 1
        LDMNEIA sp!, {r0, r2-r5, pc}
d3141 2
a3142 2
        SWI     Module
        LDMVSIA sp!, {r0, r2-r5, pc}^           ; NB R1 = 0
d3149 1
a3149 1
        LDMVCIA sp!, {r0, r2-r5, pc}^
d3152 1
a3152 1
        SWI     Module
d3154 1
a3154 1
        LDMIA   sp!, {r0, r2-r5, pc}^
d3159 1
a3159 1
        MOVS    pc, lr
d3162 1
a3162 1
        MOVS    pc, lr
d3167 2
a3168 1
        STMDB   sp!, {r0,lr}
d3176 3
a3178 1
        LDMIA   sp!, {r0,pc}
@


4.5.2.1
log
@  _kernel_call_client is now 32-bit application safe.
Detail:
  Since calls up to a 32-bit application (eg. main, atexit functions,
    qsort/bsearch comparison functions) won't preserve flags if the
    application is 32-bit, the _kernel_call_client needs to know that
    the Z flag it was relying on being preserved won't be any more.
Admin:
  Tested and verified by dry run inspection only.
@
text
@a168 2
        LDRB    lr, [v6, #O_APCS_A_Client]
        CMP     lr, #0
a189 2
        LDRB    lr, [v6, #O_APCS_A_Client]
        CMP     lr, #0
a193 1
  [ {CONFIG}=26
a194 3
    |
        LDMFD   sp!, {v6, pc}
  ]
@


4.5.2.2
log
@  Stack extension return code is now APCS variant safe.
Detail:
  Extension exit code relied on the user function preserving the
    Z flag across the function call.  This no longer happens.
Admin:
  Work in progress.

Version 4.97, 4.12.2.2. Tagged as 'RISC_OSLib-4_97-4_12_2_2'
@
text
@d2544 1
a2544 5
        LoadStaticAddress APCS_A_Client, v1, v2
        LDRB    v1, [v1]                ; determine which exit routine to use
        TEQ     v1, #0
        ADREQ   lr, StackOverflowExit   ; non APCS-A
        ADRNE   lr, StackOverflowExitA  ; APCS-A
d2605 1
a2605 5
        LoadStaticAddress APCS_A_Client, v5, v4
        LDRB    v5, [v5]
        TEQ     v5, #0
        ADREQ   v5, StackOverflowExit   ; return address... (non APCS-A)
        ADRNE   v5, StackOverflowExitA  ; return address... (APCS-A)
a2631 9
StackOverFlowExitA Keep
; We return here when returning from an APCS_A function - perform the register
; munging
        MOV     fp, r10
        MOV     sl, r13
        MOV     sp, r12
        MOV     r14, #PSRZBit           ; ensure register munging on exit
        B       StackOverflowExitCommon

d2641 5
a2645 2
        MOV     r14, #0                 ; don't munge registers later on
StackOverflowExitCommon
d2668 5
a2672 1
        CMPS    ip, #0                  ; is there a proc?
a2673 6
        BEQ     DeallocateChunkLoopSkip ; go around next chunk
        MOV     lr, pc
        MOV     pc, ip                  ; there was, so call it...
        MOV     a2, #0
        STR     a2, [v1, #SC_next-SC_SLOffset] ; and unhook next chunk
DeallocateChunkLoopSkip
@


4.5.2.3
log
@  Renamed APCS_A_Client to ClientFlags
  ClientFlags is now a (byte-wide) bitfield.
Detail:
  Bit 0 set means client is using APCS-A
  Bit 1 set means client is using APCS-32 (in either 26 or 32 bit modes)
  Bit 2 set means client is using a 32-bit mode.
  Bits 3-7 are reserved for future expansion
@
text
@d162 2
a163 2
        LDRB    ip, [v6, #O_ClientFlags]
        TST     ip, #ClientFlag_APCS_A
d169 2
a170 2
        LDRB    lr, [v6, #O_ClientFlags]
        TST     lr, #ClientFlag_APCS_A
d184 2
a185 2
        LDRB    ip, [v6, #O_ClientFlags]
        TST     ip, #ClientFlag_APCS_A
d192 2
a193 2
        LDRB    lr, [v6, #ClientFlags]
        TST     lr, #ClientFlag_APCS_A
d2546 1
a2546 1
        TST     v1, #ClientFlag_APCS_A
d2611 1
a2611 1
        TST     v5, #ClientFlag_APCS_A
@


4.5.2.4
log
@_kernel_unwind now understands SFMFD instructions in function entry.
It also copes with STFE now - it was totally broken.
32-bit stubs and corresponding LibInit SWIs created.
All rather untested.

Version 4.97, 4.12.2.3. Tagged as 'RISC_OSLib-4_97-4_12_2_3'
@
text
@d26 1
a99 1

a100 1
PSRMode         *       &00000003
a101 6
PSRPrivileged   *       &00000003

PSR32IBit       *       &00000080
PSR32Mode       *       &0000001F
PSR32SVCMode    *       &00000013
PSR32Privileged *       &0000000F
d103 1
d361 1
a361 1
        WritePSRc 0, r5                  ; back to user mode
d955 1
a955 1
        WritePSRc 0, lr
a975 1
        SavePSR v4
d979 1
a979 1
        RestPSR v4
d1233 1
a1233 1
        WritePSRc 0, v6
a1400 1
      [ No32bitCode
d1405 1
a1405 1
        SWIEQ   EnterSVC
a1409 6
      |
        LoadStaticAddress escapeSeen, a3
        MOV     a2, #0
        SWPB    a1, a2, [a3]
        Return  "", LinkNotStacked
      ]
d1413 1
a1413 1
        MOVEQ   pc, lr
d1594 1
a1594 1
        WritePSRc PSRIBit+PSRSVCMode, r1 ; we want the testing for an escape and
d1606 1
a1606 1
        WritePSRc PSRIBit, r0            ; to user mode, with interrupts off
d1634 1
a1634 1
        WritePSRc PSRIBit+PSRSVCMode, r1
d1758 2
a1759 1
        ADDNE   a3, a3, #4
d1761 2
a1763 1
        LDR     v1, [a3, #-12]
a1785 6
        ; skip over saved arguments
16      TST     v1, ip, ASL v3
        SUBNE   v2, v2, #4
        SUBS    v3, v3, #1
        BGE     %B16

a1788 36
        LDR     v1, [a3]                ; check for SUB fp, ip, #n
        LDR     v4, =&e24cb             ; (assumes fp=r11, ip=r12)
        CMP     v4, v1, LSR #12
        ADDEQ   a3, a3, #4              ; skip over it

        ; first look for SFM F4,<count>,[sp,#-count*12]!
        LDR     v4, =&ed2d4200          ; assume sp = r13 if SFM
        LDR     v1, [a3]
        LDR     r14, =&004080ff         ; ignore count + offset
        BIC     r14, v1, r14
        CMP     r14, v4
        BNE     UnwindNotSFM            ; it's not SFM

        LDRB    v3, [v6, #O_fpPresent]
        TEQ     v3, #0
        BEQ     UnwindEndFP             ; can only unwind this if FP present
        AND     v3, v1, #&FF            ; v3 = offset
        AND     v4, v1, #&8000          ; v4 = bottom bit of count
        TST     v1, #&400000
        ORRNE   v4, v4, #&10000         ; add in top bit
        MOVS    v4, v4, LSR #15
        MOVEQ   v4, #4                  ; v4 = count
        ADD     v4, v4, v4, LSL #1      ; v4 = count * 3
        TEQ     v4, v3
        BNE     UnwindEndFP             ; count didn't match offset

        ADD     v3, a1, #uwb_f4         ; v3 -> uwb_f4
        SUB     v2, v2, v4, LSL #2      ; pull v2 down to base of stored FP regs
15      LFM     f0, 1, [v2], #12
        SUBS    v4, v4, #3
        STFE    f0, [v3], #12
        BNE     %B15
        B       UnwindEndFP

        ; or alternatively multiple STFE Fn,[sp,#-12]!
UnwindNotSFM
d1791 1
a1791 1
        BIC     r14, v1, #&17000        ; sp = r12 or r13
d1799 1
a1799 1
        STR     r14, [v1, #uwb_f4-r4*4*3+8]
d1801 1
a1801 1
        STR     r14, [v1, #uwb_f4-r4*4*3+4]
d1803 1
a1803 1
        STR     r14, [v1, #uwb_f4-r4*4*3]
@


4.5.2.5
log
@Most of the obvious problems in the last check-in fixed. It now builds, at
least.
Stubs now correctly, and internationalisably, report "C library too old".
Both BL and LDR PC forms of branch table successfully created.
Tested on various existing 26-bit programs, and one 32-bit program tested.

Version 4.97, 4.12.2.4. Tagged as 'RISC_OSLib-4_97-4_12_2_4'
@
text
@d198 1
a198 1
        LDRB    lr, [v6, #O_ClientFlags]
d1419 1
a1419 1
        LoadStaticBase a3
a1420 2
        ADD     a3, a3, #O_escapeSeen :AND: :NOT: &FF
        ADD     a3, a3, #O_escapeSeen :AND: &FF         ; Yuckeroo
d2598 3
a2600 3
        LoadStaticBase v6, lr
        LDRB    lr, [v6, #O_ClientFlags]; determine which exit routine to use
        TST     lr, #ClientFlag_APCS_A
d2663 2
a2664 2
        LoadStaticBase v5, v4
        LDRB    v5, [v5, #O_ClientFlags]
d2694 1
a2694 1
StackOverflowExitA Keep
@


4.5.2.6
log
@  Work in progress.  Do not use.
Detail:
  Many changes to use the APCS macros for function entry and exit so
    that the code can build for 32-bit environments.  Changes are NOT
    yet complete.
  Makefile rebuilds swis.h header file but only exports it if it has
    changed to avoid unnecessary rebuilding of nearly all C sources
    in a build.
Admin:
  Work in progress.  Do not use.

Version 4.97, 4.12.2.5. Tagged as 'RISC_OSLib-4_97-4_12_2_5'
@
text
@d146 4
a149 1
        GET     Hdr:Wimp
d151 2
a152 1
        GET     Hdr:DDEUtils
d188 1
a188 1
        FunctionEntry "v6"
d204 5
a208 1
        Return  "v6"
d225 1
a225 1
        LDMFD   sp!, {pc}
d229 1
a229 1
        ANDS    a1, r14, #PSRIBit       ; XXXX32
d370 1
a370 1
        SWI     XDDEUtils_GetCLSize
d383 1
a383 1
        SWI     XDDEUtils_GetCl
d453 1
a453 1
        SWI     XWimp_ReadSysInfo
d533 1
a533 1
        BLLT    |_kernel_copyerror|     ; BL<cond> 32-bit OK
d985 1
a985 1
        BLVC    open_messagefile        ; BL<cond> 32-bit OK
d1199 1
a1199 1
        SWI     XWimp_SlotSize
d1926 1
a1927 1
        BLVS    CopyError               ; BL<cond> 32-bit OK
d1955 1
a1955 1
        BLVS    CopyError               ; BL<cond> 32-bit OK
d1973 1
a1974 1
        BLVS    CopyError               ; BL<cond> 32-bit OK
d1988 1
a1989 1
        BLVS    CopyError               ; BL<cond> 32-bit OK
d2022 1
a2022 1
        SWI     XOS_WriteC
d2024 3
a2026 4
        Return  "v6",,VC
        BL      CopyError
        MOV     a1, #-2
        Return  "v6"
d2068 3
a2070 3
        FunctionEntry "v6"
        SWI     XOS_Find
        Return  "v6",,VC
d2079 1
a2079 1
        FunctionEntry "r4-r6,v6"
d2082 1
a2082 1
        SWI     XOS_File
d2084 3
a2086 4
        Return  "r4-r6,v6",,VC
        BL      CopyError
        MOV     a1, #-2
        Return  "r4-r6,v6"
d2096 1
a2096 1
        Return  "v6"
d2236 1
a2236 1
        SWI     OS_CLI                  ; force non-X variant
d2260 2
a2261 3
        BEQ     %FT01
        BL      SetWimpSlot_Save_r4r5   ; set slot size back to value before CLI
        LDMFD   sp!, {r4, r5}
d2263 1
a2263 1
01      SUB     sp, sp, v5              ; and relocate sp...
d2334 1
a2334 1
        Return  ,LinkNotStacked
d2338 3
a2340 1
        FunctionEntry "v1,v2,v6", frame
d2344 2
a2345 1
        SWI     XOS_ReadVarVal
d2348 1
a2348 2
        BLVS    CopyError               ; BL<cond> 32-bit OK
        Return  "v1,v2,v6", "fpbased"
d2352 1
a2352 1
        FunctionEntry "v1,v6"
d2363 2
a2364 1
        SWI     XOS_SetVarVal
d2366 1
a2366 2
        BLVS    CopyError               ; BL<cond> 32-bit OK
        Return  "v1,v6"
d2377 1
a2377 1
        MOV     pc, r14
d2385 1
a2385 1
        Return  ,LinkNotStacked
d2531 1
a2531 1
        Return  ,LinkNotStacked
d2540 1
a2540 1
        MOV     pc, r14
d2548 1
a2548 1
        MOV     pc, r14
d2926 1
a2926 1
        Return  ,LinkNotStacked
d2936 1
a2936 1
        FunctionEntry
d2939 1
a2939 1
        Return
d2965 1
a2965 1
        Return  ,LinkNotStacked
d3049 1
a3049 1
        Return  ,LinkNotStacked
a3053 1
        FunctionEntry
d3057 1
a3057 1
        Return
d3082 1
a3082 1
        Return  ,LinkNotStacked
d3092 1
a3092 1
        BIC     r0, r14, #PSRBits               ; XXXX32
d3113 10
d3147 9
a3155 2
        GET     Hdr:MsgTrans
        GET     Hdr:ModHand
d3179 1
a3179 1
        FunctionEntry "r1-r7,r12"
d3187 1
a3187 1
        Return  "r1-r7,r12"
d3199 1
a3199 1
        FunctionEntry "r0-r7,r12"
d3214 1
a3214 1
        Return  "r0-r7,r12"
d3227 1
a3227 1
        FunctionEntry "r0,r2-r5"
d3231 1
a3231 1
        Return  "r0,r2-r5",,NE
d3234 2
a3235 2
        SWI     XOS_Module
        Return  "r0,r2-r5",,VS                  ; NB R1 = 0
d3242 1
a3242 1
        Return  "r0,r2-r5",,VC
d3245 1
a3245 1
        SWI     XOS_Module
d3247 1
a3247 1
        Return  "r0,r2-r5"
d3252 1
a3252 1
        MOV     pc, lr
d3255 1
a3255 1
        MOV     pc, lr
d3260 1
a3260 1
        FunctionEntry "r0"
d3268 1
a3268 1
        Return  "r0"
@


4.5.2.7
log
@Work in progress
@
text
@a101 1
PSRUSRMode      *       &00000000
a106 1
PSR32SVCMode    *       &00000010
d221 2
a222 10
        [ No32bitCode
        AND     a1, pc, #PSRIBit        ; 32-bit OK (in 26-bit cond)
        |
        AND     a1, pc, #PSRIBit | PSRMode
        MRS     a1, CPSR
        TST     a1, #PSR32Mode^PSRMode  ; Z set if in 26-bit mode
        ANDEQ   a1, pc, #PSRIBit        ; 32-bit OK (in 26-bit cond)
        ANDNE   a1, a1, PSR32IBit
        ]
        Return  ,LinkNotStacked
d225 1
a225 2
        FunctionEntry
|_kernel_RMAalloc_from_extend
d227 3
a229 3
        Return  ,,EQ
        MOV     r0, #Module_Claim
        SWI     Module
d232 1
a232 1
        Return
a234 1
        FunctionEntry
d237 1
a237 1
        BEQ     |_kernel_RMAalloc_from_extend|
d239 2
a240 1
        BEQ     |_kernel_RMAfree_from_extend|
d249 1
a249 1
        Return
d252 1
a252 2
        FunctionEntry
|_kernel_RMAfree_from_extend|
d257 1
a257 1
        Return
d265 1
a265 1
        MOV     pc, r14
d270 1
a270 6
        [ {CONFIG}=26
        BICS    pc, lr, #PSRIBit        ; 32-bit OK - in {CONFIG}=26
        |
        CLRPSR  #PSR32Ibit
        MOV     pr, lr
        ]
d273 1
a273 6
        [ {CONFIG}=26
        ORRS    pc, lr, #PSRIBit
        |
        PHPSEI  a2, a3
        MOV     pc, lr
        ]
a275 1
        [ {CONFIG}=26
d279 1
a279 5
        |
        MRS     a1, CPSR
        AND     a1, a1, #PSR32Mode
        MOV     pc, lr
        ]
a282 1
        [ {CONFIG}=26
a283 4
        |
        MRS     a1, CPSR
        ANDS    a1, a1, #PSR32Privileged
        ]
d286 1
a286 1
        Return  ,LinkNotStacked
a450 1
        LDREQ   r1, [v6, #O_heapLimit]
d454 1
d498 1
a498 1
        MOV     pc, r14
a525 1
        [ {CONFIG}=26
a526 3
        |
        LDMIB   sp, {r4-r9, fp, sp, pc}
        ]
d581 1
a581 1
        Return  ,LinkNotStacked, EQ
a582 1
        [ {CONFIG}=26
a583 4
        |
        MRS     ip, CPSR
        ANDS    ip, ip, #PSR32Privileged
        ]
d664 1
a664 1
        Return  ,LinkNotStacked
d669 1
a669 1
        Return  ,LinkNotStacked
d729 1
a729 8
        STMFD   r13!, {r11, r12}
        MOV     r12, #0
        MRS     r12, CPSR
        TST     r12, #2_11100
        ANDEQ   r11, r14, #3            ; obtain aborter's mode from R14
        MRSNE   r11, SPSR               ; obtain aborter's mode from SPSR
        TST     r11, #PSR32Privileged
        LDMEQFD r13!, {r11, r12}
a731 2
        TST     r12, #2_11100
        LDMFD   sp!, {r11-r12}
d733 1
a733 2
        BICEQ   r6, r14, #PSRBits       ; 32-bit OK (26-bit cond)
        MOVNE   r6, r14
d774 2
a775 2
; entry here in SVC26, SVC32, ABT32 or UND32 mode
; r0 a pointer to an error block describing the abort.
d793 5
a797 16

        MOV     r6, r14                 ; switch it to a non-banked register
        MOV     r4, #0
        MRS     r4, CPSR
        TST     r4, #2_11100
        ANDEQ   r5, r1, #3              ; obtain aborter's mode from R14
        MRSNE   r5, SPSR                ; obtain aborter's mode from SPSR
        STRNE   r5, [r14, #16*4]        ; store aborter's SPSR if in 32-bit mode
        BICNE   r4, r4, #PSR32Mode
        ORRNE   r4, r4, PSR32SVCMode
        MSRNE   CPSR_c, r4              ; switch to SVC32 (already in SVC26 if 26bit)
        TST     r5, #PSR32Privileged
        LDRNE   r1, [r6, #lr*4]
        STR     r1, [r6, #pc*4]
        STR     r2, [r6, #r0*4]
        STREQ   r3, [r6, #r12*4]
d806 1
a806 1
        ADD     r4, r6, #10 * 4
d832 1
a832 1
        ADD     r11, v6, #O_registerDump+17*4
d901 2
a902 4
        ; At this point, r12 is the user mode stack pointer and r11 points just past
        ; the 17th entry of the register dump.
        LDMDB   r11!, {a1-a4, v2-v5, lr}
        STMDB   r12!, {a1-a4, v2-v5, lr}
d909 1
a909 11
        MOV     a1, #0
        MRS     a1, CPSR
        TST     a1, #2_11100
        BEQ     %FT01                                   ; 26-bit mode
        LDRB    a2, [v6, #O_ClientFlags]                ; look for caller type
        TST     a2, #ClientFlag_32bit                   ; client in USR32?
        MSREQ   CPSR_c, #PSR32IBit | PSRUSRMode         ; USR26, I set
        MSRNE   CPSR_c, #PSR32IBit | PSR32USRMode       ; USR32, I set
        MSR     CPSR_f, #PSRVBit                        ; set V for calling IntOn.
        B       %FT02
01      LDR     a1, [v6, #O_registerDump+pc*4]
a913 1
02
a914 1
     [ No32bitCode
a915 10
     |
        MRS     a1, CPSR
        ORR     a1, a1, #PSR32IBit                      ; may not need this
        ORR     a1, a1, #PSRVBit
        BIC     a1, a1, #PSR32Privileged
        LDRB    a2, [v6, #O_ClientFlags]                ; look for caller type
        TST     a2, #ClientFlag_32bit                   ; client in USR32?
        BICEQ   a1, a1, #2_10000                        ; no - so we want USR26
        MSR     CPSR_cf, a1                             ; switch to user mode
     ]
d1047 1
a1047 1
        Return  ,LinkNotStacked
d1056 1
a1056 1
        Return  ,LinkNotStacked
a1901 1
; Abort handlers assume that lr is preserved
d1904 3
a1906 1
        FunctionEntry "a3, a4, v1-v6", makeframe
d1920 1
a1920 1
        Return  "v1-v6", fpbased
d1924 3
a1926 1
        FunctionEntry "a3, a4, v1-v6", makeframe
d1949 1
a1949 1
        Return  "v1-v6", fpbased
a1954 1
; Abort handlers assume that lr is preserved
d1957 1
a1957 1
        FunctionEntry "a3, v1-v6"
d1967 1
a1967 1
        Return  "a3, v1-v6"
d1969 1
a1969 1
        FunctionEntry "a3, v1-v6"
d1982 1
a1982 1
        Return  "a3, v1-v6"
d1989 1
a1989 1
        MOV     pc, r14
d1992 1
a1992 1
        FunctionEntry "v6"
d2000 1
a2000 1
        Return  "v6"
d2003 1
a2003 1
        FunctionEntry "v6"
d2006 1
a2006 1
        Return  "v6",,CC
d2010 1
a2010 1
        Return  "v6"
d2013 1
a2013 1
        FunctionEntry "v6"
d2015 1
a2016 1
ErrorExitV6Stacked
d2022 1
a2022 1
        FunctionEntry "v6"
d2027 1
a2027 1
        Return  "v6"
d2030 1
a2030 1
        FunctionEntry "v6"
d2032 1
a2032 1
        Return  "v6",,VC
d2043 1
a2043 1
        FunctionEntry "r4, r5, r6, r7, v6"
d2048 2
a2049 2
        BLVS    CopyError               ; BL<cond> 32-bit OK
        MOVCS   a1, #-1                 ; CopyError preserves C and V
d2051 1
a2051 1
        Return  "r4, r5, r6, r7, v6"
d2054 1
a2054 1
        FunctionEntry "v6"
d2058 1
a2058 1
        Return  "v6"
d2077 3
a2079 2
        BLVS    CopyError               ; BL<cond> 32-bit OK
        MOVVS   a1, #-2
d2083 1
a2083 1
        FunctionEntry "v6"
d2093 1
a2093 1
        FunctionEntry "v6"
d2097 1
a2097 1
        Return  "v6"
d2106 1
a2106 1
        Return  ,LinkNotStacked
d2176 1
a2176 1
        RemovePSRFroMReg pc, v4, v4     ; where to copy down to before jumping
a2204 6
        BNE     %FT01

        MOV     r0, #Env_MemoryLimit
        LDR     r1, [v6, #O_imageBase]
        ADD     r1, r1, r14
        SWI     ChangeEnv
d2206 20
a2225 15
        MOV     r0, #Env_ErrorHandler
        ADR     r1, s_ErrHandler
        MOV     r2, v6
        ADD     r3, v6, #O_errorBuffer
        SWI     ChangeEnv

        MOV     r0, #Env_ExitHandler
        ADR     r1, s_ExitHandler
        MOV     r2, v6
        SWI     ChangeEnv

        MOV     r0, #Env_UpCallHandler  ; We don't really want one of these, ...
        ADR     r1, s_UpCallHandler     ; but RISCOS rules say we must have it
        MOV     r2, v6
        SWI     ChangeEnv
d2227 1
a2227 1
01      LDR     r0, [ip, #32]           ; the CLI string to execute
d2269 1
a2269 1
        RemovePSRFromReg pc, v3, v3     ; == BIC v3, pc, #&FC000003 in 26bit
d2311 1
a2311 1
        Return  "v1-v6"
a2315 2
        ; This routine MUST preserve the C and V flags across the call.
        ; The BICS only affects N and Z (C not changed as barrel shifter not used)
d2327 2
a2328 2
        BICS    a3, a3, #&1F            ; replaces CMP a3, #' '
        BNE     %B01                    ; replaces BCS %B01
d3086 1
a3086 1
        RemovePSRFromReg r14, r1, r0            ; == BIC r0, r14, #PSRBits  IFF 26bit
@


4.5.2.8
log
@More 32-bit compatibility added.  All the C code should now be OK.
Fixed some typos in kernel.s.k_body too.

Version 4.97, 4.12.2.6. Tagged as 'RISC_OSLib-4_97-4_12_2_6'
@
text
@d108 1
a108 1
PSR32USRMode    *       &00000010
d236 1
a236 1
|_kernel_RMAalloc_from_extend|
d853 1
a853 1
        ORRNE   r4, r4, #PSR32SVCMode
d2259 1
a2259 1
        RemovePSRFromReg pc, v4, v4     ; where to copy down to before jumping
@


4.5.2.9
log
@More 32-bit work. Now functional, but still need to sort out various
build issues.

Version 4.97, 4.12.2.7. Tagged as 'RISC_OSLib-4_97-4_12_2_7'
@
text
@d226 1
a226 1
        MOV     a1, #0
d228 1
a228 1
        TST     a1, #2_11100            ; Z set if in 26-bit mode
d230 1
a230 1
        ANDNE   a1, a1, #PSR32IBit
d285 2
a286 2
        CLRPSR  PSRIBit, ip
        MOV     pc, lr
d293 1
a293 1
        SETPSR  PSRIBit, ip
d313 2
a314 2
        MRS     ip, CPSR
        TST     ip, #PSR32Privileged
d522 1
a522 1
        LDMIA   r5!, {r6, r7}                   ; first 2 instructions
d524 6
a529 3
        LDR     r6, =&E51FF004                  ; LDR PC,<nextword>
        STR     r6, [r4], #4
        STR     r5, [r4]                        ; address of main handler
a531 2
        LTORG

a717 2
        LTORG

d843 1
a843 1
        LDMFD   r13!, {r1, r2, r3}      ; abort PC, R0, R12
d856 2
a857 2
        LDRNE   r1, [r6, #lr*4]         ; if aborted in a privileged mode, save
        STR     r1, [r6, #pc*4]         ; PC as user R14
d977 4
a980 5
     [ {CONFIG}=26
        MSR     CPSR_c, #PSR32IBit + PSRUSRMode         ; USR26, I set
     |
        MSR     CPSR_c, #PSR32IBit + PSR32USRMode       ; USR32, I set
     ]
d996 4
a999 5
      [ {CONFIG}=26
        BIC     a1, a1, #PSR32Privileged                ; into USR26 mode
      |
        BIC     a1, a1, #PSR32Mode                      ; into USR32 mode
      ]
d1061 1
d1066 1
a1066 3
        ; We just trample all over the start of our workspace.
        ; Fine, as we've removed handlers and are about to go pop.
        ADD     r2, v6, #O_FatalErrorBuffer
d1077 1
a1077 1
        ADD     a2, v6, #O_FatalErrorBuffer
d1107 1
a1107 1
        ADD     r0, v6, #O_FatalErrorBuffer
d1154 1
a1154 1
        ; set up an initial unwind block.  For our purposes, we don't care
a1165 1
        [ {CONFIG}=26
a1166 1
        ]
d1197 3
a1199 5
        BNE     FCH_CallClient
        MOV     lr, pc
        MOV     pc, r2
        B       FCH_ClientCalled
FCH_CallClient
a1235 1
        [ {CONFIG}=26
a1236 3
        |
        LDMFD   sp!, {pc}
        ]
d1252 1
a1252 1
        Return  ,LinkNotStacked
d1283 1
a1283 1
        Return  ,LinkNotStacked
d1318 2
a1320 12
        [ No32bitCode
        TEQP    pc, #0
        NOP
        |
        MRS     r0, CPSR                        ; note current mode
        STR     r0, [sp, #-4]!
        [ {CONFIG}=26
        MSR     CPSR_c, #PSRUSRMode
        |
        MSR     CPSR_c, #PSR32USRMode
        ]
        ]
d1328 2
a1329 9
        [ No32bitCode
        LDMFD   sp!, {r0-r3, v1-v6, fp, sl, pc}^
        |
        LDR     r0, [sp], #4
        MSR     CPSR_c, r0                      ; back into original mode
        TST     r0, #2_11100                    ; 26 or 32-bit exit?
        LDMEQFD sp!, {r0-r3, v1-v6, fp, sl, pc}^
        LDMFD   sp!, {r0-r3, v1-v6, fp, sl, pc}
        ]
d1398 1
a1398 1
        Return  ,LinkNotStacked
d1444 1
a1444 1
        Return  ,LinkNotStacked
d1475 1
a1475 5
        MOV     r14, #0
        STR     r14, [r12, #O_registerDump+16*4]        ; zero PSR
        MRS     r14, CPSR
        TST     r14, #2_11100
        BICEQ   r1, r1, #&fc000003      ; Sanitize PC value
d1538 1
a1569 3
        MRS     r0, CPSR
        TST     r0, #2_11100

a1579 4
        ; if in a 26-bit mode - mark PSR in register dump as invalid.
        MOVEQ   r12, #-1
        STREQ   r12, [r11]

d1612 1
a1612 6
        MOV     r14, #0
        MRS     r14, CPSR
        TST     r14, #2_11100
        BICEQ   r14, r0, #PSRBits               ; 26-bit: R0 is PC+PSR
        MOVNE   r14, r0                         ; 32-bit: R0 is PC
        LDRNE   r0, [v6, #O_registerDump+16*4]  ;         get PSR
d1682 3
a1684 3
        LDMDA   r11!, {r0-r7, r14}
        STMDB   r12!, {r0-r7, r14}
        LDMDA   r11!, {r0-r7}
d1688 1
a1688 1
        WritePSRc PSRIBit+PSRSVCMode, r1; we want the testing for an escape and
d1696 5
a1700 7
        BEQ     %FT01
        MOV     r0, #&7e
        SWI     Byte
        MOV     v1, #-1                 ; escape overrides everything else
01
        [ No32bitCode
        TEQP    pc, #PSRIBit            ; to user mode, with interrupts off
a1701 8
        |
        [ {CONFIG}=26
        MSR     CPSR_c, #PSR32IBit + PSRUSRMode
        |
        MSR     CPSR_c, #PSR32IBit + PSR32USRMode
        ]
        ]

d1709 1
d1728 1
a1728 2
        [ No32bitCode
        TEQP    pc, #PSRIBit+PSRSVCMode
a1729 7
        |
        LDR     r1, [r0, #16*4]
        CMP     r1, #-1
        MSRNE   CPSR_c, #PSR32IBit+PSR32SVCMode
        MSREQ   CPSR_c, #PSR32IBit+PSRSVCMode
        MSRNE   SPSR_cxsf, r1
        ]
d1764 1
a1764 1
        Return  ,LinkNotStacked
d1775 1
a1775 1
        Return  ,LinkNotStacked
d1779 1
a1779 1
        FunctionEntry "v2, v4-v6"
a1781 1
        [ {CONFIG}=26
a1782 1
        ]
d1785 1
a1785 1
        Return  "v2, v4-v6"
d1789 1
a1789 1
        FunctionEntry "v2, v4-v6"
a1791 1
        [ {CONFIG}=26
a1792 1
        ]
d1796 1
a1796 1
        Return  "v2, v4-v6",,EQ
d1804 1
a1804 1
        Return  "v2, v4-v6"
d1808 1
a1808 1
        FunctionEntry "a1, a2, v2, v4-v6"
d1824 1
a1824 1
        Return  "v2, v4-v6"
a1844 1
        [ {CONFIG}=26
a1845 1
        ]
a1951 1
        [ {CONFIG}=26
a1952 1
        ]
d1962 1
a1962 1
        Return  "v1-v6"
d1966 2
a1967 7
        MOV     r14, #0
        MRS     r14, CPSR
        TST     r14, #2_11100
        LDRNE   r14, [v6, #O_registerDump+16*4]
        MSRNE   CPSR_c, r14
        LDREQ   r14, [v6, #O_registerDump+pc*4]
        TEQEQP  r14, #0                 ; Back to the mode and interrupt
d2298 1
a2298 1
        ADDEQ   r3, v6, #O_errorBuffer
d2533 1
a2533 1
        Return  ,LinkNotStacked
d2582 1
a2582 1
        Return  ,LinkNotStacked, GE
d2590 1
a2590 1
        Return  ,LinkNotStacked         ; and don't update heapTop)
a2678 1
     [ SharedLibrary
a2683 3
     |
        ADR     lr, StackOverflowExit
     ]
a2686 1
        [ {CONFIG}=26
a2687 3
        |
        LDMDA   v1, {a1, a2, v1-v6, pc}
        ]
a2743 1
      [ SharedLibrary
a2748 3
      |
        ADR     v5, StackOverflowExit
      ]
a2769 1
        [ {CONFIG}=26
a2770 3
        |
        LDMDA   v1, {a1, a2, v1-v6, pc}
        ]
a2774 1
      [ SharedLibrary
a2782 1
      ]
d2839 1
a2839 1
        Return  ,LinkNotStacked
a2846 1
      [ {CONFIG}=26
a2849 6
      |
        MRS     v2, CPSR
        TST     v2, #PSR32Privileged
        MSRNE   CPSR_f, #V_bit          ; maintain NE
        MOVNE   pc, lr
      ]
d2919 1
a2919 1
        Return  "a3, a4, ip"            ; restore extra saved regs
a2920 1
        [ {CONFIG}=26
a2922 4
        |
        MSR     CPSR_f, #V_bit
        LDMFD   sp!, {a3, a4, ip, pc}
        ]
d3134 1
d3315 1
a3315 1
        Return  ,LinkNotStacked
d3318 1
a3318 1
        Return  ,LinkNotStacked
@


4.5.2.10
log
@Features:

* APCS-32 support complete.
* APCS-A compatibility removed.
* Old ArthurLib code removed.
* _clib_version() now reports version from VersionNum.
* time() no longer does a run-time host check - I think we know we're not a BBC
  Master ARM second processor now.
* rename() now uses OS_FSControl 25 instead of *rename.
* getenv() can handle arbitrary length variables.
* Can now handle exceptions in 32-bit form of FPEmulator (on either 26 or 32
  bit systems).
* tmpnam() switches to SVC mode to access its zero page counter.
* Faster divide routines.

Admin:

  This will build all sorts of different things depending on the flags. See
  the Docs directory for details.

  As far as ROM builds are concerned, if using APCS-R, no changes are needed.
  If using APCS-32, the Shared C Library must be built as APCS-R to ensure
  compatibility with old binaries. To achieve this, pass in the option
  SCL_APCS="-APCS 3/26bit" in the Components file.

Version 4.97, 4.12.2.8. Tagged as 'RISC_OSLib-4_97-4_12_2_8'
@
text
@a109 1
PSR32UNDMode    *       &0000001B
d154 5
d161 10
a170 1
        ; If shared library, used to worry about calling standard change.
d173 6
d183 1
a183 1
 [ :LNOT:(SharedLibrary :LAND: {CONFIG}=26)
d186 8
a193 3
  ; If we're 26-bit and a shared library, we need to cope with APCS-32
  ; clients not preserving flags
        FunctionEntry
d196 7
a202 1
        Return
d223 4
a226 3
 [ {CONFIG} = 26
        AND     a1, lr, #PSRIBit
 |
d228 4
a231 2
        AND     a1, a1, #PSR32IBit
 ]
d277 1
a277 1
        Return  ,LinkNotStacked
d282 1
a282 1
 [ {CONFIG}=26
d284 4
a287 6
 |
        MRS     ip, CPSR
        BIC     ip, ip, #PSR32IBit
        MSR     CPSR_c, ip
        Return  ,LinkNotStacked
 ]
d290 1
a290 1
      [ {CONFIG}=26
d292 4
a295 6
      |
        MRS     ip, CPSR
        ORR     ip, ip, #PSR32IBit
        MSR     CPSR_c, ip
        Return  ,LinkNotStacked
      ]
d298 3
a300 3
      [ {CONFIG}=26
        AND     a1, lr, #3      ; the question is anyway about the caller's
        MOVS    pc, lr          ; state, not ours - the answers are probably
d302 1
a302 1
      |
d306 1
a306 1
      ]
d310 1
a310 1
      [ {CONFIG}=26
d312 1
a312 1
      |
d315 1
a315 1
      ]
d393 1
a393 1
        NOP
d411 1
a411 1
        NOP
a453 10
        ; Check where the stacks are
        ASSERT  O_svcStack = O_undStack + 4
        MOV     r0, #6
        ADR     r1, RSI6_List
        ADD     r2, v6, #O_undStack
        SWI     XOS_ReadSysInfo
        LDRVS   r0, =&01E02000
        LDRVS   r1, =&01C02000
        STMVSIA r2, {r0, r1}

a530 3
RSI6_List
        DCD     15, 16

a536 1
        [ {CONFIG} = 26
a537 4
        |
        MRS     ip, CPSR
        TST     ip, #PSR32Privileged
        ]
d622 1
a622 1
        TST     ip, #PSR32Privileged
a769 23
; Try the FPEmulator_Abort SWI
        STMFD   sp!, {r0-r2, r14}
      [ {CONFIG}=26
        BIC     r14, r14, #PSRBits
      |
        MOV     r0, #0
        MRS     r0, CPSR
        TST     r0, #2_11100
        BICEQ   r14, r14, #PSRBits
      ]
        MOV     r0, #-2                 ; current context
        LDR     r1, [sp, #20]           ; original r12
        ADD     r2, r14, #8             ; original r14
        SWI     XFPEmulator_Abort
        BVS     NoFPEAbortSWI
        TEQ     r0, #0
        LDMEQFD sp!, {r0-r2, r14}
        BEQ     Aborted                 ; not in FPEmulator
        STR     r0, [sp, #20]           ; update r12 in stack
        LDMFD   sp!, {r0-r2, r14}
        B       FPEFault

NoFPEAbortSWI
d771 8
a778 13
      [ {CONFIG}=26
        LDR     r1, [sp, #12]
        TST     r1, #PSRPrivileged
      |
        MOV     r2, #0
        MRS     r2, CPSR
        TST     r2, #2_11100
        LDREQ   r1, [sp, #12]
        ANDEQ   r1, r1, #3              ; obtain aborter's mode from R14
        MRSNE   r1, SPSR                ; obtain aborter's mode from SPSR
        TST     r1, #PSR32Privileged
      ]
        LDMEQFD sp!, {r0-r2, r14}
a779 1

d781 2
a782 4
      [ {CONFIG} <> 26
        TST     r2, #2_11100
      ]
        LDMFD   sp!, {r0-r2, r14}
a783 3
      [ {CONFIG} = 26
        BIC     r6, r14, #PSRBits
      |
a785 1
      ]
d800 6
a805 8
; We assume FPEmulator 4.00 or later - r12 in the register dump
; will point to a full register save. The format differs slightly
; depending on whether the FPEmulator is 32-bit or not. If we're
; in a 32-bit mode, we know the FPEmulator will be. If not, check
; to see if the saved r12 is in the UND stack.
FPEFault
        LDR     r1, [r13, #4]           ; r1 -> FPE stack frame
        ADD     r13, r13, #8            ; pop the saved values of r0 and r12
d807 2
a808 1
        LDMIA   r1!, {r2-r9}            ; copy R0-R15
a810 1
        SUB     r9, r9, #4
d812 2
a813 33
      [ {CONFIG}<>26
        MOV     r2, #0
        MRS     r2, CPSR
        TST     r2, #2_11100
        BNE     FPEFault_32on32
      ]
        LDR     r3, [r12, #O_undStack]
        MOV     r2, r1, LSR #20         ; we're on a 26-bit system
        TEQ     r2, r3, LSR #20         ; is the stack frame in the UND stack?
        BEQ     FPEFault_32on26
FPEFault_26on26
        MOV     sp, r1                  ; pull the SVC stack up
        B       AbortFindHandler

FPEFault_32on26
        LDR     r2, [r1, #-72]          ; get the SPSR
        AND     r2, r2, #PSRBits
        BIC     r9, r9, #PSRBits
        ORR     r9, r9, r2
        STR     r9, [r14, #-4]          ; merge it with pc in register dump
        B       FPEFault_32

FPEFault_32on32
        LDR     r2, [r1, #-72]          ; get the SPSR
        STR     r2, [r14]               ; store it in the register dump

FPEFault_32
        MRS     r2, CPSR
        BIC     r3, r2, #PSR32Mode
        ORR     r3, r3, #PSR32IBit + PSR32UNDMode
        MSR     CPSR_c, r3
        MOV     sp, r1                  ; pull the UND stack up
        MSR     CPSR_c, r2
d823 2
d862 3
a864 1
        LDR     r4, [r12, #O_svcStack]
d900 50
d962 1
d1007 1
a1007 1
        NOP
d1043 1
a1043 1
        NOP
d1321 1
a1321 1
        TEQ     r0, #256
d1331 2
a1332 1
        WritePSRc PSRUSRMode, r0
d1334 9
d1350 7
d1358 1
d1619 89
d1724 1
d1745 4
d1750 1
a1750 2
        TEQP    pc, #PSRIBit            ; to user mode, with interrupts off
        NOP
d1752 2
a1753 1
        WritePSRc PSRIBit+PSRUSRMode, r0
d1764 1
a1764 1
        ASSERT  sl = r10
d1781 1
a1781 1
        [ {CONFIG}=26
d1783 1
a1783 1
        NOP
d1793 1
a1793 1
        NOP
d1843 3
a1845 1
        RemovePSRFromReg a1, lr, r1
d1855 3
a1857 1
        RemovePSRFromReg a1, lr, r1
d1876 1
a1876 1
        RemovePSRFromReg r1, lr
d1899 1
a1899 1
        BICS    a4, a4, #ChunkChange
d1904 1
a1904 1
        ; (bottom bit used to mark stack extension).
d1906 1
a1906 1
        TST     a4, #&00000002
d1910 3
a1912 1
        RemovePSRFromReg a3, v1
d1928 2
a1929 1
        EORS    ip, ip, #&002d          ; STMFD sp!, ... (sp = r13)
d2012 1
a2012 1
        BIC     a3, a3, #ChunkChange
d2019 3
a2021 1
        RemovePSRFromReg v1, v2, r1
d2043 1
a2043 1
        NOP
d2064 1
d2080 31
d2114 1
d2126 16
d2147 1
a2147 1
        Return  ,LinkNotStacked
d2273 4
a2276 1
        SFMNEFD f4, 4, [sp]!
d2465 4
a2468 1
        LFMNEFD f4, 4, [sp]!
d2489 1
a2489 1
        MOV     pc, lr
a2494 1
        SUB     r2, r2, #1
d2530 1
a2530 1
        Return  ,LinkNotStacked
d2693 1
a2693 1
        Return  ,LinkNotStacked
d2701 1
a2701 1
        Return  ,LinkNotStacked
d2753 7
d2761 1
d2826 7
d2834 1
d2865 11
d2880 7
a2886 1

d2892 1
a2892 1
        STMFD   sp!, {a1-a2, v1-v4}     ; Save some work regs
d2925 7
a2931 2
; Return
        Return  "a1-a2, v1-v4", fpbased
d3046 1
a3046 1
; Destroys a3 and ip
d3048 61
a3108 47
        MOV     a3, #0
        RSBS    ip, a1, a2, LSR #3
        BCC     u_sh2
        RSBS    ip, a1, a2, LSR #8
        BCC     u_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&FF000000
        RSBS    ip, a1, a2, LSR #4
        BCC     u_sh3
        RSBS    ip, a1, a2, LSR #8
        BCC     u_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&00FF0000
        RSBS    ip, a1, a2, LSR #8
        MOVCS   a1, a1, LSL #8
        ORRCS   a3, a3, #&0000FF00
        RSBS    ip, a1, a2, LSR #4
        BCC     u_sh3
        RSBS    ip, a1, #0
        BCS     dividebyzero
u_loop  MOVCS   a1, a1, LSR #8
u_sh7   RSBS    ip, a1, a2, LSR #7
        SUBCS   a2, a2, a1, LSL #7
        ADC     a3, a3, a3
u_sh6   RSBS    ip, a1, a2, LSR #6
        SUBCS   a2, a2, a1, LSL #6
        ADC     a3, a3, a3
u_sh5   RSBS    ip, a1, a2, LSR #5
        SUBCS   a2, a2, a1, LSL #5
        ADC     a3, a3, a3
u_sh4   RSBS    ip, a1, a2, LSR #4
        SUBCS   a2, a2, a1, LSL #4
        ADC     a3, a3, a3
u_sh3   RSBS    ip, a1, a2, LSR #3
        SUBCS   a2, a2, a1, LSL #3
        ADC     a3, a3, a3
u_sh2   RSBS    ip, a1, a2, LSR #2
        SUBCS   a2, a2, a1, LSL #2
        ADC     a3, a3, a3
u_sh1   RSBS    ip, a1, a2, LSR #1
        SUBCS   a2, a2, a1, LSL #1
        ADC     a3, a3, a3
u_sh0   RSBS    ip, a1, a2
        SUBCS   a2, a2, a1
        ADCS    a3, a3, a3
        BCS     u_loop
        MOV     a1, a3
a3110 1

d3115 2
d3126 7
d3136 3
a3138 2
        SUB     a2, a1, #10
        SUB     a1, a1, a1, LSR #2
d3143 5
a3147 4
        ADD     a3, a1, a1, LSL #2
        SUBS    a2, a2, a3, LSL #1
        ADDPL   a1, a1, #1
        ADDMI   a2, a2, #10
d3158 74
a3231 53

        ANDS    a3, a1, #&80000000
        RSBMI   a1, a1, #0
        EORS    a4, a3, a2, ASR #32
        RSBCS   a2, a2, #0
        RSBS    ip, a1, a2, LSR #3
        BCC     s_sh2
        RSBS    ip, a1, a2, LSR #8
        BCC     s_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&FF000000
        RSBS    ip, a1, a2, LSR #4
        BCC     s_sh3
        RSBS    ip, a1, a2, LSR #8
        BCC     s_sh7
        MOV     a1, a1, LSL #8
        ORR     a3, a3, #&00FF0000
        RSBS    ip, a1, a2, LSR #8
        MOVCS   a1, a1, LSL #8
        ORRCS   a3, a3, #&0000FF00
        RSBS    ip, a1, a2, LSR #4
        BCC     s_sh3
        RSBS    ip, a1, #0
        BCS     dividebyzero
s_loop  MOVCS   a1, a1, LSR #8
s_sh7   RSBS    ip, a1, a2, LSR #7
        SUBCS   a2, a2, a1, LSL #7
        ADC     a3, a3, a3
s_sh6   RSBS    ip, a1, a2, LSR #6
        SUBCS   a2, a2, a1, LSL #6
        ADC     a3, a3, a3
s_sh5   RSBS    ip, a1, a2, LSR #5
        SUBCS   a2, a2, a1, LSL #5
        ADC     a3, a3, a3
s_sh4   RSBS    ip, a1, a2, LSR #4
        SUBCS   a2, a2, a1, LSL #4
        ADC     a3, a3, a3
s_sh3   RSBS    ip, a1, a2, LSR #3
        SUBCS   a2, a2, a1, LSL #3
        ADC     a3, a3, a3
s_sh2   RSBS    ip, a1, a2, LSR #2
        SUBCS   a2, a2, a1, LSL #2
        ADC     a3, a3, a3
s_sh1   RSBS    ip, a1, a2, LSR #1
        SUBCS   a2, a2, a1, LSL #1
        ADC     a3, a3, a3
s_sh0   RSBS    ip, a1, a2
        SUBCS   a2, a2, a1
        ADCS    a3, a3, a3
        BCS     s_loop
        EORS    a1, a3, a4, ASR #31
        ADD     a1, a1, a4, LSR #31
        RSBCS   a2, a2, #0
d3250 3
a3252 2
        SUB     a2, a1, #10
        SUB     a1, a1, a1, LSR #2
d3257 6
a3262 5
        ADD     a3, a1, a1, LSL #2
        SUBS    a2, a2, a3, LSL #1
        ADDPL   a1, a1, #1
        ADDMI   a2, a2, #10
        MOVS    a4, a4
d3291 1
a3291 1
        NOP
d3321 1
a3426 1
        SWI     EnterSVC
a3433 2
        WritePSRc PSRUSRMode, r0
        NOP
@


4.4
log
@Fixed h_StrongA to pick up the processor type and fixed knock-on problems
@
text
@a493 2
XOS_ReadVarVal          EQU     &20023
XOS_ReadDynamicArea     EQU     &2005c
a1880 3
  [ StrongARMfudge
    SyncStackCode 2
  ]
a1918 3
  [ StrongARMfudge
    SyncStackCode 2
  ]
a3075 2

OS_Module           EQU &1e
@


4.3
log
@Version RO_3_71 taken
@
text
@d1883 1
a1883 1
  [ {TRUE}
d1924 1
a1924 1
  [ {TRUE}
@


4.2
log
@Version RO_3_70 taken
@
text
@d778 7
a784 4
  [ SAnaffsilicon
    NOP
    NOP
  ]
a785 3
  [ SAnaffsilicon
    NOP
    NOP
d787 1
d1371 8
a1378 3
  [ SAnaffsilicon
    NOP
    NOP
d1380 1
a1380 1
        STMIA   r14, {r0-r14}^
d1412 1
a1412 4
  [ SAnaffsilicon
    NOP
    NOP
  ]
a1631 3
  [ SAnaffsilicon
    NOP
  ]
d1861 1
a1861 1
        MOVCS   ip, #1 
a3035 3
  [ SAnaffsilicon
    NOP
  ]
@


4.1
log
@Initial revision
@
text
@d26 1
d429 6
d481 2
d778 4
d783 4
d1370 4
d1406 4
d1629 3
d1746 10
d1757 1
d1849 19
d1883 3
d1899 1
d1905 13
d1924 3
d1935 2
d2135 6
d2148 3
d2228 8
d2244 5
d2531 10
d2542 1
d2613 8
d2622 1
d3036 3
@


4.1.7.1
log
@NCOS 1.06 Imported from Zip drive
@
text
@@


4.1.5.1
log
@Import from SrcFiler
@
text
@@


4.1.3.1
log
@Import from cleaned 370 CD
@
text
@a25 1
        GET     s.h_StrongA
a427 6
 [ StrongARM   ;CopyHandler does some dynamic code
   ;r0,lr are free to use here
   MOV   r0, #0
   SWI   XOS_SynchroniseCodeAreas
 ]

a473 2
;StrongARM - there is dynamic code here, but this is sorted in _kernel_init, after
;all calls to CopyHandler
a768 4
  [ SAnaffsilicon
    NOP
    NOP
  ]
a769 4
  [ SAnaffsilicon
    NOP
    NOP
  ]
a1352 4
  [ SAnaffsilicon
    NOP
    NOP
  ]
a1384 4
  [ SAnaffsilicon
    NOP
    NOP
  ]
a1603 3
  [ SAnaffsilicon
    NOP
  ]
a1717 10
        [ StrongARM
        STMFD   sp!, {a1-a2}
        MOV     a1, #0
        SWI     XOS_PlatformFeatures
        MOVVS   a1, #0
        TST     a1, #8
        LDREQ   v1, [a3, #-12]
        LDRNE   v1, [a3, #-8]
        LDMFD   sp!, {a1-a2}
        |
a1718 1
        ]
a1809 19
  [ StrongARM
        MOV     ip, sp
        STMFD   sp!, {a3, a4, v1-v6, fp, ip, r14, pc}
        SUB     fp, ip, #4
        BIC     r12, a1, #&80000000
        TST     a1, #&80000000          ; non-X bit requested?
        ORREQ   r12, r12, #X
        LDMIA   r1, {r0-r9}
        SWI     XOS_CallASWIR12
        LDMFD   sp!, {ip, lr}
        STMIA   ip, {r0 - r9}
        MOV     ip, #0
        MOVCS   ip, #1 
        MOVVS   ip, #0
        STR     ip, [lr]
        BLVS    CopyError
        MOVVC   a1, #0
        LDMDB   fp, {v1-v6, fp, sp, pc}^
  |
a1824 3
  [ {TRUE}
    SyncStackCode 2
  ]
a1837 1
  ]
a1842 13
  [ StrongARM
        STMDB   sp!, {a3, v1-v6, lr}
        BIC     r12, a1, #&80000000
        TST     a1, #&80000000
        ORREQ   r12, r12, #X
        LDMIA   r1, {r0-r9}
        SWI     XOS_CallASWIR12
        LDR     ip, [sp]
        STMIA   ip, {r0-r9}
        BLVS    CopyError
        MOVVC   a1, #0
        LDMIA   sp!, {a3, v1-v6, pc}^
  |
a1848 3
  [ {TRUE}
    SyncStackCode 2
  ]
a1856 2
  ]

a2054 6
  [ StrongARM
    ;in case we are jumping to code we have just copied here (ie not shared Clib)...
    CMP   v2, #0
    MOVNE r0, #0
    SWINE XOS_SynchroniseCodeAreas
  ]
a2061 3
  ;StrongARM - no need to synchronise for rest of copied code here, since we will not
  ;be executing it (we have to synchronise later, after copying down)

a2138 8
  [ StrongARM
    ;in case we are jumping to code we have just copied here (ie not shared Clib)...
    MOV   r1, r0
    CMP   v1, #0
    MOVNE r0, #0
    SWINE XOS_SynchroniseCodeAreas
    MOV   r0, r1
  ]
a2146 5
  [ StrongARM
    ;you've guessed it
    MOV    r0, #0
    SWI    XOS_SynchroniseCodeAreas
  ]
a2428 10
        [ StrongARM
        STMFD   sp!,{a1-a2}
        MOV     a1,#0
        SWI     XOS_PlatformFeatures
        MOVVS   a1,#0
        TST     a1,#8
        ADREQ   v6, StkOvfPseudoEntry+12
        ADRNE   v6, StkOvfPseudoEntry+8
        LDMFD   sp!,{a1-a2}
        |
a2429 1
        ]
a2499 8
        [ StrongARM
        MOV     a1,#0
        SWI     XOS_PlatformFeatures
        MOVVS   a1,#0
        TST     a1,#8
        ADREQ   v2, StkOvfPseudoEntry+12
        ADRNE   v2, StkOvfPseudoEntry+8
        |
a2500 1
        ]
a2913 3
  [ SAnaffsilicon
    NOP
  ]
@


4.1.3.2
log
@Version RO_3_70 taken
@
text
@d778 4
a781 7

  [ SASTMhatbroken
	STMIB	r14!, {r1-r12}
	STMIB	r14, {r13,r14}^
	NOP
	SUB	r14, r14, #12*4
  |
d783 3
a786 1

d1370 4
a1373 7

  [ SASTMhatbroken
	STMIA	r14!, {r0-r12}
	STMIA	r14, {r13,r14}^
	NOP
	SUB	r14, r14, #13*4
  |
a1374 2
  ]

d1406 4
a1409 1

d1629 3
d1861 1
a1861 1
        MOVCS   ip, #1
d3036 3
@


4.1.3.1.2.1
log
@Import from 3.71 CD
@
text
@d778 4
a781 7

  [ SASTMhatbroken
	STMIB	r14!, {r1-r12}
	STMIB	r14, {r13,r14}^
	NOP
	SUB	r14, r14, #12*4
  |
d783 3
a786 1

d1370 4
a1373 7

  [ SASTMhatbroken
	STMIA	r14!, {r0-r12}
	STMIA	r14, {r13,r14}^
	NOP
	SUB	r14, r14, #13*4
  |
a1374 2
  ]

d1406 4
a1409 1

d1629 3
d1861 1
a1861 1
        MOVCS   ip, #1
d3036 3
@


4.1.1.1
log
@Import from cleaned 360 CD
@
text
@@
